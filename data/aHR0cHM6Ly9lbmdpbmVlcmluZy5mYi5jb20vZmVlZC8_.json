{
  "sourceUrl": "https://engineering.fb.com/feed/",
  "title": "Engineering at Meta",
  "description": "Engineering at Meta Blog",
  "link": "https://engineering.fb.com/",
  "items": [
    {
      "title": "Zoomer: Powering AI Performance at Meta’s Scale Through Intelligent Debugging and Optimization",
      "link": "https://engineering.fb.com/2025/11/21/data-infrastructure/zoomer-powering-ai-performance-meta-intelligent-debugging-optimization/",
      "pubDate": "Fri, 21 Nov 2025 21:00:15 +0000",
      "isoDate": "2025-11-21T21:00:15.000Z",
      "creator": "",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Zoomer: Powering AI Performance at Meta’s Scale Through Intelligent Debugging and Optimization",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>We’re introducing Zoomer, Meta’s comprehensive, automated debugging and optimization platform for AI.  Zoomer works across all of our training and inference workloads at Meta and provides deep performance insights that enable energy savings, workflow acceleration, and efficiency gains in our AI infrastructure.  Zoomer has delivered training time reductions, and significant QPS improvements, making it the [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/21/data-infrastructure/zoomer-powering-ai-performance-meta-intelligent-debugging-optimization/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/21/data-infrastructure/zoomer-powering-ai-performance-meta-intelligent-debugging-optimization/\">Zoomer: Powering AI Performance at Meta&#8217;s Scale Through Intelligent Debugging and Optimization</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Key Transparency Comes to Messenger",
      "link": "https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/",
      "pubDate": "Thu, 20 Nov 2025 17:00:21 +0000",
      "isoDate": "2025-11-20T17:00:21.000Z",
      "creator": "",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Key Transparency Comes to Messenger",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>We&#8217;re excited to share another advancement in the security of your conversations on Messenger: the launch of key transparency verification for end-to-end encrypted chats.  This new feature enables an additional level of assurance that only you — and the people you&#8217;re communicating with — can see or listen to what is sent, and that no [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/20/security/key-transparency-comes-to-messenger/\">Key Transparency Comes to Messenger</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation",
      "link": "https://engineering.fb.com/2025/11/18/open-source/efficient-optimization-ax-open-platform-adaptive-experimentation/",
      "pubDate": "Tue, 18 Nov 2025 17:00:24 +0000",
      "isoDate": "2025-11-18T17:00:24.000Z",
      "creator": "",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation",
      "images": [
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/Meta-Adaptive-Experimentation-Ax-image1.png",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/Meta-Adaptive-Experimentation-Ax-image-2.png",
          "alt": "",
          "title": "",
          "position": 2
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/Meta-Adaptive-Experimentation-Ax-image-3.png",
          "alt": "",
          "title": "",
          "position": 3
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/Meta-Adaptive-Experimentation-Ax-image-4.png",
          "alt": "",
          "title": "",
          "position": 4
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/Meta-Adaptive-Experimentation-Ax-image-5.png",
          "alt": "",
          "title": "",
          "position": 5
        },
        {
          "url": "https://s0.wp.com/latex.php?latex=argmax_%7Bx+%5Cin+X%7D+f%28x%29&bg=ffffff&fg=000&s=0&c=20201002",
          "alt": "argmax_{x \\in X} f(x)",
          "title": "",
          "position": 6
        },
        {
          "url": "https://s0.wp.com/latex.php?latex=x+%5C+in+X&bg=ffffff&fg=000&s=0&c=20201002",
          "alt": "x \\ in X",
          "title": "",
          "position": 7
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/Meta-Adaptive-Experimentation-Ax-image-6.gif?w=916",
          "alt": "",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "RSS",
      "content": "<p>We’ve released Ax 1.0, an open-source platform that uses machine learning to automatically guide complex, resource-intensive experimentation. Ax is used at scale across Meta to improve AI models, tune production infrastructure, and accelerate advances in ML and even hardware design. Our accompanying paper, &#8220;Ax: A Platform for Adaptive Experimentation&#8221; explains Ax’s architecture, methodology, and how it [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/18/open-source/efficient-optimization-ax-open-platform-adaptive-experimentation/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/18/open-source/efficient-optimization-ax-open-platform-adaptive-experimentation/\">Efficient Optimization With Ax, an Open Platform for Adaptive Experimentation</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together",
      "link": "https://engineering.fb.com/2025/11/17/connectivity/core-2africa-system-completion-future-connectivity/",
      "pubDate": "Tue, 18 Nov 2025 06:00:58 +0000",
      "isoDate": "2025-11-18T06:00:58.000Z",
      "creator": "",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Connecting Africa and the World We’re excited to share the completion of the core 2Africa infrastructure, the world&#8217;s longest open access subsea cable system. 2Africa is a landmark subsea cable system that sets a new standard for global connectivity. This project is the result of years of collaboration, innovation, and a shared vision to connect [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/17/connectivity/core-2africa-system-completion-future-connectivity/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/17/connectivity/core-2africa-system-completion-future-connectivity/\">Announcing the Completion of the Core 2Africa System: Building the Future of Connectivity Together</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Enhancing HDR on Instagram for iOS With Dolby Vision",
      "link": "https://engineering.fb.com/2025/11/17/ios/enhancing-hdr-on-instagram-for-ios-with-dolby-vision/",
      "pubDate": "Mon, 17 Nov 2025 17:30:25 +0000",
      "isoDate": "2025-11-17T17:30:25.000Z",
      "creator": "",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Enhancing HDR on Instagram for iOS With Dolby Vision",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>We’re sharing how we’ve enabled Dolby Vision and ambient viewing environment (amve) on the Instagram iOS app to enhance the video viewing experience. HDR videos created on iPhones contain unique Dolby Vision and amve metadata that we needed to support end-to-end Instagram for iOS is now the first Meta app to support Dolby Vision video, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/17/ios/enhancing-hdr-on-instagram-for-ios-with-dolby-vision/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/17/ios/enhancing-hdr-on-instagram-for-ios-with-dolby-vision/\">Enhancing HDR on Instagram for iOS With Dolby Vision</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "开源对环境有益 (原标题: Open Source Is Good for the Environment)",
      "link": "https://engineering.fb.com/2025/11/14/production-engineering/open-source-is-good-for-the-environment/",
      "pubDate": "Fri, 14 Nov 2025 20:54:14 +0000",
      "isoDate": "2025-11-14T20:54:14.000Z",
      "creator": "",
      "summary": "# 开源对环境的积极影响\n\nMeta Tech Podcast 的最新一集深入探讨了开源软件和开源硬件如何对环境产生积极影响。节目中，Pascal Hartig 与 Dharmesh 和 Lisa 进行了对话，讨论了开源硬件的方方面面，以及 Meta 在 2025 年开放计算项目 (OCP) 峰会上的主要发布。\n\n## 播客核心内容\n\n*   **主题聚焦**：节目重点介绍了开源硬件及其对环境的积极作用。\n*   **Meta 的重要发布**：在 OCP 峰会上，Meta 宣布了一项新的开放方法，该方法利用人工智能 (AI) 来理解和量化范围 3 排放（Scope 3 emissions）。\n*   **OCP 的发展**：播客回顾了开放计算项目 (OCP) 的历史，并强调了其显著增长，目前已有超过 400 家公司为其贡献力量。\n*   **Meta 的环保目标**：文章指出，AI 和开源硬件是 Meta 实现其在 2030 年达到净零排放目标的关键推动力。其中一个具体应用是利用 AI 技术开发用于数据中心建设的新型混凝土混合物，以减少环境影响。\n\n## 播客收听与互动\n\n*   **收听平台**：听众可以在 Spotify、Apple Podcasts 和 Pocket Casts 等主流播客平台找到并收听此节目。\n*   **节目宗旨**：Meta Tech Podcast 由 Meta 制作，旨在展示 Meta 工程师在各个技术层面（从底层框架到最终用户功能）所进行的创新工作。\n*   **反馈与职业机会**：听众可以通过 Instagram、Threads 或 X 向节目发送反馈。对 Meta 职业机会感兴趣的人士可以访问 Meta 招聘页面了解更多信息。\n\n## 相关图片\n\n以下是文章中包含的图片：\n\n*   ![图片 1](https://engineering.fb.com/wp-content/uploads/2025/11/MTP80_FBLI_1200_630-2-up-new.png)\n*   ![图片 2](https://engineering.fb.com/wp-content/uploads/2025/10/@Scale-Networking-Ron-Ankur-Scaling-AI-YT.png?w=580&h=326&crop=1)\n*   ![图片 3](https://engineering.fb.com/wp-content/uploads/2025/10/@Scale-Networking-Mark-Alberto-10x-Backbone-YT.png?w=580&h=326&crop=1)\n*   ![图片 4](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-data-center-interior-Hero-2.jpg?w=580&h=326&crop=1)\n*   ![图片 5](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-data-center-interior-Hero-1.jpg?w=580&h=326&crop=1)\n*   ![图片 6](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OCP-2025-NSF-1.png?w=580&h=326&crop=1)\n*   ![图片 7](https://engineering.fb.com/wp-content/uploads/2025/09/CL2_7019-copy.png?w=580&h=326&crop=1)",
      "shortSummary": "Meta Tech Podcast 探讨了开源软件和硬件如何对环境产生积极影响。节目介绍了 Meta 在 2025 年 OCP 峰会上的重要发布，包括利用 AI 理解范围 3 排放的新开放方法。文章强调了 AI 和开源硬件如何帮助 Meta 在 2030 年实现净零排放，例如利用 AI 开发数据中心建设所需的新型混凝土。开放计算项目 (OCP) 现已发展到有 400 多家公司贡献。",
      "translated_title": "开源对环境有益",
      "images": [
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/11/MTP80_FBLI_1200_630-2-up-new.png",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/@Scale-Networking-Ron-Ankur-Scaling-AI-YT.png?w=580&h=326&crop=1",
          "alt": "",
          "title": "",
          "position": 2
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/@Scale-Networking-Mark-Alberto-10x-Backbone-YT.png?w=580&h=326&crop=1",
          "alt": "",
          "title": "",
          "position": 3
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-data-center-interior-Hero-2.jpg?w=580&h=326&crop=1",
          "alt": "",
          "title": "",
          "position": 4
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-data-center-interior-Hero-1.jpg?w=580&h=326&crop=1",
          "alt": "",
          "title": "",
          "position": 5
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OCP-2025-NSF-1.png?w=580&h=326&crop=1",
          "alt": "",
          "title": "",
          "position": 6
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/09/CL2_7019-copy.png?w=580&h=326&crop=1",
          "alt": "",
          "title": "",
          "position": 7
        }
      ],
      "contentSource": "完整文章",
      "content": "<p>Most people have heard of open-source software. But have you heard about open hardware? And did you know open source can have a positive impact on the environment? On this episode of the Meta Tech Podcast, Pascal Hartig sits down with Dharmesh and Lisa to talk about all things open hardware, and Meta’s biggest announcements [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/14/production-engineering/open-source-is-good-for-the-environment/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/14/production-engineering/open-source-is-good-for-the-environment/\">Open Source Is Good for the Environment</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "StyleX：大规模CSS样式库 (原标题: StyleX: A Styling Library for CSS at Scale)",
      "link": "https://engineering.fb.com/2025/11/11/web/stylex-a-styling-library-for-css-at-scale/",
      "pubDate": "Tue, 11 Nov 2025 17:58:20 +0000",
      "isoDate": "2025-11-11T17:58:20.000Z",
      "creator": "",
      "summary": "# StyleX：大规模CSS样式库\n\nStyleX 是 Meta 针对大规模应用开发的样式系统，旨在结合 CSS-in-JS 的人体工程学优势与静态 CSS 的高性能。它通过在构建时生成无冲突的原子 CSS，同时支持富有表现力且类型安全的样式编写。\n\n## 核心概述与发展\n\n*   **发布与采纳**：StyleX 于 2023 年底开源，现已成为 Meta 旗下产品（如 Facebook、Instagram、WhatsApp、Messenger 和 Threads）以及外部公司（如 Figma 和 Snowflake）的标准样式系统。\n*   **核心机制**：StyleX 本质上是一个编译器，在构建时提取样式并生成静态样式表。它也是一种理念，为大规模 CSS 的编写、共享和维护提供了一个框架。\n*   **解决的问题**：\n    *   Meta 早期在处理大规模 CSS 时面临诸多挑战，包括跨捆绑包的样式冲突、样式表依赖管理困难、特异性冲突（specificity wars）以及大型 CSS 捆绑包导致的性能问题（浏览器下载大量未使用的规则）。\n    *   早期的解决方案 `cx`（类似 CSS Modules）解决了命名空间冲突和依赖管理，但仍限于静态样式文件。\n    *   CSS-in-JS 运动兴起，开发者希望将样式与组件代码并置，编写基于运行时状态的动态样式。然而，早期的 CSS-in-JS 系统依赖运行时注入，引入了性能开销。\n*   **StyleX 的创新**：StyleX 吸取了 CSS-in-JS 的经验，但其样式会编译成静态 CSS，避免了运行时性能问题。它取代了 `cx` 系统，实现了样式在 JavaScript 中定义，支持组合、条件逻辑和构建时编译。这使得 CSS 大小减少了 80%，并显著提高了代码库的可维护性。\n\n## 编译器深入解析\n\nStyleX 的强大之处在于其抽象能力。它自动处理 CSS 特异性、变量生成和静态编译，从而生成可预测、无冲突的原子 CSS，让开发者专注于样式编写。\n\n*   **架构**：StyleX 是一个由多个集成包组成的 Monorepo。核心引擎是一个 Babel 插件，负责在项目上运行转换，提取 CSS。\n*   **编译流程**：\n    1.  编译器遍历文件，从样式对象中提取 CSS 元数据。\n    2.  将样式声明转换为原子 CSS 类。\n    3.  收集到的元数据经过值规范化、`@rules` 包装和旧版 polyfill 处理。\n    4.  最后，CSS 规则被排序并输出到静态样式表。\n\n## StyleX 的核心价值\n\n### 1. 可扩展性 (Scalability)\n\n*   **原子 CSS 编译**：StyleX 的核心是将其样式静态编译为原子 CSS。样式被转换为包含单个样式声明的类，以便在整个代码库中重用，从而使 CSS 大小随着应用程序的增长而趋于稳定。\n*   **构建时优化**：样式尽可能在构建时编译和缓存，系统可以分析所有可达样式，去重共享声明，并仅在运行时输出所需内容。\n*   **轻量级 API**：\n    *   `stylex.create()`：用于定义样式对象。这些对象在构建时被剥离，并转换为原子 CSS。每个 `property: value` 对都被哈希并输出为 CSS 类。此 API 专为可缓存性设计，只允许静态可解析的值。\n    *   `stylex.props()`：处理样式对象的合并和去重。每次调用都会被转译为一个对象，其中包含一个对应于每个原子样式的空格分隔的 `className` 字符串，以及一个用于动态样式的 `style` 属性。\n*   **编译示例**：\n    ```javascript\n    // 原始组件\n    import * as stylex from '@stylexjs/stylex';\n    const styles = stylex.create({\n      foo: { margin: 10 },\n      bar: { margin: 10, color: 'red' }\n    });\n    function MyComponent({style}) {\n      return (\n        <>\n          <div {...styles.props(styles.foo)}/>\n          <div {...styles.props(styles.bar)}/>\n          <div {...stylex.props(style)}/>\n        </>\n      )\n    }\n\n    // 编译后（简化）\n    import * as stylex from '@stylexjs/stylex';\n    function MyComponent({style}) {\n      return (\n        <>\n          <div className=\"m-10\" />\n          <div className=\"c-red m-10\" />\n          <div {...stylex.props(style)}/>\n        </>\n      )\n    }\n    // 对应的静态 CSS\n    .m-10 { margin: 10px }\n    .c-red { color: red }\n    ```\n*   **后处理**：转换完成后，系统会处理收集到的元数据，生成 LTR/RTL 变体，解析常量，并按优先级排序 CSS 规则，最终输出为静态样式表。\n\n### 2. 表现力 (Expressiveness)\n\nStyleX 将约束视为设计原则而非限制，禁止容易冲突的模式（如远距离样式），并强制执行静态可解析的模式。\n\n*   **可共享的值**：\n    *   `stylex.create()` 专为文件级可缓存性设计。\n    *   `stylex.defineVars()` 和 `stylex.defineConsts()`：提供 API 以在文件间重用值。它们根据变量名和导入路径生成确定性哈希，确保跨模块一致性。构建时，共享常量会被完全内联，而共享变量则成为可在组件间引用的全局 CSS 自定义属性。\n*   **样式封装**：StyleX 是一个组件样式系统，通过直接在元素上应用局部类名来避免全局样式。它禁止全局和复杂选择器，以防止远距离样式（即间接影响 DOM 中其他元素的规则），并促进样式封装。全局基线规则（如元素选择器或 CSS 重置）必须在单独的样式表中定义。\n*   **远距离观察 (Observing from a Distance)**：通过 `stylex.when` API，StyleX 允许使用关系选择器根据祖先、后代或兄弟元素的状态来样式化组件。被观察的元素必须使用 `stylex.defaultMarker()` 标记，以确保样式直接应用同时支持上下文行为。\n*   **保留 CSS 特性**：StyleX 通过构建时的静态转换保留了大部分 CSS 特性（媒体查询、伪类、关键帧等），尽可能模拟原生 CSS 行为。\n*   **动态样式支持**：当值在构建时未知时，编译器会发出 CSS 变量引用，运行时通过 `style` 属性将其内联写入。\n*   **主题化 API**：\n    *   `stylex.defineVars()`：创建变量分组。\n    *   `stylex.createTheme()`：通过在更高特异性下重新定义变量组来创建主题变体。\n*   **动画支持**：`stylex.keyframes()` 和 `stylex.viewTransitionClass()` API 支持动画，生成 `@keyframes` 和 `::view-transition-*` 规则。\n\n### 3. 可预测性 (Predictability)\n\nStyleX 的设计围绕可预测的样式合并展开：“最后一个样式总是胜出！”\n\n*   **确定性合并**：`stylex.props` 函数被视为样式对象的确定性合并：`stylex.props(styles.foo, styles.bar)` 中，`bar` 总是覆盖 `foo`。这使得跨文件共享和组合样式变得可预测。\n*   **CSS 特异性处理**：由于 StyleX 完全基于类，解决样式对象之间的冲突意味着确定要应用哪些类名并强制执行它们之间的优先级。在合并过程中，样式对象中重复的属性会被去重，只应用最后一个值。\n*   **优先级计算**：StyleX 为每个 CSS 规则计算一个数值优先级。这些优先级与用户配置的 `styleResolution` 一起，通过 `@layer` at-rule 或等效的 polyfill 来确定每个类选择器的特异性。\n*   **结果**：长手属性和短手属性可预测地合并，`:active` 状态覆盖 `:hover` 状态，媒体查询覆盖默认行为，并在可能的情况下尊重用户编写的顺序。这种幕后的特异性处理允许开发者组合和重用样式，而无需手动解决冲突。\n\n## 未来展望\n\nStyleX 由一群 CSS 爱好者维护，旨在让样式对所有人可用。\n\n*   **Monorepo 工具**：除了编译器，Monorepo 还包括 ESLint 插件（用于样式验证）、CLI（用于轻松生成样式表）、PostCSS 插件（用于后处理）和一个实验性的 CSS 解析器。\n*   **社区贡献**：开源社区在 StyleX 的发展方向上发挥了关键作用，贡献了社区构建的 Playground、VS Code 扩展、SWC 编译器、多个捆绑器集成等。\n*   **路线图亮点**：包括可共享函数 API、LLM 就绪的上下文文件、内联样式支持、开发者扩展、严格的编译器验证、逻辑样式工具等。",
      "shortSummary": "StyleX 是 Meta 开源的大规模应用样式系统，结合了 CSS-in-JS 的人体工程学和静态 CSS 的高性能。它通过构建时编译生成无冲突的原子 CSS，支持类型安全和富有表现力的样式编写。StyleX 解决了传统 CSS 的可扩展性、维护性和性能问题，通过其编译器实现样式封装、可预测的合并和高效的 CSS 输出。它已成为 Meta 产品及多家外部公司的标准，并持续通过社区贡献和路线图规划进行发展。",
      "translated_title": "StyleX：大规模CSS样式库",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>StyleX is Meta’s styling system for large-scale applications. It combines the ergonomics of CSS-in-JS with the performance of static CSS, generating collision-free atomic CSS while allowing for expressive, type-safe style authoring. StyleX was open sourced at the end of 2023 and has since become the standard styling system across Meta products like Facebook, Instagram, WhatsApp, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/11/web/stylex-a-styling-library-for-css-at-scale/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/11/web/stylex-a-styling-library-for-css-at-scale/\">StyleX: A Styling Library for CSS at Scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Meta的生成式广告模型（GEM）：加速广告推荐AI创新的核心大脑 (原标题: Meta’s Generative Ads Model (GEM): The Central Brain Accelerating Ads Recommendation AI Innovation)",
      "link": "https://engineering.fb.com/2025/11/10/ml-applications/metas-generative-ads-model-gem-the-central-brain-accelerating-ads-recommendation-ai-innovation/",
      "pubDate": "Mon, 10 Nov 2025 17:00:01 +0000",
      "isoDate": "2025-11-10T17:00:01.000Z",
      "creator": "",
      "summary": "Meta的生成式广告模型（GEM）：加速广告推荐AI创新的核心大脑\n\nMeta推出了其生成式广告推荐模型（GEM），这是一个基于大型语言模型（LLM）启发的新型基础模型，旨在通过增强现有广告推荐模型的能力来提供更相关的广告，从而显著提升广告效果和广告商的投资回报率（ROI）。GEM的创新架构使其能够随着参数数量的增加而高效扩展，并持续生成更精确的预测。\n\n**GEM的核心目标与成果**\n\n*   **提升广告性能与ROI：** GEM通过优化广告推荐，已在Instagram和Facebook上显著提升了广告转化率。\n*   **行业领先：** 它是目前业界规模最大的推荐系统（RecSys）基础模型，训练规模与大型语言模型相当。\n*   **实际效果：** 自今年早些时候推出以来，GEM在第二季度为Instagram带来了5%的广告转化率增长，为Facebook Feed带来了3%的增长。第三季度，模型架构的改进使相同数据和计算量下的性能效益翻倍。\n\n**GEM的三大关键创新**\n\nGEM通过以下三个核心创新，在推荐系统领域取得了重大进展：\n\n1.  **采用先进架构的模型扩展**\n    *   **挑战与应对：** Meta的广告推荐系统面临处理庞大且动态的特征空间、多样化的数据类型（广告主目标、创意格式、用户行为等）以及高效训练大规模模型的挑战。GEM通过其可扩展的架构克服了这些问题。\n    *   **可扩展的模型架构：** GEM的架构在给定数据和计算量下，驱动广告性能提升的效率比Meta原始的广告推荐排序模型高出4倍。它通过定制的注意力机制和跨特征学习，处理广告内容和用户互动数据（包括序列特征和非序列特征）。\n    *   **非序列特征交互建模：** 增强了Wukong架构，利用带有跨层注意力连接的可堆叠分解机，以学习最重要的特征组合。\n    *   **离线序列特征建模：** 采用金字塔并行结构，高效处理长达数千个事件的用户行为序列，从而从更长的用户互动历史中学习。\n    *   **跨特征学习（InterFormer）：** 采用并行摘要和交错结构，在序列学习和跨特征交互层之间交替，在保留完整序列信息的同时实现高效的跨特征学习。\n    *   **多领域学习与领域特定优化：** GEM能够从跨平台用户互动中学习，同时确保预测针对Facebook、Instagram和商业消息等不同Meta平台的独特特性进行优化。\n\n2.  **优化知识转移的后训练技术**\n    *   **知识转移的重要性：** GEM的知识必须高效地转移到数百个面向用户的垂直模型（VMs）中，才能产生实际影响。GEM采用直接和分层知识转移策略，并结合多种技术实现这一目标。\n    *   **知识蒸馏：** 通过使用“学生适配器”组件，利用最新的真实数据来优化教师模型（GEM）的输出，解决VMs中因延迟和领域不匹配导致的监督信号过时问题，使学生模型获得更及时和相关的监督。\n    *   **表示学习：** 自动从原始数据中提取有意义且紧凑的特征，支持教师模型到学生模型的知识高效转移，且不增加推理开销。\n    *   **参数共享：** 允许多个模型或组件重用相同的参数集，减少冗余，提高效率，并使较小的、对延迟敏感的VMs能够利用基础模型（FMs）丰富的表示和预学习模式，而无需承担其全部计算成本。\n\n3.  **增强的训练基础设施以支持可扩展性**\n    *   **训练规模与效率提升：** GEM的训练规模与现代LLM相当，Meta为此彻底改造了训练方案。重新设计的训练堆栈使有效训练FLOPs增加了23倍，同时使用16倍的GPU，硬件效率（MFU）提高了1.43倍。\n    *   **分布式训练：** 针对模型的密集部分采用混合分片分布式并行（HSDP），优化内存使用和通信成本；针对稀疏组件（如大型嵌入表）采用二维数据并行和模型并行方法。\n    *   **GPU吞吐量的系统级优化：** 实施了一系列技术以饱和GPU计算吞吐量并减少训练瓶颈，包括定制的内部GPU内核、PyTorch 2.0的图级编译、内存压缩技术（如FP8量化）以及不占用SM资源的GPU通信集合（NCCLX）。\n    *   **减少训练开销和作业启动时间：** 通过优化训练器初始化、数据读取器设置、检查点和PyTorch 2.0编译时间等，将作业启动时间缩短了5倍（PyTorch 2.0编译时间通过缓存策略缩短了7倍），从而提高了训练敏捷性。\n    *   **最大化开发生命周期中的GPU效率：** 在模型生命周期的所有阶段（从早期实验到大规模训练和后训练）都优化了GPU效率，例如在探索阶段使用轻量级模型变体加速迭代，并进行持续的在线训练以刷新基础模型。\n\n**GEM的未来展望**\n\nGEM的推出标志着Meta在广告推荐AI领域迈出了重要一步，通过持续的架构改进和训练优化，Meta将能够以更具吸引力的投资回报率继续扩展GEM的训练能力，进一步提升广告效果和用户体验。",
      "shortSummary": "Meta推出了生成式广告模型（GEM），这是一个基于LLM启发的新型基础模型，旨在通过增强广告推荐能力，提升广告效果和广告商投资回报率。GEM采用创新架构，实现了高效扩展和精准预测，并在Instagram和Facebook上显著提升了广告转化率（Q2分别增长5%和3%）。它通过先进的架构、后训练知识转移技术和优化的训练基础设施，克服了处理大规模、多样化广告数据的挑战，推动了Meta广告推荐系统的范式转变。",
      "translated_title": "Meta的生成式广告模型（GEM）：加速广告推荐AI创新的核心大脑",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>We’re sharing details about Meta’s Generative Ads Recommendation Model (GEM), a new foundation model that delivers increased ad performance and advertiser ROI by enhancing other ads recommendation models’ ability to serve relevant ads. GEM’s novel architecture allows it to scale with an increasing number of parameters while consistently generating more precise predictions efficiently. GEM propagates [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/10/ml-applications/metas-generative-ads-model-gem-the-central-brain-accelerating-ads-recommendation-ai-innovation/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/10/ml-applications/metas-generative-ads-model-gem-the-central-brain-accelerating-ads-recommendation-ai-innovation/\">Meta’s Generative Ads Model (GEM): The Central Brain Accelerating Ads Recommendation AI Innovation</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "视频隐形水印的规模化应用 (原标题: Video Invisible Watermarking at Scale)",
      "link": "https://engineering.fb.com/2025/11/04/video-engineering/video-invisible-watermarking-at-scale/",
      "pubDate": "Tue, 04 Nov 2025 18:00:52 +0000",
      "isoDate": "2025-11-04T18:00:52.000Z",
      "creator": "",
      "summary": "Meta公司在其平台上广泛应用隐形水印技术，以解决多种内容溯源问题。这项技术能够检测AI生成视频、验证视频首发者，并识别视频的来源和创作工具。\n\n### 什么是隐形水印？\n隐形水印是一种强大的媒体处理技术，它以人眼无法察觉的方式将信号嵌入到媒体中，但软件可以检测到。它通过巧妙地修改图像的像素值、音频的波形或大型语言模型（LLM）生成的文本标记来嵌入少量数据。与可能丢失的元数据标签不同，水印系统通过添加必要的冗余来确保嵌入的标识在转码和编辑后依然持久存在。\n\n### 隐形水印的应用场景\n1.  **谁首先发布了视频？** 隐形水印可以帮助识别视频的首次上传者，解决内容归属问题。\n2.  **内容是否由AI生成？** 随着生成式AI（GenAI）视频的日益逼真，区分真实和AI生成内容变得越来越困难。隐形水印可用于推断内容是否为AI生成。\n3.  **使用了什么工具创作？** 隐形水印可以直接推断出图像或视频的来源和创作工具。\n\n传统方法如可见水印（分散注意力）或元数据标签（编辑或重新编码时可能丢失）无法充分且稳健地解决这些挑战。隐形水印因其持久性和不可察觉性，提供了一种更优越的替代方案。\n\n### 隐形水印与相关概念的对比\n| 特征         | 数字水印           | 隐写术             | 隐形水印           |\n| :----------- | :----------------- | :----------------- | :----------------- |\n| **目的**     | 内容归属、保护、溯源 | 秘密通信           | 内容归属、保护、溯源 |\n| **可见性**   | 可见或不可见       | 不可见             | 不可见             |\n| **鲁棒性**   | 中到高             | 通常低             | 高（可抵抗编辑）   |\n| **载荷容量** | 中（可变）         | 可变               | 中（例如，>64位）  |\n| **计算成本** | 低（可见）到高（不可见） | 可变               | 高（高级机器学习模型） |\n\n### 规模化挑战与GPU到CPU的转变\n早期的数字水印研究（始于20世纪90年代）主要采用数字信号处理技术。然而，这些方法对社交媒体中常见的几何变换和过滤不够鲁棒。当前最先进的解决方案（如VideoSeal）使用机器学习（ML）技术，显著提高了鲁棒性。但将这些解决方案应用于视频领域（即逐帧水印）可能因计算成本过高而难以实现，除非进行必要的推理优化。\n\n尽管GPU似乎是部署基于ML的视频水印解决方案的显而易见的方案，但大多数GPU硬件专门用于大规模模型的训练和推理，对视频转码（压缩和解压缩）的支持有限或没有。这给Meta现有的视频处理软件（FFmpeg）和硬件堆栈带来了独特的挑战。\n\n**GPU优化尝试及转向CPU：**\nMeta的嵌入架构使用FFmpeg与自定义过滤器来计算和应用隐形水印掩码。在GPU上进行性能分析发现GPU利用率较低。即使实施了帧批处理和线程化，延迟或利用率也没有显著改善。主要瓶颈包括：\n*   **数据传输开销：** CPU与多个GPU之间高分辨率视频帧的来回传输导致线程和内存优化困难，GPU利用率不佳。\n*   **推理延迟：** 在同一主机上并行处理多个GPU上的隐形水印请求导致推理延迟显著增加。\n*   **模型加载时间：** 尽管模型尺寸小，但加载模型占用了总处理时间的很大一部分。依赖FFmpeg使得无法使用GPU上预加载的、已预热的模型。\n\n认识到这些限制后，Meta开始研究纯CPU推理方案。虽然初始基准测试显示CPU上的端到端（E2E）性能慢两倍以上，但通过调整编码器、解码器和PyTorch的线程参数，并优化隐形水印过滤器使用的采样参数，他们取得了显著改进。最终，经过适当调整的线程和嵌入参数，在单个进程中CPU上运行隐形水印的E2E延迟与GPU性能相差不到5%。更重要的是，他们可以在CPU上并行运行多个FFmpeg进程而不会增加延迟。这一突破使得他们能够以更高的运营效率部署解决方案。\n\n### 优化考量与权衡\n规模化部署隐形水印涉及在以下四个指标之间进行权衡：\n*   **延迟：** 水印处理的速度。\n*   **水印检测位准确性：** 检测嵌入水印的准确性。\n*   **视觉质量：** 确保嵌入的水印对人眼不可察觉。\n*   **压缩效率（通过BD-Rate衡量）：** 确保嵌入的水印不会显著增加比特率。\n\n优化一个指标可能会对其他指标产生负面影响。例如，更强的水印可能会提高位准确性，但可能导致可见伪影和比特率增加。\n\n**管理BD-Rate影响：** 隐形水印会引入熵，可能导致视频编码器产生更高的比特率。Meta的初始实现显示BD-Rate回归约20%。为缓解此问题，他们设计了一种新颖的帧选择水印方法，大大降低了BD-Rate影响，同时提高了视觉质量并最大限度地减少了水印位检测准确性的影响。\n\n**解决视觉质量回归：** 确保“隐形”水印真正隐形至关重要。尽管高质量指标得分（VMAF和SSIM）很高，但他们最初观察到明显的视觉伪影。通过实施自定义后处理技术和众包人工检查不同嵌入设置，他们解决了视觉质量问题。事实证明，传统视觉质量指标不足以检测隐形水印可能引入的伪影类型，因此主观评估至关重要。在调整算法以实现人眼不可见性的同时，他们密切监测了位准确性影响，以实现视觉质量和检测准确性之间的最佳平衡。\n\n### 经验教训与未来展望\n1.  **CPU效率：** 经过适当优化，纯CPU流水线在特定用例中可以达到与GPU流水线相当的性能，且成本更低。CPU为隐形水印系统提供了更具运营效率和可扩展性的解决方案。\n2.  **传统视频质量分数不足：** VMAF和SSIM等指标无法完全捕捉隐形水印引入的感知质量问题，需要人工检查。需要更多研究来开发一种能够以编程方式检测隐形水印造成的视觉质量损失的指标。\n3.  **生产质量标准高：** 水印技术可能因对BD-Rate和下游视频压缩的影响而无法直接应用于实际用例。需要扩展现有文献，以在保持卓越位准确性的同时，将BD-Rate影响降至最低。\n\nMeta已成功推出一个可扩展的水印解决方案，具有出色的延迟、视觉质量、检测位准确性和最小的BD-Rate影响。未来，他们将继续提高隐形水印检测的精度和复制检测召回率，并设想将隐形水印作为一个轻量级的“过滤器模块”，无缝集成到各种视频用例中，对用户体验影响最小，同时提供强大的内容溯源能力。",
      "shortSummary": "Meta公司已成功规模化部署隐形水印技术，用于内容溯源，包括检测AI生成视频、验证首发者和识别创作工具。该技术通过微妙修改媒体数据实现人眼不可察觉的嵌入。面对GPU在视频转码上的局限性，Meta通过优化FFmpeg和PyTorch参数，开发出CPU-based解决方案，其端到端性能与GPU相当，但运营效率更高。该方案在延迟、检测准确性、视觉质量和压缩效率（BD-Rate）之间取得了平衡，并通过人工检查解决了传统质量指标的不足，实现了鲁棒且高效的视频内容溯源。",
      "translated_title": "视频隐形水印的规模化应用",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>At Meta, we use invisible watermarking for a variety of content provenance use cases on our platforms. Invisible watermarking serves a number of use cases, including detecting AI-generated videos, verifying who posted a video first, and identifying the source and tools used to create a video. We&#8217;re sharing how we overcame the challenges of scaling [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/11/04/video-engineering/video-invisible-watermarking-at-scale/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/11/04/video-engineering/video-invisible-watermarking-at-scale/\">Video Invisible Watermarking at Scale</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "为生成式AI产品创新扩展隐私基础设施 (原标题: Scaling Privacy Infrastructure for GenAI Product Innovation)",
      "link": "https://engineering.fb.com/2025/10/23/security/scaling-privacy-infrastructure-for-genai-product-innovation/",
      "pubDate": "Thu, 23 Oct 2025 08:00:00 +0000",
      "isoDate": "2025-10-23T08:00:00.000Z",
      "creator": "",
      "summary": "# Meta为生成式AI产品创新扩展隐私基础设施\n\nMeta致力于赋能其产品团队负责任地利用生成式AI（GenAI）的力量。本文深入探讨了Meta如何通过扩展其**隐私感知基础设施（Privacy Aware Infrastructure, PAI）**来应对GenAI时代的数据保护挑战，并以Meta的AI眼镜作为GenAI用例的典范。Meta的目标是通过赋能产品团队获得血缘洞察和自动化隐私控制，加速GenAI产品创新，同时将用户信任和隐私作为基本原则。\n\n## GenAI面临的关键隐私挑战\n\nMeta在确保GenAI隐私方面遇到了三大主要挑战：\n\n*   **技术演进与数据爆炸式增长：** GenAI带来了新型数据类型和数据量的急剧增加，使得数据可观测性和管理变得更加复杂。\n*   **不断变化的合规要求：** 技术进步不断产生新的隐私和合规要求，Meta的竞争力取决于其适应这些需求的速度。\n*   **加速的创新周期：** GenAI驱动的功能加速了产品开发， necessitating infrastructure that can scale rapidly and enforce privacy controls automatically.\n\n## Meta AI眼镜：GenAI用例示例\n\nMeta的AI眼镜将可穿戴技术与GenAI结合，提供实时信息、个性化辅助和创意功能，所有这些都与佩戴者的环境相关联：\n\n*   **实时场景理解：** 利用先进的摄像头和传感器解释周围环境，实现即时、相关的问答。\n*   **情境叠加：** GenAI模型提供动态叠加和摘要，根据当前位置或活动提供量身定制的指导和信息。\n*   **自然直观的交互：** 通过Meta神经腕带等创新输入方法和Meta Ray-Ban显示眼镜中的先进输出技术，实现无缝、低延迟的全双工对话。\n\n这些前瞻性用例凸显了GenAI所实现的复杂数据流：连续的传感器输入、设备端和云端的实时处理，以及动态的用户反馈循环。\n\n## Meta隐私感知基础设施（PAI）概述\n\nMeta的PAI是其隐私策略的核心，它是一套基础设施服务、API和监控系统，旨在将隐私集成到产品开发的各个方面。PAI包括：\n\n*   **增强的可观测性：**\n    *   通过高级扫描和标记实现数据自动检测，识别摄取点处的相关数据。\n    *   通过数据血缘追踪进一步加强，维护数据来源、传播路径和使用情况的实时地图，提供数据在系统间流动的全面可见性。\n*   **高效的隐私控制：**\n    *   策略执行API，用于在数据存储、处理和访问层以编程方式强制执行隐私约束。\n    *   策略自动化，将区域和全球要求嵌入到自动化检查和工作流约束中。\n*   **可扩展性：** 支持Meta庞大生态系统中的数千个微服务和产品团队。\n\nPAI赋能工程师在创新的同时，自动确保策略合规性和安全性。\n\n### 图示：AI眼镜与Meta AI应用的系统上下文\n\n![图片 1](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-1.png)\n图1：AI眼镜与Meta AI应用交互的系统上下文。\n\n### 图示：关键隐私工作流\n\n![图片 2](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-2.png)\n图2：关键隐私工作流。\n\n## 深入探究PAI的“发现”阶段：大规模数据血缘\n\nPAI最具变革性的技术之一是其大规模数据血缘方法。该系统持续追踪和映射整个基础设施中的数据流。Meta的血缘解决方案必须跨越数百万数据和代码资产，涵盖数百个平台和多种编程语言。\n\n### 收集跨栈血缘以获取交互数据\n\n为了维护数据（例如AI眼镜的用户交互数据）的隐私要求，需要一个完整的数据移动图谱。跨栈血缘提供了这种可追溯性：\n\n*   **[A] 在Web内部：** 通过隐私探测器捕获交互数据进入Meta Web服务器以及Web组件之间的数据流，精确了解数据的收集和处理方式。\n*   **[B] Web -> 记录器 -> 数据仓库：** 当Web处理持久化数据时，血缘追踪写入数据仓库表的记录器。然后，在下游批量处理数据时，解析记录器配置、SQL查询和处理日志以提取数据血缘。\n*   **[C] Web <> 推理：** 对于大型语言模型（LLM）调用，在服务/RPC边界收集血缘信号，例如调用了哪些模型检查点、输入是什么以及返回给应用的响应是什么。\n*   **[D] 数据仓库 -> 训练：** 最后，血缘将数据仓库表链接到训练作业及其生成的检查点。这个边界可以强制执行和证明关于允许用途的隐私要求。\n\n### 图示：跨栈血缘\n\n![图片 3](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-3.png)\n图3：跨栈血缘。PAI收集所有堆栈的血缘信号，包括Web探测、记录器、批量处理血缘、RPC血缘和训练清单。它们共同构成了交互数据的端到端图。\n\n### 图示：AI眼镜交互的端到端血缘\n\n![图片 4](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-4.png)\n图4：AI眼镜交互的端到端血缘。通过这种可见性，Meta可以具体地推断隐私：精确知道哪些系统参与了，哪些没有，从而在边界强制执行数据流并证明策略合规性。\n\n### 构建全面的血缘可观测性\n\n一个健全的血缘可观测性系统必须全面捕获数据处理时所有实际的数据流或I/O操作：\n\n*   **捕获并链接所有读取操作到写入操作：** 写入数据资产时，确保使用与读取操作相同的关联键记录所有相关的写入操作。这适用于SQL和非SQL查询，以及分布式I/O操作。\n*   **创建通用隐私库以记录数据流信息：** Meta的隐私库（PrivacyLib）旨在初始化和传播隐私策略，为各种操作（如读取、写入、远程调用）提供通用抽象，并标准化日志记录等扩展。\n*   **在Meta所有相关数据系统中放置库集成点：** 该库已集成到所有相关数据系统，以各种编程语言实现，并确保全面覆盖I/O操作。\n\n### 图示：通过PrivacyLib构建血缘可观测性\n\n![图片 5](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-5.png)\n图5：通过PrivacyLib构建血缘可观测性。\n\n## 从血缘到AI眼镜的证明\n\n数据血缘揭示了哪些系统处理AI眼镜的交互数据。基于此，Meta可以保护数据：\n\n*   **使用血缘指导策略区域（Policy Zones）的放置**，以保护交互数据。\n*   **仅当所有训练数据资产都允许用于特定目的时**，才启动使用该区域数据资产的模型训练作业；否则，进行补救。\n*   **验证器持续监控这些边界**，以便在功能开发早期识别任何新增或更改的数据处理作业。\n\n### 图示：通过策略区域从血缘到证明\n\n![图片 6](https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-6.png)\n图6：通过策略区域从血缘到证明。\n\n## 关键要点：PAI如何扩展GenAI隐私\n\nMeta的隐私方法是：扩展基础设施，而不仅仅是规则。通过将包括数据血缘在内的PAI技术嵌入到技术栈中，Meta赋能工程师安全、快速、全球化地交付下一波GenAI产品。\n\n*   GenAI及其驱动产品的飞速发展带来了新的隐私和策略挑战，需要快速开发隐私感知基础设施。\n*   隐私感知基础设施（PAI）提供可重用的工作流（理解 -> 发现 -> 执行 -> 证明），同样可以扩展GenAI产品的隐私执行。\n*   可扩展的数据血缘技术通过提供可审计的实时数据流洞察，促进隐私控制。\n*   自动防护措施和即时开发反馈帮助产品团队更快、更安全、更顺畅地推进。\n\n## 随着GenAI发展，隐私也在发展\n\n为GenAI扩展隐私是一个持续的旅程。随着AI能力的进步，隐私保护的复杂性和期望也在增加。Meta的PAI正在同步发展，整合更智能的血缘分析和更友好的开发者工具，以满足这些新需求。通过将隐私基础设施作为产品赋能者而非障碍，Meta正在为负责任的AI产品创新奠定基础。",
      "shortSummary": "Meta通过扩展其隐私感知基础设施（PAI）来负责任地推动生成式AI（GenAI）产品创新。PAI通过大规模数据血缘追踪、自动化隐私控制和增强的可观测性，应对GenAI带来的数据隐私挑战。以Meta AI眼镜为例，PAI确保数据从收集到训练的整个生命周期都符合隐私要求。其核心理念是扩展基础设施而非仅规则，从而赋能产品团队更快、更安全地开发新功能，同时维护用户信任和数据隐私。",
      "translated_title": "为生成式AI产品创新扩展隐私基础设施",
      "images": [
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-1.png",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-2.png",
          "alt": "",
          "title": "",
          "position": 2
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-3.png",
          "alt": "",
          "title": "",
          "position": 3
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-4.png",
          "alt": "",
          "title": "",
          "position": 4
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-5.png",
          "alt": "",
          "title": "",
          "position": 5
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/10/Meta-PAI-for-GenAI-Figure-6.png",
          "alt": "",
          "title": "",
          "position": 6
        }
      ],
      "contentSource": "完整文章",
      "content": "<p>How does Meta empower its product teams to harness GenAI’s power responsibly? In this post, we delve into how Meta addresses the challenges of safeguarding data in the GenAI era by scaling its Privacy Aware Infrastructure (PAI), with a particular focus on Meta’s AI glasses as an example GenAI use case.  We’ll describe in detail [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/23/security/scaling-privacy-infrastructure-for-genai-product-innovation/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/23/security/scaling-privacy-infrastructure-for-genai-product-innovation/\">Scaling Privacy Infrastructure for GenAI Product Innovation</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    }
  ],
  "lastUpdated": "2025-12-15T05:32:59.790Z"
}
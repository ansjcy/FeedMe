{
  "sourceUrl": "https://engineering.fb.com/feed/",
  "title": "Engineering at Meta",
  "description": "Engineering at Meta Blog",
  "link": "https://engineering.fb.com/",
  "items": [
    {
      "title": "可持续性设计：降低IT硬件排放的新设计原则 (原标题: Design for Sustainability: New Design Principles for Reducing IT Hardware Emissions)",
      "link": "https://engineering.fb.com/2025/10/14/data-center-engineering/design-for-sustainability-new-design-principles-for-reducing-it-hardware-emissions/",
      "pubDate": "Tue, 14 Oct 2025 20:40:20 +0000",
      "isoDate": "2025-10-14T20:40:20.000Z",
      "creator": "",
      "summary": "## 可持续性设计：降低IT硬件排放的新设计原则\n\nMeta公司提出了“可持续性设计”原则，这是一套针对IT硬件新设计的技术设计原则，旨在通过重用、延长使用寿命和优化设计来减少排放和成本。Meta已通过整合模块化、重用、改造、去物质化、使用更环保材料以及延长硬件生命周期等多种设计策略，显著降低了其数据中心的碳足迹，并呼吁更广泛的行业采纳这些策略以实现可持续发展目标。\n\n### Meta的可持续发展目标与关注点\n\n*   **净零排放目标**：Meta致力于在2030年实现整个价值链的净零排放。\n*   **关注Scope 3排放**：主要关注来自数据中心建设、IT硬件（计算、存储、冷却设备）和网络光纤基础设施等物理来源的Scope 3（价值链）排放。\n*   **排放来源**：包括IT硬件的制造、交付以及报废处理、回收或转售相关的排放。\n*   **控制与减少策略**：\n    *   优化材料选择。\n    *   在设计中选择和开发低碳替代品。\n    *   与硬件供应商合作，减少上游排放。\n\n### 什么是可持续性设计？\n\n“可持续性设计”是Meta开发和提出的一套指导方针，旨在帮助硬件设计师减少IT机架的环境影响。它考虑了能效、材料的选择、减少、循环性以及硬件的报废处理等多种因素。可持续硬件设计需要硬件设计师、工程师和可持续性专家之间的协作，以创建既满足性能要求又限制环境影响的硬件。本指南特别关注数据中心机架的设计，并为各种组件（如机械、冷却、计算、存储和布线）提供可持续的选择。\n\n### 减少Scope 3排放的内部团队行动\n\nMeta内部团队为减少IT硬件的Scope 3排放采取了以下措施：\n\n*   **优化硬件设计**：以最低排放为目标，尽可能延长材料的使用寿命，或使用低碳材料。\n*   **提高效率**：通过延长IT机架的使用寿命，可能跳过新一代设备的采购。\n*   **组件回收**：回收不再可用的服务器组件作为备件，例如从报废机架中回收双列直插式内存模块（DIMM）并重新部署到新构建中。\n*   **排放概况分析**：了解供应商、组件和系统设计的排放概况，以指导未来的减排路线图。\n*   **供应商协作**：与供应商合作，推动其制造过程电气化，转向可再生能源，并利用低碳材料和设计。\n\n这些减少IT硬件Scope 3排放的行动，同时也有助于减少数据中心产生的电子垃圾（e-waste）。\n\n### Meta部署的机架类型与组件\n\nMeta数据中心部署了多种机架设计，以支持不同的工作负载和基础设施需求，主要包括：\n\n*   **AI**：AI训练和推理工作负载。\n*   **计算**：运行Meta产品和服务所需的通用计算。\n*   **存储**：存储和维护产品使用的数据。\n*   **网络**：提供服务器之间的低延迟互连。\n\n尽管这些机架类型在架构上存在差异，但大多数都应用通用的硬件设计原则，并包含来自类似供应商的活跃和被动组件。因此，相同的可持续性设计原则适用于这些不同的机架类型。每个机架内，有五大类组件是排放减少的目标：\n\n*   计算（即内存、HDD/SSD）\n*   存储\n*   网络\n*   电源\n*   机架基础设施（即机械和散热）\n\n### 减少排放的具体技术\n\nMeta主要通过以下四个类别来解决与硬件组件相关的排放问题：\n\n1.  **模块化机架设计**\n    *   允许旧机架组件在新机架中重用，例如Open Rack设计（ORv2和ORv3）。\n    *   **ORv3关键特点**：电源单元（PSU）和电池备份单元（BBU）分离，实现更可靠和灵活的配置；48V电源输出，允许电源货架在机架中任意放置；可根据平台和区域需求配置PSU和BBU货架；正在努力设计“通用化”ORv3机架框架以简化组装和降低成本；ORv3N是ORv3的衍生品，专为网络应用设计，提供效率和成本改进。\n    *   随着AI工作负载的扩展，新的专业机架设计需要设计师采纳最模块化的设计原则。\n\n2.  **重用/改造现有机架设计**\n    *   这是一种经济高效且可持续的方法，可以满足不断演进的数据中心需求，减少电子垃圾、降低成本并加速部署。\n    *   **优点**：成本节约、减少电子垃圾、加快部署、环境效益。\n    *   **挑战**：兼容性问题、电源和冷却要求、可扩展性和灵活性限制、测试和验证。\n    *   Meta认为，在每个新机架设计中都应充分考虑重用或改造现有机架的益处。\n\n3.  **绿色和回收材料**\n    *   **绿色钢铁**：通过电弧炉（EAF）而非传统高炉生产，使用清洁可再生电力和更高比例的回收含量，显著减少碳排放。Meta与提供100%清洁可再生能源生产绿色钢铁的供应商合作。\n    *   **回收钢铁、铝和铜**：回收这些材料可节省大量生产硬件所需的能源。Meta要求所有机架/底盘至少包含20%的回收钢铁，所有散热器必须完全由回收铝或铜制造。\n\n4.  **提高可靠性以延长使用寿命**\n    *   延长机架、服务器、内存和SSD的使用寿命有助于Meta减少硬件采购量，从而显著降低排放和成本。\n    *   可靠性基准测试是评估硬件寿命延长可行性的重要因素。\n    *   需要考虑备件和供应商支持的可用性可能下降，以及设备故障率增加的风险。\n\n5.  **去物质化**\n    *   减少和移除不必要的硬件组件可以显著减少原材料、水和/或能源的使用。\n    *   这包括减少机架上的钢铁使用，或在保持设计约束的同时移除服务器主板上不必要的组件。\n    *   去物质化还涉及将多个机架整合为更少、更高效的机架，从而减少整体物理占地面积。\n    *   硬件板上多余组件的原因可能包括：未来验证、灵活性、调试和测试、冗余、模块化、法规遵从性。\n    *   Meta强调，每个硬件设计都应优化组件填充，避免不必要的组件，例如未填充的集成电路（IC）插座、未使用的连接器、测试点、冗余电源或可选内存/存储组件。\n\n6.  **生产化低排放新技术**\n    *   内存和SSD/HDD通常是服务器机架中最大的隐含碳排放源。\n    *   新技术可以帮助Meta显著减少排放和成本，同时提供更高的功率归一化性能。\n    *   **示例**：\n        *   从HDD转向SSD：减少驱动器、服务器、机架、BBU和PSU的需求，并有助于降低整体能耗。\n        *   液冷：根据当地环境条件和数据中心工作负载，液冷在服务器机架中可能比传统空冷碳效率高17%。\n        *   探索替代技术：如相变存储器（PCM）或磁阻随机存取存储器（MRAM），它们具有相同性能但碳排放较低。\n        *   使用低功耗双倍数据速率（LPDDR）代替DDR，以实现低功耗和高带宽。",
      "shortSummary": "Meta推出了“可持续性设计”原则，旨在通过重用、延长使用寿命和优化设计，减少IT硬件的排放和成本。这些原则关注数据中心IT硬件的Scope 3排放，涵盖模块化设计、重用改造、使用绿色和回收材料、提高可靠性、去物质化以及采用低排放新技术。Meta呼吁全行业采纳这些策略，以实现2030年净零排放目标并减少电子垃圾。",
      "translated_title": "可持续性设计：降低IT硬件排放的新设计原则",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>We’re presenting Design for Sustainability,  a set of technical design principles for new designs of IT hardware to reduce emissions and cost through reuse, extending useful life, and optimizing design. At Meta, we’ve been able to significantly reduce the carbon footprint of our data centers by integrating several design strategies such as modularity, reuse, retrofitting, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/design-for-sustainability-new-design-principles-for-reducing-it-hardware-emissions/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/design-for-sustainability-new-design-principles-for-reducing-it-hardware-emissions/\">Design for Sustainability: New Design Principles for Reducing IT Hardware Emissions</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Meta 如何利用人工智能提高 IT 硬件范围 3 排放估算的质量 (原标题: How Meta Is Leveraging AI To Improve the Quality of Scope 3 Emission Estimates for IT Hardware)",
      "link": "https://engineering.fb.com/2025/10/14/data-center-engineering/how-meta-is-leveraging-ai-to-improve-the-quality-of-scope-3-emission-estimates-for-it-hardware/",
      "pubDate": "Tue, 14 Oct 2025 20:40:01 +0000",
      "isoDate": "2025-10-14T20:40:01.000Z",
      "creator": "",
      "summary": "Meta 致力于在 2030 年实现净零排放，并旨在为整个行业创建测量碳排放的通用分类法。为实现这一目标，Meta 在 2025 年 OCP 区域 EMEA 峰会上提出了一种新方法，该方法利用人工智能 (AI) 来改进对 IT 硬件范围 3 排放的理解。Meta 正与 OCP PCR 工作流合作，计划在 2025 年 OCP 全球峰会上开源此方法论。\n\n**IT 硬件范围 3 排放估算的挑战**\n\n*   理解服务器硬件的碳足迹对于可持续采购和设计至关重要。\n*   挑战在于复杂的供应链和供应商有限的数据，使得精确计算碳足迹变得困难。\n*   数据中心 IT 硬件的制造和运输所产生的隐含碳是主要的排放源，且难以量化。\n\n**Meta 的排放估算方法论**\n\nMeta 开发了一种方法来估算和追踪数据中心数亿个组件的碳排放。该方法结合了：\n\n*   **基于成本的估算**\n*   **模型估算**\n*   **组件特定的产品碳足迹 (PCF)**\n\n这些组件级别的估算根据数据质量进行排名，并聚合到服务器机架级别。这种方法允许 Meta 从单个螺丝到整个机架组件进行多级别粒度的排放分析，从而识别高影响的减排区域。最终目标是推动行业采用更可持续的制造实践，并生产低排放组件。\n\n**AI 在改进范围 3 排放估算中的应用**\n\nMeta 利用 AI 改进其数据库并理解 IT 硬件相关的范围 3 排放，主要通过以下方式：\n\n1.  **识别相似组件并应用现有 PCF**\n    *   **问题**：PCF 耗时且通常与特定标识符绑定，但库存中存在大量相似或变体组件。若不识别这些相似组件，其碳足迹估算数据质量会较低。\n    *   **方法**：Meta 采用自然语言处理 (NLP) 算法（如 TF-IDF 和余弦相似度）分析文本描述，识别相似组件。当收到新的 PCF 时，算法会识别同类别中描述相似的组件，并将其映射到代表性 PCF。对于数据质量低的组件，算法会寻找高质量的参考数据来改进估算。\n    *   **目的**：确保高质量 PCF 数据在所有相似组件中得到有效利用，提高数据准确性和一致性，并增强碳足迹估算的追溯性。\n\n2.  **从异构数据源提取数据**\n    *   **问题**：当 PCF 不可用时，Meta 避免使用基于支出的方法。参数化模型需要一致的输入数据，但信息可能存储在不同的表格、格式或单位中，导致难以应用模型。\n    *   **方法**：Meta 使用大型语言模型 (LLM)，特别是 Llama 3.1，从异构数据源中提取相关信息，并将其注入参数化模型。LLM 能够识别相同信息的不同表示形式。\n    *   **应用**：该方法已应用于内存（提取容量）和电缆（提取长度/类型）的排放计算，确保估算的一致性。\n\n3.  **创建 IT 硬件排放的组件级分类法**\n    *   **问题**：不同供应商的物料清单 (BOM) 结构不同，使得识别减排行动变得困难。\n    *   **方法**：Meta 使用 AI 将机架的描述性数据分类为两个层次：\n        *   **领域级**：机架的主要功能分组（如计算、网络、电源、机械、存储）。\n        *   **组件级**：主要排放源组件（如 CPU、GPU、DRAM、闪存）。\n    *   **过程**：在探索阶段，生成式 AI (GenAI) 模型自由识别潜在类别。与内部硬件专家审查后，确定了主要组件的固定列表，然后使用严格的 GenAI 分类器进行分组，生成互斥的层次结构。\n    *   **目的**：为碳足迹分析提供帮助，并推动行业采用通用的 IT 硬件碳足迹分类法，以便比较不同类型和世代硬件的排放。\n\n**未来计划：开源分类法和方法论**\n\nMeta 计划开源其学习成果和方法论，包括：\n\n*   服务器机架排放核算的分类法和方法论。\n*   使用 GenAI 分类器的分类法构建器。\n*   改进全行业设施报告流程的聚合方法论。\n\nMeta 致力于与 OCP PCR 组织合作，共同发展和分享这些方法论。",
      "shortSummary": "Meta 致力于在 2030 年实现净零排放，并正利用 AI 提高 IT 硬件范围 3 排放估算的质量。面对供应链复杂和数据有限的挑战，Meta 开发了一种结合成本、模型和产品碳足迹 (PCF) 的方法。AI 在此过程中发挥关键作用：通过 NLP 识别相似组件以应用 PCF；利用 LLM 从异构数据源提取信息；并使用生成式 AI 创建 IT 硬件的通用分类法，以识别减排热点。Meta 计划开源这些分类法和方法论，以推动行业标准化和可持续实践。",
      "translated_title": "Meta 如何利用人工智能提高 IT 硬件范围 3 排放估算的质量",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>As we focus on our goal of achieving net zero emissions in 2030, we also aim to create a common taxonomy for the entire industry to measure carbon emissions. We’re sharing details on a new methodology we presented at the 2025 OCP regional EMEA summit that leverages AI to improve our understanding of our IT [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/how-meta-is-leveraging-ai-to-improve-the-quality-of-scope-3-emission-estimates-for-it-hardware/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/14/data-center-engineering/how-meta-is-leveraging-ai-to-improve-the-quality-of-scope-3-emission-estimates-for-it-hardware/\">How Meta Is Leveraging AI To Improve the Quality of Scope 3 Emission Estimates for IT Hardware</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "OCP 峰会 2025：AI 网络硬件的开放未来 (原标题: OCP Summit 2025: The Open Future of Networking Hardware for AI)",
      "link": "https://engineering.fb.com/2025/10/13/data-infrastructure/ocp-summit-2025-the-open-future-of-networking-hardware-for-ai/",
      "pubDate": "Tue, 14 Oct 2025 00:00:20 +0000",
      "isoDate": "2025-10-14T00:00:20.000Z",
      "creator": "",
      "summary": "# OCP 峰会 2025：AI 网络硬件的开放未来\n\n在2025年开放计算项目（OCP）峰会上，Meta详细介绍了其AI训练集群下一代网络架构的发展方向。Meta扩展了其网络硬件产品组合，并向OCP贡献了新的解耦网络平台，旨在通过开放机架、服务器、存储盒和主板设计，促进整个行业的创新和协作。\n\n## 开放硬件与AI创新\nMeta坚信开放硬件是创新的催化剂，尤其是在数据中心基础设施日益支持新兴AI技术的情况下。开放硬件通过实现解耦，将传统数据中心技术分解为核心组件，从而构建更灵活、可扩展和高效的系统。自2011年共同创立OCP以来，Meta一直分享数据中心和组件设计，并开源其网络操作系统FBOSS，以推动行业内外的创新。\n\n## 数据中心网络新里程碑\nMeta宣布了其数据中心网络的几项重要进展：\n\n### 1. 解耦调度结构（DSF）的演进\n*   **规模扩展**：DSF已演进为支持跨越整个数据中心建筑的大型AI集群的横向扩展互连。\n*   **双阶段架构**：去年的DSF是基于VOQ的系统，支持开放标准的以太网RoCE接口。现在已发展为双阶段架构，可扩展支持多达18,432个XPU的无阻塞网络，是构建跨区域AI集群的基础。\n*   **大规模部署**：Meta已利用双阶段DSF构建了规模达整个数据中心建筑的18,000个GPU集群。\n\n### 2. 非调度结构（NSF）架构\n*   **新架构**：与DSF演进并行，Meta开发了新的非调度结构（NSF）架构。\n*   **关键特性**：\n    *   基于浅缓存OCP以太网交换机。\n    *   提供低往返延迟。\n    *   支持自适应路由，实现有效负载均衡，优化利用率并最小化拥塞。\n    *   作为Prometheus等千兆瓦级AI集群的基础构建模块。\n*   **三层NSF**：用于构建规模化AI集群。\n\n### 3. 新一代AI网络OCP交换机平台\n*   **现有平台**：去年Meta推出了Minipack3（基于Broadcom Tomahawk5）和Cisco 8501（基于Cisco Silicon One G200）两款51T以太网交换机，它们提供51.2 Tbps带宽，无需重定时器，并运行FBOSS。\n*   **Minipack3N**：今年推出基于NVIDIA Spectrum-4交换ASIC的新型51T以太网交换机Minipack3N，采用与Minipack3相同的系统设计，由Meta设计并由Accton制造。\n\n### 4. FBOSS和SAI的演进\n*   **开放基础**：Meta持续将OCP-SAI作为新网络结构、交换机硬件平台和光收发器集成到FBOSS的基础。\n*   **协作创新**：通过与供应商和OCP社区的紧密合作，SAI已演进以支持DSF、NSF以及为现代数据中心和AI工作负载量身定制的其他增强路由方案等高级功能。这种开放方法加速了整个行业的进步。\n\n### 5. 400G/800G光互连技术\n*   **现有部署**：去年推出的2x400G FR4 BASE（3公里）光模块已在Meta数据中心广泛部署。\n*   **新产品**：\n    *   **2x400G FR4 LITE（500米）**：为数据中心内部大多数用例优化，旨在加速光模块成本降低。\n    *   **400G DR4 OSFP-RHS**：Meta首代用于AI主机侧NIC连接的DR4解决方案。\n    *   **2x400G DR4 OSFP**：部署在交换机侧，提供从主机到交换机的连接。\n\n## OCP中的“以太网用于横向扩展网络”（ESUN）倡议\nMeta是OCP 2025全球峰会期间启动的“以太网用于横向扩展网络”（ESUN）倡议的创始参与者。\n\n*   **ESUN是什么？** ESUN是OCP网络项目中的一个新工作流，作为一个开放技术论坛，供行业运营商和领先供应商协作推进以太网技术的使用。其目标是利用和调整成熟的以太网生态系统，以满足现代AI系统中横向扩展领域独特的高性能需求。\n*   **关注点**：ESUN专注于横向扩展系统的网络功能方面，解决数据流量在网络交换机中管理和传输的技术挑战，包括定义协议头、错误处理机制和实现网络无损数据传输的最佳实践和标准。\n*   **合作与标准**：该倡议汇集了运营商、供应商和标准机构，共同开发适用于横向扩展网络的以太网解决方案，专注于以太网帧和交换层，确保强大、无损和容错的多跳拓扑，并与UEC和IEEE等组织紧密合作，与开放标准保持一致。\n*   **Meta的贡献**：Meta作为ESUN的初始成员之一，与AMD、Arista、ARM、Broadcom、Cisco、HPE、Marvell、Microsoft、NVIDIA、OpenAI和Oracle等行业领导者共同推动该倡议。Meta的贡献包括在定义AI集群ESUN需求方面的技术领导、与供应商和标准机构的开放协作，以及分享在Meta数据中心部署先进以太网网络方面的最佳实践。\n\n## 行业邀请：加入开放未来\nMeta邀请工程师、开发人员和行业合作伙伴加入OCP社区，共同塑造AI的下一代网络硬件。通过协作和分享想法，可以加速开放、面向未来的AI基础设施的开发，从而造福整个行业并支持未来技术的需求。",
      "shortSummary": "Meta在OCP峰会2025上发布了AI训练集群网络硬件的重大更新，包括DSF/NSF架构、Minipack3N交换机及新光模块。同时，Meta启动了“以太网用于横向扩展网络（ESUN）”倡议，旨在推动AI数据中心基础设施的创新、效率和可扩展性。",
      "translated_title": "OCP 峰会 2025：AI 网络硬件的开放未来",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>At Open Compute Project Summit (OCP) 2025, we’re sharing details about the direction of next-generation network fabrics for our AI training clusters. We’ve expanded our network hardware portfolio and are contributing new disaggregated network platforms to OCP. We look forward to continued collaboration with OCP to open designs for racks, servers, storage boxes, and motherboards [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/13/data-infrastructure/ocp-summit-2025-the-open-future-of-networking-hardware-for-ai/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/13/data-infrastructure/ocp-summit-2025-the-open-future-of-networking-hardware-for-ai/\">OCP Summit 2025: The Open Future of Networking Hardware for AI</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "介绍 React 基金会：React 和 React Native 的新家 (原标题: Introducing the React Foundation: The New Home for React & React Native)",
      "link": "https://engineering.fb.com/2025/10/07/open-source/introducing-the-react-foundation-the-new-home-for-react-react-native/",
      "pubDate": "Tue, 07 Oct 2025 18:00:01 +0000",
      "isoDate": "2025-10-07T18:00:01.000Z",
      "creator": "",
      "summary": "# 介绍 React 基金会：React 和 React Native 的新家\n\nMeta 宣布将 React、React Native 以及 JSX 等支持项目移交给新成立的 React 基金会，标志着 React 生态系统发展的一个重要里程碑。\n\n## React 的发展历程与影响力\n*   **起源与增长**：Meta 在十多年前开源了 React，旨在帮助开发者构建更好的用户体验。如今，React 已成为全球最受欢迎的开源项目之一，为超过 5000 万个网站和产品提供支持，这些产品来自微软、Shopify、彭博社、Discord、Coinbase、NFL 等众多公司。\n*   **平台扩展**：通过 React Native，React 的应用范围已超越了网页，扩展到移动设备、平板电脑、桌面应用、电视、游戏机乃至混合现实设备。\n*   **社区贡献**：React 的巨大成功离不开数千名教育工作者、公司和项目对其开发的贡献。社区是 React 的核心，推动了开源创新。\n\n## React 基金会的成立与使命\n*   **新家**：React 及其生态系统中的多个项目（包括 React、React Native 和 JSX）将过渡到 React 基金会。\n*   **使命**：React 基金会的任务是支持 React 社区及其成员，具体包括：\n    *   维护 React 的基础设施。\n    *   组织 React Conf 大会。\n    *   发起支持 React 生态系统的各项倡议。\n*   **隶属关系**：React 基金会将成为 Linux 基金会的一部分。Linux 基金会长期以来为开源项目提供了一个供应商中立的环境。\n\n## 治理结构\n*   **理事会**：React 基金会的理事会将由来自亚马逊、Callstack、Expo、Meta、微软、Software Mansion 和 Vercel 的代表组成，并计划未来进一步扩大。\n*   **业务与技术分离**：React 的业务治理和技术治理之间将有明确的分离。\n*   **技术治理**：发布、功能和技术方向将由一个新的结构来管理，该结构由 React 的维护者和贡献者驱动，并且独立于 React 基金会。React 团队正在积极制定这一新的技术治理结构，并将在未来的 React 博客文章中分享更多细节。\n\n## Meta 的承诺与未来展望\n*   **五年合作**：Meta 承诺与 React 基金会建立为期五年的合作伙伴关系。\n*   **资金与支持**：Meta 将提供超过 300 万美元的资金和专门的工程支持，以确保 React 平稳过渡到独立治理，同时保持社区所期望的稳定性和创新性。\n*   **持续投入**：Meta 将继续投资 React，并将其作为在网页和 Meta 众多应用中构建 UI 的主要工具。Meta 也将继续拥有一支全职致力于 React 和 React Native 的工程师团队。\n*   **未来机遇**：React 基金会的成立将为协作、创新和增长开启新的机遇，造福整个生态系统。通过强化的治理、更广泛的行业参与和持续的技术卓越，React 有望应对 UI 开发领域的下一代挑战。",
      "shortSummary": "Meta 宣布将 React、React Native 及相关项目移交给新成立的 React 基金会。该基金会隶属于 Linux 基金会，旨在维护 React 生态系统，并由亚马逊、Meta、微软等公司代表组成的理事会管理。Meta 承诺五年内提供超 300 万美元资金和工程支持，确保 React 的独立治理和持续发展。此举旨在促进更广泛的行业参与、协作与创新，应对 UI 开发的未来挑战。",
      "translated_title": "介绍 React 基金会：React 和 React Native 的新家",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Meta open-sourced React over a decade ago to help developers build better user experiences. Since then, React has grown into one of the world’s most popular open source projects, powering over 50 million websites and products built by companies such as Microsoft, Shopify, Bloomberg, Discord, Coinbase, the NFL, and many others. With React Native, React [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/07/open-source/introducing-the-react-foundation-the-new-home-for-react-react-native/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/07/open-source/introducing-the-react-foundation-the-new-home-for-react-react-native/\">Introducing the React Foundation: The New Home for React &#038; React Native</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "介绍 OpenZL：一个开源的格式感知压缩框架 (原标题: Introducing OpenZL: An Open Source Format-Aware Compression Framework)",
      "link": "https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/",
      "pubDate": "Mon, 06 Oct 2025 16:00:53 +0000",
      "isoDate": "2025-10-06T16:00:53.000Z",
      "creator": "",
      "summary": "# 介绍 OpenZL：一个开源的格式感知压缩框架\n\nOpenZL 是 Meta 推出的一款新型开源数据压缩框架，专为结构化数据提供无损压缩。它旨在结合格式特定压缩器的卓越性能与单一可执行二进制文件的易于维护性。\n\n## OpenZL 的核心理念与背景\n\n*   **挑战与机遇：** 尽管 Zstandard 等通用压缩工具在数据中心工作负载中表现出色，但它们在处理结构化数据时，由于无法充分利用数据内部的特定模式，仍有大量压缩潜力未被挖掘。\n*   **定制化压缩器的困境：** 格式特定的压缩器能显著提升压缩比和速度，但为每种数据格式开发、部署和维护独立的压缩器和解压缩器会带来巨大的运维负担。\n*   **OpenZL 的解决方案：** OpenZL 应运而生，旨在解决这一矛盾，它通过一种创新的方法，在实现定制化性能的同时，保持了单一二进制文件的简洁性。\n\n## OpenZL 的工作原理\n\nOpenZL 的核心在于将数据结构作为显式输入参数，而非让压缩器猜测。\n\n1.  **显式结构输入：** 用户通过预设或简洁的格式描述（如 Simple Data Description Language, SDDL）向 OpenZL 提供数据形状。SDDL 仅用于解析，描述字节如何映射到字段（行、列、枚举、嵌套记录）。用户也可以编写自定义解析函数。\n2.  **离线训练器：** 一个离线优化组件（训练器）根据数据形状和样本，运行预算搜索，探索不同的转换选择和参数，以构建一个高效的压缩配置（“计划”）。它能提供一系列速度/压缩比的权衡，或直接针对特定速度约束下的最佳配置。\n3.  **编码时解析：** 在编码过程中，编码器将“计划”转换为具体的“解析图”（decode recipe），并将其嵌入到压缩帧中。如果“计划”包含控制点，编码器会根据数据特性选择最合适的路径并记录下来。\n4.  **通用解压缩器：** 所有的 OpenZL 文件都可以使用同一个通用解压缩器进行解压缩。解压缩器直接执行帧中嵌入的“解析图”，无需任何带外信息。\n\n## 性能示例：与通用压缩器的对比\n\n以压缩 Silesia 压缩语料库中的 `sao` 文件为例，该文件包含描述恒星的记录数组。通过向 OpenZL 提供其结构信息，OpenZL 展现出优于通用无损压缩器的性能：\n\n| 压缩器    | 压缩大小     | 压缩比 | 压缩速度 | 解压缩速度 |\n| :-------- | :----------- | :----- | :------- | :--------- |\n| zstd -3   | 5,531,935 B  | x1.31  | 220 MB/s | 850 MB/s   |\n| xz -9     | 4,414,351 B  | x1.64  | 3.5 MB/s | 45 MB/s    |\n| **OpenZL** | **3,516,649 B** | **x2.06** | **340 MB/s** | **1200 MB/s** |\n\nOpenZL 在实现更高压缩比的同时，保持甚至提升了压缩和解压缩速度，这对于数据中心处理管道至关重要。\n\n## 示例解析：OpenZL 如何利用结构\n\n在 `sao` 文件的压缩中，OpenZL 的处理流程包括：\n\n1.  **结构分解：** 将文件头与主体（大型结构表）分离。\n2.  **字段提取：** 将结构数组转换为数组结构，把每个字段提取到独立的流中。\n3.  **同质流处理：** 每个流包含同质数据，OpenZL 为其寻找最佳压缩策略：\n    *   **SRA0 (X轴位置)：** 索引大多有序，使用差分编码（delta）减小值范围。\n    *   **SDEC0 (Y轴位置)：** 虽不如X轴有序，但有明确的上下限，利用转置操作（transpose）使高位字节更可预测。\n    *   **其他字段 (IS, MAG, XRPM, XDPM)：** 基数远低于数量，且连续值间无关联，适合使用 `tokenize` 转换为字典和索引列表，再分别进行压缩。\n4.  **自动化与精细化：** 离线训练器在此阶段发挥作用，为每个流生成并优化特定的压缩策略。\n\n## 适应数据演变：再训练与运行时控制\n\n在实际应用中，数据结构和内容不断变化。OpenZL 通过其灵活的压缩计划来应对：\n\n*   **持续训练：** OpenZL 提供训练过程，根据提供的数据样本更新压缩计划，以维持或提升压缩性能。Meta 内部的“托管压缩”系统利用此功能，定期对注册用例进行监控、采样和再训练，并部署新的配置。\n*   **运行时自适应（控制点）：** 压缩配置可以包含控制点，在压缩时读取轻量级统计信息（如字符串重复、游程长度、直方图偏斜、差分方差），并选择“计划”中最佳的分支。这使得 OpenZL 能够动态适应数据变化、处理突发情况和异常值，而无需进行无限制的搜索，同时不增加解压缩器的复杂性。\n\n## 通用解压缩器的优势\n\nOpenZL 最大的运营优势在于其单一的通用解压缩器二进制文件，即使压缩配置改变，解压缩器也无需更新。\n\n*   **单一审计面：** 安全和正确性审查集中在一个二进制文件上，简化了审计流程。\n*   **全舰队范围的改进：** 解压缩器（如安全更新、性能优化）的任何更新都能惠及所有已压缩文件，包括旧数据。\n*   **操作清晰性：** 跨数据集使用相同的二进制文件、命令行接口、指标和仪表板，简化了修补和部署。\n*   **持续改进：** 可以在系统运行时不断训练和部署新的压缩计划，旧数据仍可解码，新数据则获得更好的压缩效果，实现了领域特定压缩而不碎片化生态系统。\n\n## OpenZL 的适用场景与局限性\n\n*   **适用场景：** OpenZL 特别适用于压缩向量、表格或树形结构数据，以及数值、字符串或二进制数据。常见示例包括时间序列数据集、机器学习张量和数据库表。前提是输入数据具有可被揭示的内部秩序。\n*   **局限性：** 当数据不包含可利用的结构时（例如纯文本文件），OpenZL 的优势不复存在，此时它会回退到 Zstandard，提供大致相同的性能水平。\n\n## 如何开始使用 OpenZL\n\n用户可以通过访问 OpenZL 网站和快速入门指南开始使用。源代码、文档和示例可在 GitHub 仓库中找到。OpenZL 欢迎社区的贡献和反馈。未来，OpenZL 将继续致力于简化结构暴露，并利用自动化压缩计划来处理不断演变的数据。",
      "shortSummary": "OpenZL 是一个开源的格式感知数据压缩框架，为结构化数据提供无损压缩。它通过显式利用数据结构，实现格式特定压缩器的性能，同时保持单一通用解压缩器的易维护性。OpenZL 包含离线训练器自动生成优化压缩计划，并支持运行时自适应。与通用压缩器相比，OpenZL 能在更高压缩比的同时保持或提升速度，特别适用于向量、表格和树形结构数据。其通用解压缩器简化了部署和维护，并支持持续改进。",
      "translated_title": "介绍 OpenZL：一个开源的格式感知压缩框架",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>OpenZL is a new open source data compression framework that offers lossless compression for structured data. OpenZL is designed to offer the performance of a format-specific compressor with the easy maintenance of a single executable binary. You can get started with OpenZL today by visiting our Quick Start guide and the OpenZL GitHub repository. Learn more [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/\">Introducing OpenZL: An Open Source Format-Aware Compression Framework</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "推出Candle海底电缆，更新我们在亚太地区的连接项目 (原标题: Introducing the Candle Subsea Cable, Updates to Our Asia-Pacific Connectivity Projects)",
      "link": "https://engineering.fb.com/2025/10/05/connectivity/introducing-the-candle-subsea-cable-updates-to-our-asia-pacific-connectivity-projects/",
      "pubDate": "Mon, 06 Oct 2025 02:30:07 +0000",
      "isoDate": "2025-10-06T02:30:07.000Z",
      "creator": "",
      "summary": "## Meta推出Candle海底电缆并更新亚太连接项目\n\nMeta近日宣布推出新的Candle海底电缆系统，并提供了其在亚太地区其他连接项目的最新进展，其中包括Bifrost电缆系统的竣工。此举旨在加强全球和区域连接，特别是在亚太地区，以支持Meta的服务、人工智能（AI）和新兴技术。\n\n### 亚太地区连接的重要性\n亚太地区拥有全球超过58%的互联网用户，他们高度依赖强大的全球基础设施来获取在线连接和创新技术（如AI）。Meta致力于构建世界级的网络基础设施，以提供足够的容量和弹性，支持全球用户的丰富在线体验，并实现AI和个人超级智能的未来愿景。\n\n### Candle海底电缆：亚太最大容量系统\n*   **名称：** Candle\n*   **连接范围：** 将连接东亚和东南亚国家，包括日本、台湾、菲律宾、印度尼西亚、马来西亚和新加坡。\n*   **上线时间：** 预计于2028年投入使用。\n*   **容量：** 提供570 Tbps的容量，使其成为亚太地区容量最大的电缆系统。\n*   **长度：** 跨越8,000公里。\n*   **覆盖人数：** 将连接超过5.8亿人。\n*   **技术：** 采用最新开发的24对光纤电缆技术，提供与Meta现有最大容量电缆Anjana相似的带宽。\n*   **合作：** Meta正与该地区领先的电信公司合作建设此系统。\n\n### 其他亚太地区海底电缆更新\nMeta还公布了其在亚太地区其他几个海底电缆项目的进展：\n\n*   **Bifrost电缆：**\n    *   该系统已完成建设。\n    *   目前连接新加坡、印度尼西亚、菲律宾和美国，预计2026年将延伸至墨西哥。\n    *   Bifrost将提供260 Tbps的冗余容量，为热门的跨太平洋数字路由开辟新路径。\n    *   与Echo电缆一起，Bifrost是Meta及其合作伙伴在2021年承诺将跨太平洋容量增加70%的关键组成部分。\n\n*   **Echo电缆：**\n    *   目前在关岛和加利福尼亚之间提供260 Tbps的容量。\n    *   未来可选择延伸至亚洲。\n\n*   **Apricot电缆：**\n    *   已在日本、台湾和关岛之间投入使用。\n    *   未来将延伸至菲律宾、印度尼西亚和新加坡。\n    *   长度：12,000公里。\n    *   容量：290 Tbps。\n    *   该系统将补充Bifrost和Echo系统，进一步增强区域连接。\n\n### 综合影响与未来展望\nCandle、Echo、Bifrost和Apricot系统将共同增强亚太地区的区域内连接，并建立通往美洲的跨太平洋桥梁。此外，Meta还投资了其他全球项目，如2Africa（通往印度、中东和欧洲）和Project Waterworth（预计在本十年末连接五大洲，包括亚洲），以实现更广泛的全球连接。\n\n这些数字基础设施的开发是Meta致力于将世界各地的人们连接起来的承诺的一部分。通过与合作伙伴的共同努力，这些投资将提升全球电信网络的规模和可靠性，确保Meta的服务能够快速高效地送达亚太地区及其他地区的商业和个人用户。\n\n**数据来源：** 根据Statista数据，截至2025年9月5日，全球56.5亿互联网用户中，亚太地区约占33亿。",
      "shortSummary": "Meta宣布推出Candle海底电缆，这是亚太地区容量最大的新系统，将于2028年连接日本、台湾、菲律宾、印尼、马来西亚和新加坡，提供570 Tbps容量。同时，Meta更新了其他亚太连接项目进展，包括已完成的Bifrost电缆（连接新加坡、印尼、菲律宾、美国）、Echo电缆（连接关岛和加州）以及已启用的Apricot电缆（连接日本、台湾、关岛）。这些投资旨在增强亚太地区及全球的连接性，支持Meta的服务、AI和新兴技术，以满足该地区庞大的互联网用户需求。",
      "translated_title": "推出Candle海底电缆，更新我们在亚太地区的连接项目",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>We’re introducing Candle, a new submarine cable connecting countries across East Asia and Southeast Asia. We’re also announcing several updates to our subsea cables across the Asia-Pacific, including the completion of the Bifrost cable system. The Asia-Pacific (APAC) region is home to over 58% of the world’s internet users1 – many who rely on robust [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/05/connectivity/introducing-the-candle-subsea-cable-updates-to-our-asia-pacific-connectivity-projects/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/05/connectivity/introducing-the-candle-subsea-cable-updates-to-our-asia-pacific-connectivity-projects/\">Introducing the Candle Subsea Cable, Updates to Our Asia-Pacific Connectivity Projects</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "使用基线配置文件加速我们的安卓应用 (原标题: Accelerating our Android apps with Baseline Profiles)",
      "link": "https://engineering.fb.com/2025/10/01/android/accelerating-our-android-apps-with-baseline-profiles/",
      "pubDate": "Wed, 01 Oct 2025 16:00:17 +0000",
      "isoDate": "2025-10-01T16:00:17.000Z",
      "creator": "",
      "summary": "# 使用基线配置文件加速Meta的安卓应用\n\nMeta公司致力于提升其数十亿安卓用户的应用体验。本文探讨了Meta如何利用Android的基线配置文件（Baseline Profiles）显著改善其安卓应用的性能，某些关键指标提升高达40%。\n\n## 应用性能的重要性与挑战\n\n良好的应用性能对用户体验至关重要。启动缓慢、掉帧和响应迟钝都会导致用户沮丧并最终流失。除了在开发过程中注重性能（如使用合适的数据结构、算法和缓存策略），理解编译代码的底层表示及其加载和执行方式也同样重要，以便优化构建工具和运行时。\n\nMeta在过去几年中开发了针对安卓应用的配置文件引导编译器和运行时优化基础设施，其中Android Runtime (ART) 的基线配置文件是核心组件。\n\n### ART性能考量\n\n*   **代码编译与执行：** Android应用主要使用Kotlin和Java，它们被编译成Dalvik字节码（Dex代码）。ART必须将Dex代码翻译成机器码才能执行。\n*   **默认执行流程：** 运行时，Dex方法会同时通过解释器执行并进行分析，以确定是否为“热点”方法。一旦确定为热点，ART的即时编译器（JIT）会将其编译成机器码，后续执行将使用编译后的版本（机器码通常比解释执行快得多）。\n*   **性能开销：** 类加载和Dex方法解释/分析阶段都会产生运行时开销，可能导致用户可感知的性能下降。\n*   **冷启动问题：** 应用首次启动（冷启动）时，类需要重新加载。每次应用版本更新后，即使编译过的方法也需要重新分析和编译。\n\n### Meta移动应用面临的挑战\n\n*   **用户访问主要途径：** Meta的大多数用户通过移动应用访问，其中大部分是安卓用户。\n*   **平衡开发速度与性能：** 在快速迭代新功能（如Instagram Reels、Messenger端到端加密）的同时，保持高性能是一个挑战。\n*   **启动性能：** 启动性能尤为关键，对用户体验影响巨大。Facebook和Instagram在启动时会加载超过20,000个类，滚动信息流时还会加载数千个。\n*   **用户旅程优化：** 除了启动，Meta还关注启动后的用户旅程性能，例如信息流滚动、照片加载和渲染时间。这些旅程根据用户行为和发生场景进行细分（例如，滚动信息流与滚动收件箱是不同的）。\n*   **代码库的动态性：** Meta的单体仓库每天有数千次提交。用户数据收集到的类加载配置文件差异巨大，即使是同一用户在不同时间、不同实验组下也可能不同。\n*   **解决方案需求：** 需要一个能够智能适应频繁代码变更、快速生成编译代码和配置文件，并能同时优化启动和其他用户旅程的解决方案。\n\n## ART安装时优化\n\n自Android 9以来，ART提供了以下安装时优化：\n\n1.  **AOT（Ahead of Time）编译：** 在应用首次运行前，将指定方法编译成机器码，消除初始执行时的解释和分析开销。\n2.  **应用镜像（App Image）创建：** 包含指定类的内存中ART数据结构的局部表示。应用启动时，应用镜像被映射到进程堆中，从而实现极快的类加载，并消除后续运行时加载这些类的成本。\n\n这些优化通过在应用安装时向ART提供特殊配置文件来触发，主要机制有两种：云配置文件（Cloud Profiles）和基线配置文件（Baseline Profiles）。\n\n### 云配置文件（Cloud Profiles）\n\n*   **生成方式：** 由Google Play在应用版本首次发布期间收集和聚合大量用户的分析数据。\n*   **应用方式：** 一旦云配置文件生成，所有后续通过Google Play安装该应用版本的用户都会收到该配置文件，ART会用它进行AOT编译和应用镜像创建。\n*   **缺点：**\n    *   早期用户无法受益，因为他们是数据提供者。\n    *   应用开发者无法观察或控制配置文件中的类和方法。\n    *   配置文件强烈倾向于早期启动性能改进。\n    *   仅通过Google Play提供，其他安装方式（如其他应用商店或侧载）无法使用。\n\n### 基线配置文件（Baseline Profiles）\n\n*   **核心特点：** 与云配置文件类似，也触发ART安装时优化，但由应用开发者生成和提供，并可打包在APK或AAB中。\n*   **与云配置文件的协同：** 当两者都可用时，可以协同使用。\n*   **优势：**\n    *   **开发者完全控制：** 开发者可以完全控制安装时优化，使其更符合应用的特定需求，包括优化启动之外的场景。\n    *   **即时可用：** 用户可以立即受益。\n    *   **生成方式灵活：** 可以通过基准测试（如Google的Macrobenchmark）生成，也可以通过`profgen`工具直接指定类和方法。\n\n## Meta如何创建基线配置文件\n\nMeta利用基线配置文件解决了其安卓应用性能面临的诸多挑战，尤其是在冷启动和每周更新导致编译代码被清除的问题上。\n\n### 数据收集与处理\n\nMeta最初使用AndroidX库附带的静态配置文件。如今，Meta采用了一套复杂的收集技术来生成应用配置文件：\n\n*   **基准测试：** 对部分应用使用本地基准测试，通过内部工具收集类和方法使用信息。\n*   **用户数据（针对复杂应用）：** 对于Facebook和Instagram等复杂应用，Meta还会从用户那里收集类和方法使用数据，以获得更全面的视图。\n    *   **类使用数据：** 使用自定义ClassLoader，插入代码记录加载的类，并以极低的采样率有条件地启用上传。收集到的类加载日志经过聚合，根据出现频率，超过特定阈值的类会被包含在下一版本的基线配置文件中。\n    *   **方法使用数据：** 通过应用内专门的遥测技术，识别用户通常调用的方法集群，并以类似方式进行采样和聚合。\n*   **配置文件生成：** 所有收集到的数据被组合成一个“人类可读配置文件”（Human Readable Profile），然后输入给`profgen`工具，生成最终的基线配置文件。\n\n### 人类可读配置文件示例（格式描述）\n\n人类可读配置文件采用特定格式，例如：\n*   `#` 用于注释行。\n*   类可以直接通过其描述符指定。\n*   方法可以直接指定，并可带可选标志。\n*   可以使用通配符匹配所有符合给定前缀的类或方法。\n\n### 调优与实验\n\n*   **初始策略：** Meta最初将冷启动作为主要优化目标，保守地设置了较高的类和方法包含频率阈值（要求在80%到90%的用户跟踪中出现）。\n*   **担忧：** 过大的基线配置文件可能导致性能下降，因为编译后的机器码通常比原始解释代码大10倍，会增加I/O成本。\n*   **持续优化：** 随着时间的推移，Meta尝试了不同的包含阈值，并将优化范围从冷启动扩展到其他用户交互。目前，对于大多数应用，只要在20%或更多的冷启动用户跟踪中出现的类和方法，都会被包含在内。\n*   **优化场景：** 已通过基线配置文件优化的交互包括Facebook和Instagram的信息流滚动，以及Messenger和Instagram私信中从聊天列表到聊天视图的导航。",
      "shortSummary": "Meta利用Android的基线配置文件（Baseline Profiles）显著提升了其安卓应用的性能，某些关键指标提升高达40%。面对启动慢、帧率下降等挑战，Meta发现传统的云配置文件存在局限。基线配置文件赋予开发者完全控制权，可根据用户数据（包括基准测试和真实用户行为）定制优化，预编译热点代码和类，从而加速应用启动和关键用户旅程。通过持续的实验和调整，Meta已将优化范围从冷启动扩展到新闻推送滚动等多种用户交互。",
      "translated_title": "使用基线配置文件加速我们的安卓应用",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Key Takeways: With billions of Android app users, we’re always looking to improve the Meta app experience, and in this post, we explore the ways we’ve leveraged Android’s Baseline Profiles to significantly improve their performance. We discuss the performance challenges we’ve faced as Meta’s apps, how the needs of users have become more complex over [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/01/android/accelerating-our-android-apps-with-baseline-profiles/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/01/android/accelerating-our-android-apps-with-baseline-profiles/\">Accelerating our Android apps with Baseline Profiles</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "大型语言模型是变异测试和更好合规性的关键 (原标题: LLMs Are the Key to Mutation Testing and Better Compliance)",
      "link": "https://engineering.fb.com/2025/09/30/security/llms-are-the-key-to-mutation-testing-and-better-compliance/",
      "pubDate": "Tue, 30 Sep 2025 16:00:08 +0000",
      "isoDate": "2025-09-30T16:00:08.000Z",
      "creator": "",
      "summary": "大型语言模型（LLM）正在变革Meta的软件测试和合规性流程，通过其**自动化合规性强化（ACH）工具**实现。该工具已在FSE 2025和Eurostar 2025会议上进行主题演讲，旨在自动化合规性，加速开发速度，并克服传统变异测试的规模化障碍。\n\n### Meta的ACH工具：LLM驱动的解决方案\n\n传统上，合规性依赖手动流程，效率低下且难以扩展。Meta通过投资先进的AI检测机制，特别是ACH工具，来解决这一问题。ACH工具利用LLM进行**变异引导的测试生成**，其核心功能包括：\n\n*   **引入故障（变异体）**：故意在源代码中引入故障，以评估测试框架检测这些故障的能力。\n*   **生成相关变异体和测试**：结合自动化测试生成技术与LLM，创建高度相关的变异体以及能够捕获这些变异体的测试。\n*   **直观操作**：工程师通过简单的纯文本提示描述要测试的变异体，使过程直观可靠。\n*   **预防性识别**：ACH能更轻松、更主动地识别可能影响合规性的bug，并阻止它们进入系统，从而确保代码库的风险弹性。\n\n### 传统变异测试面临的挑战\n\n尽管变异测试被认为是评估测试质量的强大方法，但其大规模部署一直面临五大障碍：\n\n1.  **不可扩展性**：生成大量变异体，计算成本高昂，难以应用于大型工业代码库。\n2.  **生成不切实际的变异体**：传统的基于规则的变异操作符生成通用、与上下文无关的变异体，不代表开发者实际关注的故障。\n3.  **等价变异体浪费资源**：语法不同但语义等价的变异体难以识别，浪费开发时间和计算资源。\n4.  **高计算资源需求**：运行测试和分析结果需要大量基础设施和时间，在快节奏的工业环境中难以承受。\n5.  **过度拉伸测试工作**：可能专注于捕获低影响故障，导致测试投入产出比降低。\n\n### LLM如何解决变异测试的挑战\n\nMeta利用其庞大的bug数据训练LLM，以指导测试生成。ACH系统通过以下方式克服了上述障碍：\n\n1.  **实现可扩展的变异测试**：ACH利用LLM生成更少、更真实、更具体的变异体（例如，针对隐私故障），从而提高相关性和可扩展性。\n2.  **创建真实的变异体**：安全或隐私工程师可以通过文本描述关注的问题，生成高度真实的问题特定bug。\n3.  **检测并消除等价变异体**：ACH包含一个基于LLM的等价检测器，结合简单的静态分析预处理，能高效识别等价变异体（高精度和召回率），并自动生成杀死非等价变异体的单元测试。\n4.  **生成高效且易于部署的测试**：\n    *   在2024年10月至12月的试点中，ACH在Meta的多个平台（包括Facebook、Instagram、WhatsApp、Quest和Ray-Ban Meta眼镜）上用于隐私测试。\n    *   在数千个变异体和数百个生成测试中，隐私工程师接受了73%的生成测试，其中36%被判定为与隐私相关。\n    *   工程师们重视评估测试而非构建测试，这显著提高了效率。\n5.  **防止过度拉伸**：ACH生成与关注问题紧密耦合的变异体，并生成捕获现有测试遗漏故障的测试，有效提高了测试覆盖率和质量。\n\n### “及时测试捕获”（JiTTest）挑战：LLM在软件测试中的新前沿\n\nLLM为自动化软件测试（包括强化测试和捕获测试）开辟了新的探索领域。Meta特别关注**“及时测试”（JiTTest）**的生成，即在拉取请求合并前及时生成测试进行人工审查，以在代码进入生产环境前捕获故障。\n\n*   **核心挑战**：**测试预言问题（Test Oracle Problem）**，即区分给定输入下的预期正确行为与错误行为。\n*   **社区邀请**：Meta提出了“及时测试捕获”（JiTTest）挑战，鼓励社区构建能够高精度检测拉取请求中bug的系统，同时保持人工参与以确保低误报率。\n*   相关研究论文：“Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges”已作为FSE 2025的主题演讲发布。\n\n### LLM与软件测试的未来\n\nAI正在帮助Meta简化和优化其合规性和整体风险管理框架。未来的工作方向包括：\n\n*   **ACH的扩展**：将ACH的应用扩展到其他领域和更多编程语言（目前主要为Kotlin和隐私测试）。\n*   **提高精确性**：研究如何利用微调和提示工程使变异体生成更加精确和相关。\n*   **解决测试预言问题**：探索实现高精度故障检测并避免误报的方法。\n*   **关注人机交互**：研究开发者如何与LLM生成的测试进行交互，以提高其采用率和可用性。\n\nMeta将在即将举行的Product@Scale会议上分享更多工作，并邀请社区共同探索AI在软件测试和风险管理领域的潜力。",
      "shortSummary": "Meta正利用其基于大型语言模型（LLM）的自动化合规性强化（ACH）工具，革新软件测试和合规性。ACH通过生成更少、更真实、问题特定的变异体，并自动生成捕获这些变异体的测试，解决了传统变异测试在可扩展性、真实性、等价变异体处理和资源消耗方面的五大挑战。该工具显著简化了风险评估，降低了开发者负担，并实现了持续合规。Meta还提出了“及时测试捕获”（JiTTest）挑战，旨在利用LLM在代码进入生产前，高精度地发现拉取请求中的bug，推动LLM在软件测试领域的进一步应用。",
      "translated_title": "大型语言模型是变异测试和更好合规性的关键",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Following our keynote presentations at FSE 2025 and Eurostar 2025, we’re delving further into the development of Meta’s Automated Compliance Hardening (ACH) tool, an LLM-based tool for software testing that is automating aspects of compliance adherence at Meta, while accelerating developer and product velocity. By leveraging LLMs we’ve been able to overcome the barriers that [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/30/security/llms-are-the-key-to-mutation-testing-and-better-compliance/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/30/security/llms-are-the-key-to-mutation-testing-and-better-compliance/\">LLMs Are the Key to Mutation Testing and Better Compliance</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Meta 3D AssetGen：用AI生成3D世界 (原标题: Meta 3D AssetGen: Generating 3D Worlds With AI)",
      "link": "https://engineering.fb.com/2025/09/29/virtual-reality/assetgen-generating-3d-worlds-with-ai/",
      "pubDate": "Mon, 29 Sep 2025 14:00:42 +0000",
      "isoDate": "2025-09-29T14:00:42.000Z",
      "creator": "",
      "summary": "## Meta 3D AssetGen：用AI生成3D世界\n\n### 引言\n\nAI与VR的结合是今年Meta Connect大会上的一个重要议题。马克·扎克伯格在主题演讲中分享了他的愿景：未来任何人都可以像生成图片一样，通过AI工具（例如即将推出的Meta Horizon Studio中的工具）轻松创建虚拟世界。AI正在以前所未有的方式简化3D资产的创建。\n\n### AssetGen：3D资产的AI基础模型\n\n*   **核心概念**：Meta正在开发AssetGen，这是一个用于3D资产的新型基础模型。\n*   **团队与讨论**：在Meta Tech播客的一期节目中，Meta XR技术团队的Mahima和Rakesh讨论了AssetGen。\n*   **主要目标**：该模型旨在通过简单的文本提示生成整个3D世界，实现从文本到3D内容的直接转换。\n\n### AssetGen的开发与愿景\n\n*   **构建与训练**：播客中详细介绍了AssetGen的构建和训练过程。\n*   **LLMs的作用**：讨论了大型语言模型（LLMs）在VR未来中将扮演的重要角色。\n*   **雄心勃勃的目标**：团队正在努力实现从简单的文本提示生成完整3D世界的宏伟目标。\n\n### 相关资源\n\n*   **Meta Tech播客**：关于AssetGen的详细讨论可在Meta Tech播客中收听。\n*   **收听平台**：该播客可在Spotify、Apple Podcasts、Pocket Casts等平台获取。\n*   **Meta Tech播客简介**：该播客由Meta推出，旨在展示Meta工程师在从底层框架到终端用户功能各个层面的工作。\n*   **职业机会**：对Meta职业机会感兴趣的读者可以访问Meta Careers页面。",
      "shortSummary": "Meta正在通过其新的AI基础模型AssetGen，推动AI在3D世界创建中的应用。在Meta Connect大会上，马克·扎克伯格展望了未来，用户能像生成图片一样，通过文本提示轻松创建虚拟世界。AssetGen由Meta的XR技术团队开发，旨在简化3D资产的生成，并最终实现从简单文本提示生成完整的3D世界，大型语言模型在此过程中扮演关键角色。",
      "translated_title": "Meta 3D AssetGen：用AI生成3D世界",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Imagine being able to use AI to create 3D virtual worlds using prompts as easily as you can generate images. The intersection of AI and VR was one of the biggest topics at Meta Connect this year. In his keynote, Mark Zuckerberg shared his vision of a future where anyone can create virtual worlds using [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/29/virtual-reality/assetgen-generating-3d-worlds-with-ai/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/29/virtual-reality/assetgen-generating-3d-worlds-with-ai/\">Meta 3D AssetGen: Generating 3D Worlds With AI</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Meta的基础设施演进与人工智能的到来 (原标题: Meta’s Infrastructure Evolution and the Advent of AI)",
      "link": "https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/",
      "pubDate": "Mon, 29 Sep 2025 13:00:15 +0000",
      "isoDate": "2025-09-29T13:00:15.000Z",
      "creator": "",
      "summary": "# Meta的基础设施演进与人工智能的到来\n\nMeta在过去21年里实现了指数级增长，从一个连接数千人的小型社交网络发展成为服务全球34亿多用户的多个应用和创新硬件产品。公司的基础设施也随之发生了显著演变，从少数服务器上的软件系统发展成为一个庞大的全球网络化运营体系。人工智能（AI）的出现彻底改变了Meta对基础设施扩展的假设，要求在硬件、软件、网络和数据中心等堆栈的每个层面进行创新。Meta秉承其开源根基，通过研究论文和开源硬件/软件系统与工程社区分享其工作，并致力于在推动计算机科学前沿的同时，采用开放标准方法来构建芯片和硬件系统。\n\n## 基础设施堆栈的扩展 (2004 – 2010)\n\n在早期，Meta的工程工作主要集中在软件堆栈的扩展上。\n*   **软件扩展：** 随着Facebook从哈佛扩展到其他大学，然后是高中和公众，用户数量急剧增加。Meta通过扩展Memcache部署、构建TAO社交图谱、开发新的缓存和数据管理系统来管理数据库负载。同时，还开发了新闻源的排名服务和照片分享服务。\n*   **物理基础设施扩展：** 随着用户群扩展到欧洲，仅靠软件扩展已不足够。Meta开始扩展其物理基础设施，从湾区的小型合租设施扩展到弗吉尼亚州的合租设施，并建设了其首批数据中心（俄勒冈州的普林维尔和北卡罗来纳州的森林城）。\n*   **面临的挑战及解决方案：**\n    *   **用户连接：** 为连接分布在美国和欧洲的用户到数据中心，Meta积极建设边缘基础设施，在每个本地互联网服务提供商（ISP）旁获取计算能力，并投资于连接ISP和数据中心的对等网络。\n    *   **软件复制：** 为确保用户无论连接到哪个物理位置都能获得相同体验，Meta需要在每个数据中心复制整个软件堆栈。这要求构建一个互连数据中心的高带宽、多路径骨干网络，最初通过建设陆地光纤网络实现。\n*   **全球化：** 随着用户群的全球增长，Meta超越了单一数据中心建筑，发展为由多个建筑组成的数据中心区域，并在全球运营数百个接入点（POPs）。\n\n## 扩展的挑战 (2010 – 2020)\n\n构建全球基础设施带来了复杂的计算机科学挑战。\n*   **缓存一致性：** 跨数据中心区域的数据更新延迟导致用户体验不一致。Meta通过构建新颖的软件系统提供缓存失效，并最终为分布式系统构建了一致性API来解决这些问题。\n*   **集群管理：** 随着数据中心区域和机器集群的增长，Meta开发了新的抽象层来管理它们，包括：\n    *   **Twine：** 可扩展管理数据中心区域内数百万台机器的集群管理系统。\n    *   **Tectonic：** 数据中心规模的分布式文件系统。\n    *   **ZippyDB：** 强一致性分布式键值存储。\n    *   **Shard Manager：** 管理数千万个数据分片，托管在数十万台服务器上。\n    *   **Delos：** Meta全球基础设施的新控制平面。\n    *   **Service Router：** 管理全球服务网格。\n*   **掩盖硬件故障：** 机器数量增加意味着故障可能性更高。Meta通过构建新系统确保向用户掩盖故障，提供高可用性服务：\n    *   **Kraken：** 利用实时流量负载测试识别和解决资源利用瓶颈。\n    *   **Taiji：** 管理用户流量负载均衡。\n    *   **Maelstrom：** 安全高效地处理数据中心规模的灾难。\n\n## AI工作负载的出现 (2020)\n\n在应对扩展挑战的同时，Meta也预见到AI工作负载将如何影响其基础设施。\n*   **GPU的兴起：** 2010年代末，短视频的流行带来了个性化推荐的需求。这与Meta之前基于社区兴趣的排名方式截然不同。个性化推荐需要理解平台上所有上传的视频，并为每个人挑选感兴趣的视频，这需要处理比朋友互动内容大几个数量级的数据。\n    *   **GPU的作用：** GPU作为向量和矩阵处理机器，比CPU能执行多几个数量级的计算。通过将视频库构建成数学表示（嵌入），AI结合内容相似性的数学概念和GPU的计算能力，提供个性化推荐。\n*   **AI集群：** 与传统互联网服务不同，AI集群是由数百甚至数千个极其强大的GPU组成的高性能计算系统，配备充足内存、高带宽低延迟网络和定制软件堆栈，以榨取最大性能。Meta最初的AI集群互连了4k个GPU用于训练排名和推荐模型。\n*   **整体规划：** 随着AI集群的规模和复杂性增长，Meta意识到需要对数据中心空间、冷却、机械系统、硬件、网络、存储和软件进行整体规划。\n\n## 大型语言模型的崛起 (2022)\n\n2022年大型语言模型（LLM）的兴起带来了新的挑战。\n*   **计算需求激增：** LLM需要显著更多的计算能力，并且投入的计算资源越多，模型质量越好。Meta的训练任务规模在几周内从128个GPU迅速扩展到2k，然后是4k个GPU。\n*   **同步运行挑战：** 首次需要数千个GPU同步运行训练任务。任何一个滞后的GPU都可能影响整个集群的性能。GPU故障、内存错误、网络抖动等问题都可能导致整个训练任务停止。\n*   **可靠性提升：** 通过与行业和合作伙伴的协作，Meta将中断率降低了约50倍。\n*   **AI基础设施研发：** LLM也影响了排名和推荐模型的开发，例如分层序列转导单元（HSTU）将生成式推荐器的训练和推理速度提高了10-1000倍。\n\n## 加速GPU规模和AI基础设施 (2023)\n\nMeta致力于构建更大规模的AI集群。\n*   **24k H100集群：** 2023年末，Meta利用数据中心建筑的全部可用电力，构建了两个各包含24k个H100 GPU的集群，分别使用Infiniband和RoCE网络技术，为Llama 3等大型LLM模型训练提供所需容量。\n*   **129k H100集群：** 鉴于AI研究人员发现投入的计算能力越多，LLM模型质量和性能越高，Meta的基础设施工程师被要求将AI集群规模再扩大一个数量级。Meta采取了前所未有的举措：清空了五个生产数据中心，在数月内构建了一个包含129k个H100 GPU的单一AI集群。\n*   **效率挑战与多供应商策略：** Meta面临的最终挑战是效率问题：如何最有效地支持异构AI工作负载，并最大化数据中心容量利用率。Meta与AMD、NVIDIA等合作伙伴以及自研芯片合作，鼓励市场多样性，以期获得更健康的生态系统和更好的长期解决方案。\n\n**相关媒体：**\n\n*   **视频：** [Meta数据中心AI基础设施视频](https://engineering.fb.com/wp-content/uploads/2025/09/Meta-data-centers-AI-Infra-video_small.mp4)",
      "shortSummary": "Meta在21年间从小型社交网络发展为服务34亿用户的全球平台，其基础设施经历了从软件扩展到全球数据中心建设的巨大演进。2020年后，AI工作负载，特别是短视频推荐和大型语言模型（LLM），彻底改变了基础设施需求。Meta通过部署大规模GPU集群（如129k H100 GPU集群）、解决缓存一致性和硬件故障等挑战，并投资于定制硬件和软件，以支持其日益增长的AI雄心。公司致力于开放标准和多供应商合作，以实现高效、可靠的AI基础设施。",
      "translated_title": "Meta的基础设施演进与人工智能的到来",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>&#160; Over the past 21 years, Meta has grown exponentially from a small social network connecting a few thousand people in a handful of universities in the U.S. into several apps and novel hardware products that serve over 3.4 billion people throughout the world. Our infrastructure has evolved significantly over the years, growing from a [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/\">Meta’s Infrastructure Evolution and the Advent of AI</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    }
  ],
  "lastUpdated": "2025-10-15T05:27:02.299Z"
}
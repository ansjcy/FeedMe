{
  "sourceUrl": "https://engineering.fb.com/feed/",
  "title": "Engineering at Meta",
  "description": "Engineering at Meta Blog",
  "link": "https://engineering.fb.com/",
  "items": [
    {
      "title": "使用基线配置文件加速我们的安卓应用 (原标题: Accelerating our Android apps with Baseline Profiles)",
      "link": "https://engineering.fb.com/2025/10/01/android/accelerating-our-android-apps-with-baseline-profiles/",
      "pubDate": "Wed, 01 Oct 2025 16:00:17 +0000",
      "isoDate": "2025-10-01T16:00:17.000Z",
      "creator": "",
      "summary": "# 使用基线配置文件加速Meta的安卓应用\n\nMeta公司致力于提升其数十亿安卓用户的应用体验。本文探讨了Meta如何利用Android的基线配置文件（Baseline Profiles）显著改善其安卓应用的性能，某些关键指标提升高达40%。\n\n## 应用性能的重要性与挑战\n\n良好的应用性能对用户体验至关重要。启动缓慢、掉帧和响应迟钝都会导致用户沮丧并最终流失。除了在开发过程中注重性能（如使用合适的数据结构、算法和缓存策略），理解编译代码的底层表示及其加载和执行方式也同样重要，以便优化构建工具和运行时。\n\nMeta在过去几年中开发了针对安卓应用的配置文件引导编译器和运行时优化基础设施，其中Android Runtime (ART) 的基线配置文件是核心组件。\n\n### ART性能考量\n\n*   **代码编译与执行：** Android应用主要使用Kotlin和Java，它们被编译成Dalvik字节码（Dex代码）。ART必须将Dex代码翻译成机器码才能执行。\n*   **默认执行流程：** 运行时，Dex方法会同时通过解释器执行并进行分析，以确定是否为“热点”方法。一旦确定为热点，ART的即时编译器（JIT）会将其编译成机器码，后续执行将使用编译后的版本（机器码通常比解释执行快得多）。\n*   **性能开销：** 类加载和Dex方法解释/分析阶段都会产生运行时开销，可能导致用户可感知的性能下降。\n*   **冷启动问题：** 应用首次启动（冷启动）时，类需要重新加载。每次应用版本更新后，即使编译过的方法也需要重新分析和编译。\n\n### Meta移动应用面临的挑战\n\n*   **用户访问主要途径：** Meta的大多数用户通过移动应用访问，其中大部分是安卓用户。\n*   **平衡开发速度与性能：** 在快速迭代新功能（如Instagram Reels、Messenger端到端加密）的同时，保持高性能是一个挑战。\n*   **启动性能：** 启动性能尤为关键，对用户体验影响巨大。Facebook和Instagram在启动时会加载超过20,000个类，滚动信息流时还会加载数千个。\n*   **用户旅程优化：** 除了启动，Meta还关注启动后的用户旅程性能，例如信息流滚动、照片加载和渲染时间。这些旅程根据用户行为和发生场景进行细分（例如，滚动信息流与滚动收件箱是不同的）。\n*   **代码库的动态性：** Meta的单体仓库每天有数千次提交。用户数据收集到的类加载配置文件差异巨大，即使是同一用户在不同时间、不同实验组下也可能不同。\n*   **解决方案需求：** 需要一个能够智能适应频繁代码变更、快速生成编译代码和配置文件，并能同时优化启动和其他用户旅程的解决方案。\n\n## ART安装时优化\n\n自Android 9以来，ART提供了以下安装时优化：\n\n1.  **AOT（Ahead of Time）编译：** 在应用首次运行前，将指定方法编译成机器码，消除初始执行时的解释和分析开销。\n2.  **应用镜像（App Image）创建：** 包含指定类的内存中ART数据结构的局部表示。应用启动时，应用镜像被映射到进程堆中，从而实现极快的类加载，并消除后续运行时加载这些类的成本。\n\n这些优化通过在应用安装时向ART提供特殊配置文件来触发，主要机制有两种：云配置文件（Cloud Profiles）和基线配置文件（Baseline Profiles）。\n\n### 云配置文件（Cloud Profiles）\n\n*   **生成方式：** 由Google Play在应用版本首次发布期间收集和聚合大量用户的分析数据。\n*   **应用方式：** 一旦云配置文件生成，所有后续通过Google Play安装该应用版本的用户都会收到该配置文件，ART会用它进行AOT编译和应用镜像创建。\n*   **缺点：**\n    *   早期用户无法受益，因为他们是数据提供者。\n    *   应用开发者无法观察或控制配置文件中的类和方法。\n    *   配置文件强烈倾向于早期启动性能改进。\n    *   仅通过Google Play提供，其他安装方式（如其他应用商店或侧载）无法使用。\n\n### 基线配置文件（Baseline Profiles）\n\n*   **核心特点：** 与云配置文件类似，也触发ART安装时优化，但由应用开发者生成和提供，并可打包在APK或AAB中。\n*   **与云配置文件的协同：** 当两者都可用时，可以协同使用。\n*   **优势：**\n    *   **开发者完全控制：** 开发者可以完全控制安装时优化，使其更符合应用的特定需求，包括优化启动之外的场景。\n    *   **即时可用：** 用户可以立即受益。\n    *   **生成方式灵活：** 可以通过基准测试（如Google的Macrobenchmark）生成，也可以通过`profgen`工具直接指定类和方法。\n\n## Meta如何创建基线配置文件\n\nMeta利用基线配置文件解决了其安卓应用性能面临的诸多挑战，尤其是在冷启动和每周更新导致编译代码被清除的问题上。\n\n### 数据收集与处理\n\nMeta最初使用AndroidX库附带的静态配置文件。如今，Meta采用了一套复杂的收集技术来生成应用配置文件：\n\n*   **基准测试：** 对部分应用使用本地基准测试，通过内部工具收集类和方法使用信息。\n*   **用户数据（针对复杂应用）：** 对于Facebook和Instagram等复杂应用，Meta还会从用户那里收集类和方法使用数据，以获得更全面的视图。\n    *   **类使用数据：** 使用自定义ClassLoader，插入代码记录加载的类，并以极低的采样率有条件地启用上传。收集到的类加载日志经过聚合，根据出现频率，超过特定阈值的类会被包含在下一版本的基线配置文件中。\n    *   **方法使用数据：** 通过应用内专门的遥测技术，识别用户通常调用的方法集群，并以类似方式进行采样和聚合。\n*   **配置文件生成：** 所有收集到的数据被组合成一个“人类可读配置文件”（Human Readable Profile），然后输入给`profgen`工具，生成最终的基线配置文件。\n\n### 人类可读配置文件示例（格式描述）\n\n人类可读配置文件采用特定格式，例如：\n*   `#` 用于注释行。\n*   类可以直接通过其描述符指定。\n*   方法可以直接指定，并可带可选标志。\n*   可以使用通配符匹配所有符合给定前缀的类或方法。\n\n### 调优与实验\n\n*   **初始策略：** Meta最初将冷启动作为主要优化目标，保守地设置了较高的类和方法包含频率阈值（要求在80%到90%的用户跟踪中出现）。\n*   **担忧：** 过大的基线配置文件可能导致性能下降，因为编译后的机器码通常比原始解释代码大10倍，会增加I/O成本。\n*   **持续优化：** 随着时间的推移，Meta尝试了不同的包含阈值，并将优化范围从冷启动扩展到其他用户交互。目前，对于大多数应用，只要在20%或更多的冷启动用户跟踪中出现的类和方法，都会被包含在内。\n*   **优化场景：** 已通过基线配置文件优化的交互包括Facebook和Instagram的信息流滚动，以及Messenger和Instagram私信中从聊天列表到聊天视图的导航。",
      "shortSummary": "Meta利用Android的基线配置文件（Baseline Profiles）显著提升了其安卓应用的性能，某些关键指标提升高达40%。面对启动慢、帧率下降等挑战，Meta发现传统的云配置文件存在局限。基线配置文件赋予开发者完全控制权，可根据用户数据（包括基准测试和真实用户行为）定制优化，预编译热点代码和类，从而加速应用启动和关键用户旅程。通过持续的实验和调整，Meta已将优化范围从冷启动扩展到新闻推送滚动等多种用户交互。",
      "translated_title": "使用基线配置文件加速我们的安卓应用",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Key Takeways: With billions of Android app users, we’re always looking to improve the Meta app experience, and in this post, we explore the ways we’ve leveraged Android’s Baseline Profiles to significantly improve their performance. We discuss the performance challenges we’ve faced as Meta’s apps, how the needs of users have become more complex over [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/10/01/android/accelerating-our-android-apps-with-baseline-profiles/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/10/01/android/accelerating-our-android-apps-with-baseline-profiles/\">Accelerating our Android apps with Baseline Profiles</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "大型语言模型是变异测试和更好合规性的关键 (原标题: LLMs Are the Key to Mutation Testing and Better Compliance)",
      "link": "https://engineering.fb.com/2025/09/30/security/llms-are-the-key-to-mutation-testing-and-better-compliance/",
      "pubDate": "Tue, 30 Sep 2025 16:00:08 +0000",
      "isoDate": "2025-09-30T16:00:08.000Z",
      "creator": "",
      "summary": "大型语言模型（LLM）正在变革Meta的软件测试和合规性流程，通过其**自动化合规性强化（ACH）工具**实现。该工具已在FSE 2025和Eurostar 2025会议上进行主题演讲，旨在自动化合规性，加速开发速度，并克服传统变异测试的规模化障碍。\n\n### Meta的ACH工具：LLM驱动的解决方案\n\n传统上，合规性依赖手动流程，效率低下且难以扩展。Meta通过投资先进的AI检测机制，特别是ACH工具，来解决这一问题。ACH工具利用LLM进行**变异引导的测试生成**，其核心功能包括：\n\n*   **引入故障（变异体）**：故意在源代码中引入故障，以评估测试框架检测这些故障的能力。\n*   **生成相关变异体和测试**：结合自动化测试生成技术与LLM，创建高度相关的变异体以及能够捕获这些变异体的测试。\n*   **直观操作**：工程师通过简单的纯文本提示描述要测试的变异体，使过程直观可靠。\n*   **预防性识别**：ACH能更轻松、更主动地识别可能影响合规性的bug，并阻止它们进入系统，从而确保代码库的风险弹性。\n\n### 传统变异测试面临的挑战\n\n尽管变异测试被认为是评估测试质量的强大方法，但其大规模部署一直面临五大障碍：\n\n1.  **不可扩展性**：生成大量变异体，计算成本高昂，难以应用于大型工业代码库。\n2.  **生成不切实际的变异体**：传统的基于规则的变异操作符生成通用、与上下文无关的变异体，不代表开发者实际关注的故障。\n3.  **等价变异体浪费资源**：语法不同但语义等价的变异体难以识别，浪费开发时间和计算资源。\n4.  **高计算资源需求**：运行测试和分析结果需要大量基础设施和时间，在快节奏的工业环境中难以承受。\n5.  **过度拉伸测试工作**：可能专注于捕获低影响故障，导致测试投入产出比降低。\n\n### LLM如何解决变异测试的挑战\n\nMeta利用其庞大的bug数据训练LLM，以指导测试生成。ACH系统通过以下方式克服了上述障碍：\n\n1.  **实现可扩展的变异测试**：ACH利用LLM生成更少、更真实、更具体的变异体（例如，针对隐私故障），从而提高相关性和可扩展性。\n2.  **创建真实的变异体**：安全或隐私工程师可以通过文本描述关注的问题，生成高度真实的问题特定bug。\n3.  **检测并消除等价变异体**：ACH包含一个基于LLM的等价检测器，结合简单的静态分析预处理，能高效识别等价变异体（高精度和召回率），并自动生成杀死非等价变异体的单元测试。\n4.  **生成高效且易于部署的测试**：\n    *   在2024年10月至12月的试点中，ACH在Meta的多个平台（包括Facebook、Instagram、WhatsApp、Quest和Ray-Ban Meta眼镜）上用于隐私测试。\n    *   在数千个变异体和数百个生成测试中，隐私工程师接受了73%的生成测试，其中36%被判定为与隐私相关。\n    *   工程师们重视评估测试而非构建测试，这显著提高了效率。\n5.  **防止过度拉伸**：ACH生成与关注问题紧密耦合的变异体，并生成捕获现有测试遗漏故障的测试，有效提高了测试覆盖率和质量。\n\n### “及时测试捕获”（JiTTest）挑战：LLM在软件测试中的新前沿\n\nLLM为自动化软件测试（包括强化测试和捕获测试）开辟了新的探索领域。Meta特别关注**“及时测试”（JiTTest）**的生成，即在拉取请求合并前及时生成测试进行人工审查，以在代码进入生产环境前捕获故障。\n\n*   **核心挑战**：**测试预言问题（Test Oracle Problem）**，即区分给定输入下的预期正确行为与错误行为。\n*   **社区邀请**：Meta提出了“及时测试捕获”（JiTTest）挑战，鼓励社区构建能够高精度检测拉取请求中bug的系统，同时保持人工参与以确保低误报率。\n*   相关研究论文：“Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges”已作为FSE 2025的主题演讲发布。\n\n### LLM与软件测试的未来\n\nAI正在帮助Meta简化和优化其合规性和整体风险管理框架。未来的工作方向包括：\n\n*   **ACH的扩展**：将ACH的应用扩展到其他领域和更多编程语言（目前主要为Kotlin和隐私测试）。\n*   **提高精确性**：研究如何利用微调和提示工程使变异体生成更加精确和相关。\n*   **解决测试预言问题**：探索实现高精度故障检测并避免误报的方法。\n*   **关注人机交互**：研究开发者如何与LLM生成的测试进行交互，以提高其采用率和可用性。\n\nMeta将在即将举行的Product@Scale会议上分享更多工作，并邀请社区共同探索AI在软件测试和风险管理领域的潜力。",
      "shortSummary": "Meta正利用其基于大型语言模型（LLM）的自动化合规性强化（ACH）工具，革新软件测试和合规性。ACH通过生成更少、更真实、问题特定的变异体，并自动生成捕获这些变异体的测试，解决了传统变异测试在可扩展性、真实性、等价变异体处理和资源消耗方面的五大挑战。该工具显著简化了风险评估，降低了开发者负担，并实现了持续合规。Meta还提出了“及时测试捕获”（JiTTest）挑战，旨在利用LLM在代码进入生产前，高精度地发现拉取请求中的bug，推动LLM在软件测试领域的进一步应用。",
      "translated_title": "大型语言模型是变异测试和更好合规性的关键",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Following our keynote presentations at FSE 2025 and Eurostar 2025, we’re delving further into the development of Meta’s Automated Compliance Hardening (ACH) tool, an LLM-based tool for software testing that is automating aspects of compliance adherence at Meta, while accelerating developer and product velocity. By leveraging LLMs we’ve been able to overcome the barriers that [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/30/security/llms-are-the-key-to-mutation-testing-and-better-compliance/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/30/security/llms-are-the-key-to-mutation-testing-and-better-compliance/\">LLMs Are the Key to Mutation Testing and Better Compliance</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Meta 3D AssetGen：用AI生成3D世界 (原标题: Meta 3D AssetGen: Generating 3D Worlds With AI)",
      "link": "https://engineering.fb.com/2025/09/29/virtual-reality/assetgen-generating-3d-worlds-with-ai/",
      "pubDate": "Mon, 29 Sep 2025 14:00:42 +0000",
      "isoDate": "2025-09-29T14:00:42.000Z",
      "creator": "",
      "summary": "## Meta 3D AssetGen：用AI生成3D世界\n\n### 引言\n\nAI与VR的结合是今年Meta Connect大会上的一个重要议题。马克·扎克伯格在主题演讲中分享了他的愿景：未来任何人都可以像生成图片一样，通过AI工具（例如即将推出的Meta Horizon Studio中的工具）轻松创建虚拟世界。AI正在以前所未有的方式简化3D资产的创建。\n\n### AssetGen：3D资产的AI基础模型\n\n*   **核心概念**：Meta正在开发AssetGen，这是一个用于3D资产的新型基础模型。\n*   **团队与讨论**：在Meta Tech播客的一期节目中，Meta XR技术团队的Mahima和Rakesh讨论了AssetGen。\n*   **主要目标**：该模型旨在通过简单的文本提示生成整个3D世界，实现从文本到3D内容的直接转换。\n\n### AssetGen的开发与愿景\n\n*   **构建与训练**：播客中详细介绍了AssetGen的构建和训练过程。\n*   **LLMs的作用**：讨论了大型语言模型（LLMs）在VR未来中将扮演的重要角色。\n*   **雄心勃勃的目标**：团队正在努力实现从简单的文本提示生成完整3D世界的宏伟目标。\n\n### 相关资源\n\n*   **Meta Tech播客**：关于AssetGen的详细讨论可在Meta Tech播客中收听。\n*   **收听平台**：该播客可在Spotify、Apple Podcasts、Pocket Casts等平台获取。\n*   **Meta Tech播客简介**：该播客由Meta推出，旨在展示Meta工程师在从底层框架到终端用户功能各个层面的工作。\n*   **职业机会**：对Meta职业机会感兴趣的读者可以访问Meta Careers页面。",
      "shortSummary": "Meta正在通过其新的AI基础模型AssetGen，推动AI在3D世界创建中的应用。在Meta Connect大会上，马克·扎克伯格展望了未来，用户能像生成图片一样，通过文本提示轻松创建虚拟世界。AssetGen由Meta的XR技术团队开发，旨在简化3D资产的生成，并最终实现从简单文本提示生成完整的3D世界，大型语言模型在此过程中扮演关键角色。",
      "translated_title": "Meta 3D AssetGen：用AI生成3D世界",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Imagine being able to use AI to create 3D virtual worlds using prompts as easily as you can generate images. The intersection of AI and VR was one of the biggest topics at Meta Connect this year. In his keynote, Mark Zuckerberg shared his vision of a future where anyone can create virtual worlds using [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/29/virtual-reality/assetgen-generating-3d-worlds-with-ai/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/29/virtual-reality/assetgen-generating-3d-worlds-with-ai/\">Meta 3D AssetGen: Generating 3D Worlds With AI</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Meta的基础设施演进与人工智能的到来 (原标题: Meta’s Infrastructure Evolution and the Advent of AI)",
      "link": "https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/",
      "pubDate": "Mon, 29 Sep 2025 13:00:15 +0000",
      "isoDate": "2025-09-29T13:00:15.000Z",
      "creator": "",
      "summary": "# Meta的基础设施演进与人工智能的到来\n\nMeta在过去21年里实现了指数级增长，从一个连接数千人的小型社交网络发展成为服务全球34亿多用户的多个应用和创新硬件产品。公司的基础设施也随之发生了显著演变，从少数服务器上的软件系统发展成为一个庞大的全球网络化运营体系。人工智能（AI）的出现彻底改变了Meta对基础设施扩展的假设，要求在硬件、软件、网络和数据中心等堆栈的每个层面进行创新。Meta秉承其开源根基，通过研究论文和开源硬件/软件系统与工程社区分享其工作，并致力于在推动计算机科学前沿的同时，采用开放标准方法来构建芯片和硬件系统。\n\n## 基础设施堆栈的扩展 (2004 – 2010)\n\n在早期，Meta的工程工作主要集中在软件堆栈的扩展上。\n*   **软件扩展：** 随着Facebook从哈佛扩展到其他大学，然后是高中和公众，用户数量急剧增加。Meta通过扩展Memcache部署、构建TAO社交图谱、开发新的缓存和数据管理系统来管理数据库负载。同时，还开发了新闻源的排名服务和照片分享服务。\n*   **物理基础设施扩展：** 随着用户群扩展到欧洲，仅靠软件扩展已不足够。Meta开始扩展其物理基础设施，从湾区的小型合租设施扩展到弗吉尼亚州的合租设施，并建设了其首批数据中心（俄勒冈州的普林维尔和北卡罗来纳州的森林城）。\n*   **面临的挑战及解决方案：**\n    *   **用户连接：** 为连接分布在美国和欧洲的用户到数据中心，Meta积极建设边缘基础设施，在每个本地互联网服务提供商（ISP）旁获取计算能力，并投资于连接ISP和数据中心的对等网络。\n    *   **软件复制：** 为确保用户无论连接到哪个物理位置都能获得相同体验，Meta需要在每个数据中心复制整个软件堆栈。这要求构建一个互连数据中心的高带宽、多路径骨干网络，最初通过建设陆地光纤网络实现。\n*   **全球化：** 随着用户群的全球增长，Meta超越了单一数据中心建筑，发展为由多个建筑组成的数据中心区域，并在全球运营数百个接入点（POPs）。\n\n## 扩展的挑战 (2010 – 2020)\n\n构建全球基础设施带来了复杂的计算机科学挑战。\n*   **缓存一致性：** 跨数据中心区域的数据更新延迟导致用户体验不一致。Meta通过构建新颖的软件系统提供缓存失效，并最终为分布式系统构建了一致性API来解决这些问题。\n*   **集群管理：** 随着数据中心区域和机器集群的增长，Meta开发了新的抽象层来管理它们，包括：\n    *   **Twine：** 可扩展管理数据中心区域内数百万台机器的集群管理系统。\n    *   **Tectonic：** 数据中心规模的分布式文件系统。\n    *   **ZippyDB：** 强一致性分布式键值存储。\n    *   **Shard Manager：** 管理数千万个数据分片，托管在数十万台服务器上。\n    *   **Delos：** Meta全球基础设施的新控制平面。\n    *   **Service Router：** 管理全球服务网格。\n*   **掩盖硬件故障：** 机器数量增加意味着故障可能性更高。Meta通过构建新系统确保向用户掩盖故障，提供高可用性服务：\n    *   **Kraken：** 利用实时流量负载测试识别和解决资源利用瓶颈。\n    *   **Taiji：** 管理用户流量负载均衡。\n    *   **Maelstrom：** 安全高效地处理数据中心规模的灾难。\n\n## AI工作负载的出现 (2020)\n\n在应对扩展挑战的同时，Meta也预见到AI工作负载将如何影响其基础设施。\n*   **GPU的兴起：** 2010年代末，短视频的流行带来了个性化推荐的需求。这与Meta之前基于社区兴趣的排名方式截然不同。个性化推荐需要理解平台上所有上传的视频，并为每个人挑选感兴趣的视频，这需要处理比朋友互动内容大几个数量级的数据。\n    *   **GPU的作用：** GPU作为向量和矩阵处理机器，比CPU能执行多几个数量级的计算。通过将视频库构建成数学表示（嵌入），AI结合内容相似性的数学概念和GPU的计算能力，提供个性化推荐。\n*   **AI集群：** 与传统互联网服务不同，AI集群是由数百甚至数千个极其强大的GPU组成的高性能计算系统，配备充足内存、高带宽低延迟网络和定制软件堆栈，以榨取最大性能。Meta最初的AI集群互连了4k个GPU用于训练排名和推荐模型。\n*   **整体规划：** 随着AI集群的规模和复杂性增长，Meta意识到需要对数据中心空间、冷却、机械系统、硬件、网络、存储和软件进行整体规划。\n\n## 大型语言模型的崛起 (2022)\n\n2022年大型语言模型（LLM）的兴起带来了新的挑战。\n*   **计算需求激增：** LLM需要显著更多的计算能力，并且投入的计算资源越多，模型质量越好。Meta的训练任务规模在几周内从128个GPU迅速扩展到2k，然后是4k个GPU。\n*   **同步运行挑战：** 首次需要数千个GPU同步运行训练任务。任何一个滞后的GPU都可能影响整个集群的性能。GPU故障、内存错误、网络抖动等问题都可能导致整个训练任务停止。\n*   **可靠性提升：** 通过与行业和合作伙伴的协作，Meta将中断率降低了约50倍。\n*   **AI基础设施研发：** LLM也影响了排名和推荐模型的开发，例如分层序列转导单元（HSTU）将生成式推荐器的训练和推理速度提高了10-1000倍。\n\n## 加速GPU规模和AI基础设施 (2023)\n\nMeta致力于构建更大规模的AI集群。\n*   **24k H100集群：** 2023年末，Meta利用数据中心建筑的全部可用电力，构建了两个各包含24k个H100 GPU的集群，分别使用Infiniband和RoCE网络技术，为Llama 3等大型LLM模型训练提供所需容量。\n*   **129k H100集群：** 鉴于AI研究人员发现投入的计算能力越多，LLM模型质量和性能越高，Meta的基础设施工程师被要求将AI集群规模再扩大一个数量级。Meta采取了前所未有的举措：清空了五个生产数据中心，在数月内构建了一个包含129k个H100 GPU的单一AI集群。\n*   **效率挑战与多供应商策略：** Meta面临的最终挑战是效率问题：如何最有效地支持异构AI工作负载，并最大化数据中心容量利用率。Meta与AMD、NVIDIA等合作伙伴以及自研芯片合作，鼓励市场多样性，以期获得更健康的生态系统和更好的长期解决方案。\n\n**相关媒体：**\n\n*   **视频：** [Meta数据中心AI基础设施视频](https://engineering.fb.com/wp-content/uploads/2025/09/Meta-data-centers-AI-Infra-video_small.mp4)",
      "shortSummary": "Meta在21年间从小型社交网络发展为服务34亿用户的全球平台，其基础设施经历了从软件扩展到全球数据中心建设的巨大演进。2020年后，AI工作负载，特别是短视频推荐和大型语言模型（LLM），彻底改变了基础设施需求。Meta通过部署大规模GPU集群（如129k H100 GPU集群）、解决缓存一致性和硬件故障等挑战，并投资于定制硬件和软件，以支持其日益增长的AI雄心。公司致力于开放标准和多供应商合作，以实现高效、可靠的AI基础设施。",
      "translated_title": "Meta的基础设施演进与人工智能的到来",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>&#160; Over the past 21 years, Meta has grown exponentially from a small social network connecting a few thousand people in a handful of universities in the U.S. into several apps and novel hardware products that serve over 3.4 billion people throughout the world. Our infrastructure has evolved significantly over the years, growing from a [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/29/data-infrastructure/metas-infrastructure-evolution-and-the-advent-of-ai/\">Meta’s Infrastructure Evolution and the Advent of AI</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "网络：人工智能的核心 — @Scale: 网络 2025 回顾 (原标题: Networking at the Heart of AI — @Scale: Networking 2025 Recap)",
      "link": "https://engineering.fb.com/2025/09/26/networking-traffic/networking-at-the-heart-of-ai-scale-networking-2025-recap/",
      "pubDate": "Fri, 26 Sep 2025 16:00:52 +0000",
      "isoDate": "2025-09-26T16:00:52.000Z",
      "creator": "",
      "summary": "# 网络：人工智能的核心 — @Scale: 网络 2025 回顾\n\n## 引言\n人工智能（AI）已无处不在，网络工程师在构建AI网络基础设施中扮演着核心角色。在有史以来规模最大的 @Scale: Networking 2025 大会上，来自Meta、字节跳动、谷歌、微软、甲骨文、AMD、博通、思科和英伟达的工程师们齐聚一堂，分享了他们在架构、设计、运营和调试AI网络方面的最新经验。网络在推动大规模AI发展方面发挥了至关重要的作用，并将继续定义AI的未来。\n\n## 背景：快速变化与演进\n鉴于AI持续推动网络和通用基础设施的创新，@Scale: Networking 大会再次聚焦AI网络，分享了该领域的最新见解和进展。过去一年中，出现了两个重要趋势：\n\n### AI基础设施成为焦点\n*   整个行业，AI公司计划在未来几年内投入数千亿美元用于基础设施建设。\n*   Meta 在此方面进行了大量投资，包括：\n    *   建设千兆瓦级集群，如 Prometheus 和 Hyperion，提供清洁可再生能源。\n    *   铺设全球最大的跨洋光缆系统，确保全球数十亿人能够访问AI创新。\n    *   短期内，甚至通过“临时结构”（sprung structures）扩展建设组合，以尽快上线容量。\n\n### 模型和主要AI工作负载的快速演进\n*   过去几年主要关注大规模基础训练的需求。\n*   Meta 在不到两年内，将基于以太网/RoCE的GPU集群从4K扩展到24K，再到129K，每次飞跃都应对了高性能和高可靠性的新挑战。\n*   在过去9-12个月中，工作负载迅速扩展，包括：\n    *   专家混合模型（mixture-of-experts）\n    *   推理模型（reasoning models）\n    *   强化学习（reinforcement learning）\n    *   后训练（post-training）\n    *   合成数据生成（synthetic data generation）\n    *   分布式推理（distributed inference）\n    *   这些多样化的工作负载都对网络提出了不同的要求。\n\n## 网络在AI中的作用\n在上述背景下，网络的重要性愈发凸显。\n\n### 网络即计算机\n*   在快速变化的AI工作负载和大规模物理基础设施建设之间，网络扮演着接口角色，尽可能地将底层基础设施抽象化，以适应工作负载。\n*   从模型的角度来看，基础设施应表现为一个巨大的GPU，而网络是实现这一抽象的关键。\n\n### 与AI堆栈协同设计网络\n*   实现这一抽象目标需要解决诸多挑战，例如：\n    *   不同距离和带宽（尤其是在横向扩展和纵向扩展领域）。\n    *   不同加速器、网卡（NIC）和网络结构（fabrics）的硬件多样性。\n*   这是一个全栈/端到端的问题，需要利用在网卡、路由和拥塞控制方面的所有经验，并与基于GPU的堆栈紧密协调。\n\n### 可靠性是关键\n*   不仅要提供模型所需的高性能和易用性，还必须以高可靠性运行基础设施，无缝地发现并快速响应故障。\n\n### 创新与选择性\n*   未来需要持续创新以保持领先地位并提供选择性，因为预计模型/工作负载和基础设施的其余部分将不断变化。\n*   目标是构建一个网络堆栈，融合高性能计算的最佳能力与开放、可扩展的分布式系统原则，以应对未来的任何挑战。\n\n## @Scale: Networking 2025 大会回顾\n*   所有会议演讲均可在 @Scale YouTube 频道上查看。\n*   Meta 持续组织 @Scale 系列活动（系统与可靠性、AI与数据、以及即将到来的十月产品大会），旨在促进社区分享创新和挑战，并相互学习。\n*   本次大会的演讲和现场问答围绕两大主题：\n    *   **底层物理网络基础设施：** 交换机拓扑和控制平面、网卡和主机网络、可扩展操作/高可靠性。\n    *   **高层、面向模型的议题：** 并行设计、作业级可调试性、大规模预训练的扩展、以及强化学习、专家混合模型和推理等新用例的处理。\n*   关于AI和网络未来的展望，大会邀请了Meta和微软进行主题演讲，并举办了由主要GPU和网络ASIC供应商参与的厂商小组讨论。\n*   文章感谢所有参与分享最新经验的公司和个人，并期待2026年的 @Scale: Networking 大会能再次覆盖网络和AI领域的快速创新。",
      "shortSummary": "@Scale: Networking 2025 大会强调网络是AI基础设施的核心。随着AI基础设施的巨大投资和工作负载的快速演进，网络工程师面临构建高性能、高可靠性AI网络的挑战。网络被视为“计算机”，负责抽象底层硬件，需要与AI堆栈协同设计，并持续创新。来自Meta、字节跳动、谷歌等公司的专家分享了在物理网络和模型层面应对这些挑战的最新经验，展望了AI与网络融合的未来。",
      "translated_title": "网络：人工智能的核心 — @Scale: 网络 2025 回顾",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>AI is everywhere and, as network engineers, we are right in the thick of it: building the network infrastructure for AI. This year, at  our largest @Scale:Networking ever, engineers from Meta, ByteDance, Google, Microsoft, Oracle, AMD, Broadcom, Cisco, and NVIDIA came together to share our latest experiences in architecting, designing, operating, and debugging our AI [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/26/networking-traffic/networking-at-the-heart-of-ai-scale-networking-2025-recap/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/26/networking-traffic/networking-at-the-heart-of-ai-scale-networking-2025-recap/\">Networking at the Heart of AI — @Scale: Networking 2025 Recap</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "移动设备上的AV1视频编解码器流媒体 (原标题: Video Streaming With the AV1 Video Codec in Mobile Devices)",
      "link": "https://engineering.fb.com/2025/09/24/video-engineering/video-streaming-with-av1-video-codec-mobile-devices-meta-white-paper/",
      "pubDate": "Wed, 24 Sep 2025 08:00:44 +0000",
      "isoDate": "2025-09-24T08:00:44.000Z",
      "creator": "",
      "summary": "# 移动设备上的AV1视频编解码器流媒体白皮书要点\n\nMeta、沃达丰和谷歌联合发布了一份题为《移动设备上的AV1视频编解码器流媒体》的白皮书，详细阐述了AV1编解码器在提升移动设备视频流媒体体验方面的诸多优势。该白皮书旨在推广AV1这一先进视频压缩技术。\n\n## AV1编解码器的核心优势\n\n*   **卓越的压缩效率：** AV1是一种先进的视频压缩技术，与H.264和VP9等早期标准相比，其视频压缩效率可提高高达30%。这意味着在相同画质下，AV1能显著减少所需的数据量，适用于大多数视频格式。\n*   **提升用户体验：** 在中低端智能手机上，AV1能够提供与高端手机相媲美的视频质量，并减少缓冲，从而显著改善用户的观看体验。\n*   **优化网络资源：** 视频内容占据了移动数据流量的70-80%。通过更高效的压缩，AV1有助于释放网络容量，降低移动运营商的网络拥堵，并满足日益增长的用户需求。\n*   **节省计算与能源：** AV1的广泛采用有助于优化计算能力、存储空间，并节省计算资源、边缘缓存资源以及能源成本。\n*   **灵活的实现方式：** AV1可以在智能手机中通过软件升级实现，也可以嵌入到移动设备的中央处理器（SoC）中，后者能带来更好的电池效率和性能。\n\n## 白皮书的关键建议\n\n白皮书向行业参与者提出了以下建议：\n\n*   **核心处理器（SoC）供应商：** 应评估并采纳AV1硬件解码方案，以实现卓越的能效压缩增益。\n*   **中低端设备支持：** 对于无法采用硬件方案的设备，供应商应考虑使用基于软件的AV1解码器，以帮助中低端设备过渡到AV1，并确保其也能获得优质的视频体验。\n\n## 当前挑战与合作机遇\n\n*   **市场现状：** 全球约75%的手机销量来自中低端设备。然而，目前许多中低端手机缺乏必要的AV1编解码器支持，特别是内置硬件解码能力，这限制了它们提供无缓冲视频体验的能力。\n*   **芯片组支持：** 智能手机芯片组对AV1编解码器的支持目前主要限于高端产品。\n*   **合作呼吁：** 为了让更多人享受到先进视频压缩技术带来的观看体验提升，白皮书强调了内容提供商、网络运营商、芯片组制造商和设备操作系统开发商之间加强合作的重要性。这种合作旨在确保为终端用户提供最佳的体验质量，同时优化网络资源利用并减少拥堵。\n\n## 结论\n\nAV1技术已经足够成熟，可以帮助运营商应对不断增长的移动设备视频流量，同时在计算、边缘缓存资源和能源成本方面实现节约。推广AV1的采用将有助于移动运营商减少网络容量需求，并更好地满足用户日益增长的需求。",
      "shortSummary": "Meta、沃达丰和谷歌发布白皮书，强调AV1视频编解码器在移动设备上的优势。AV1可将视频压缩效率提高30%，在中低端手机上提供与高端设备相当的视频质量，并释放网络容量。白皮书建议SoC供应商采纳AV1硬件，或在中低端设备上使用软件解码器。AV1有助于优化网络资源、节省成本并提升用户体验，呼吁行业各方合作推广。",
      "translated_title": "移动设备上的AV1视频编解码器流媒体",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>Today, Meta, Vodafone, and Google released a white paper, “Video Streaming with the AV1 Video Codec in Mobile Devices,&#8221; detailing the benefits of the AV1 codec, an advanced video compression technique, to enhance the streaming video experience on mobile devices.  The white paper recommends that: Vendors of core processors (SoCs) should evaluate the adoption of [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/24/video-engineering/video-streaming-with-av1-video-codec-mobile-devices-meta-white-paper/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/24/video-engineering/video-streaming-with-av1-video-codec-mobile-devices-meta-white-paper/\">Video Streaming With the AV1 Video Codec in Mobile Devices</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "阅读Meta的2025年可持续发展报告 (原标题: Read Meta’s 2025 Sustainability Report)",
      "link": "https://sustainability.atmeta.com/2025-sustainability-report/",
      "pubDate": "Fri, 12 Sep 2025 16:36:33 +0000",
      "isoDate": "2025-09-12T16:36:33.000Z",
      "creator": "",
      "summary": "# Meta 2025年可持续发展报告\n\n## 报告愿景：连接到更美好的现实\nMeta的2025年可持续发展报告旨在通过其在气候、负责任的供应链、水资源和生物多样性方面的努力，构建一个更美好的现实。\n\n![户外空旷道路通向山脉](https://sustainability.atmeta.com/wp-content/uploads/2025/08/1_Meta-2025-Sustainability-Landing-Page_Headline_Connecting-to-a-Better-Reality.jpg?resize=5953%2C4802)\n\n![俯瞰树梢和山脉的自然风光](https://sustainability.atmeta.com/wp-content/uploads/2025/08/2_Meta-2025-Sustainability-Landing-Page_Pillar_Climate.jpg?resize=5184%2C2916)\n\n## 可持续发展支柱\n\n### 气候\n随着气候变化影响日益普遍，Meta致力于通过业务脱碳，为建设更健康的地球、更具韧性的社区和净零现实贡献力量。\n\n### 负责任的供应链\nMeta作为复杂价值链的一部分，通过开放沟通、支持安全工作条件的倡议以及对核心可持续发展问题的深入理解，努力赋能工人并保护环境。\n\n![戴安全眼镜和实验服的人用小钳子操作手机](https://sustainability.atmeta.com/wp-content/uploads/2025/08/4_Meta-2025-Sustainability-Landing-Page_Pillar_RSC.jpg?w=1620&resize=1620%2C911)\n\n### 水资源\n水是地球生命的重要资源。Meta致力于通过专业技术和责任管理水资源，以确保健康的水生生态系统。\n\n![海浪拍打海岸的海洋景色](https://sustainability.atmeta.com/wp-content/uploads/2025/08/3_Meta-2025-Sustainability-Landing-Page_Pillar_Water.jpg?w=1620&resize=1620%2C1078)\n\n### 生物多样性\n生物多样性支持生态系统稳定，确保地球上生物繁荣。Meta通过积极行动支持数据中心所在地原生生态系统的生物多样性，并投资当地社区的长期活力。\n\n![野花盛开的草地自然风光](https://sustainability.atmeta.com/wp-content/uploads/2025/08/5_Meta-2025-Sustainability-Landing-Page_Pillar_Biodiversity.jpg?resize=3200%2C2136)\n\n## 目标与承诺\n\nMeta的核心可持续发展战略旨在到2030年实现全价值链净零排放和水资源正效益。为实现向零碳经济和更健康地球的愿景，Meta设定了以下支持目标：\n\n![一个人在刚准备好的土地上植树](https://sustainability.atmeta.com/wp-content/uploads/2025/08/6_Meta-2025-Sustainability-Landing-Page_Goals-and-Commitments.jpg)\n\n*   到2031年，将范围1和范围2排放量在2021年基准上减少42%。\n*   到2026年，使至少三分之二的供应商设定符合科学的减排目标。\n*   到2031年底，范围3排放量不超过2021年基准。\n*   在高水资源压力地区恢复200%的用水量，在中水资源压力地区恢复100%的用水量。\n*   继续以清洁和可再生能源匹配100%的电力使用，以支持运营。\n*   与供应链合作伙伴设定人权和环境期望，并与他们合作建立能力以达到Meta的标准。\n\n## 亮点成就\n\n### 清洁和可再生能源\nMeta支持的风能和太阳能项目在全球电网中增加了超过15吉瓦的清洁和可再生能源。\n\n![日落时分有风力涡轮机的田野](https://sustainability.atmeta.com/wp-content/uploads/2025/08/7_Meta-2025-Sustainability-Landing-Page_Highlight_Clean-and-Renewable-Energy.jpg?w=1620&resize=8272%2C6200)\n\n### 水资源恢复\n自2017年以来，Meta已资助40多个水资源恢复项目。2024年，这些项目在高和中水资源压力地区恢复了超过16亿加仑的水。\n\n![河岸有树木，水流中有植物的河流](https://sustainability.atmeta.com/wp-content/uploads/2025/08/8_Meta-2025-Sustainability-Landing-Page_Highlight_Water-Restoration_PLACEHOLDER-FOR-WATER-PROJECT-1.jpeg?w=1620&resize=3840%2C2160)\n\n### 数据中心园区生物多样性\n超过50%的运营数据中心园区面积（超过4000英亩）已规划、安装或保留，以有意支持本地物种的栖息地。\n\n![位于亚利桑那州梅萨的Meta数据中心](https://sustainability.atmeta.com/wp-content/uploads/2025/08/9_Meta-2025-Sustainability-Landing-Page_Highlight_Data-Center-Campus-Biodiversity.jpeg?w=1620&resize=2048%2C1536)\n\n### 负责任的供应链\nMeta持续在供应商现场推广安全的工艺化学品管理，开展意识提升和风险缓解培训，并支持在可行的情况下用更安全的替代品替换有害化学品。\n\n![穿着安全装备的制造工人](https://sustainability.atmeta.com/wp-content/uploads/2025/08/10_Meta-2025-Sustainability-Landing-Page_Highlight_RSC.jpeg?w=1620&resize=5616%2C3744)\n\n### 为AI设计数据中心\nMeta投资创建可扩展的基础设施，以支持当前和未来的AI需求。其设计融合了高性能和定制解决方案，以更少的占地面积提供相似的计算能力，从而提高了交付时间和成本效率。\n\n![AI数据中心设计图](https://sustainability.atmeta.com/wp-content/uploads/2025/08/Opt3-min-4.jpg)\n\n### 创新投资\n*   2024年，Meta自有数据中心建设废弃物中有91%被转移出垃圾填埋场。\n*   Meta所有自有数据中心均获得LEED金级或更高认证。",
      "shortSummary": "Meta的2025年可持续发展报告阐述了其通过气候行动、负责任的供应链、水资源管理和生物多样性等支柱，实现“连接到更美好现实”的承诺。核心目标是到2030年实现全价值链净零排放和水资源正效益。具体目标包括到2031年减少42%的范围1和2排放，并恢复高水压地区200%的用水。报告亮点包括新增15吉瓦清洁能源、2024年恢复超16亿加仑水、提升数据中心生物多样性，以及推广负责任的供应链实践和可持续的AI数据中心设计。",
      "translated_title": "阅读Meta的2025年可持续发展报告",
      "images": [
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2025/08/1_Meta-2025-Sustainability-Landing-Page_Headline_Connecting-to-a-Better-Reality.jpg?resize=5953%2C4802",
          "alt": "An outdoor scene with an empty road leading toward mountains.",
          "title": "",
          "position": 1
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2025/08/2_Meta-2025-Sustainability-Landing-Page_Pillar_Climate.jpg?resize=5184%2C2916",
          "alt": "A nature scene overlooking treetops and mountains.",
          "title": "",
          "position": 2
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2025/08/4_Meta-2025-Sustainability-Landing-Page_Pillar_RSC.jpg?w=1620&resize=1620%2C911",
          "alt": "A person in safety glasses and a lab coat working on a mobile phone with small pliers.",
          "title": "",
          "position": 3
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2025/08/3_Meta-2025-Sustainability-Landing-Page_Pillar_Water.jpg?w=1620&resize=1620%2C1078",
          "alt": "A view of the ocean, showing waves crashing.",
          "title": "",
          "position": 4
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2025/08/5_Meta-2025-Sustainability-Landing-Page_Pillar_Biodiversity.jpg?resize=3200%2C2136",
          "alt": "A nature scene of a meadow with wildflowers.",
          "title": "",
          "position": 5
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2025/08/6_Meta-2025-Sustainability-Landing-Page_Goals-and-Commitments.jpg",
          "alt": "A person planting trees in freshly prepared ground.",
          "title": "",
          "position": 6
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2024/08/download-icon.png",
          "alt": "",
          "title": "",
          "position": 7
        },
        {
          "url": "https://sustainability.atmeta.com/wp-content/uploads/2024/08/Icon_Expanded__7b2e82.png",
          "alt": "vehicle icon",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "完整文章",
      "content": "<p> [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://sustainability.atmeta.com/2025-sustainability-report/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://sustainability.atmeta.com/2025-sustainability-report/\">Read Meta&#8217;s 2025 Sustainability Report</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "Instagram 提升通知质量的新排名框架 (原标题: A New Ranking Framework for Better Notification Quality on Instagram)",
      "link": "https://engineering.fb.com/2025/09/02/ml-applications/a-new-ranking-framework-for-better-notification-quality-on-instagram/",
      "pubDate": "Tue, 02 Sep 2025 16:00:08 +0000",
      "isoDate": "2025-09-02T16:00:08.000Z",
      "creator": "",
      "summary": "# Instagram 提升通知质量的新排名框架\n\nMeta 正在利用机器学习 (ML) 和多样性算法来改进 Instagram 上的通知质量和用户体验。通过引入一个多样性感知通知排名框架，旨在减少通知的单一性，提供更丰富、更具吸引力的通知组合，从而降低通知总量并提高参与率。\n\n## 引言\n\n通知是促使用户返回 Instagram 并增强参与度的强大工具。无论是朋友点赞照片、亲密朋友发布故事，还是推荐可能喜欢的 Reels，通知都能实时呈现重要时刻。Instagram 利用 ML 模型决定何时向谁发送通知以及包含哪些内容，这些模型旨在优化用户积极参与度，如点击率 (CTR) 和使用时长。\n\n## 现有机器学习模型的局限性\n\n尽管以参与度为优化的模型能有效促进互动，但它们可能过度优先考虑用户之前互动过的产品类型和作者。这会导致用户过度接触相同的创作者或产品类型，而忽略其他有价值且多样的体验。长此以往，通知可能会变得像垃圾邮件，增加用户禁用通知的可能性，从而错失更平衡、满意和丰富的体验。\n\n## 挑战：平衡多样性与个性化\n\n核心挑战在于如何引入有意义的通知多样性，同时又不牺牲用户对 Instagram 个性化和相关性的期望。\n\n## Instagram 的多样性感知通知排名框架\n\n为了解决这一问题，Instagram 引入了一个多样性感知通知排名框架，旨在提供更具多样性、更好策划且重复性更低的通知。该框架显著降低了每日通知量，同时提高了点击率，并带来了多项益处：\n\n*   **可扩展性**：能够为每个维度纳入定制化的软惩罚（降权）逻辑，实现更具适应性和复杂的多元化策略。\n*   **灵活性**：通过可调节的权重，灵活调整内容、作者和产品类型等维度的降权强度。\n*   **整合性**：平衡个性化与多样性，确保通知既相关又多样。\n\n## 缺乏多样性的风险（过度曝光）\n\n通知中过度曝光的问题主要体现在两个方面：\n\n*   **对同一作者的过度曝光**：用户可能收到大部分来自同一朋友的通知，即使他们也与其他朋友互动。这会让人感到重复和单一，降低通知的整体价值。\n*   **对同一产品界面的过度曝光**：用户可能主要收到来自同一产品界面（如 Stories）的通知，即使 Feed 或 Reels 也能提供价值。例如，如果用户最近更多地与 Stories 互动，系统可能会只发送 Stories 通知，而忽略其更广泛的兴趣。\n\n## 框架工作原理\n\nInstagram 的多样性感知通知排名框架旨在通过平衡用户参与的预测潜力与内容多样性的需求来增强通知体验。该框架在现有参与度 ML 模型之上引入了一个**多样性层**，对这些模型生成的候选分数应用乘法惩罚，如下图所示：\n\n![图片 1](https://engineering.fb.com/wp-content/uploads/2025/09/A-new-ranking-framework-for-better-notification-quality-on-Instagram.png)\n\n**图 1**：Instagram 的多样性感知排名框架，其中多样性层位于现有建模层之上，并对与最近发送的通知过于相似的通知进行惩罚。\n\n多样性层评估每个通知候选与最近发送的通知在多个维度（如内容、作者、通知类型和产品界面）上的相似性。然后，它应用经过精心校准的惩罚（以乘法降权因子表示），以降低过于相似或重复的候选的排名。调整后的分数用于重新排名候选，使系统能够选择既保持高参与潜力又引入有意义多样性的通知。最终，质量门槛会选择通过排名和多样性标准的最优候选。\n\n### 数学公式\n\n在多样性层中，我们对每个候选的基础相关性分数应用一个乘法降权因子。给定一个通知候选 `c`，其最终分数计算为其基础排名分数 `R(c)` 与多样性降权乘数 `D(c)` 的乘积。`D(c)` 是一个介于 [0,1] 之间的惩罚因子，根据与最近发送通知的相似性来降低分数。\n\n我们定义了一组语义维度（例如，作者、产品类型）以促进多样性。对于每个维度 `i`，我们使用最大边际相关性 (MMR) 方法计算候选 `c` 与历史通知集合 `H` 之间的相似性信号 `p_i(c)`。在基线实现中，`p_i(c)` 是一个二进制值：如果相似性超过阈值 `τ_i` 则为 1，否则为 0。\n\n最终的降权乘数 `D(c)` 是通过对所有维度 `i` 的 `(1 - w_i * p_i(c))` 乘积计算得出的，其中 `w_i` 控制其相应维度的降权强度。这种公式确保了与先前已发送通知在一个或多个维度上相似的候选被按比例降权，从而减少冗余并促进内容多样性。\n\n## 未来展望\n\nInstagram 将继续发展其多样性感知通知排名系统，下一步是引入更具适应性、动态的降权策略。例如，当用户收到更多通知（特别是相似类型或快速连续的通知）时，系统将逐步对新的通知候选应用更强的惩罚，从而有效缓解高通知量或紧密间隔发送造成的压倒性体验。\n\n从长远来看，Instagram 计划将大型语言模型 (LLMs) 引入多样性管道。LLMs 可以帮助系统超越表面规则，理解消息之间的语义相似性，并以更多样化、用户友好的方式重新措辞内容。这将允许系统通过更丰富的语言和改进的相关性来个性化通知体验，同时保持主题、语气和时间上的多样性。",
      "shortSummary": "Instagram 推出了一项新的多样性感知通知排名框架，旨在解决传统机器学习模型导致的通知过度曝光问题。该框架在现有模型之上增加了一个多样性层，通过对重复内容和作者施加惩罚，减少了通知总量，同时提高了用户参与度。这为用户提供了更丰富、更个性化的通知体验。未来，该系统将引入自适应降权策略并整合大型语言模型，以进一步提升通知质量和多样性。",
      "translated_title": "Instagram 提升通知质量的新排名框架",
      "images": [
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/09/A-new-ranking-framework-for-better-notification-quality-on-Instagram.png",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://s0.wp.com/latex.php?latex=%5Ctext%7BScore%7D%28c%29+%3D+R%28c%29+%5Ctimes+D%28c%29+&bg=ffffff&fg=000&s=0&c=20201002",
          "alt": "\\text{Score}(c) = R(c) \\times D(c) ",
          "title": "",
          "position": 2
        },
        {
          "url": "https://s0.wp.com/latex.php?latex=p_i%28c%29+%3D+%5Cmathrm%7Bmax%7D_%7Bh+%5Cin+H%7D%5Cmathrm%7Bsim%7D_i%28c%2C+h%29+&bg=ffffff&fg=000&s=0&c=20201002",
          "alt": "p_i(c) = \\mathrm{max}_{h \\in H}\\mathrm{sim}_i(c, h) ",
          "title": "",
          "position": 3
        },
        {
          "url": "https://s0.wp.com/latex.php?latex=D%28c%29+%3D+%5Cprod_%7Bi%3D1%7D%5E%7Bm%7D+%5Cleft%28+1+-+w_i+%5Ccdot+p_i%28c%29+%5Cright%29+&bg=ffffff&fg=000&s=0&c=20201002",
          "alt": "D(c) = \\prod_{i=1}^{m} \\left( 1 - w_i \\cdot p_i(c) \\right) ",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "<p>We’re sharing how Meta is applying machine learning (ML) and diversity algorithms to improve notification quality and user experience.  We’ve introduced a diversity-aware notification ranking framework to reduce uniformity and deliver a more varied and engaging mix of notifications. This new framework reduces the volume of notifications and drives higher engagement rates through more diverse [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/09/02/ml-applications/a-new-ranking-framework-for-better-notification-quality-on-instagram/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/09/02/ml-applications/a-new-ranking-framework-for-better-notification-quality-on-instagram/\">A New Ranking Framework for Better Notification Quality on Instagram</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "在Buck2上启用Kotlin增量编译 (原标题: Enabling Kotlin incremental compilation on Buck2)",
      "link": "https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/",
      "pubDate": "Tue, 26 Aug 2025 16:00:52 +0000",
      "isoDate": "2025-08-26T16:00:52.000Z",
      "creator": "",
      "summary": "## 在Buck2上启用Kotlin增量编译\n\nMeta工程团队成功地将Kotlin增量编译器集成到其构建系统Buck2中，以解决大型Kotlin模块导致的构建时间过长问题，显著提升了开发效率和构建速度。\n\n### 背景与动机\n\n尽管Buck2鼓励使用小型模块以实现快速构建，但随着代码库的增长和团队的变化，一些Kotlin模块变得庞大，开始对构建时间产生显著影响。为了解决这一问题，团队决定深入研究Kotlin增量编译器。\n\n### 关键成果\n\n*   **构建速度提升**：关键模块的构建速度提升高达3倍。\n*   **开发者效率**：平均开发者构建时间提升约30%。\n*   **特定模块优化**：对于不涉及注解处理的模块，速度几乎翻倍。\n\n### 实施步骤与挑战\n\n#### 1. 集成Kotlin的构建工具API (Build Tools API)\n\n*   **挑战**：命令行接口（CLI）不支持增量编译，而内部编译器API不稳定且不保证向后兼容性。\n*   **解决方案**：采用了Kotlin 1.9.20中引入的实验性Build Tools API (KEEP)，该API是官方的编译器集成点，支持增量编译。团队认为其最终会稳定，并提前介入提供反馈。\n*   **Shading冲突**：Build Tools API依赖于`kotlin-compiler-embeddable`（经过混淆处理的版本），而Meta的Android工具链历史上使用`kotlin-compiler`（未混淆版本），导致`NoClassDefFoundError`。最初通过对Build Tools API进行反混淆处理来解决，随后将整个工具链迁移到使用混淆处理的Kotlin编译器，以实现更稳定的设置。\n\n#### 2. 保留前次构建输出\n\n*   **挑战**：Buck2默认在重建模块前删除前次构建的输出，而增量编译器需要访问这些输出。\n*   **解决方案**：通过配置Buck2的增量操作（incremental actions），跳过对前次输出的自动清理。这使得构建操作可以访问上次运行的所有内容，但需要手动清理不再有用的文件。\n\n#### 3. 使增量编译器缓存可重定位\n\n*   **挑战**：在Buck2支持的分布式构建环境中，如果编译器缓存不可重定位，可能导致路径不匹配的错误和冲突。\n*   **解决方案**：在增量编译设置中明确配置了根项目目录和构建目录，确保编译器缓存的稳定性和可靠性，无论构建在哪里执行。\n\n#### 4. 配置增量编译器\n\n*   **原理**：增量编译器通过跟踪模块内部文件和依赖项的变化来决定需要重新编译的内容。\n*   **模块内部变化**：利用Buck2增量操作提供的哈希摘要，比较前后两次构建的哈希值，生成修改文件列表并传递给编译器，避免编译器自行检测变化。\n*   **依赖项变化**：通过生成类路径快照（ABI）来检测依赖项的变化。Buck2中新增了一个专门的操作来从库输出生成类路径快照，并将其作为输入传递给消费模块。由于这是一个独立的操作，可以远程执行或从缓存中获取，减轻了本地机器的负担。\n\n#### 5. 使编译器插件与增量编译器协同工作\n\n*   **挑战1：结果不完整**：自定义编译器插件未针对部分输入设计，在只处理文件子集时会产生不完整的结果。\n*   **解决方案1**：将插件也改造为增量模式，使其能够正确处理部分输入。\n*   **挑战2：多轮编译**：增量编译器可能在单次构建中进行多轮编译，每次处理不同的文件集，导致插件被多次触发并可能覆盖早期输出。\n*   **解决方案2**：更新插件，使其在多轮编译中累积结果而非替换。\n\n#### 6. 验证注解处理器功能\n\n*   **解决方案**：大多数注解处理器使用Kotlin符号处理（KSP2）。KSP2作为一个独立的工具，利用Kotlin分析API分析源代码，独立于标准编译流程运行，并自带增量处理支持，因此无需修改即可继续使用。\n\n#### 7. 启用针对ABI的编译\n\n*   **挑战**：为了最大化缓存命中率，Buck2针对类ABI而非完整的JAR文件构建Android模块。Kotlin目标使用`jvm-abi-gen`编译器插件生成ABI，但在启用增量编译后，该插件缺乏增量支持，且ABI提取会发生两次（插件和类路径快照）。\n*   **当前解决方案**：实现了一个自定义的（但非最优的）解决方案，将新生成的ABI与之前的结果合并。\n*   **未来展望**：正在积极探索更好的长期替代方案，理想情况是重用已收集的类路径快照信息，或将此功能直接内置到Kotlin编译器中（参见KT-62881）。\n\n#### 8. 测试\n\n*   **方法**：通过A/B测试在Meta的代码库上衡量Kotlin增量编译的真实影响，确保结果的可靠性。\n*   **结果**：在最大的模块上，增量编译带来了显著的性能提升，证实了其价值。\n\n### 后续计划\n\nKotlin增量编译目前已在Buck2中得到支持，并正在Meta的代码库中积极推广。目前仅供内部使用，但团队正努力将其引入最近开源的工具链中，并探索在整个Android工具链中扩展增量能力的方法。",
      "shortSummary": "Meta已成功在Buck2构建系统中启用Kotlin增量编译，显著提升了构建速度和开发者效率。通过集成Kotlin Build Tools API、保留前次输出、使缓存可重定位、优化编译器配置、改造编译器插件以及利用KSP2，团队实现了关键模块构建速度提升高达3倍，平均开发者构建时间缩短30%。目前该功能正在内部推广，并计划开源，以进一步扩展Android工具链的增量能力。",
      "translated_title": "在Buck2上启用Kotlin增量编译",
      "images": [],
      "contentSource": "RSS",
      "content": "<p>The Kotlin incremental compiler has been a true gem for developers chasing faster compilation since its introduction in build tools. Now, we’re excited to bring its benefits to Buck2 –  Meta’s build system – to unlock even more speed and efficiency for Kotlin developers. Unlike a traditional compiler that recompiles an entire module every time, [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/08/26/open-source/enabling-kotlin-incremental-compilation-on-buck2/\">Enabling Kotlin incremental compilation on Buck2</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    },
    {
      "title": "为数据仓库数据访问和安全创建AI代理解决方案 (原标题: Creating AI agent solutions for warehouse data access and security)",
      "link": "https://engineering.fb.com/2025/08/13/data-infrastructure/agentic-solution-for-warehouse-data-access/",
      "pubDate": "Wed, 13 Aug 2025 22:05:07 +0000",
      "isoDate": "2025-08-13T22:05:07.000Z",
      "creator": "",
      "summary": "Meta正在改进其数据仓库，以提高生产力和安全性，同时服务于人类用户和AI代理。本文详细介绍了Meta如何开发AI代理来简化数据访问请求并帮助数据所有者管理安全。\n\n## 背景与挑战\n\n*   **传统方法：** 过去，Meta通过将数据仓库组织成层次结构（图1）来扩展数据访问和管理，并使用基于角色的访问控制。数据流被视为图（图2），数据访问决策是局部的、规则驱动的。\n*   **日益增长的复杂性：** 随着数据量和AI系统的发展，数据访问模式变得更加复杂。AI系统能够处理数据图的不同部分，使得人工驱动的决策变得困难且耗时。人类和代理跨领域协作增加了系统复杂性（图3）。\n*   **AI作为解决方案：** 尽管AI是复杂性的驱动因素，但Meta认为AI也能提供解决方案。需要一种代理化解决方案，将其原生集成到数据产品中，并建立严格的防护措施。\n\n## 多代理系统设计\n\nMeta将解决方案建模为一个多代理系统（图4），包含两种主要代理：\n\n*   **数据用户代理：** 协助数据用户获取所需数据。\n    *   由三个专业子代理组成，由一个分类代理协调（图5）：\n        1.  **建议替代方案：** 当用户遇到受限表时，提供非受限或限制较少的替代方案，帮助用户重写查询以使用非受限列，或利用精选分析。这些见解通常是隐性的，LLM和代理能够大规模地综合和引导用户。\n        2.  **促进低风险数据探索：** 为数据探索阶段提供上下文感知、任务特定的低风险数据访问，通常只涉及少量数据。\n        3.  **协助获取访问权限：** 帮助用户制定权限请求并与数据所有者代理协商（目前仍有人工干预）。\n*   **数据所有者代理：** 帮助数据所有者管理访问和维护安全。\n    *   由多个子代理组成（图6）：\n        1.  **安全操作：** 像初级工程师一样，根据数据所有者提供的SOP（标准操作程序）处理传入的权限请求。\n        2.  **主动配置访问规则：** 利用语义和内容，改进传统的角色挖掘过程。\n\n## 代理的输入与管理\n\n*   **数据仓库作为资源：** 数据仓库的层次结构被转换为文本形式，类似于嵌套文件夹，为LLM提供只读的摘要视图（图7）。SOP（规则、维基、历史交互）也以文本形式作为代理的输入。\n*   **上下文管理：** 区分三种场景（图8）：\n    *   **自动上下文：** 系统根据用户访问行为自动获取精确上下文。\n    *   **静态上下文：** 用户明确选择特定范围或扩展自动上下文。\n    *   **动态上下文：** 代理通过元数据（如数据语义）或相似性搜索进一步过滤资源。\n*   **意图管理：** 用户意图通过两种方式建模（图9）：\n    *   **显式意图：** 用户通过假定关联角色等方式明确传达其业务需求。\n    *   **隐式意图：** 系统在短时间内从用户活动中推断意图（例如，根据夜间处理管道故障推断数据访问意图）。\n\n## 深度探索：部分数据预览\n\n部分数据预览是一个端到端用例，旨在数据探索阶段实现任务特定、上下文感知的数据访问。它通过代理工作流协调四个关键能力（图10）：\n\n1.  **上下文：** 分析用户活动以理解业务需求，并与数据控制对齐，提供任务特定、上下文感知的控制。\n2.  **查询级访问控制：** 分析查询的结构，例如是否涉及聚合或随机抽样。\n3.  **数据访问预算：** 根据员工通常访问的数据量分配每日刷新的预算，作为第一道防线。\n4.  **基于规则的风险管理：** 采用基于规则的风险控制，防御AI代理的攻击或故障。\n\n### 系统架构\n\n*   **数据用户代理：** 利用用户活动工具（diffs、任务、帖子、SEVs、仪表板、文档）和用户配置文件工具，根据用户活动、配置文件和查询形状形成用户意图，然后调用数据所有者代理（图11）。\n*   **数据所有者代理：** 分析查询，获取相关资源的元数据（表摘要、列描述、数据语义、SOPs）。利用LLM模型生成决策和推理，并通过输出防护措施确保决策符合基于规则的风险计算。\n*   所有决策和日志都安全存储，用于未来参考和分析。\n\n### LLM与代理的优势\n\nLLM的语言和推理能力对于建模难以分析建模的上下文和任务特定业务需求至关重要。代理帮助构建动态、端到端的工作流。同时，通过分析性规则风险计算等防护措施，确保代理在既定边界内运行，并强调透明度和可追溯性。\n\n## 评估与反馈\n\n*   **评估：** 通过使用真实请求、用户活动和配置文件数据策划评估数据集来评估系统准确性和性能。每天运行评估以捕获潜在的回归（图12）。\n*   **反馈循环（数据飞轮）：** 用户查询、代理处理轨迹、上下文和最终输出都安全存储，用于反馈和审计。为数据所有者创建了数据工具，允许他们查看和审查决策并提供反馈，从而更新评估并评估整体流程（图13）。\n\n## 未来展望\n\n未来工作包括：\n\n*   **代理协作：** 支持代理代表用户直接访问数据的场景。\n*   **工具演进：** 持续改进数据仓库和工具，使其能被代理有效使用（最初为员工或服务构建）。",
      "shortSummary": "Meta正在通过AI代理解决方案提升数据仓库的数据访问和安全性。该方案采用多代理系统，数据用户代理协助获取数据，数据所有者代理管理权限。系统利用LLM进行上下文和意图管理，实现细粒度、风险受控的数据访问，尤其在数据探索阶段。通过防护措施、审计和反馈循环，确保代理安全高效运行，以应对日益复杂的数据管理挑战。",
      "translated_title": "为数据仓库数据访问和安全创建AI代理解决方案",
      "images": [
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image3.png",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image5.png",
          "alt": "",
          "title": "",
          "position": 2
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image4.png",
          "alt": "",
          "title": "",
          "position": 3
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image7.png",
          "alt": "",
          "title": "",
          "position": 4
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image10.png",
          "alt": "",
          "title": "",
          "position": 5
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image8.png",
          "alt": "",
          "title": "",
          "position": 6
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image9.png",
          "alt": "",
          "title": "",
          "position": 7
        },
        {
          "url": "https://engineering.fb.com/wp-content/uploads/2025/07/image2.png",
          "alt": "",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "完整文章",
      "content": "<p>In this post, we explore the ways we’re evolving Meta’s data warehouse to facilitate productivity and security to serve both human users and AI agents.  We detail how we’re developing agents that help users making data access requests to get to the data they need, and that help data owners process requests and maintain security.  [...]</p>\n<p><a class=\"btn btn-secondary understrap-read-more-link\" href=\"https://engineering.fb.com/2025/08/13/data-infrastructure/agentic-solution-for-warehouse-data-access/\">Read More...</a></p>\n<p>The post <a rel=\"nofollow\" href=\"https://engineering.fb.com/2025/08/13/data-infrastructure/agentic-solution-for-warehouse-data-access/\">Creating AI agent solutions for warehouse data access and security</a> appeared first on <a rel=\"nofollow\" href=\"https://engineering.fb.com\">Engineering at Meta</a>.</p>\n"
    }
  ],
  "lastUpdated": "2025-10-03T05:24:48.915Z"
}
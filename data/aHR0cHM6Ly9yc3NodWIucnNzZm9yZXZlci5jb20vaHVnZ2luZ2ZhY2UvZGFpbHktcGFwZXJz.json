{
  "sourceUrl": "https://rsshub.rssforever.com/huggingface/daily-papers",
  "title": "Huggingface Daily Papers",
  "description": "Huggingface Daily Papers - Powered by RSSHub",
  "link": "https://huggingface.co/papers",
  "items": [
    {
      "title": "EXAONE 4.0：整合非推理和推理模式的统一大型语言模型 (原标题: EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes)",
      "link": "https://arxiv.org/abs/2507.11407",
      "pubDate": "Tue, 15 Jul 2025 11:24:51 GMT",
      "isoDate": "2025-07-15T11:24:51.000Z",
      "creator": "LG AI Research, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Yemuk Choi, Kyubeen Han, Seokhee Hong, Junwon Hwang, Taewan Hwang, Joonwon Jang, Hyojin Jeon, Kijeong Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Euisoon Kim, Hyosang Kim, Jihoon Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Gwangho Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Young Min Paik, Yongmin Park, Youngyong Park, Sanghyun Seo, Sihoon Yang, Heuiyeen Yeen, Sihyuk Yi, Hyeongu Yun",
      "summary": "# EXAONE 4.0：统一大型语言模型技术报告概述\n\n本技术报告介绍了由LG AI Research开发的EXAONE 4.0大型语言模型。EXAONE 4.0旨在通过整合“非推理模式”和“推理模式”，同时实现EXAONE 3.5卓越的可用性以及EXAONE Deep先进的推理能力。\n\n## 核心创新与目标\n*   **模式整合**：EXAONE 4.0的核心创新在于其统一架构，将非推理能力与强大的推理能力相结合，以提供更全面的AI解决方案。\n*   **代理AI时代准备**：为迎接代理AI时代的到来，EXAONE 4.0融入了关键的智能体工具使用（agentic tool use）功能。\n\n## 主要特性\n*   **多语言能力扩展**：除了原有的英语和韩语，EXAONE 4.0的多语言能力已扩展至支持西班牙语。\n*   **模型尺寸与应用**：\n    *   **中型模型 (32B)**：该版本经过优化，旨在提供高性能表现。\n    *   **小型模型 (1.2B)**：该版本专为设备端（on-device）应用设计，适用于资源受限的环境。\n\n## 性能表现\nEXAONE 4.0在性能上展现出显著优势：\n*   **超越同类开源模型**：与同级别的开源模型相比，EXAONE 4.0展现出卓越的性能。\n*   **与前沿模型竞争**：即使面对前沿级（frontier-class）模型，EXAONE 4.0也保持了强大的竞争力。\n\n## 可用性与研究\nEXAONE 4.0模型系列已向公众开放，供研究目的使用。研究人员可以通过提供的链接轻松下载这些模型。\n\n## 报告信息\n*   **作者**：LG AI Research团队（包括Kyunghoon Bae, Eunbi Choi等众多研究人员）。\n*   **类型**：技术报告，共30页。\n*   **主题**：计算与语言（cs.CL）；人工智能（cs.AI）。\n*   **引用方式**：arXiv:2507.11407。\n*   **提交日期**：2025年7月15日。",
      "shortSummary": "EXAONE 4.0是LG AI Research推出的大型语言模型，整合了非推理和推理模式。它具备智能体工具使用能力，并支持英语、韩语和西班牙语。该模型提供32B（高性能）和1.2B（设备端）两种尺寸，性能优于同类开源模型，并能与前沿模型竞争。EXAONE 4.0已公开供研究使用。",
      "translated_title": "EXAONE 4.0：整合非推理和推理模式的统一大型语言模型",
      "images": [],
      "contentSource": "完整文章",
      "content": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5 and the advanced reasoning abilities of EXAONE Deep. To pave the way for the agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool use, and its multilingual capabilities are extended to support Spanish in addition to English and Korean. The EXAONE 4.0 model series consists of two sizes: a mid-size 32B model optimized for high performance, and a small-size 1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates superior performance compared to open-weight models in its class and remains competitive even against frontier-class models. The models are publicly available for research purposes and can be easily downloaded via https://huggingface.co/LGAI-EXAONE."
    },
    {
      "title": "多模态基础模型能否理解示意图？一项关于科学论文信息检索问答的实证研究 (原标题: Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers)",
      "link": "https://arxiv.org/abs/2507.10787",
      "pubDate": "Mon, 14 Jul 2025 16:35:25 GMT",
      "isoDate": "2025-07-14T16:35:25.000Z",
      "creator": "Yilun Zhao, Chengye Wang, Chuhan Li, Arman Cohan",
      "summary": "### MISS-QA：评估多模态基础模型对科学示意图的理解能力\n\n本文介绍了一个名为MISS-QA的新基准，该基准专门用于评估模型解释科学文献中示意图的能力。\n\n**基准概述：**\n*   **设计目的：** 专门评估模型对科学文献中示意图的理解能力。\n*   **构成：** 包含来自465篇科学论文的1,500个由专家标注的示例。\n*   **任务设置：** 模型需要解释说明研究概览的示意图，并根据论文的更广泛上下文回答相应的信息检索问题。\n\n**模型评估与发现：**\n*   **评估对象：** 评估了18个前沿的多模态基础模型，包括o4-mini、Gemini-2.5-Flash和Qwen2.5-VL。\n*   **主要发现：** 在MISS-QA基准上，这些模型的表现与人类专家之间存在显著的性能差距。\n*   **深入分析：**\n    *   对模型在无法回答问题上的表现进行了分析。\n    *   进行了详细的错误分析。\n    *   这些分析突出了当前模型的优势和局限性。\n*   **研究意义：** 为增强模型理解多模态科学文献的能力提供了关键见解。\n\n**相关信息：**\n*   **会议：** ACL 2025 Findings\n*   **研究领域：** 计算与语言 (cs.CL); 计算机视觉与模式识别 (cs.CV)\n*   **引用信息：** arXiv:2507.10787 [cs.CL]",
      "shortSummary": "本文引入了MISS-QA，一个旨在评估多模态基础模型理解科学论文中示意图能力的基准。该研究测试了18个前沿模型，发现它们在解释示意图并回答相关信息检索问题方面与人类专家存在显著差距。详细的错误分析揭示了当前模型的优势与局限，为提升模型对多模态科学文献的理解提供了重要见解。",
      "translated_title": "多模态基础模型能否理解示意图？一项关于科学论文信息检索问答的实证研究",
      "images": [],
      "contentSource": "完整文章",
      "content": "This paper introduces MISS-QA, the first benchmark specifically designed to evaluate the ability of models to interpret schematic diagrams within scientific literature. MISS-QA comprises 1,500 expert-annotated examples over 465 scientific papers. In this benchmark, models are tasked with interpreting schematic diagrams that illustrate research overviews and answering corresponding information-seeking questions based on the broader context of the paper. We assess the performance of 18 frontier multimodal foundation models, including o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant performance gap between these models and human experts on MISS-QA. Our analysis of model performance on unanswerable questions and our detailed error analysis further highlight the strengths and limitations of current models, offering key insights to enhance models in comprehending multimodal scientific literature."
    },
    {
      "title": "EmbRACE-3K：复杂环境中的具身推理与行动 (原标题: EmbRACE-3K: Embodied Reasoning and Action in Complex Environments)",
      "link": "https://arxiv.org/abs/2507.10548",
      "pubDate": "Mon, 14 Jul 2025 13:59:46 GMT",
      "isoDate": "2025-07-14T13:59:46.000Z",
      "creator": "Mingxian Lin, Wei Huang, Yitang Li, Chengjie Jiang, Kui Wu, Fangwei Zhong, Shengju Qian, Xin Wang, Xiaojuan Qi",
      "summary": "## EmbRACE-3K：复杂环境中的具身推理与行动\n\n### 引言\n\n近期先进的视觉-语言模型（VLMs）在被动、离线的图像和视频理解任务中展现出强大的性能。然而，它们在具身设置中的有效性仍然有限，这类设置需要在线交互和主动的场景理解。在具身场景中，智能体从第一人称视角感知环境，每个动作都会动态地影响后续的观察。即使是GPT-4o、Claude 3.5 Sonnet和Gemini 2.5 Pro等最先进的模型，在开放环境交互中也表现出明显的局限性，尤其是在空间推理和长程规划方面。\n\n### 解决方案：引入EmRACE-3K数据集\n\n为了弥补这一差距，我们引入了EmRACE-3K数据集，它包含3000多个语言引导任务，这些任务设置在利用虚幻引擎（Unreal Engine）和UnrealCV-Zoo框架构建的各种逼真环境中。\n\n*   **任务范围广泛**：数据集中的任务涵盖了广泛的具身挑战，包括导航、物体操作和多阶段目标执行。\n*   **多步轨迹**：每个任务都以多步轨迹的形式展开，将第一人称视觉观察与高级指令、具身动作以及在每一步表达智能体意图的自然语言理由配对。\n\n### 基准评估\n\n我们利用EmRACE-3K建立了一个基准，以评估VLMs在三个关键维度上的具身推理能力：\n\n1.  **探索（Exploration）**\n2.  **动态空间-语义推理（Dynamic Spatial-Semantic Reasoning）**\n3.  **多阶段目标执行（Multi-stage Goal Execution）**\n\n在零样本（zero-shot）设置下，所有模型的成功率均低于20%，这突显了我们基准测试所带来的挑战以及当前VLMs在交互式环境中的局限性。\n\n### 数据集效用演示\n\n为了展示EmRACE-3K的实用性，我们进一步通过监督学习（supervised learning）和强化学习（reinforcement learning）对Qwen2.5-VL-7B进行了微调。这种方法在所有三个挑战类别中都取得了显著的改进，突显了该数据集在促进具身推理能力发展方面的有效性。",
      "shortSummary": "文章介绍了EmRACE-3K数据集，旨在解决现有视觉-语言模型（VLMs）在复杂具身环境中具身推理和行动能力不足的问题。该数据集包含3000多个语言引导任务，涵盖导航、物体操作和多阶段目标执行。基准测试显示，VLMs在零样本设置下成功率低于20%。通过EmRACE-3K对模型进行微调，能显著提升其在探索、动态空间-语义推理和多阶段目标执行方面的表现，证明了数据集在发展具身推理能力方面的有效性。",
      "translated_title": "EmbRACE-3K：复杂环境中的具身推理与行动",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advanced vision-language models(VLMs) have demonstrated strong performance on passive, offline image and video understanding tasks. However, their effectiveness in embodied settings, which require online interaction and active scene understanding remains limited. In such scenarios, an agent perceives the environment from a first-person perspective, with each action dynamically shaping subsequent observations. Even state-of-the-art models such as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment interactions, exhibiting clear limitations in spatial reasoning and long-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset of over 3,000 language-guided tasks situated in diverse, photorealistic environments constructed using Unreal Engine and the UnrealCV-Zoo framework. The tasks encompass a wide range of embodied challenges, including navigation, object manipulation, and multi-stage goal execution. Each task unfolds as a multi-step trajectory, pairing first-person visual observations with high-level instructions, grounded actions, and natural language rationales that express the agent's intent at every step. Using EmRACE-3K, we establish a benchmark to evaluate the embodied reasoning capabilities of VLMs across three key dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage Goal Execution. In zero-shot settings, all models achieve success rates below 20%, underscoring the challenge posed by our benchmark and the current limitations of VLMs in interactive environments. To demonstrate the utility of EmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning followed by reinforcement learning. This approach yields substantial improvements across all three challenge categories, highlighting the dataset's effectiveness in enabling the development of embodied reasoning capabilities."
    },
    {
      "title": "REST：通过同时提出多个问题对大型推理模型进行压力测试 (原标题: REST: Stress Testing Large Reasoning Models by Asking Multiple Problems at Once)",
      "link": "https://arxiv.org/abs/2507.10541",
      "pubDate": "Mon, 14 Jul 2025 13:58:47 GMT",
      "isoDate": "2025-07-14T13:58:47.000Z",
      "creator": "Zhuoshi Pan, Qizhi Pei, Yu Li, Qiyao Sun, Zinan Tang, H. Vicky Zhao, Conghui He, Lijun Wu",
      "summary": "## REST：大型推理模型的压力测试\n\n### 引言：现有评估方法的局限性\n\n当前对大型推理模型（LRMs）的评估主要局限于孤立的问题解决范式，即通过顺序测试评估模型对单个问题的推理能力。这种方法存在以下关键局限性：\n\n*   **数据污染和挑战性不足**：容易受到数据污染，且挑战性较低（例如，DeepSeek-R1在MATH500上达到97.0%），这导致需要投入大量人力和成本持续创建新问题。\n*   **缺乏多上下文压力评估**：未能评估模型在多上下文压力下的表现，而这在现实世界部署中至关重要。\n\n### REST 框架的提出\n\n为了弥补这一空白，研究人员提出了 **REST (Reasoning Evaluation through Simultaneous Testing)**，这是一个对LRMs进行压力测试的框架，它能够同时向模型提出多个问题。\n\n### REST 评估的能力\n\n除了基本的推理能力，REST 还特别评估了几种此前未充分测试的能力：\n\n*   **上下文优先级分配**：模型在多个问题中分配注意力的能力。\n*   **跨问题干扰抵抗**：模型在处理一个问题时，抵抗其他问题干扰的能力。\n*   **动态认知负荷管理**：模型在认知负荷变化时保持性能的能力。\n\n### 关键发现\n\n评估结果揭示了几个显著的发现：\n\n*   **性能显著下降**：即使是像DeepSeek-R1这样的最先进（SOTA）模型，在REST压力测试下也表现出显著的性能下降。\n*   **更强的区分能力**：REST比现有基准测试展现出更强的区分能力，能够揭示在单问题评估中表现相似、接近上限的模型之间明显的性能差异。\n\n### 机制洞察\n\n分析中得出了一些关键的机制洞察：\n\n*   **“过度思考陷阱”**：这是一个导致性能下降的关键因素。\n*   **“long2short”训练技术**：采用“long2short”技术训练的模型在REST测试中能更好地保持其单问题性能的准确性，优于标准训练的模型。\n\n### 结论：REST 的优势\n\n这些结果表明，REST 是一种：\n\n*   **成本效益高**：减少对持续人工标注的依赖。\n*   **面向未来**：能够更好地反映现实世界的推理需求。\n*   **更有效**：提供更全面、更具挑战性的评估范式。",
      "shortSummary": "REST（Reasoning Evaluation through Simultaneous Testing）是一个新颖的压力测试框架，旨在通过同时向大型推理模型（LRMs）提出多个问题，解决现有单问题评估的局限性。它评估模型在多上下文压力下的表现，包括上下文优先级分配和抗干扰能力。研究发现，即使是SOTA模型在REST测试下性能也会显著下降，且REST比现有基准具有更强的区分能力。此外，“过度思考陷阱”是性能下降的原因之一，而“long2short”训练技术有助于模型保持准确性。REST提供了一种更具成本效益且能反映真实世界需求的评估范式。",
      "translated_title": "REST：通过同时提出多个问题对大型推理模型进行压力测试",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent Large Reasoning Models (LRMs) have achieved remarkable progress on task-specific benchmarks, yet their evaluation methods remain constrained by isolated problem-solving paradigms. Existing benchmarks predominantly assess single-question reasoning through sequential testing, resulting critical limitations: (1) vulnerability to data contamination and less challenging (e.g., DeepSeek-R1 achieves 97.0% on MATH500), forcing costly and perpetual creation of new questions with large human efforts, (2) failure to evaluate models under multi-context pressure, a key requirement for real-world deployment. To bridge this gap, we present REST (Reasoning Evaluation through Simultaneous Testing), a stress-testing framework that concurrently exposes LRMs to multiple problems simultaneously. Beyond basic reasoning, REST specifically evaluates several under-tested capabilities: contextual priority allocation, cross-problem interference resistance, and dynamic cognitive load management. Our evaluation reveals several striking findings: Even state-of-the-art (SOTA) models like DeepSeek-R1 exhibit substantial performance degradation under stress testing. Crucially, REST demonstrates stronger discriminative power than existing benchmarks, revealing pronounced performance differences among models that exhibit similar, near-ceiling performance under single-question evaluations. Some key mechanistic insights emerge from our analysis: (1) the \"overthinking trap\" is a critical factor contributing to the performance degradation; (2) the models trained with \"long2short\" technique preserve more accuracy of their single-problem performance under REST, outperforming standard-trained counterparts. These results establish REST as a cost-efficient, future-proof evaluation paradigm that better reflects real-world reasoning demands while reducing reliance on continuous human annotation."
    },
    {
      "title": "推理还是记忆？强化学习因数据污染导致结果不可靠 (原标题: Reasoning or Memorization? Unreliable Results of Reinforcement Learning Due to Data Contamination)",
      "link": "https://arxiv.org/abs/2507.10532",
      "pubDate": "Mon, 14 Jul 2025 13:55:15 GMT",
      "isoDate": "2025-07-14T13:55:15.000Z",
      "creator": "Mingqi Wu, Zhihao Zhang, Qiaole Dong, Zhiheng Xi, Jun Zhao, Senjie Jin, Xiaoran Fan, Yuhao Zhou, Yanwei Fu, Qin Liu, Songyang Zhang, Qi Zhang",
      "summary": "## 强化学习中数据污染导致结果不可靠\n\n### 引言\n\n本文探讨了大型语言模型（LLMs）的推理能力，特别是强化学习（RL）在增强这些能力方面的应用，并指出当前研究中存在的潜在问题。\n\n### 问题与观察\n\n*   **声称的突破与局限性**：近期许多RL方法声称能显著提升LLM的推理能力，甚至在奖励信号随机或不正确的情况下也能实现。然而，这些突破主要集中在Qwen2.5模型家族上，并在MATH-500、AMC和AIME等知名基准上进行评估。令人担忧的是，在Llama等其他模型上未能观察到类似的性能提升，这促使了进一步的深入调查。\n*   **性能差异的疑问**：一些研究甚至提出随机或不正确的奖励信号也能增强推理性能，这与直觉相悖，并加剧了对结果可靠性的质疑。\n\n### 分析与发现\n\n*   **数据污染的风险**：研究分析表明，尽管Qwen2.5在数学推理方面表现出色，但其在大规模网络语料库上的预训练使其容易受到流行基准中数据污染的影响。这意味着模型可能不是真正地进行推理，而是在一定程度上“记忆”了训练数据中包含的基准问题或其解决方案。\n*   **结果的不可靠性**：由于数据污染的存在，从这些受污染基准得出的结果可能并不可靠，无法真实反映RL方法对LLM推理能力的提升效果。\n\n### 解决方案与贡献\n\n*   **生成合成数据集**：为解决数据污染问题，研究引入了一个生成器，能够生成任意长度和难度的完全合成算术问题。这种方法确保了生成的问题是全新的，未曾出现在任何预训练语料或现有基准中。\n*   **构建“RandomCalculation”数据集**：基于此生成器，作者构建了一个名为“RandomCalculation”的干净、无泄露（leakage-free）数据集。这个数据集为评估RL方法提供了一个公正、无偏的环境。\n\n### 关键实验结果\n\n*   **奖励信号的有效性**：使用这些无污染数据集进行评估，研究发现只有准确的奖励信号才能持续且一致地提升性能。这与之前声称随机或不正确奖励信号也能有效的说法形成鲜明对比。\n*   **嘈杂信号的无效性**：实验结果明确指出，嘈杂或不正确的奖励信号并不能带来性能提升，这进一步强调了奖励信号质量的重要性。\n\n### 研究建议\n\n*   **评估标准**：作者强烈倡导在无污染的基准上，并跨越不同的模型家族来评估强化学习方法。\n*   **确保结论可信**：这种严格的评估方法对于确保研究结论的可靠性和可信度至关重要，有助于推动LLM推理能力研究的健康发展。\n\n### 其他信息\n\n本文共26页，属于机器学习（cs.LG）、人工智能（cs.AI）和计算语言学（cs.CL）领域。",
      "shortSummary": "一项研究指出，强化学习（RL）提升大型语言模型（LLM）推理能力的结果可能因数据污染而不可靠。Qwen2.5在流行基准上的出色表现被发现可能源于预训练数据污染，而其他模型未见此提升。为解决此问题，作者创建了无污染的“RandomCalculation”数据集。实验表明，只有准确的奖励信号才能持续提升性能，嘈杂或不正确的信号无效。研究建议在无污染基准和多样模型上评估RL方法，以确保结论可信。",
      "translated_title": "推理还是记忆？强化学习因数据污染导致结果不可靠",
      "images": [],
      "contentSource": "完整文章",
      "content": "The reasoning capabilities of large language models (LLMs) have been a longstanding focus of research. Recent works have further enhanced these capabilities using reinforcement learning (RL), with many new methods claiming significant improvements with minimal or no external supervision. Surprisingly, some studies even suggest that random or incorrect reward signals can enhance reasoning performance. However, these breakthroughs are mostly reported on the Qwen2.5 model family and evaluated on well-known benchmarks such as MATH-500, AMC, and AIME, while failing to achieve similar gains on other models like Llama, which warrants further investigation. Our analysis shows that although Qwen2.5 achieves strong mathematical reasoning performance, its pretraining on large-scale web corpora makes it vulnerable to data contamination in popular benchmarks. As a result, results derived from these benchmarks may be unreliable. To address this, we introduce a generator that produces fully synthetic arithmetic problems of arbitrary length and difficulty, yielding a clean dataset we call RandomCalculation. Using these leakage-free datasets, we show that only accurate reward signals consistently improve performance, while noisy or incorrect signals do not. We advocate for evaluating RL methods on uncontaminated benchmarks and across diverse model families to ensure trustworthy conclusions."
    },
    {
      "title": "递归混合体：学习动态递归深度以实现自适应令牌级计算 (原标题: Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation)",
      "link": "https://arxiv.org/abs/2507.10524",
      "pubDate": "Mon, 14 Jul 2025 13:49:00 GMT",
      "isoDate": "2025-07-14T13:49:00.000Z",
      "creator": "Sangmin Bae, Yujin Kim, Reza Bayat, Sungnyun Kim, Jiyoun Ha, Tal Schuster, Adam Fisch, Hrayr Harutyunyan, Ziwei Ji, Aaron Courville, Se-Young Yun",
      "summary": "## 递归混合体 (MoR)：一种高效的语言模型框架\n\n### 核心问题\n\n大型语言模型虽然能力强大，但其训练和部署所需的计算与内存成本高昂。现有的效率提升方法通常侧重于参数共享或自适应计算，但未能同时实现两者。\n\n### 解决方案：递归混合体 (MoR)\n\nMoR 是一种统一的框架，它在一个单一的递归 Transformer 中结合了参数共享和自适应计算这两个效率维度。\n\n### MoR 的工作原理\n\n*   **参数效率**：MoR 通过在递归步骤中重用共享的层堆栈来实现参数效率。\n*   **自适应计算**：轻量级路由器能够动态地为单个令牌分配不同的递归深度，从而实现令牌级的自适应“思考”。\n*   **注意力计算优化**：MoR 仅将二次注意力计算集中在给定递归深度下仍然活跃的令牌上。\n*   **内存访问效率**：通过选择性地缓存仅活跃令牌的键值（KV）对，进一步提高了内存访问效率。\n\n### 额外机制：KV 共享变体\n\nMoR 还提出了一种 KV 共享变体，它重用第一次递归中的 KV 对，专门设计用于减少预填充延迟和内存占用。\n\n### 性能表现\n\nMoR 在 1.35 亿到 17 亿参数的模型规模范围内，形成了一个新的帕累托前沿：\n\n*   在相同的训练 FLOPs 和更小的模型尺寸下，MoR 显著降低了验证困惑度并提高了少样本准确性。\n*   与传统的和现有的递归基线相比，MoR 提供了更高的吞吐量。\n\n### 结论\n\n这些成果表明，MoR 是在不承担大型模型成本的情况下，实现大型模型质量的有效途径。",
      "shortSummary": "递归混合体（MoR）是一种新型框架，旨在解决大型语言模型的高成本问题。它在一个递归 Transformer 中结合了参数共享和自适应计算，通过重用层和动态分配递归深度来提高效率。MoR 优化了注意力计算和内存访问，并引入 KV 共享以减少延迟。实验表明，MoR 在更小的模型尺寸和相同计算量下，显著提升了性能（降低困惑度、提高准确性、增加吞吐量），实现了低成本下的高质量模型。",
      "translated_title": "递归混合体：学习动态递归深度以实现自适应令牌级计算",
      "images": [],
      "contentSource": "完整文章",
      "content": "Scaling language models unlocks impressive capabilities, but the accompanying computational and memory demands make both training and deployment expensive. Existing efficiency efforts typically target either parameter sharing or adaptive computation, leaving open the question of how to attain both simultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework that combines the two axes of efficiency inside a single Recursive Transformer. MoR reuses a shared stack of layers across recursion steps to achieve parameter efficiency, while lightweight routers enable adaptive token-level thinking by dynamically assigning different recursion depths to individual tokens. This allows MoR to focus quadratic attention computation only among tokens still active at a given recursion depth, further improving memory access efficiency by selectively caching only their key-value pairs. Beyond these core mechanisms, we also propose a KV sharing variant that reuses KV pairs from the first recursion, specifically designed to decrease prefill latency and memory footprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms a new Pareto frontier: at equal training FLOPs and smaller model sizes, it significantly lowers validation perplexity and improves few-shot accuracy, while delivering higher throughput compared with vanilla and existing recursive baselines. These gains demonstrate that MoR is an effective path towards large-model quality without incurring large-model cost."
    },
    {
      "title": "MoVieS：一秒内运动感知4D动态视图合成 (原标题: MoVieS: Motion-Aware 4D Dynamic View Synthesis in One Second)",
      "link": "https://arxiv.org/abs/2507.10065",
      "pubDate": "Mon, 14 Jul 2025 04:49:57 GMT",
      "isoDate": "2025-07-14T04:49:57.000Z",
      "creator": "Chenguo Lin, Yuchen Lin, Panwang Pan, Yifan Yu, Honglei Yan, Katerina Fragkiadaki, Yadong Mu",
      "summary": "MoVieS 是一种新颖的前馈模型，它能够在一秒钟内从单目视频合成 4D 动态新视图。\n\n**核心技术与创新点：**\n\n*   **场景表示：** MoVieS 使用高斯基元（Gaussian primitives）的像素对齐网格来表示动态 3D 场景。\n*   **运动监督：** 模型明确地监督这些高斯基元的时变运动，这是其“运动感知”的关键。\n*   **统一建模：** MoVieS 首次实现了外观、几何和运动的统一建模，将这三个关键要素整合到一个框架中。\n\n**多功能性与应用：**\n\n*   **多任务支持：** 在一个单一的基于学习的框架内，MoVieS 能够同时进行视图合成、重建和 3D 点跟踪。\n*   **训练效率：** 通过将新视图合成与动态几何重建相结合，MoVieS 可以在多样化数据集上进行大规模训练，同时对特定任务的监督依赖性极小。\n*   **零样本能力：** 该模型自然支持广泛的零样本应用，例如场景流估计和运动物体分割，无需额外的特定任务训练。\n\n**性能表现：**\n\n*   大量实验验证了 MoVieS 在多项任务中的有效性和效率。\n*   它实现了具有竞争力的性能，同时提供了数量级的速度提升，显著优于现有方法。",
      "shortSummary": "MoVieS是一种创新的前馈模型，能在一秒内从单目视频合成4D动态新视图。它通过高斯基元统一建模外观、几何和运动，并明确监督时变运动。该模型在一个框架内支持视图合成、重建和3D点跟踪，并能进行零样本应用如场景流估计和运动物体分割。实验证明MoVieS高效且性能优异，实现了显著的速度提升。",
      "translated_title": "MoVieS：一秒内运动感知4D动态视图合成",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present MoVieS, a novel feed-forward model that synthesizes 4D dynamic novel views from monocular videos in one second. MoVieS represents dynamic 3D scenes using pixel-aligned grids of Gaussian primitives, explicitly supervising their time-varying motion. This allows, for the first time, the unified modeling of appearance, geometry and motion, and enables view synthesis, reconstruction and 3D point tracking within a single learning-based framework. By bridging novel view synthesis with dynamic geometry reconstruction, MoVieS enables large-scale training on diverse datasets with minimal dependence on task-specific supervision. As a result, it also naturally supports a wide range of zero-shot applications, such as scene flow estimation and moving object segmentation. Extensive experiments validate the effectiveness and efficiency of MoVieS across multiple tasks, achieving competitive performance while offering several orders of magnitude speedups."
    },
    {
      "title": "SpeakerVid-5M：一个用于音视频双向交互式数字人生成的大规模高质量数据集 (原标题: SpeakerVid-5M: A Large-Scale High-Quality Dataset for Audio-Visual Dyadic Interactive Human Generation)",
      "link": "https://arxiv.org/abs/2507.09862",
      "pubDate": "Sun, 13 Jul 2025 22:22:47 GMT",
      "isoDate": "2025-07-13T22:22:47.000Z",
      "creator": "Youliang Zhang, Zhaoyang Li, Duomin Wang, Jiahe Zhang, Deyu Zhou, Zixin Yin, Xili Dai, Gang Yu, Xiu Li",
      "summary": "## SpeakerVid-5M：音视频双向交互式数字人生成数据集\n\n### 背景与挑战\n\n随着大规模模型的快速发展，数字人领域取得了显著突破，尤其在虚拟形象驱动和渲染方面实现了高保真解决方案。学术界目前的焦点已转向下一个主要挑战：**音视频双向交互式虚拟人**的生成。\n\n### SpeakerVid-5M 数据集介绍\n\n为了促进这一新兴领域的研究，本文提出了 **SpeakerVid-5M** 数据集，这是首个专为音视频双向交互式虚拟人生成设计的大规模、高质量数据集。\n\n*   **规模宏大**：数据集总时长超过 **8,743 小时**，包含超过 **520 万个**人类肖像视频片段。\n*   **内容多样**：涵盖了多种尺度和交互类型，包括单人说话（monadic talking）、听众反应（listening）以及双向对话（dyadic conversations）。\n\n### 数据集结构与特点\n\nSpeakerVid-5M 数据集在两个关键维度上进行了结构化设计：**交互类型**和**数据质量**。\n\n1.  **基于交互场景的分类（交互类型）**：\n    *   **对话分支 (dialogue branch)**\n    *   **单人分支 (single branch)**\n    *   **听众分支 (listening branch)**\n    *   **多轮分支 (multi-turn branch)**\n\n2.  **基于数据质量的分层（数据质量）**：\n    *   一个**大规模预训练子集**，用于基础模型的训练。\n    *   一个经过精心策划的**高质量子集**，专为监督微调（Supervised Fine-Tuning, SFT）设计。\n\n这种双重结构能够支持广泛的2D虚拟人任务。\n\n### 附加贡献与基准\n\n除了数据集本身，研究团队还提供了以下资源：\n\n*   一个基于该数据训练的**自回归（AR）视频聊天基线模型**。\n*   一套专门的**评估指标和测试数据**，共同构成 **VidChatBench**，作为未来研究的基准。\n\n### 可用性\n\nSpeakerVid-5M 数据集及其相应的数据处理代码将**公开发布**，以促进社区研究。\n\n*   **项目页面**：提供更多详细信息（请注意，文章中提供的URL为占位符，此处不展示具体链接）。\n*   **研究领域**：计算机视觉与模式识别 (cs.CV)；音频与语音处理 (eess.AS)。",
      "shortSummary": "SpeakerVid-5M是首个大规模、高质量的音视频双向交互式数字人生成数据集。它包含超过8,743小时、520万个视频片段，涵盖单人、双向等多种交互类型。数据集按交互场景和数据质量分层，包括预训练和SFT子集，支持多样化的2D虚拟人任务。项目还提供了基于该数据的AR视频聊天基线模型和VidChatBench基准测试集。数据集及处理代码将公开发布，旨在推动相关领域研究。",
      "translated_title": "SpeakerVid-5M：一个用于音视频双向交互式数字人生成的大规模高质量数据集",
      "images": [],
      "contentSource": "完整文章",
      "content": "The rapid development of large-scale models has catalyzed significant breakthroughs in the digital human domain. These advanced methodologies offer high-fidelity solutions for avatar driving and rendering, leading academia to focus on the next major challenge: audio-visual dyadic interactive virtual human. To facilitate research in this emerging area, we present SpeakerVid-5M dataset, the first large-scale, high-quality dataset designed for audio-visual dyadic interactive virtual human generation. Totaling over 8,743 hours, SpeakerVid-5M contains more than 5.2 million video clips of human portraits. It covers diverse scales and interaction types, including monadic talking, listening, and dyadic conversations. Crucially, the dataset is structured along two key dimensions: interaction type and data quality. First, it is categorized into four types (dialogue branch, single branch, listening branch and multi-turn branch) based on the interaction scenario. Second, it is stratified into a large-scale pre-training subset and a curated, high-quality subset for Supervised Fine-Tuning (SFT). This dual structure accommodates a wide array of 2D virtual human tasks. In addition, we provide an autoregressive (AR)-based video chat baseline trained on this data, accompanied by a dedicated set of metrics and test data to serve as a benchmark VidChatBench for future work. Both the dataset and the corresponding data processing code will be publicly released. Project page: https://dorniwang.github.io/SpeakerVid-5M/"
    },
    {
      "title": "LLMalMorph：关于使用大型语言模型生成变种恶意软件的可行性 (原标题: LLMalMorph: On The Feasibility of Generating Variant Malware using Large-Language-Models)",
      "link": "https://arxiv.org/abs/2507.09411",
      "pubDate": "Sat, 12 Jul 2025 18:11:10 GMT",
      "isoDate": "2025-07-12T18:11:10.000Z",
      "creator": "Md Ajwad Akil, Adrian Shuai Li, Imtiaz Karim, Arun Iyengar, Ashish Kundu, Vinny Parla, Elisa Bertino",
      "summary": "## LLMalMorph：使用大型语言模型生成变种恶意软件的可行性\n\n### 研究背景与动机\n\n*   大型语言模型（LLMs）已彻底改变了软件开发和自动化代码生成领域。\n*   受这些进展的启发，本文旨在探讨LLMs在修改恶意软件源代码以生成变种方面的可行性。\n\n### LLMalMorph框架介绍\n\n*   本文提出了 **LLMalMorph**，一个半自动化框架，它利用LLMs对代码的语义和语法理解能力来生成新的恶意软件变种。\n*   **工作原理：**\n    *   LLMalMorph从恶意软件源代码中提取函数级信息。\n    *   它结合了定制设计的提示（prompts）和策略性定义的代码转换。\n    *   这些机制共同引导LLM生成变种，而无需进行资源密集型的微调。\n\n### 实验评估\n\n*   **样本选择：** 为了评估LLMalMorph的有效性，研究人员收集了10个多样化的Windows恶意软件样本，这些样本在类型、复杂性和功能上各不相同。\n*   **变种生成：** 通过LLMalMorph，共生成了618个恶意软件变种。\n\n### 实验结果\n\n*   **规避传统检测：** 彻底的实验表明，这些恶意软件变种的杀毒引擎检测率可以在一定程度上降低，同时成功保留了恶意软件的原始功能。\n*   **对抗机器学习检测器：** 尽管LLMalMorph在设计时并未针对任何基于机器学习（ML）的恶意软件检测器进行优化，但一些生成的变种对基于ML的恶意软件分类器也取得了显著的攻击成功率。\n\n### 讨论与展望\n\n*   文章还讨论了当前LLM在从源代码生成恶意软件变种方面的能力局限性。\n*   评估了这项新兴技术在更广泛的恶意软件变种生成背景下的地位和潜力。",
      "shortSummary": "本文提出了LLMalMorph框架，利用大型语言模型（LLMs）从源代码生成恶意软件变种。通过对10个Windows恶意软件样本生成618个变种的实验表明，LLMalMorph能在一定程度上降低杀毒引擎的检测率，同时保持恶意软件功能。部分变种对基于机器学习的检测器也有效。研究还讨论了LLM在生成恶意软件变种方面的局限性。",
      "translated_title": "LLMalMorph：关于使用大型语言模型生成变种恶意软件的可行性",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have transformed software development and automated code generation. Motivated by these advancements, this paper explores the feasibility of LLMs in modifying malware source code to generate variants. We introduce LLMalMorph, a semi-automated framework that leverages semantical and syntactical code comprehension by LLMs to generate new malware variants. LLMalMorph extracts function-level information from the malware source code and employs custom-engineered prompts coupled with strategically defined code transformations to guide the LLM in generating variants without resource-intensive fine-tuning. To evaluate LLMalMorph, we collected 10 diverse Windows malware samples of varying types, complexity and functionality and generated 618 variants. Our thorough experiments demonstrate that it is possible to reduce the detection rates of antivirus engines of these malware variants to some extent while preserving malware functionalities. In addition, despite not optimizing against any Machine Learning (ML)-based malware detectors, several variants also achieved notable attack success rates against an ML-based malware classifier. We also discuss the limitations of current LLM capabilities in generating malware variants from source code and assess where this emerging technology stands in the broader context of malware variant generation."
    },
    {
      "title": "最优数据混合的缩放定律 (原标题: Scaling Laws for Optimal Data Mixtures)",
      "link": "https://arxiv.org/abs/2507.09404",
      "pubDate": "Sat, 12 Jul 2025 17:16:08 GMT",
      "isoDate": "2025-07-12T17:16:08.000Z",
      "creator": "Mustafa Shukor, Louis Bethune, Dan Busbridge, David Grangier, Enrico Fini, Alaaeldin El-Nouby, Pierre Ablin",
      "summary": "## 最优数据混合的缩放定律\n\n### 核心问题\n\n*   大型基础模型通常使用来自多个领域的数据进行训练，其中数据混合比例（即每个领域数据的使用比例）对模型性能至关重要。\n*   目前选择数据混合比例的标准方法依赖于试错法，这对于大规模预训练来说变得不切实际且成本高昂。\n\n### 提出的解决方案\n\n*   本文提出了一种系统性的方法，利用**缩放定律**来确定任何目标领域的最优数据混合比例。\n*   该方法能够准确预测在给定模型大小 $N$、训练令牌数量 $D$ 和特定领域权重向量 $h$ 的情况下，模型的损失。\n\n### 缩放定律的普适性验证\n\n*   研究通过在三个不同且大规模的预训练设置中验证了这些缩放定律的普适性：\n    *   **大型语言模型 (LLM)**\n    *   **原生多模态模型 (NMM)**\n    *   **大型视觉模型 (LVM)**\n\n### 关键能力与优势\n\n*   **外推能力**：这些缩放定律可以外推到新的数据混合比例和不同的规模。\n*   **参数估计**：其参数可以通过少量小规模训练运行准确估计，并用于预测更大规模和未见领域权重下的性能。\n*   **替代传统方法**：缩放定律允许在给定训练预算（$N$, $D$）下推导出任何目标领域的最优领域权重，为昂贵的试错法提供了一种有原则的替代方案。",
      "shortSummary": "本文提出了一种利用缩放定律的系统方法，以确定大型基础模型的最优数据混合比例。该方法能准确预测模型在不同规模和数据混合下的性能，并已在大型语言模型、多模态模型和视觉模型预训练中得到验证。通过少量小规模训练即可估计参数，进而推导出最优领域权重，从而取代了耗时且昂贵的试错法，为模型训练提供了更高效、有原则的指导。",
      "translated_title": "最优数据混合的缩放定律",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large foundation models are typically trained on data from multiple domains, with the data mixture--the proportion of each domain used--playing a critical role in model performance. The standard approach to selecting this mixture relies on trial and error, which becomes impractical for large-scale pretraining. We propose a systematic method to determine the optimal data mixture for any target domain using scaling laws. Our approach accurately predicts the loss of a model of size N trained with D tokens and a specific domain weight vector h. We validate the universality of these scaling laws by demonstrating their predictive power in three distinct and large-scale settings: large language model (LLM), native multimodal model (NMM), and large vision models (LVM) pretraining. We further show that these scaling laws can extrapolate to new data mixtures and across scales: their parameters can be accurately estimated using a few small-scale training runs, and used to estimate the performance at larger scales and unseen domain weights. The scaling laws allow to derive the optimal domain weights for any target domain under a given training budget (N,D), providing a principled alternative to costly trial-and-error methods."
    },
    {
      "title": "CompassJudger-2：通过可验证奖励迈向通用评判模型 (原标题: CompassJudger-2: Towards Generalist Judge Model via Verifiable Rewards)",
      "link": "https://arxiv.org/abs/2507.09104",
      "pubDate": "Fri, 11 Jul 2025 21:34:24 GMT",
      "isoDate": "2025-07-11T21:34:24.000Z",
      "creator": "Taolin Zhang, Maosong Cao, Alexander Lam, Songyang Zhang, Kai Chen",
      "summary": "### CompassJudger-2：通过可验证奖励迈向通用评判模型\n\n**引言与背景**\n\n*   近年来，大型语言模型（LLM）作为评判者（LLM-as-judge）在评估其他LLM方面的重要性日益凸显。\n*   然而，当前的评判模型普遍存在专业化狭隘和鲁棒性不足的问题，这限制了它们进行全面评估的能力。\n\n**CompassJudger-2 核心方法**\n\n*   本文提出了 CompassJudger-2，一个新型的通用评判模型，旨在克服现有模型的局限性。\n*   **数据策略**：采用任务驱动、多领域的数据整理策略。\n*   **监督机制**：通过可验证奖励（verifiable rewards）监督评判任务，引导内在批判性推理。\n*   **训练优化**：通过拒绝采样（rejection sampling）来培养鲁棒的、可泛化的评判能力。\n*   **学习目标**：引入了带有边际策略梯度损失（margin policy gradient loss）的改进学习目标，以增强模型性能。\n\n**实验结果与性能**\n\n*   CompassJudger-2 在多个评判和奖励基准测试中取得了卓越的成果。\n*   其7B模型展现出与DeepSeek-V3和Qwen3-235B-A22B等显著更大的模型相媲美的评判准确性。\n\n**JudgerBenchV2 新基准**\n\n*   为了标准化评判模型的评估，研究团队还提出了 JudgerBenchV2。\n*   这是一个综合性基准，用于评估跨领域评判准确性和排名一致性。\n\n**贡献与影响**\n\n*   这些贡献推动了鲁棒、可扩展的LLM评判技术的发展。\n*   为评判模型的性能和评估树立了新的标准。",
      "shortSummary": "CompassJudger-2是一个新型通用评判模型，旨在解决现有LLM评判模型专业化狭隘和鲁棒性不足的问题。它采用任务驱动的多领域数据整理策略，并通过可验证奖励和拒绝采样来指导批判性推理。该模型在多个基准测试中表现卓越，其7B版本能与大型模型媲美。此外，研究还提出了JudgerBenchV2，一个用于标准化评估的综合基准。这些进展为LLM评判技术树立了新标准。",
      "translated_title": "CompassJudger-2：通过可验证奖励迈向通用评判模型",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recently, the role of LLM-as-judge in evaluating large language models has gained prominence. However, current judge models suffer from narrow specialization and limited robustness, undermining their capacity for comprehensive evaluations. In this work, we present CompassJudger-2, a novel generalist judge model that overcomes these limitations via a task-driven, multi-domain data curation strategy. Central to our approach is supervising judgment tasks with verifiable rewards, guiding intrinsic critical reasoning through rejection sampling to foster robust, generalizable judgment capabilities. We introduce a refined learning objective with margin policy gradient loss to enhance performance. Empirically, CompassJudger-2 achieves superior results across multiple judge and reward benchmarks, and our 7B model demonstrates competitive judgment accuracy with significantly larger models like DeepSeek-V3 and Qwen3-235B-A22B. Additionally, we propose JudgerBenchV2, a comprehensive benchmark evaluating cross-domain judgment accuracy and rank consistency to standardize judge model evaluation. These contributions advance robust, scalable LLM judgment and establish new performance and evaluation standards."
    },
    {
      "title": "OpenCodeReasoning-II：一种通过自我批判实现的简单测试时扩展方法 (原标题: OpenCodeReasoning-II: A Simple Test Time Scaling Approach via Self-Critique)",
      "link": "https://arxiv.org/abs/2507.09075",
      "pubDate": "Fri, 11 Jul 2025 19:35:54 GMT",
      "isoDate": "2025-07-11T19:35:54.000Z",
      "creator": "Wasi Uddin Ahmad, Somshubra Majumdar, Aleksander Ficek, Sean Narenthiran, Mehrzad Samadi, Jocelyn Huang, Siddhartha Jain, Vahid Noroozi, Boris Ginsburg",
      "summary": "## OpenCodeReasoning-II：通过自我批判实现测试时扩展\n\n### 摘要\n\n本文介绍了OpenCodeReasoning-II，一个旨在促进大型语言模型（LLMs）在代码生成和批判领域发展的项目。该工作旨在解决高质量、大规模数据集在这些领域进展中的关键作用。\n\n### 关键贡献\n\n*   **OpenCodeReasoning-II 数据集**：\n    *   包含250万个“问题-解决方案-批判”三元组，涵盖约3.5万个独特的编程问题。\n    *   其规模几乎是此前最大的公开可用代码推理数据集的两倍。\n*   **两阶段监督微调策略**：\n    *   **第一阶段**：专注于代码生成模型的微调。\n    *   **第二阶段**：对代码生成和批判模型进行联合训练。\n*   **模型性能**：\n    *   使用Qwen2.5-Instruct模型进行微调，在代码生成方面的性能达到或超越了现有最佳的开源蒸馏模型。\n    *   将代码生成模型与批判模型相结合，显著提升了在竞争性编程任务中的表现。\n*   **LiveCodeBench 基准扩展**：\n    *   将LiveCodeBench基准扩展以支持C++编程语言。\n    *   此举旨在促进对LLMs更全面的评估。",
      "shortSummary": "OpenCodeReasoning-II引入了一个包含250万个“问题-解决方案-批判”三元组的大规模代码推理数据集，旨在推动LLM在代码生成和批判领域的发展。该项目采用两阶段监督微调策略，使Qwen2.5-Instruct模型在代码生成方面表现出色，并显著提升了竞争性编程性能。此外，它还扩展了LiveCodeBench基准以支持C++语言，促进更全面的LLM评估。",
      "translated_title": "OpenCodeReasoning-II：一种通过自我批判实现的简单测试时扩展方法",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advancements in reasoning-based Large Language Models (LLMs), particularly their potential through test-time scaling, have created significant opportunities for distillation in code generation and critique. However, progress in both areas fundamentally depends on large-scale, high-quality datasets. In this work, we introduce OpenCodeReasoning-II, a dataset consists of 2.5M question-solution-critique triples (approx. 35K unique programming questions), making it nearly twice the size of the previous largest publicly available code reasoning dataset. In this work, we employ a two-stage supervised fine-tuning strategy. The first stage focuses on fine-tuning for code generation, while the second stage involves the joint training of models for both code generation and critique. Our resulting finetuned Qwen2.5-Instruct models achieve performance in code generation that either exceeds or equals the best prior open-weight distilled models. Notably, the integration of our code generation and critique models leads to significant improvements in competitive coding performance. Furthermore, we present an extension of the LiveCodeBench benchmark to specifically support the C++ programming language, thereby facilitating more comprehensive LLM evaluation using this benchmark."
    },
    {
      "title": "Lumos-1：从统一模型视角看自回归视频生成 (原标题: Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective)",
      "link": "https://arxiv.org/abs/2507.08801",
      "pubDate": "Fri, 11 Jul 2025 13:59:42 GMT",
      "isoDate": "2025-07-11T13:59:42.000Z",
      "creator": "Hangjie Yuan, Weihua Chen, Jun Cen, Hu Yu, Jingyun Liang, Shuning Chang, Zhihui Lin, Tao Feng, Pengwei Liu, Jiazheng Xing, Hao Luo, Jiasheng Tang, Fan Wang, Yi Yang",
      "summary": "## Lumos-1：从统一模型视角看自回归视频生成\n\n### 引言\n大型语言模型（LLMs）在统一各种语言任务方面取得了巨大成功，这启发了自回归视频生成领域的初步探索。然而，现有的自回归视频生成器面临一些挑战，包括：\n*   偏离标准的LLM架构。\n*   依赖笨重的外部文本编码器。\n*   由于逐token解码导致高昂的延迟。\n\n### Lumos-1 介绍\n本文提出了 **Lumos-1**，一个自回归视频生成器。Lumos-1 的核心设计理念是在保持LLM架构的同时，进行最小的架构修改，以克服现有方法的局限性。\n\n### 核心创新点\nLumos-1 引入了多项创新来有效建模时空数据并优化训练过程：\n\n1.  **MM-RoPE (Multimodal Rotational Positional Embedding)**\n    *   **问题识别**：为了在LLMs中注入时空相关性，研究人员发现3D RoPE是有效的，但其频率频谱范围存在不平衡问题。\n    *   **解决方案**：Lumos-1 提出了 MM-RoPE。该方案在保留原始文本RoPE的同时，为建模多模态时空数据提供了全面的频率频谱和缩放的3D位置，从而更有效地捕捉视频的时空信息。\n\n2.  **Token 依赖策略**\n    *   Lumos-1 采用了一种精巧的token依赖策略，该策略遵循 **帧内双向性**（intra-frame bidirectionality）和 **帧间时间因果性**（inter-frame temporal causality）。这种策略有助于模型理解视频帧内部的空间关系以及帧之间的时间演变。\n\n3.  **自回归离散扩散强制 (AR-DF)**\n    *   **问题识别**：基于上述token依赖策略，研究人员发现由于空间信息冗余，存在帧级损失不平衡的问题。\n    *   **解决方案**：Lumos-1 通过提出 AR-DF 来解决这一问题。AR-DF 在训练期间引入了 **时间管掩码**（temporal tube masking），并采用了一种兼容的推理时掩码策略，以避免在生成过程中出现质量下降。\n\n### 训练与性能\nLumos-1 的训练效率显著：\n*   通过使用内存高效的训练技术，Lumos-1 仅在48个GPU上进行了预训练。\n*   尽管训练资源相对较少，Lumos-1 仍取得了令人印象深刻的性能：\n    *   在 GenEval 基准测试上，其性能与 EMU3 相当。\n    *   在 VBench-I2V（图像到视频）任务上，其性能与 COSMOS-Video2World 相当。\n    *   在 VBench-T2V（文本到视频）任务上，其性能与 OpenSoraPlan 相当。\n\n### 可用性\nLumos-1 的代码和模型已公开。",
      "shortSummary": "Lumos-1是一个创新的自回归视频生成器，它在保持LLM架构的同时，解决了现有方法的局限性。该模型引入了MM-RoPE以有效建模时空相关性，并提出了AR-DF来解决帧级损失不平衡问题。Lumos-1通过内存高效的训练，仅使用48个GPU就达到了与EMU3、COSMOS-Video2World和OpenSoraPlan等先进模型相当的性能，展示了其高效性和竞争力。",
      "translated_title": "Lumos-1：从统一模型视角看自回归视频生成",
      "images": [],
      "contentSource": "完整文章",
      "content": "Autoregressive large language models (LLMs) have unified a vast range of language tasks, inspiring preliminary efforts in autoregressive video generation. Existing autoregressive video generators either diverge from standard LLM architectures, depend on bulky external text encoders, or incur prohibitive latency due to next-token decoding. In this paper, we introduce Lumos-1, an autoregressive video generator that retains the LLM architecture with minimal architectural modifications. To inject spatiotemporal correlations in LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its imbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE scheme that preserves the original textual RoPE while providing comprehensive frequency spectra and scaled 3D positions for modeling multimodal spatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy that obeys intra-frame bidirectionality and inter-frame temporal causality. Based on this dependency strategy, we identify the issue of frame-wise loss imbalance caused by spatial information redundancy and solve it by proposing Autoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal tube masking during training with a compatible inference-time masking policy to avoid quality degradation. By using memory-efficient training techniques, we pre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on GenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code and models are available at https://github.com/alibaba-damo-academy/Lumos."
    },
    {
      "title": "NeuralOS：通过神经生成模型模拟操作系统 (原标题: NeuralOS: Towards Simulating Operating Systems via Neural Generative Models)",
      "link": "https://arxiv.org/abs/2507.08800",
      "pubDate": "Fri, 11 Jul 2025 13:59:40 GMT",
      "isoDate": "2025-07-11T13:59:40.000Z",
      "creator": "Luke Rivard, Sun Sun, Hongyu Guo, Wenhu Chen, Yuntian Deng",
      "summary": "## NeuralOS 简介\n\nNeuralOS 是一个创新的神经框架，旨在通过直接预测屏幕帧来模拟操作系统的图形用户界面（GUI），以响应用户的鼠标移动、点击和键盘事件等输入。\n\n### 核心组成与工作原理\n\n*   **状态跟踪与图像生成**：NeuralOS 结合了两种关键组件：\n    *   **循环神经网络（RNN）**：负责跟踪计算机的内部状态。\n    *   **基于扩散的神经渲染器**：用于生成屏幕图像。\n*   **训练数据**：该模型在一个大规模的 Ubuntu XFCE 录制数据集上进行训练。这些录制数据包含了随机生成的交互以及由 AI 代理产生的真实交互。\n\n### 实验成果与能力\n\n实验结果表明，NeuralOS 在以下方面表现出色：\n\n*   **真实 GUI 序列渲染**：成功渲染出逼真的 GUI 序列。\n*   **精确的鼠标交互捕获**：能够准确捕捉并响应鼠标交互。\n*   **可靠的状态转换预测**：能够可靠地预测状态转换，例如应用程序的启动。\n\n### 挑战与未来展望\n\n尽管在精确建模细粒度的键盘交互方面仍面临挑战，但 NeuralOS 的出现标志着向未来人机交互系统迈出了重要一步，有望创建出完全自适应、生成式的神经界面。\n\n### 相关领域\n\n该研究涉及多个计算机科学领域，包括：\n\n*   计算机视觉与模式识别 (cs.CV)\n*   人工智能 (cs.AI)\n*   计算与语言 (cs.CL)\n*   人机交互 (cs.HC)\n*   机器学习 (cs.LG)",
      "shortSummary": "NeuralOS 是一个神经框架，通过预测屏幕帧来模拟操作系统的图形用户界面（GUI），响应用户输入。它结合了循环神经网络（RNN）和基于扩散的神经渲染器，并在大规模 Ubuntu XFCE 数据集上进行训练。该模型能成功渲染逼真 GUI 序列，准确捕获鼠标交互并预测状态转换。尽管键盘交互仍是挑战，NeuralOS 为未来自适应生成式人机交互界面奠定了基础。",
      "translated_title": "NeuralOS：通过神经生成模型模拟操作系统",
      "images": [],
      "contentSource": "完整文章",
      "content": "We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems."
    },
    {
      "title": "KV缓存转向：在小型语言模型中诱导推理 (原标题: KV Cache Steering for Inducing Reasoning in Small Language Models)",
      "link": "https://arxiv.org/abs/2507.08799",
      "pubDate": "Fri, 11 Jul 2025 13:59:36 GMT",
      "isoDate": "2025-07-11T13:59:36.000Z",
      "creator": "Max Belitsky, Dawid J. Kopiczko, Michael Dorkenwald, M. Jehanzeb Mirza, Cees G. M. Snoek, Yuki M. Asano",
      "summary": "### 核心提案：缓存转向 (Cache Steering)\n\n*   **定义与机制：** 缓存转向是一种轻量级方法，通过对语言模型的键值（KV）缓存进行“一次性”（one-shot）干预，实现对模型行为的隐式引导。\n\n### 应用与目标\n\n*   **主要应用：** 该方法被应用于在小型语言模型中诱导思维链（chain-of-thought）推理。\n*   **目标：** 在不进行模型微调或修改提示词的情况下，促使模型生成更显式、多步的推理过程。\n\n### 工作原理\n\n*   **转向向量构建：** 缓存转向利用GPT-4o生成的推理轨迹来构建“转向向量”（steering vectors）。\n*   **行为调整：** 这些转向向量直接作用于KV缓存，从而将模型的行为模式转向更倾向于显式、多步骤的推理。\n\n### 主要优势与性能\n\n*   **无需微调或提示词修改：** 显著降低了实施复杂性，无需对模型架构或输入方式进行根本性改变。\n*   **性能提升：** 在多样化的推理基准测试中，实验评估表明缓存转向不仅改善了模型推理的定性结构（即推理过程的清晰度和逻辑性），还提高了量化任务性能（即最终答案的准确性）。\n*   **与现有技术的比较：**\n    *   **一次性干预：** 与需要持续干预的现有激活转向（activation steering）技术相比，缓存转向仅需一次性干预，大大简化了操作。\n    *   **鲁棒性与效率：** 这种一次性干预的特性带来了超参数稳定性、推理时间效率和集成便捷性方面的显著优势。\n    *   **实用性：** 使得缓存转向成为一种更鲁棒、更实用的受控生成解决方案。",
      "shortSummary": "“缓存转向”是一种轻量级方法，通过对键值（KV）缓存进行一次性干预，在小型语言模型中诱导思维链推理。该方法利用GPT-4o生成的推理轨迹构建转向向量，无需微调或修改提示词，即可将模型行为转向更显式、多步的推理。实验表明，它能提升推理质量和任务性能，且相比传统激活转向技术，在效率和鲁棒性方面更具优势，是一种实用的受控生成解决方案。",
      "translated_title": "KV缓存转向：在小型语言模型中诱导推理",
      "images": [],
      "contentSource": "完整文章",
      "content": "We propose cache steering, a lightweight method for implicit steering of language models via a one-shot intervention applied directly to the key-value cache. To validate its effectiveness, we apply cache steering to induce chain-of-thought reasoning in small language models. Our approach leverages GPT-4o-generated reasoning traces to construct steering vectors that shift model behavior toward more explicit, multi-step reasoning without fine-tuning or prompt modifications. Experimental evaluations on diverse reasoning benchmarks demonstrate that cache steering improves both the qualitative structure of model reasoning and quantitative task performance. Compared to prior activation steering techniques that require continuous interventions, our one-shot cache steering offers substantial advantages in terms of hyperparameter stability, inference-time efficiency, and ease of integration, making it a more robust and practical solution for controlled generation."
    },
    {
      "title": "从KMMLU-Redux到KMMLU-Pro：一个用于LLM评估的专业韩语基准测试套件 (原标题: From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation)",
      "link": "https://arxiv.org/abs/2507.08924",
      "pubDate": "Fri, 11 Jul 2025 13:56:32 GMT",
      "isoDate": "2025-07-11T13:56:32.000Z",
      "creator": "Seokhee Hong, Sunkyoung Kim, Guijin Son, Soyeon Kim, Yeonjung Hong, Jinsik Lee",
      "summary": "### 介绍KMMLU-Redux和KMMLU-Pro：用于LLM评估的专业韩语基准测试套件\n\n**引言**\n\n大语言模型（LLM）的开发需要强大的基准测试，这些基准不仅要涵盖学术领域，还要包括工业领域，以有效评估其在实际场景中的适用性。\n\n**新基准介绍**\n\n本文介绍了两个韩语专家级基准测试，旨在满足上述需求：\n\n*   **KMMLU-Redux**\n    *   从现有KMMLU重建而来。\n    *   包含来自韩国国家技术资格考试的问题。\n    *   已移除关键错误，以增强其可靠性。\n\n*   **KMMLU-Pro**\n    *   基于韩国国家专业执照考试。\n    *   旨在反映韩国的专业知识。\n\n**实验结果与数据可用性**\n\n实验表明，这些基准测试能够全面代表韩国的工业知识。作者已将数据集公开发布。",
      "shortSummary": "本文介绍了两个新的韩语专家级大语言模型（LLM）评估基准：KMMLU-Redux和KMMLU-Pro。KMMLU-Redux基于韩国国家技术资格考试并纠正了错误，而KMMLU-Pro则源于韩国国家专业执照考试，旨在反映专业知识。这些基准旨在全面评估LLM在韩国工业和专业领域的实际应用能力。数据集已公开发布。",
      "translated_title": "从KMMLU-Redux到KMMLU-Pro：一个用于LLM评估的专业韩语基准测试套件",
      "images": [],
      "contentSource": "完整文章",
      "content": "The development of Large Language Models (LLMs) requires robust benchmarks that encompass not only academic domains but also industrial fields to effectively evaluate their applicability in real-world scenarios. In this paper, we introduce two Korean expert-level benchmarks. KMMLU-Redux, reconstructed from the existing KMMLU, consists of questions from the Korean National Technical Qualification exams, with critical errors removed to enhance reliability. KMMLU-Pro is based on Korean National Professional Licensure exams to reflect professional knowledge in Korea. Our experiments demonstrate that these benchmarks comprehensively represent industrial knowledge in Korea. We release our dataset publicly available."
    },
    {
      "title": "一个Token即可欺骗作为评判者的LLM (原标题: One Token to Fool LLM-as-a-Judge)",
      "link": "https://arxiv.org/abs/2507.08794",
      "pubDate": "Fri, 11 Jul 2025 13:55:22 GMT",
      "isoDate": "2025-07-11T13:55:22.000Z",
      "creator": "Yulai Zhao, Haolin Liu, Dian Yu, S. Y. Kung, Haitao Mi, Dong Yu",
      "summary": "## 摘要：一个Token即可欺骗作为评判者的LLM\n\n### 背景与问题\n\n生成式奖励模型（也称为“作为评判者的LLM”，即LLM-as-a-judge）在可验证奖励强化学习（RLVR）中日益普及。它们通常优于僵化的基于规则的度量标准，尤其适用于涉及自由形式输出的复杂推理任务。在这种范式中，LLM通常被提示将候选答案与真实参考进行比较，并分配一个二进制奖励以指示正确性。\n\n### 核心发现：LLM-as-a-judge的脆弱性\n\n尽管这种比较任务看似简单，但研究发现生成式奖励模型对表面操作表现出惊人的脆弱性：\n\n*   **具体表现**：非单词符号（例如“:”或“.”）或推理引导词（如“Thought process:”和“Let's solve this problem step by step.”）\n*   **结果**：这些简单的操作常常导致假阳性奖励。\n*   **影响范围**：这种弱点在不同的LLM、数据集和提示格式中普遍存在。\n*   **潜在威胁**：这对依赖生成式奖励模型的核心算法范式（如拒绝采样、偏好优化和RLVR）构成了严重威胁。\n\n### 解决方案与成果\n\n为了缓解这个问题，研究人员引入了一种简单而有效的数据增强策略，并训练了一个新的生成式奖励模型。\n\n*   **成果**：新模型表现出显著提高的鲁棒性。\n\n### 结论与展望\n\n这些发现凸显了对更可靠的基于LLM的评估方法的迫切需求。研究团队已发布其鲁棒的通用领域奖励模型及其合成训练数据。",
      "shortSummary": "研究发现，用于评估答案质量的“作为评判者的LLM”（LLM-as-a-judge）模型存在严重漏洞。简单的非单词符号或推理引导词（如“Thought process:”）就能导致模型给出错误的正面评价。这种脆弱性普遍存在，对依赖这些模型的强化学习范式构成威胁。为解决此问题，研究引入了一种数据增强策略，并训练出更鲁棒的奖励模型，强调了开发更可靠LLM评估方法的紧迫性。",
      "translated_title": "一个Token即可欺骗作为评判者的LLM",
      "images": [],
      "contentSource": "完整文章",
      "content": "Generative reward models (also known as LLMs-as-judges), which use large language models (LLMs) to evaluate answer quality, are increasingly adopted in reinforcement learning with verifiable rewards (RLVR). They are often preferred over rigid rule-based metrics, especially for complex reasoning tasks involving free-form outputs. In this paradigm, an LLM is typically prompted to compare a candidate answer against a ground-truth reference and assign a binary reward indicating correctness. Despite the seeming simplicity of this comparison task, we find that generative reward models exhibit surprising vulnerabilities to superficial manipulations: non-word symbols (e.g., \":\" or \".\") or reasoning openers like \"Thought process:\" and \"Let's solve this problem step by step.\" can often lead to false positive rewards. We demonstrate that this weakness is widespread across LLMs, datasets, and prompt formats, posing a serious threat for core algorithmic paradigms that rely on generative reward models, such as rejection sampling, preference optimization, and RLVR. To mitigate this issue, we introduce a simple yet effective data augmentation strategy and train a new generative reward model with substantially improved robustness. Our findings highlight the urgent need for more reliable LLM-based evaluation methods. We release our robust, general-domain reward model and its synthetic training data at https://huggingface.co/sarosavo/Master-RM and https://huggingface.co/datasets/sarosavo/Master-RM."
    },
    {
      "title": "CLiFT：用于计算高效和自适应神经渲染的压缩光场令牌 (原标题: CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering)",
      "link": "https://arxiv.org/abs/2507.08776",
      "pubDate": "Fri, 11 Jul 2025 13:38:52 GMT",
      "isoDate": "2025-07-11T13:38:52.000Z",
      "creator": "Zhengqing Wang, Yuefan Wu, Jiacheng Chen, Fuyang Zhang, Yasutaka Furukawa",
      "summary": "### CLiFT：用于计算高效和自适应神经渲染的压缩光场令牌\n\n本文提出了一种名为“压缩光场令牌（CLiFTs）”的神经渲染方法，旨在高效且自适应地表示场景。\n\n**核心概念与优势：**\n\n*   **信息保留：** CLiFTs能够保留场景丰富的外观和几何信息。\n*   **计算效率：** 通过使用压缩令牌，实现了计算高效的渲染。\n*   **自适应性：** 允许在单个训练网络下，根据计算预算（即CLiFTs的数量）灵活地改变用于表示场景的令牌数量，或渲染新的视角。\n\n**CLiFTs的构建过程：**\n\n1.  **多视角编码器：** 给定一组输入图像，多视角编码器利用相应的相机姿态对这些图像进行令牌化处理。\n2.  **潜在空间K-means：** 基于生成的令牌，通过潜在空间K-means算法选择一组数量减少的光线作为聚类中心。\n3.  **多视角“冷凝器”：** 一个多视角“冷凝器”将所有原始令牌的信息压缩到这些选定的中心令牌中，从而构建最终的CLiFTs。\n\n**测试时渲染机制：**\n\n*   在测试阶段，给定一个目标视角和预设的计算预算（即允许使用的CLiFTs数量）。\n*   系统会收集指定数量的邻近令牌。\n*   随后，一个计算自适应渲染器利用这些令牌合成出新的视角。\n\n**实验验证：**\n\n*   研究人员在RealEstate10K和DL3DV数据集上进行了广泛的定量和定性实验。\n*   实验结果验证了CLiFT方法的有效性，表明它在实现显著数据缩减的同时，保持了可比的渲染质量。\n*   该方法取得了最高的整体渲染分数。\n*   CLiFT在数据大小、渲染质量和渲染速度之间提供了灵活的权衡，使其适用于不同的应用需求。",
      "shortSummary": "CLiFT是一种用于神经渲染的压缩光场令牌方法，旨在高效且自适应地表示场景。它通过多视角编码器、潜在空间K-means和“冷凝器”构建压缩令牌。CLiFTs能保留丰富的场景信息，实现计算高效的渲染，并允许在单个网络下灵活调整令牌数量以适应计算预算。实验证明，CLiFT在数据缩减、渲染质量和速度之间提供了良好平衡，并在RealEstate10K和DL3DV数据集上取得了优异表现。",
      "translated_title": "CLiFT：用于计算高效和自适应神经渲染的压缩光场令牌",
      "images": [],
      "contentSource": "完整文章",
      "content": "This paper proposes a neural rendering approach that represents a scene as \"compressed light-field tokens (CLiFTs)\", retaining rich appearance and geometric information of a scene. CLiFT enables compute-efficient rendering by compressed tokens, while being capable of changing the number of tokens to represent a scene or render a novel view with one trained network. Concretely, given a set of images, multi-view encoder tokenizes the images with the camera poses. Latent-space K-means selects a reduced set of rays as cluster centroids using the tokens. The multi-view ``condenser'' compresses the information of all the tokens into the centroid tokens to construct CLiFTs. At test time, given a target view and a compute budget (i.e., the number of CLiFTs), the system collects the specified number of nearby tokens and synthesizes a novel view using a compute-adaptive renderer. Extensive experiments on RealEstate10K and DL3DV datasets quantitatively and qualitatively validate our approach, achieving significant data reduction with comparable rendering quality and the highest overall rendering score, while providing trade-offs of data size, rendering quality, and rendering speed."
    },
    {
      "title": "从一到多：用于3D生成的上下文部分潜在表示 (原标题: From One to More: Contextual Part Latents for 3D Generation)",
      "link": "https://arxiv.org/abs/2507.08772",
      "pubDate": "Fri, 11 Jul 2025 13:33:18 GMT",
      "isoDate": "2025-07-11T13:33:18.000Z",
      "creator": "Shaocong Dong, Lihe Ding, Xiao Chen, Yaokun Li, Yuxin Wang, Yucheng Wang, Qi Wang, Jaehyeok Kim, Chenjian Gao, Zhanpeng Huang, Zibin Wang, Tianfan Xue, Dan Xu",
      "summary": "# CoPart：一种面向多部件3D生成的上下文感知扩散框架\n\n## 引言\n\n近期3D生成技术取得了显著进展，已从多视图2D渲染方法转向利用真实数据中几何先验的3D原生潜在扩散框架。然而，现有方法仍存在以下三个主要局限性：\n\n## 现有方法的局限性\n\n1.  **单一体素表示的不足：** 无法有效捕捉复杂的多部件几何结构，导致细节退化。\n2.  **整体潜在编码的缺陷：** 忽略了部件的独立性和相互关系，而这些对于组合设计至关重要。\n3.  **全局条件机制的限制：** 缺乏细粒度的可控性。\n\n## CoPart框架提案\n\n受人类3D设计工作流程的启发，我们提出了 **CoPart**——一个部件感知的扩散框架。该框架将3D对象分解为上下文部分潜在表示，以实现连贯的多部件生成。这种范式带来了以下三个显著优势：\n\n*   **降低编码复杂性：** 通过部件分解简化了编码过程。\n*   **显式部件关系建模：** 能够明确地建模部件之间的相互关系。\n*   **支持部件级条件控制：** 提供了更精细的控制能力。\n\n## 互引导策略与数据集\n\n我们进一步开发了一种**互引导策略**，用于微调预训练的扩散模型，以实现联合部件潜在表示去噪，从而确保几何连贯性和基础模型先验的一致性。\n\n为了支持大规模训练，我们构建了 **Partverse**——一个新颖的3D部件数据集。该数据集通过自动化网格分割和人工验证标注，从Objaverse中提取而来。\n\n## 实验结果\n\n广泛的实验证明，CoPart在部件级编辑、铰接对象生成和场景组合方面展现出卓越的能力，并提供了前所未有的可控性。",
      "shortSummary": "CoPart是一种新型的3D生成框架，旨在解决现有方法在处理复杂多部件对象时的局限性。它通过将3D对象分解为上下文部分潜在表示，实现了部件级控制、降低了编码复杂性并能显式建模部件关系。CoPart引入了互引导策略进行模型微调，并构建了Partverse数据集支持训练。实验证明，CoPart在部件编辑、铰接对象生成和场景组合方面表现出色，提供了前所未有的可控性。",
      "translated_title": "从一到多：用于3D生成的上下文部分潜在表示",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in 3D generation have transitioned from multi-view 2D rendering approaches to 3D-native latent diffusion frameworks that exploit geometric priors in ground truth data. Despite progress, three key limitations persist: (1) Single-latent representations fail to capture complex multi-part geometries, causing detail degradation; (2) Holistic latent coding neglects part independence and interrelationships critical for compositional design; (3) Global conditioning mechanisms lack fine-grained controllability. Inspired by human 3D design workflows, we propose CoPart - a part-aware diffusion framework that decomposes 3D objects into contextual part latents for coherent multi-part generation. This paradigm offers three advantages: i) Reduces encoding complexity through part decomposition; ii) Enables explicit part relationship modeling; iii) Supports part-level conditioning. We further develop a mutual guidance strategy to fine-tune pre-trained diffusion models for joint part latent denoising, ensuring both geometric coherence and foundation model priors. To enable large-scale training, we construct Partverse - a novel 3D part dataset derived from Objaverse through automated mesh segmentation and human-verified annotations. Extensive experiments demonstrate CoPart's superior capabilities in part-level editing, articulated object generation, and scene composition with unprecedented controllability."
    },
    {
      "title": "BlockFFN：面向端侧加速友好的块级激活稀疏混合专家模型 (原标题: BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity)",
      "link": "https://arxiv.org/abs/2507.08771",
      "pubDate": "Fri, 11 Jul 2025 13:28:56 GMT",
      "isoDate": "2025-07-11T13:28:56.000Z",
      "creator": "Chenyang Song, Weilin Zhao, Xu Han, Chaojun Xiao, Yingfa Chen, Yuxuan Li, Zhiyuan Liu, Maosong Sun",
      "summary": "# BlockFFN：面向端侧加速友好的块级激活稀疏混合专家模型\n\n## 概述\nBlockFFN是一种新颖的混合专家（MoE）架构，旨在解决大型语言模型（LLMs）的计算负担，特别是在低资源（如端侧）设备上的加速问题。它通过引入创新的路由机制、块级稀疏性感知训练目标以及高效的加速核，显著提升了MoE模型的性能和部署友好性。\n\n## 挑战与问题\n传统的MoE架构虽然通过激活稀疏性减轻了计算负担，但存在以下问题：\n\n*   **路由机制缺陷：** 香草MoE的路由是非可微且不灵活的，这会损害模型性能。\n*   **块级稀疏性不足：** 尽管每个token只激活少数参数（token级稀疏性，TLS），但多个连续token的联合激活会导致大量参数被激活，即块级稀疏性（CLS）较低。这种稀疏模式不利于低资源条件下的加速，且与主流加速技术（如推测解码）不兼容。\n\n## BlockFFN的解决方案\n为应对上述挑战，BlockFFN引入了以下关键创新：\n\n### 1. 可微且灵活的路由\n*   BlockFFN采用了一个集成了ReLU激活和RMSNorm的路由器，实现了可微且灵活的路由，从而提升了模型性能。\n\n### 2. 促进块级稀疏性（CLS）\n*   为了同时促进token级稀疏性（TLS）和块级稀疏性（CLS），BlockFFN设计了CLS感知的训练目标。这使得模型在端侧设备上更易于加速。\n\n### 3. 高效加速核\n*   BlockFFN首次将激活稀疏性与推测解码相结合，实现了高效的加速核。这对于在实际端侧设备上部署LLMs至关重要。\n\n## 实验结果与性能\n实验结果表明，BlockFFN在性能上优于其他MoE基线模型：\n\n*   **稀疏性表现：** 实现了超过80%的token级稀疏性（TLS）和70%的8-token块级稀疏性（CLS）。\n*   **加速效果：** 其加速核在实际端侧设备上比密集模型实现了高达3.67倍的加速。\n\n## 可用性\n所有代码和检查点均已公开提供。",
      "shortSummary": "BlockFFN是一种新型混合专家（MoE）架构，旨在提升大型语言模型在端侧设备的加速效率。它通过引入可微路由、块级稀疏性感知训练目标，并首次将激活稀疏性与推测解码结合，解决了传统MoE的性能和部署挑战。实验证明，BlockFFN实现了高token/块级稀疏性，并在端侧设备上比密集模型提速高达3.67倍，使其更适合低资源环境。",
      "translated_title": "BlockFFN：面向端侧加速友好的块级激活稀疏混合专家模型",
      "images": [],
      "contentSource": "完整文章",
      "content": "To alleviate the computational burden of large language models (LLMs), architectures with activation sparsity, represented by mixture-of-experts (MoE), have attracted increasing attention. However, the non-differentiable and inflexible routing of vanilla MoE hurts model performance. Moreover, while each token activates only a few parameters, these sparsely-activated architectures exhibit low chunk-level sparsity, indicating that the union of multiple consecutive tokens activates a large ratio of parameters. Such a sparsity pattern is unfriendly for acceleration under low-resource conditions (e.g., end-side devices) and incompatible with mainstream acceleration techniques (e.g., speculative decoding). To address these challenges, we introduce a novel MoE architecture, BlockFFN, as well as its efficient training and deployment techniques. Specifically, we use a router integrating ReLU activation and RMSNorm for differentiable and flexible routing. Next, to promote both token-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training objectives are designed, making BlockFFN more acceleration-friendly. Finally, we implement efficient acceleration kernels, combining activation sparsity and speculative decoding for the first time. The experimental results demonstrate the superior performance of BlockFFN over other MoE baselines, achieving over 80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67times speedup on real end-side devices than dense models. All codes and checkpoints are available publicly (https://github.com/thunlp/BlockFFN)."
    }
  ],
  "lastUpdated": "2025-07-16T09:37:02.055Z"
}
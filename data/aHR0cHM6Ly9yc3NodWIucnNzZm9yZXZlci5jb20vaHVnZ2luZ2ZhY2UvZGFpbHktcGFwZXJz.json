{
  "sourceUrl": "https://rsshub.rssforever.com/huggingface/daily-papers",
  "title": "Huggingface Daily Papers",
  "description": "Huggingface Daily Papers - Powered by RSSHub",
  "link": "https://huggingface.co/papers",
  "items": [
    {
      "title": "Genie Envisioner：一个用于机器人操作的统一世界基础平台 (原标题: Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation)",
      "link": "https://arxiv.org/abs/2508.05635",
      "pubDate": "Thu, 07 Aug 2025 13:59:44 GMT",
      "isoDate": "2025-08-07T13:59:44.000Z",
      "creator": "Yue Liao, Pengfei Zhou, Siyuan Huang, Donglin Yang, Shengcong Chen, Yuxin Jiang, Yue Hu, Jingbin Cai, Si Liu, Jianlan Luo, Liliang Chen, Shuicheng Yan, Maoqing Yao, Guanghui Ren",
      "summary": "## Genie Envisioner：机器人操作的统一世界基础平台\n\nGenie Envisioner (GE) 是一个为机器人操作设计的统一世界基础平台，它将策略学习、评估和仿真整合到一个单一的视频生成框架中。\n\n### 核心组件与功能\n\n1.  **GE-Base：核心视频扩散模型**\n    *   **定位**：GE平台的核心。\n    *   **类型**：一个大规模、指令条件（instruction-conditioned）的视频扩散模型。\n    *   **能力**：能够捕获真实世界机器人交互的空间、时间及语义动态。\n    *   **输出**：将这些动态信息编码到一个结构化的潜在空间中。\n\n2.  **GE-Act：从潜在表示到可执行动作**\n    *   **基础**：构建在GE-Base之上。\n    *   **机制**：通过一个轻量级的流匹配解码器（flow-matching decoder），将GE-Base生成的潜在表示映射到可执行的动作轨迹。\n    *   **优势**：\n        *   实现精确且泛化能力强的策略推理。\n        *   适用于多种不同的机器人实体（embodiments）。\n        *   所需监督（supervision）极少。\n\n3.  **GE-Sim：动作条件神经仿真器**\n    *   **作用**：作为一种动作条件（action-conditioned）的神经仿真器。\n    *   **支持**：为可扩展的评估和训练提供支持。\n    *   **输出**：生成高保真度的推演（rollouts），用于闭环策略的开发。\n\n### 评估与基准\n\n*   **EWMBench**：平台配备了一个名为EWMBench的标准化基准套件。\n    *   **衡量指标**：用于衡量视觉保真度（visual fidelity）、物理一致性（physical consistency）以及指令-动作对齐（instruction-action alignment）。\n\n### 平台愿景与可用性\n\n*   **目标**：Genie Envisioner的各个组件共同建立了一个可扩展且实用的基础，旨在实现指令驱动的通用具身智能（general-purpose embodied intelligence）。\n*   **发布**：所有代码、模型和基准都将公开发布。",
      "shortSummary": "Genie Envisioner (GE) 是一个统一的机器人操作平台，集成了策略学习、评估和仿真。其核心是GE-Base，一个指令条件视频扩散模型，用于捕获机器人交互动态。GE-Act将潜在表示映射为可执行动作，实现精确泛化。GE-Sim作为神经仿真器，支持可扩展训练和评估。平台还包含EWMBench基准套件。GE旨在成为指令驱动型通用具身智能的可扩展基础，所有资源将公开发布。",
      "translated_title": "Genie Envisioner：一个用于机器人操作的统一世界基础平台",
      "images": [],
      "contentSource": "完整文章",
      "content": "We introduce Genie Envisioner (GE), a unified world foundation platform for robotic manipulation that integrates policy learning, evaluation, and simulation within a single video-generative framework. At its core, GE-Base is a large-scale, instruction-conditioned video diffusion model that captures the spatial, temporal, and semantic dynamics of real-world robotic interactions in a structured latent space. Built upon this foundation, GE-Act maps latent representations to executable action trajectories through a lightweight, flow-matching decoder, enabling precise and generalizable policy inference across diverse embodiments with minimal supervision. To support scalable evaluation and training, GE-Sim serves as an action-conditioned neural simulator, producing high-fidelity rollouts for closed-loop policy development. The platform is further equipped with EWMBench, a standardized benchmark suite measuring visual fidelity, physical consistency, and instruction-action alignment. Together, these components establish Genie Envisioner as a scalable and practical foundation for instruction-driven, general-purpose embodied intelligence. All code, models, and benchmarks will be released publicly."
    },
    {
      "title": "MOSEv2：一个更具挑战性的复杂场景视频目标分割数据集 (原标题: MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes)",
      "link": "https://arxiv.org/abs/2508.05630",
      "pubDate": "Thu, 07 Aug 2025 13:59:27 GMT",
      "isoDate": "2025-08-07T13:59:27.000Z",
      "creator": "Henghui Ding, Kaining Ying, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang, Philip H. S. Torr, Song Bai",
      "summary": "## MOSEv2：一个更具挑战性的复杂场景视频目标分割数据集\n\n### 引言：视频目标分割 (VOS) 及其现有挑战\n\n视频目标分割（VOS）旨在在整个视频中分割出指定的目标物体。尽管目前最先进的方法在DAVIS和YouTube-VOS等现有基准测试中取得了令人印象深刻的性能（例如，超过90%的J&F分数），但这些数据集主要包含突出、主导和孤立的物体，这限制了它们在真实世界场景中的泛化能力。为了推动VOS在更真实的复杂环境中发展，研究人员引入了MOSEv1（复杂视频目标分割）数据集。\n\n### MOSEv2 数据集概述\n\n*   **背景与目的**：MOSEv2建立在MOSEv1的优势和局限性之上，是一个显著更具挑战性的数据集，旨在进一步推动VOS方法在真实世界条件下的发展。\n*   **数据集规模与内容**：\n    *   包含5,024个视频。\n    *   拥有超过701,976个高质量掩码。\n    *   涵盖10,074个物体。\n    *   涉及200个类别。\n\n### MOSEv2 引入的复杂性与新挑战\n\n与MOSEv1相比，MOSEv2引入了显著更高的场景复杂性，具体包括：\n\n*   **场景复杂性**：\n    *   更频繁的物体消失和重新出现。\n    *   严重的遮挡和拥挤。\n    *   更小的物体。\n*   **环境条件**：\n    *   恶劣天气（例如，雨、雪、雾）。\n    *   低光照场景（例如，夜间、水下）。\n*   **特殊目标与场景**：\n    *   多镜头序列。\n    *   伪装物体。\n    *   非物理目标（例如，阴影、反射）。\n    *   需要外部知识的场景。\n\n### 基准测试结果\n\n研究人员在5种不同设置下对20种代表性VOS方法进行了基准测试，并观察到性能普遍下降。例如，SAM2在MOSEv1上的性能从76.4%下降到MOSEv2上的50.9%。此外，对9种视频目标跟踪方法进行评估也发现了类似的性能下降，这表明MOSEv2对不同任务都提出了挑战。\n\n### 结论与意义\n\n这些结果突出表明，尽管现有VOS方法在现有数据集上表现出高精度，但它们在面对真实世界的复杂性时仍然面临困难。MOSEv2的发布旨在促进VOS领域的研究，以开发出更鲁棒、更适用于真实世界场景的算法。\n\n### 数据集可用性\n\nMOSEv2数据集已公开可用。",
      "shortSummary": "MOSEv2是一个为复杂场景视频目标分割（VOS）设计的更具挑战性的数据集，旨在弥补现有数据集在真实世界复杂性方面的不足。它包含5024个视频和超过70万个高质量掩码，引入了物体消失重现、严重遮挡、小物体、恶劣天气、低光照及非物理目标等新挑战。基准测试显示，现有VOS方法在MOSEv2上的性能显著下降，凸显了在真实复杂场景下提升VOS能力的必要性。",
      "translated_title": "MOSEv2：一个更具挑战性的复杂场景视频目标分割数据集",
      "images": [],
      "contentSource": "完整文章",
      "content": "Video object segmentation (VOS) aims to segment specified target objects throughout a video. Although state-of-the-art methods have achieved impressive performance (e.g., 90+% J&amp;F) on existing benchmarks such as DAVIS and YouTube-VOS, these datasets primarily contain salient, dominant, and isolated objects, limiting their generalization to real-world scenarios. To advance VOS toward more realistic environments, coMplex video Object SEgmentation (MOSEv1) was introduced to facilitate VOS research in complex scenes. Building on the strengths and limitations of MOSEv1, we present MOSEv2, a significantly more challenging dataset designed to further advance VOS methods under real-world conditions. MOSEv2 consists of 5,024 videos and over 701,976 high-quality masks for 10,074 objects across 200 categories. Compared to its predecessor, MOSEv2 introduces significantly greater scene complexity, including more frequent object disappearance and reappearance, severe occlusions and crowding, smaller objects, as well as a range of new challenges such as adverse weather (e.g., rain, snow, fog), low-light scenes (e.g., nighttime, underwater), multi-shot sequences, camouflaged objects, non-physical targets (e.g., shadows, reflections), scenarios requiring external knowledge, etc. We benchmark 20 representative VOS methods under 5 different settings and observe consistent performance drops. For example, SAM2 drops from 76.4% on MOSEv1 to only 50.9% on MOSEv2. We further evaluate 9 video object tracking methods and find similar declines, demonstrating that MOSEv2 presents challenges across tasks. These results highlight that despite high accuracy on existing datasets, current VOS methods still struggle under real-world complexities. MOSEv2 is publicly available at https://MOSE.video."
    },
    {
      "title": "关于SFT的泛化性：一个带有奖励修正的强化学习视角 (原标题: On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification)",
      "link": "https://arxiv.org/abs/2508.05629",
      "pubDate": "Thu, 07 Aug 2025 13:59:04 GMT",
      "isoDate": "2025-08-07T13:59:04.000Z",
      "creator": "Yongliang Wu, Yizhou Zhou, Zhou Ziheng, Yingzhe Peng, Xinyu Ye, Xinting Hu, Wenbo Zhu, Lu Qi, Ming-Hsuan Yang, Xu Yang",
      "summary": "### SFT泛化性改进：动态微调（DFT）\n\n本文提出了一种名为“动态微调”（Dynamic Fine-Tuning, DFT）的方法，旨在解决大型语言模型（LLM）中监督微调（SFT）相对于强化学习（RL）泛化能力有限的问题。\n\n**核心问题与理论洞察：**\n\n*   **SFT的局限性：** 标准SFT在泛化能力方面不如强化学习。\n*   **数学分析揭示：** 通过数学分析，研究人员发现标准SFT的梯度隐式地编码了一种有问题的奖励结构，这严重限制了模型的泛化能力。\n\n**提出的解决方案：动态微调（DFT）**\n\n*   **方法：** DFT通过动态地根据每个标记的概率重新调整目标函数，从而稳定了梯度更新。\n*   **实现：** 这一改进仅需一行代码的修改。\n\n**实验结果与优势：**\n\n*   **显著提升：** DFT在多个具有挑战性的基准测试和基础模型上显著优于标准SFT，展现出极大的泛化能力提升。\n*   **离线RL表现：** 此外，该方法在离线强化学习（offline RL）设置中也表现出竞争力，提供了一种有效但更简单的替代方案。\n\n**意义：**\n\n*   这项工作将理论洞察与实际解决方案相结合，显著提升了SFT的性能。",
      "shortSummary": "本文提出动态微调（DFT）以解决监督微调（SFT）在大型语言模型中泛化能力有限的问题。研究发现标准SFT梯度隐含了有问题的奖励结构。DFT通过动态调整目标函数来稳定梯度更新，仅需一行代码修改。实验证明，DFT在多个基准测试中显著优于标准SFT，并提升了泛化能力，同时在离线强化学习中也表现出色，为SFT性能带来了实质性进展。",
      "translated_title": "关于SFT的泛化性：一个带有奖励修正的强化学习视角",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present a simple yet theoretically motivated improvement to Supervised Fine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited generalization compared to reinforcement learning (RL). Through mathematical analysis, we reveal that standard SFT gradients implicitly encode a problematic reward structure that may severely restrict the generalization capabilities of model. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing gradient updates for each token by dynamically rescaling the objective function with the probability of this token. Remarkably, this single-line code change significantly outperforms standard SFT across multiple challenging benchmarks and base models, demonstrating greatly improved generalization. Additionally, our approach shows competitive results in offline RL settings, offering an effective yet simpler alternative. This work bridges theoretical insight and practical solutions, substantially advancing SFT performance. The code will be available at https://github.com/yongliang-wu/DFT."
    },
    {
      "title": "Hi3DEval：通过分层有效性推进3D生成评估 (原标题: Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity)",
      "link": "https://arxiv.org/abs/2508.05609",
      "pubDate": "Thu, 07 Aug 2025 13:50:13 GMT",
      "isoDate": "2025-08-07T13:50:13.000Z",
      "creator": "Yuhan Zhang, Long Zhuo, Ziyang Chu, Tong Wu, Zhibing Li, Liang Pan, Dahua Lin, Ziwei Liu",
      "summary": "## Hi3DEval：推进3D生成评估的分层框架\n\n### 挑战\n尽管3D内容生成技术取得了快速进展，但对所生成3D资产的质量评估仍然充满挑战。现有方法主要依赖于基于图像的度量，并且仅在对象级别进行操作，这限制了它们捕捉空间一致性、材料真实性和高保真局部细节的能力。\n\n### Hi3DEval 框架\n为了解决这些挑战，研究人员引入了 **Hi3DEval**，一个专为3D生成内容设计的分层评估框架。该框架具有以下特点：\n\n*   **分层评估**：结合了对象级别和部件级别的评估，从而能够进行多维度的整体评估以及细粒度的质量分析。\n*   **扩展纹理评估**：将纹理评估扩展到美学外观之外，明确评估材料的真实性，重点关注反照率（albedo）、饱和度（saturation）和金属度（metallicness）等属性。\n\n### Hi3DBench 数据集与自动化评分系统\n为支持Hi3DEval框架，研究人员构建了以下关键组件：\n\n*   **Hi3DBench 数据集**：一个大规模数据集，包含多样化的3D资产和高质量的标注，并辅以可靠的多代理标注流程。\n*   **3D感知自动化评分系统**：基于混合3D表示提出，具体包括：\n    *   **视频表示**：用于对象级别和材料主题评估，以增强时空一致性建模。\n    *   **预训练3D特征**：用于部件级别的感知。\n\n### 实验结果\n广泛的实验表明，Hi3DEval 方法在建模3D特性方面优于现有的基于图像的度量，并实现了与人类偏好更高的对齐度，为手动评估提供了一种可扩展的替代方案。",
      "shortSummary": "Hi3DEval是一个分层评估框架，旨在解决3D内容生成质量评估的挑战。它结合了对象级和部件级评估，并扩展了对材料真实性的评估。该框架由大规模的Hi3DBench数据集和基于混合3D表示的自动化评分系统支持。实验证明，Hi3DEval在建模3D特性方面优于现有方法，并与人类偏好高度一致，为3D生成评估提供了可扩展的解决方案。",
      "translated_title": "Hi3DEval：通过分层有效性推进3D生成评估",
      "images": [],
      "contentSource": "完整文章",
      "content": "Despite rapid advances in 3D content generation, quality assessment for the generated 3D assets remains challenging. Existing methods mainly rely on image-based metrics and operate solely at the object level, limiting their ability to capture spatial coherence, material authenticity, and high-fidelity local details. 1) To address these challenges, we introduce Hi3DEval, a hierarchical evaluation framework tailored for 3D generative content. It combines both object-level and part-level evaluation, enabling holistic assessments across multiple dimensions as well as fine-grained quality analysis. Additionally, we extend texture evaluation beyond aesthetic appearance by explicitly assessing material realism, focusing on attributes such as albedo, saturation, and metallicness. 2) To support this framework, we construct Hi3DBench, a large-scale dataset comprising diverse 3D assets and high-quality annotations, accompanied by a reliable multi-agent annotation pipeline. We further propose a 3D-aware automated scoring system based on hybrid 3D representations. Specifically, we leverage video-based representations for object-level and material-subject evaluations to enhance modeling of spatio-temporal consistency and employ pretrained 3D features for part-level perception. Extensive experiments demonstrate that our approach outperforms existing image-based metrics in modeling 3D characteristics and achieves superior alignment with human preference, providing a scalable alternative to manual evaluations. The project page is available at https://zyh482.github.io/Hi3DEval/."
    },
    {
      "title": "PRvL：量化大型语言模型在个人身份信息（PII）匿名化方面的能力与风险 (原标题: PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction)",
      "link": "https://arxiv.org/abs/2508.05545",
      "pubDate": "Thu, 07 Aug 2025 12:22:49 GMT",
      "isoDate": "2025-08-07T12:22:49.000Z",
      "creator": "Leon Garza, Anantaa Kotal, Aritran Piplai, Lavanya Elluri, Prajit Das, Aman Chadha",
      "summary": "### PRvL：大型语言模型在个人身份信息（PII）匿名化方面的能力与风险分析\n\n**引言**\n在受监管领域，从非结构化文本中匿名化个人身份信息（PII）对于确保数据隐私至关重要。传统方法，如基于规则的系统和领域特定的命名实体识别（NER）模型，在泛化性方面表现不佳，难以适应不同的格式和上下文。\n\n**大型语言模型（LLMs）的潜力与挑战**\n近期大型语言模型（LLMs）的进展为PII匿名化提供了有前景的替代方案。LLMs在需要上下文语言理解的任务中表现出色，包括自由文本中的PII匿名化。先前的研究表明，经过适当调整，LLMs可以成为有效的上下文隐私学习器。然而，LLM的架构和训练选择对匿名化性能的影响尚未得到充分探索。\n\n**本研究的贡献与分析**\n本研究对LLMs作为隐私保护的PII匿名化系统进行了全面分析。研究评估了一系列LLM架构和训练策略在PII匿名化方面的有效性。分析衡量了以下关键指标：\n\n*   **匿名化性能**：模型识别和匿名化PII的准确性。\n*   **语义保留**：匿名化后文本的原始含义和上下文是否得到有效保留。\n*   **PII泄露**：匿名化过程中PII信息意外暴露的风险。\n*   **延迟和计算成本**：系统运行效率和资源消耗。\n\n研究结果为配置准确、高效且注重隐私的基于LLM的匿名化器提供了实用指导。\n\n**PRvL：开源工具套件的发布**\n为了支持研究的可复现性和实际部署，本研究发布了PRvL，一个开源的微调模型和评估工具套件，专为通用PII匿名化设计。\n\n**PRvL 的特点与优势**\n\n*   **基于开源LLMs**：PRvL完全基于开源大型语言模型构建。\n*   **灵活的推理设置**：支持多种推理设置，以满足不同的灵活性和合规性需求。\n*   **高度可定制**：易于针对不同领域进行定制。\n*   **安全自管理环境**：PRvL设计为可在安全的、自管理的（on-premise）环境中完全操作。这意味着数据所有者无需依赖第三方服务，也无需将敏感内容暴露在自身基础设施之外，即可执行匿名化操作，从而最大程度地保障数据安全和隐私。\n\n**结论**\nPRvL提供了一个强大的框架，用于量化和优化LLMs在PII匿名化中的能力和风险，为企业和组织在保护数据隐私方面提供了实用的解决方案。",
      "shortSummary": "本研究全面分析了大型语言模型（LLMs）在个人身份信息（PII）匿名化方面的能力与风险。通过评估不同LLM架构和训练策略的匿名化性能、语义保留、PII泄露、延迟和计算成本，研究提供了配置高效、隐私感知匿名化器的实用指导。为支持实际应用，研究发布了PRvL，一个开源的微调模型和评估工具套件，允许数据所有者在安全的自管理环境中进行PII匿名化，无需依赖第三方服务。",
      "translated_title": "PRvL：量化大型语言模型在个人身份信息（PII）匿名化方面的能力与风险",
      "images": [],
      "contentSource": "完整文章",
      "content": "Redacting Personally Identifiable Information (PII) from unstructured text is critical for ensuring data privacy in regulated domains. While earlier approaches have relied on rule-based systems and domain-specific Named Entity Recognition (NER) models, these methods fail to generalize across formats and contexts. Recent advances in Large Language Models (LLMs) offer a promising alternative, yet the effect of architectural and training choices on redaction performance remains underexplored. LLMs have demonstrated strong performance in tasks that require contextual language understanding, including the redaction of PII in free-form text. Prior work suggests that with appropriate adaptation, LLMs can become effective contextual privacy learners. However, the consequences of architectural and training choices for PII Redaction remain underexplored. In this work, we present a comprehensive analysis of LLMs as privacy-preserving PII Redaction systems. We evaluate a range of LLM architectures and training strategies for their effectiveness in PII Redaction. Our analysis measures redaction performance, semantic preservation, and PII leakage, and compares these outcomes against latency and computational cost. The results provide practical guidance for configuring LLM-based redactors that are accurate, efficient, and privacy-aware. To support reproducibility and real-world deployment, we release PRvL, an open-source suite of fine-tuned models, and evaluation tools for general-purpose PII Redaction. PRvL is built entirely on open-source LLMs and supports multiple inference settings for flexibility and compliance. It is designed to be easily customized for different domains and fully operable within secure, self-managed environments. This enables data owners to perform redactions without relying on third-party services or exposing sensitive content beyond their own infrastructure."
    },
    {
      "title": "InfiAlign：一个可扩展且样本高效的LLM对齐框架，用于增强推理能力 (原标题: InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities)",
      "link": "https://arxiv.org/abs/2508.05496",
      "pubDate": "Thu, 07 Aug 2025 11:34:06 GMT",
      "isoDate": "2025-08-07T11:34:06.000Z",
      "creator": "Shuo Cai, Su Lu, Qi Zhou, Kejing Yang, Zhijie Sang, Congkai Xie, Hongxia Yang",
      "summary": "# InfiAlign: 可扩展且样本高效的LLM对齐框架，用于增强推理能力\n\n## 引言\n大型语言模型（LLMs）在复杂任务中展现出强大的推理能力。然而，通过后期训练（post-training）来增强这些能力通常资源密集，尤其是在数据和计算成本方面。现有提高样本效率的方法常依赖启发式或任务特定策略，限制了其可扩展性。\n\n## InfiAlign 框架介绍\n本文引入了 **InfiAlign**，一个可扩展且样本高效的后期训练框架，它通过整合监督微调（SFT）和直接偏好优化（DPO）来对齐LLMs，以增强其推理能力。\n\n### 核心组成\nInfiAlign 的核心是一个强大的数据选择管道。该管道利用多维质量指标，从开源推理数据集中自动筛选出高质量的对齐数据。\n\n### 关键优势\n*   **显著的性能提升**：通过精选数据实现卓越性能。\n*   **大幅降低数据需求**：显著减少了训练所需的数据量。\n*   **可扩展性**：该管道可扩展到新的数据源。\n\n## 实验结果与性能\n研究团队将 InfiAlign 应用于 **Qwen2.5-Math-7B-Base** 模型，并取得了显著成果：\n\n*   **SFT 阶段表现**：\n    *   InfiAlign 的 SFT 模型实现了与 DeepSeek-R1-Distill-Qwen-7B 相当的性能。\n    *   它仅使用了 DeepSeek-R1-Distill-Qwen-7B 大约 **12%** 的训练数据，极大地提高了数据效率。\n    *   模型在多样化的推理任务中展现出强大的泛化能力。\n*   **DPO 阶段提升**：\n    *   通过应用 DPO，模型获得了额外的性能提升，尤其在数学推理任务中表现出显著进步。\n    *   在 AIME 24/25 基准测试中，模型平均提升了 **3.89%**。\n\n## 结论与意义\n研究结果强调了将原则性数据选择与全阶段后期训练相结合的有效性。InfiAlign 为以可扩展和数据高效的方式对齐大型推理模型提供了一个实用的解决方案。\n\n## 资源可用性\n模型的检查点可在指定链接获取。",
      "shortSummary": "InfiAlign是一个可扩展且样本高效的LLM对齐框架，旨在增强推理能力。它结合了SFT和DPO，并采用强大的数据选择管道，从开源数据中自动筛选高质量数据。该框架在Qwen2.5-Math-7B-Base模型上，仅用12%的数据就达到了与DeepSeek-R1-Distill-Qwen-7B相当的SFT性能，并展现出强大的泛化能力。DPO进一步提升了数学推理表现，在AIME基准上平均提升3.89%。InfiAlign为LLM对齐提供了一个可扩展且数据高效的实用方案。",
      "translated_title": "InfiAlign：一个可扩展且样本高效的LLM对齐框架，用于增强推理能力",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large language models (LLMs) have exhibited impressive reasoning abilities on a wide range of complex tasks. However, enhancing these capabilities through post-training remains resource intensive, particularly in terms of data and computational cost. Although recent efforts have sought to improve sample efficiency through selective data curation, existing methods often rely on heuristic or task-specific strategies that hinder scalability. In this work, we introduce InfiAlign, a scalable and sample-efficient post-training framework that integrates supervised fine-tuning (SFT) with Direct Preference Optimization (DPO) to align LLMs for enhanced reasoning. At the core of InfiAlign is a robust data selection pipeline that automatically curates high-quality alignment data from open-source reasoning datasets using multidimensional quality metrics. This pipeline enables significant performance gains while drastically reducing data requirements and remains extensible to new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only approximately 12% of the training data, and demonstrates strong generalization across diverse reasoning tasks. Additional improvements are obtained through the application of DPO, with particularly notable gains in mathematical reasoning tasks. The model achieves an average improvement of 3.89% on AIME 24/25 benchmarks. Our results highlight the effectiveness of combining principled data selection with full-stage post-training, offering a practical solution for aligning large reasoning models in a scalable and data-efficient manner. The model checkpoints are available at https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT."
    },
    {
      "title": "DeepPHY：基准测试智能体视觉语言模型在物理推理方面的表现 (原标题: DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning)",
      "link": "https://arxiv.org/abs/2508.05405",
      "pubDate": "Thu, 07 Aug 2025 09:58:19 GMT",
      "isoDate": "2025-08-07T09:58:19.000Z",
      "creator": "Xinrun Xu, Pi Bu, Ye Wang, Börje F. Karlsson, Ziming Wang, Tengtao Song, Qi Zhu, Jun Song, Zhiming Ding, Bo Zheng",
      "summary": "# DeepPHY：基准测试智能体视觉语言模型在物理推理方面的表现\n\n## 引言与背景\n*   **视觉语言模型（VLMs）的现状与挑战：**\n    *   尽管视觉语言模型（VLMs）展现出强大的感知能力和令人印象深刻的视觉推理能力，但在处理复杂、动态环境时，它们在细节关注和精确行动规划方面仍面临挑战，导致性能不佳。\n    *   现实世界中的任务通常需要复杂的交互、高级空间推理、长期规划以及持续的策略优化，而这些能力往往依赖于对目标场景物理规则的理解。\n*   **评估难题：**\n    *   在现实世界场景中评估VLMs的这些能力通常成本极高，难以实现。\n\n## DeepPHY：新型基准测试框架\n*   **目的：**\n    *   为了弥补现有评估方法的不足，本研究引入了DeepPHY，一个新颖的基准测试框架。\n    *   DeepPHY旨在系统地评估视觉语言模型对基本物理原理的理解和推理能力。\n*   **设计与构成：**\n    *   DeepPHY整合了多个难度级别各异的物理推理模拟环境。\n    *   该框架还包含了细粒度的评估指标，以提供更精确的性能衡量。\n\n## 主要发现\n*   **性能局限性：**\n    *   通过DeepPHY进行的评估发现，即使是目前最先进的视觉语言模型，也难以将描述性的物理知识转化为精确的、预测性的控制行为。这表明VLMs在将抽象物理理解应用于具体行动规划方面仍有显著不足。\n\n## 其他信息\n*   **文档详情：** 本研究报告共48页。\n*   **研究领域：** 属于人工智能（cs.AI）领域。\n*   **引用信息：** 可通过arXiv:2508.05405 [cs.AI] 或 DOI: 10.48550/arXiv.2508.05405 进行引用。\n*   **提交日期：** 该论文于2025年8月7日提交。",
      "shortSummary": "视觉语言模型（VLMs）在复杂动态环境中的物理推理和精确行动规划方面表现不足，且现实世界评估成本高昂。为解决此问题，研究引入了DeepPHY基准框架。DeepPHY通过整合多难度模拟环境和细粒度评估指标，系统评估VLMs对基本物理原理的理解和推理能力。评估结果显示，即使是先进的VLMs也难以将描述性物理知识转化为精确的预测性控制，揭示了其在应用物理理解方面的局限性。",
      "translated_title": "DeepPHY：基准测试智能体视觉语言模型在物理推理方面的表现",
      "images": [],
      "contentSource": "完整文章",
      "content": "Although Vision Language Models (VLMs) exhibit strong perceptual abilities and impressive visual reasoning, they struggle with attention to detail and precise action planning in complex, dynamic environments, leading to subpar performance. Real-world tasks typically require complex interactions, advanced spatial reasoning, long-term planning, and continuous strategy refinement, usually necessitating understanding the physics rules of the target scenario. However, evaluating these capabilities in real-world scenarios is often prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel benchmark framework designed to systematically evaluate VLMs' understanding and reasoning about fundamental physical principles through a series of challenging simulated environments. DeepPHY integrates multiple physical reasoning environments of varying difficulty levels and incorporates fine-grained evaluation metrics. Our evaluation finds that even state-of-the-art VLMs struggle to translate descriptive physical knowledge into precise, predictive control."
    },
    {
      "title": "R-Zero：从零数据自进化的推理LLM (原标题: R-Zero: Self-Evolving Reasoning LLM from Zero Data)",
      "link": "https://arxiv.org/abs/2508.05004",
      "pubDate": "Wed, 06 Aug 2025 23:38:16 GMT",
      "isoDate": "2025-08-06T23:38:16.000Z",
      "creator": "Chengsong Huang, Wenhao Yu, Xiaoyang Wang, Hongming Zhang, Zongxia Li, Ruosen Li, Jiaxin Huang, Haitao Mi, Dong Yu",
      "summary": "# R-Zero：从零数据自进化的推理LLM\n\n## 核心问题\n现有的自进化大型语言模型（LLMs）虽然提供了通向超智能的可扩展路径，但它们在训练过程中仍严重依赖大量人工整理的任务和标签（通常通过微调或强化学习）。这构成了AI系统能力超越人类智能的根本瓶颈。\n\n## R-Zero 框架介绍\n为了克服这一限制，研究人员引入了 **R-Zero**，这是一个完全自主的框架，能够从零开始生成自己的训练数据。\n\n## R-Zero 的工作机制\nR-Zero 的核心机制涉及两个独立模型的协同进化：\n*   **初始化**：从一个基础LLM开始，R-Zero 初始化两个具有不同角色的独立模型：一个“挑战者”（Challenger）和一个“解决者”（Solver）。\n*   **独立优化与协同进化**：\n    *   **挑战者**：其目标是提出接近解决者能力边缘的任务。挑战者因成功提出这些挑战性任务而获得奖励。\n    *   **解决者**：其目标是解决挑战者提出的日益复杂的任务。解决者因成功解决这些任务而获得奖励。\n*   **自生成课程**：通过这种持续的交互和优化过程，R-Zero 能够生成一个有针对性的、自我改进的课程，而无需任何预先存在的任务和标签。\n\n## 实验结果\nR-Zero 在经验上显著提升了不同骨干LLM的推理能力：\n*   在数学推理基准测试中，将 Qwen3-4B-Base 的性能提升了 **+6.49**。\n*   在通用领域推理基准测试中，将 Qwen3-4B-Base 的性能提升了 **+7.54**。\n\n## 总结\nR-Zero 提供了一种全新的、完全自主的LLM训练范式，摆脱了对人工数据的依赖，为实现超越人类智能的AI系统开辟了道路。",
      "shortSummary": "R-Zero是一个创新的、完全自主的框架，旨在从零数据训练自进化的推理LLM。它通过初始化“挑战者”和“解决者”两个模型，让挑战者提出任务，解决者解决任务，从而实现模型间的协同进化和自我改进。这种方法克服了传统LLM对人工数据的依赖，并在数学和通用推理基准测试中显著提升了模型性能，为AI超越人类智能提供了新路径。",
      "translated_title": "R-Zero：从零数据自进化的推理LLM",
      "images": [],
      "contentSource": "完整文章",
      "content": "Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks."
    },
    {
      "title": "REINA：基于正则化熵信息的损失函数，用于高效的同声语音翻译 (原标题: REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation)",
      "link": "https://arxiv.org/abs/2508.04946",
      "pubDate": "Wed, 06 Aug 2025 20:25:58 GMT",
      "isoDate": "2025-08-06T20:25:58.000Z",
      "creator": "Nameer Hirschkind, Joseph Liu, Mahesh Kumar Nandwana, Xiao Yu",
      "summary": "## REINA：高效同声语音翻译的正则化熵信息损失函数\n\n### 摘要\n\n*   **背景与挑战**\n    *   同声语音翻译（SimulST）系统在接收音频流的同时输出翻译文本或语音。\n    *   这类系统面临的核心挑战是如何平衡翻译质量与延迟之间的矛盾。\n\n*   **REINA 方法介绍**\n    *   **核心策略：** 仅当通过等待更多输入能够获取信息增益时才等待。\n    *   **新颖损失函数：** 引入了“正则化熵信息适应”（REINA）作为一种新型损失函数，用于训练自适应策略。\n    *   **理论基础：** REINA 是基于信息论原理推导而来的，旨在利用现有的非流式翻译模型进行训练。\n\n*   **性能与成果**\n    *   **帕累托前沿改进：** REINA 有助于将延迟/质量权衡的帕累托前沿推向超越现有工作的水平。\n    *   **最先进（SOTA）结果：** 利用 REINA 训练的 SimulST 模型在法语、西班牙语和德语与英语之间的互译任务上，仅使用开源或合成数据，就实现了与同等规模模型相比的最先进流式翻译结果。\n    *   **效率度量与提升：**\n        *   文章引入了一个新的流式传输效率度量标准。\n        *   定量分析表明，与现有方法相比，REINA 在延迟/质量权衡方面提高了高达21%（相对于非流式基线BLEU分数进行归一化）。\n\n*   **研究领域**\n    *   机器学习 (cs.LG)\n    *   计算与语言 (cs.CL)\n    *   音频与语音处理 (eess.AS)",
      "shortSummary": "REINA是一种基于正则化熵信息的新型损失函数，旨在优化同声语音翻译（SimulST）系统的翻译质量与延迟之间的权衡。其核心策略是仅在获取信息增益时才等待更多输入。REINA基于信息论原理，能将延迟/质量帕累托前沿推向新高。在法、西、德语与英语互译任务中，REINA实现了最先进的流式翻译结果，并使延迟/质量权衡效率提升高达21%。",
      "translated_title": "REINA：基于正则化熵信息的损失函数，用于高效的同声语音翻译",
      "images": [],
      "contentSource": "完整文章",
      "content": "Simultaneous Speech Translation (SimulST) systems stream in audio while simultaneously emitting translated text or speech. Such systems face the significant challenge of balancing translation quality and latency. We introduce a strategy to optimize this tradeoff: wait for more input only if you gain information by doing so. Based on this strategy, we present Regularized Entropy INformation Adaptation (REINA), a novel loss to train an adaptive policy using an existing non-streaming translation model. We derive REINA from information theory principles and show that REINA helps push the reported Pareto frontier of the latency/quality tradeoff over prior works. Utilizing REINA, we train a SimulST model on French, Spanish and German, both from and into English. Training on only open source or synthetically generated data, we achieve state-of-the-art (SOTA) streaming results for models of comparable size. We also introduce a metric for streaming efficiency, quantitatively showing REINA improves the latency/quality trade-off by as much as 21% compared to prior approaches, normalized against non-streaming baseline BLEU scores."
    },
    {
      "title": "我思，故我能力不足？一个评估大型语言模型在招聘评估中语言试金石检测的基准 (原标题: I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations)",
      "link": "https://arxiv.org/abs/2508.04939",
      "pubDate": "Wed, 06 Aug 2025 19:51:03 GMT",
      "isoDate": "2025-08-06T19:51:03.000Z",
      "creator": "Julia Kharchenko, Tanya Roosta, Aman Chadha, Chirag Shah",
      "summary": "## 大型语言模型招聘评估中的语言偏见检测基准\n\n### 研究背景与目的\n\n本论文提出了一个全面的基准，旨在评估大型语言模型（LLMs）如何响应“语言试金石”（linguistic shibboleths）。“语言试金石”是指那些微妙的语言标记，它们可能无意中揭示说话者的性别、社会阶层或地域背景等人口统计学属性。\n\n### 研究方法\n\n*   通过精心构建的面试模拟进行评估。\n*   使用了100对经过验证的问题-回答对。\n*   该基准能够生成受控的语言变体，从而在保持语义等效性的前提下，隔离并精确测量特定语言现象对自动化评估系统中的人口统计学偏见的影响。\n\n### 主要发现\n\n*   研究表明，LLMs系统性地惩罚某些语言模式，尤其是“对冲语言”（hedging language），即使这些回答的内容质量与非对冲性回答相同。\n*   经验证，使用对冲语言的回答平均得分降低了25.6%。\n*   该基准在识别模型特定偏见方面表现出有效性。\n\n### 意义与应用\n\n*   这项工作为检测和衡量人工智能系统中的语言歧视奠定了基础框架。\n*   其研究成果在自动化决策制定（如招聘、贷款审批等）的公平性方面具有广泛的应用价值。",
      "shortSummary": "该研究引入了一个基准，用于评估大型语言模型（LLMs）在招聘评估中对“语言试金石”的反应。研究发现，LLMs系统性地惩罚某些语言模式，特别是“对冲语言”，即使内容质量相同，也会导致评分显著降低。该基准能够有效识别并量化AI系统中的语言歧视，为自动化决策的公平性提供了重要工具。",
      "translated_title": "我思，故我能力不足？一个评估大型语言模型在招聘评估中语言试金石检测的基准",
      "images": [],
      "contentSource": "完整文章",
      "content": "This paper introduces a comprehensive benchmark for evaluating how Large Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic markers that can inadvertently reveal demographic attributes such as gender, social class, or regional background. Through carefully constructed interview simulations using 100 validated question-response pairs, we demonstrate how LLMs systematically penalize certain linguistic patterns, particularly hedging language, despite equivalent content quality. Our benchmark generates controlled linguistic variations that isolate specific phenomena while maintaining semantic equivalence, which enables the precise measurement of demographic bias in automated evaluation systems. We validate our approach along multiple linguistic dimensions, showing that hedged responses receive 25.6% lower ratings on average, and demonstrate the benchmark's effectiveness in identifying model-specific biases. This work establishes a foundational framework for detecting and measuring linguistic discrimination in AI systems, with broad applications to fairness in automated decision-making contexts."
    },
    {
      "title": "SEAgent：基于经验自主学习的自进化计算机使用智能体 (原标题: SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience)",
      "link": "https://arxiv.org/abs/2508.04700",
      "pubDate": "Wed, 06 Aug 2025 13:58:46 GMT",
      "isoDate": "2025-08-06T13:58:46.000Z",
      "creator": "Zeyi Sun, Ziyu Liu, Yuhang Zang, Yuhang Cao, Xiaoyi Dong, Tong Wu, Dahua Lin, Jiaqi Wang",
      "summary": "## SEAgent：基于经验自主学习的自进化计算机使用智能体\n\nSEAgent是一种创新的自进化框架，旨在解决大型视觉语言模型（LVLMs）作为计算机使用智能体（CUAs）在处理新型和专业软件时面临的挑战，尤其是在缺乏人工标注数据的情况下。\n\n### 核心问题与挑战\n*   当前将LVLMs用作CUAs的方法主要依赖于人工标注数据，这限制了它们在面对不熟悉或专业软件时的表现。\n*   在缺乏人类标注的场景中，这些模型难以有效应对。\n\n### SEAgent框架概述\nSEAgent赋能计算机使用智能体通过与陌生软件的交互进行自主进化。其核心在于“经验学习”，智能体通过以下方式掌握新软件环境：\n1.  **探索与试错：** 智能体主动探索新软件，并通过迭代的试错过程进行学习。\n2.  **任务渐进：** 逐步解决从简单到复杂的自动生成任务。\n\n### 关键设计与机制\n为了实现自主学习和进化，SEAgent引入了以下关键组件和策略：\n*   **世界状态模型（World State Model）：** 用于对每一步的轨迹进行评估，确保学习过程的有效性。\n*   **课程生成器（Curriculum Generator）：** 负责生成日益多样化和具有挑战性的任务，引导智能体逐步提升能力。\n*   **策略更新机制：** 智能体的策略通过经验学习进行更新，具体包括：\n    *   **失败动作的对抗性模仿：** 从失败中学习，避免重复错误。\n    *   **成功动作的群组相对策略优化（GRPO）：** 优化成功的行为模式。\n*   **专家到通用型训练策略（Specialist-to-Generalist Training Strategy）：**\n    *   该策略整合了来自单个专家智能体的经验洞察。\n    *   旨在培养一个更强大的通用型CUA，使其能够持续自主进化。\n    *   这种统一的智能体最终在各自的专业软件上，其性能超越了由多个独立专家智能体组成的集合。\n\n### 实验验证与成果\n*   SEAgent在OS-World中的五个新型软件环境中进行了有效性验证。\n*   与竞争性的开源CUA（UI-TARS）相比，SEAgent取得了显著的性能提升。\n*   成功率从11.3%提高到34.5%，实现了23.2%的显著增长。\n\n### 总结\nSEAgent提供了一种有效的方法，使计算机使用智能体能够自主学习和适应新的软件环境，克服了传统方法对大量人工标注数据的依赖，为未来智能体在复杂、动态计算机环境中的应用奠定了基础。",
      "shortSummary": "SEAgent是一个自进化的计算机使用智能体框架，旨在解决现有智能体在缺乏人工标注数据时难以掌握新型软件的问题。它通过经验学习、世界状态模型、课程生成器以及专家到通用型训练策略，使智能体能够自主探索、试错并优化行为。实验结果显示，SEAgent在新型软件环境中的成功率显著提升了23.2%，超越了现有基线。",
      "translated_title": "SEAgent：基于经验自主学习的自进化计算机使用智能体",
      "images": [],
      "contentSource": "完整文章",
      "content": "Repurposing large vision-language models (LVLMs) as computer use agents (CUAs) has led to substantial breakthroughs, primarily driven by human-labeled data. However, these models often struggle with novel and specialized software, particularly in scenarios lacking human annotations. To address this challenge, we propose SEAgent, an agentic self-evolving framework enabling CUAs to autonomously evolve through interactions with unfamiliar software. Specifically, SEAgent empowers computer-use agents to autonomously master novel software environments via experiential learning, where agents explore new software, learn through iterative trial-and-error, and progressively tackle auto-generated tasks organized from simple to complex. To achieve this goal, we design a World State Model for step-wise trajectory assessment, along with a Curriculum Generator that generates increasingly diverse and challenging tasks. The agent's policy is updated through experiential learning, comprised of adversarial imitation of failure actions and Group Relative Policy Optimization (GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist training strategy that integrates individual experiential insights from specialist agents, facilitating the development of a stronger generalist CUA capable of continuous autonomous evolution. This unified agent ultimately achieves performance surpassing ensembles of individual specialist agents on their specialized software. We validate the effectiveness of SEAgent across five novel software environments within OS-World. Our approach achieves a significant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a competitive open-source CUA, i.e., UI-TARS."
    },
    {
      "title": "跳跃、跳过与过度思考：诊断推理模型在多跳分析中为何失误 (原标题: Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during Multi-Hop Analysis)",
      "link": "https://arxiv.org/abs/2508.04699",
      "pubDate": "Wed, 06 Aug 2025 13:58:36 GMT",
      "isoDate": "2025-08-06T13:58:36.000Z",
      "creator": "Anushka Yadav, Isha Nalawade, Srujana Pillarichety, Yashwanth Babu, Reshmi Ghosh, Samyadeep Basu, Wenlong Zhao, Ali Nasaeh, Sriram Balasubramanian, Soundararajan Srinivasan",
      "summary": "### 研究背景与问题\n推理模型的出现及其在实际AI聊天机器人中的整合，在解决需要复杂多步思维过程的高级数学、深度搜索和提取式问答等问题上取得了突破。然而，对于这些模型为何比通用语言模型更容易产生幻觉，目前仍缺乏全面的理解。\n\n### 研究目的与方法\n本项调查性研究旨在系统性地探究当代语言模型在多跳问答任务中的推理失败。研究引入了一个新颖且细致的错误分类框架，从三个关键维度审视模型失败：\n\n*   **跳跃（Hops）**：涉及源文档的多样性和独特性。\n*   **覆盖（Coverage）**：捕获相关信息的完整性。\n*   **过度思考（Overthinking）**：认知效率低下。\n\n通过严谨的人工标注，并辅以互补的自动化指标，本研究深入探索了这些复杂的错误模式。\n\n### 主要发现\n研究揭示了复杂的错误模式，这些模式往往被以准确率为中心的评估方法所掩盖。这种调查性方法提供了对当前模型认知局限性的更深层见解。\n\n### 研究意义与指导\n本研究为未来语言模型的发展提供了可操作的指导，旨在增强其推理的忠实性、透明度和鲁棒性。\n\n*(文章内容中不包含有效的实际图片链接，因此详细摘要中不包含图片。)*",
      "shortSummary": "本研究系统性探究了推理模型在多跳问答任务中的失败原因，尽管其在复杂问题解决上有所突破，但幻觉问题突出。研究引入了一个新颖的错误分类框架，从源文档的“跳跃”多样性、信息“覆盖”完整性及“过度思考”的认知效率三个维度诊断问题。通过人工标注，揭示了传统评估方法难以发现的复杂错误模式，为提升未来语言模型的推理能力、透明度和鲁棒性提供了深入见解和指导。",
      "translated_title": "跳跃、跳过与过度思考：诊断推理模型在多跳分析中为何失误",
      "images": [],
      "contentSource": "完整文章",
      "content": "The emergence of reasoning models and their integration into practical AI chat bots has led to breakthroughs in solving advanced math, deep search, and extractive question answering problems that requires a complex and multi-step thought process. Yet, a complete understanding of why these models hallucinate more than general purpose language models is missing. In this investigative study, we systematicallyexplore reasoning failures of contemporary language models on multi-hop question answering tasks. We introduce a novel, nuanced error categorization framework that examines failures across three critical dimensions: the diversity and uniqueness of source documents involved (\"hops\"), completeness in capturing relevant information (\"coverage\"), and cognitive inefficiency (\"overthinking\"). Through rigorous hu-man annotation, supported by complementary automated metrics, our exploration uncovers intricate error patterns often hidden by accuracy-centric evaluations. This investigative approach provides deeper insights into the cognitive limitations of current models and offers actionable guidance toward enhancing reasoning fidelity, transparency, and robustness in future language modeling efforts."
    },
    {
      "title": "Sculptor：通过主动上下文管理赋予大型语言模型认知能动性 (原标题: Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management)",
      "link": "https://arxiv.org/abs/2508.04664",
      "pubDate": "Wed, 06 Aug 2025 13:32:58 GMT",
      "isoDate": "2025-08-06T13:32:58.000Z",
      "creator": "Mo Li, L. H. Xu, Qitai Tan, Ting Cao, Yunxin Liu",
      "summary": "## Sculptor：通过主动上下文管理增强大型语言模型的认知能动性\n\n### 问题背景\n大型语言模型（LLMs）在处理长上下文时面临显著的性能下降。这主要是由于“前瞻性干扰”（proactive interference），即上下文早期部分的不相关信息会干扰模型的推理过程和记忆回忆能力。\n\n### 解决方案：主动上下文管理（ACM）\n传统的LLM研究多集中于通过外部记忆系统来增强模型能力。本文提出了一种互补的方法：通过赋予LLMs“主动上下文管理”（Active Context Management, ACM）工具，使其能够主动地雕塑自身的内部工作记忆。这种方法类似于人类选择性地关注相关信息并过滤掉干扰。\n\n### Sculptor 框架\n我们引入了 Sculptor 框架，它为LLMs配备了三类工具，以实现主动上下文管理：\n1.  **上下文碎片化（Context Fragmentation）**：将长上下文分解为更小的、可管理的片段。\n2.  **总结、隐藏和恢复（Summary, Hide, and Restore）**：允许LLMs对信息进行总结、暂时隐藏不相关内容，并在需要时恢复。\n3.  **智能搜索（Intelligent Search）**：使LLMs能够高效地在上下文中搜索和检索相关信息。\n\n### 实验评估\n*   **基准测试：** Sculptor 在信息稀疏的基准测试中进行了评估，包括：\n    *   **PI-LLM (Proactive Interference)**：专门用于测试前瞻性干扰的缓解效果。\n    *   **NeedleBench Multi-Needle Reasoning**：用于评估在复杂长上下文中的多点推理能力。\n*   **实验结果：** 评估表明，即使在没有特定训练的情况下，Sculptor 也能显著提高LLMs的性能。这得益于LLMs固有的工具调用泛化能力。\n\n### 结论与意义\n通过启用主动上下文管理，Sculptor 不仅有效缓解了前瞻性干扰，还为LLMs在各种长上下文任务中实现更可靠的推理提供了认知基础。研究强调，明确的上下文控制策略，而非仅仅扩大token窗口，是实现LLMs大规模鲁棒性的关键。",
      "shortSummary": "大型语言模型在处理长上下文时因“前瞻性干扰”导致性能下降。Sculptor框架提出“主动上下文管理”（ACM），通过上下文碎片化、总结/隐藏/恢复和智能搜索等工具，赋予LLMs主动管理其注意力和工作记忆的能力。实验证明，Sculptor显著提升了模型在信息稀疏基准上的表现，无需特定训练。这表明，明确的上下文控制策略对于LLMs在大规模应用中的鲁棒性至关重要，而非简单增加token窗口。",
      "translated_title": "Sculptor：通过主动上下文管理赋予大型语言模型认知能动性",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) suffer from significant performance degradation when processing long contexts due to proactive interference, where irrelevant information in earlier parts of the context disrupts reasoning and memory recall. While most research focuses on external memory systems to augment LLMs' capabilities, we propose a complementary approach: empowering LLMs with Active Context Management (ACM) tools to actively sculpt their internal working memory. We introduce Sculptor, a framework that equips LLMs with three categories of tools: (1) context fragmentation, (2) summary, hide, and restore, and (3) intelligent search. Our approach enables LLMs to proactively manage their attention and working memory, analogous to how humans selectively focus on relevant information while filtering out distractions. Experimental evaluation on information-sparse benchmarks-PI-LLM (proactive interference) and NeedleBench Multi-Needle Reasoning-demonstrates that Sculptor significantly improves performance even without specific training, leveraging LLMs' inherent tool calling generalization capabilities. By enabling Active Context Management, Sculptor not only mitigates proactive interference but also provides a cognitive foundation for more reliable reasoning across diverse long-context tasks-highlighting that explicit context-control strategies, rather than merely larger token windows, are key to robustness at scale."
    },
    {
      "title": "立场：当前人工智能会议模式不可持续！诊断中心化人工智能会议的危机 (原标题: Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference)",
      "link": "https://arxiv.org/abs/2508.04586",
      "pubDate": "Wed, 06 Aug 2025 12:08:27 GMT",
      "isoDate": "2025-08-06T12:08:27.000Z",
      "creator": "Nuo Chen, Moming Duan, Andre Huikai Lin, Qian Wang, Jiaying Wu, Bingsheng He",
      "summary": "## 当前人工智能会议模式的危机诊断\n\n人工智能（AI）会议在推动研究、分享知识和促进学术社区发展方面发挥着至关重要的作用。然而，随着AI领域的迅速扩张，当前中心化的会议模式正变得越来越不可持续。本文通过数据驱动的方式，深入诊断了这一结构性危机，指出其正威胁着科学传播、公平性和社区福祉等核心目标。\n\n### 危机的主要压力领域\n\n文章识别出四个关键的压力领域，这些压力共同指向一个与其核心使命不符的系统：\n\n1.  **科学方面：**\n    *   过去十年间，每位作者的论文发表率翻了一倍多，达到每年超过4.5篇。这种高发表率给同行评审系统和研究人员带来了巨大压力。\n\n2.  **环境方面：**\n    *   单次大型会议的碳足迹已超过其主办城市一天的排放量。这凸显了中心化会议模式对环境的巨大影响。\n\n3.  **心理方面：**\n    *   在线社区讨论中，有71%的内容反映出负面情绪。\n    *   其中35%的讨论提及了心理健康问题。这表明高压的会议环境和学术竞争对研究人员的心理健康造成了负面影响。\n\n4.  **物流方面：**\n    *   顶级会议（如NeurIPS 2024）的参会人数已开始超出现有场地容量。这导致了参会体验下降、资源紧张以及潜在的排他性问题。\n\n### 提出的解决方案：社区联邦会议（CFC）模型\n\n为了应对这些日益增长的压力，文章提出了“社区联邦会议（Community-Federated Conference, CFC）”模型。该模型旨在提供一个更可持续、更具包容性和更具弹性的AI研究发展路径。\n\n**CFC模型的核心特点：**\n\n*   **分离功能：** 将同行评审、论文演示和社交活动这三个核心功能进行分离。\n*   **全球协调与本地组织：** 这些分离的功能在全球范围内进行协调，但在本地层面进行组织和实施。\n\n通过这种去中心化和联邦化的方法，CFC模型有望缓解当前中心化会议模式所面临的各项挑战，更好地服务于AI研究社区的长期发展。",
      "shortSummary": "当前人工智能会议的中心化模式因快速扩张而不可持续，面临科学（高发表率）、环境（高碳足迹）、心理（负面情绪与心理健康问题）和物流（场地容量不足）四方面压力。为解决此危机，文章提出“社区联邦会议（CFC）”模型，通过将同行评审、演示和社交活动分离，并进行全球协调、本地组织，旨在为AI研究提供一个更可持续、包容和弹性的发展路径。",
      "translated_title": "立场：当前人工智能会议模式不可持续！诊断中心化人工智能会议的危机",
      "images": [],
      "contentSource": "完整文章",
      "content": "Artificial Intelligence (AI) conferences are essential for advancing research, sharing knowledge, and fostering academic community. However, their rapid expansion has rendered the centralized conference model increasingly unsustainable. This paper offers a data-driven diagnosis of a structural crisis that threatens the foundational goals of scientific dissemination, equity, and community well-being. We identify four key areas of strain: (1) scientifically, with per-author publication rates more than doubling over the past decade to over 4.5 papers annually; (2) environmentally, with the carbon footprint of a single conference exceeding the daily emissions of its host city; (3) psychologically, with 71% of online community discourse reflecting negative sentiment and 35% referencing mental health concerns; and (4) logistically, with attendance at top conferences such as NeurIPS 2024 beginning to outpace venue capacity. These pressures point to a system that is misaligned with its core mission. In response, we propose the Community-Federated Conference (CFC) model, which separates peer review, presentation, and networking into globally coordinated but locally organized components, offering a more sustainable, inclusive, and resilient path forward for AI research."
    },
    {
      "title": "客户支持对话的评估、合成与增强 (原标题: Evaluating, Synthesizing, and Enhancing for Customer Support Conversation)",
      "link": "https://arxiv.org/abs/2508.04423",
      "pubDate": "Wed, 06 Aug 2025 09:11:17 GMT",
      "isoDate": "2025-08-06T09:11:17.000Z",
      "creator": "Jie Zhu, Huaixia Dou, Junhui Li, Lifan Guo, Feng Chen, Chi Zhang, Fang Kong",
      "summary": "### 客户支持对话的评估、合成与增强\n\n**1. 引言与背景**\n有效的客户支持不仅需要准确的问题解决能力，还需要结构化、富有同理心且符合专业标准的沟通。然而，现有对话数据集往往缺乏战略指导，且真实世界服务数据难以获取和标注。为解决这一挑战，本文引入了“客户支持对话”（Customer Support Conversation, CSC）任务，旨在训练客户服务代理使用明确定义的策略进行响应。\n\n**2. CSC框架**\n本文提出了一个基于COPC（Customer Operations Performance Center）准则的结构化CSC框架。该框架定义了：\n*   **五个对话阶段**：指导对话流程。\n*   **十二种策略**：用于引导高质量的互动。\n\n**3. 数据集构建**\n基于上述CSC框架，研究团队构建了两个关键数据集：\n\n*   **CSConv（评估数据集）**\n    *   包含1,855个真实的客户与代理对话。\n    *   这些对话使用大型语言模型（LLMs）进行了重写，以反映有意的策略使用。\n    *   对话内容已相应地进行了标注，用于评估模型表现。\n\n*   **RoleCS（训练数据集）**\n    *   通过一种角色扮演方法开发。\n    *   该方法利用LLM驱动的角色模拟富含策略的对话，这些角色与CSC框架保持一致。\n    *   RoleCS作为训练数据集，旨在教授模型生成策略性响应。\n\n**4. 实验与结果**\n实验结果表明：\n*   在RoleCS数据集上对强大的LLMs进行微调，显著提升了它们在CSConv数据集上生成高质量、策略一致响应的能力。\n*   人工评估进一步证实了模型在问题解决方面的提升。\n\n**5. 数据与代码可用性**\n所有相关的代码和数据都将公开发布。",
      "shortSummary": "本文针对客户支持对话中缺乏战略指导的问题，提出了“客户支持对话”（CSC）任务。研究团队基于COPC准则构建了一个包含五个对话阶段和十二种策略的CSC框架。在此基础上，他们创建了评估数据集CSConv（1,855个重写并标注的真实对话）和训练数据集RoleCS（通过LLM角色扮演模拟的策略丰富对话）。实验证明，在RoleCS上微调LLM能显著提升其生成高质量、策略一致响应的能力，并经人工评估证实有助于问题解决。所有代码和数据将公开。",
      "translated_title": "客户支持对话的评估、合成与增强",
      "images": [],
      "contentSource": "完整文章",
      "content": "Effective customer support requires not only accurate problem solving but also structured and empathetic communication aligned with professional standards. However, existing dialogue datasets often lack strategic guidance, and real-world service data is difficult to access and annotate. To address this, we introduce the task of Customer Support Conversation (CSC), aimed at training customer service agents to respond using well-defined support strategies. We propose a structured CSC framework grounded in COPC guidelines, defining five conversational stages and twelve strategies to guide high-quality interactions. Based on this, we construct CSConv, an evaluation dataset of 1,855 real-world customer-agent conversations rewritten using LLMs to reflect deliberate strategy use, and annotated accordingly. Additionally, we develop a role-playing approach that simulates strategy-rich conversations using LLM-powered roles aligned with the CSC framework, resulting in the training dataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS significantly improves their ability to generate high-quality, strategy-aligned responses on CSConv. Human evaluations further confirm gains in problem resolution. All code and data will be made publicly available at https://github.com/aliyun/qwen-dianjin."
    },
    {
      "title": "EVOC2RUST：一个用于项目级C到Rust翻译的骨架引导框架 (原标题: EVOC2RUST: A Skeleton-guided Framework for Project-Level C-to-Rust Translation)",
      "link": "https://arxiv.org/abs/2508.04295",
      "pubDate": "Wed, 06 Aug 2025 06:31:23 GMT",
      "isoDate": "2025-08-06T06:31:23.000Z",
      "creator": "Chaofan Wang, Tingrui Yu, Jie Wang, Dong Chen, Wenrui Zhang, Yuling Shi, Xiaodong Gu, Beijun Shen",
      "summary": "## EVOC2RUST：一个用于项目级C到Rust翻译的骨架引导框架\n\n### 引言：现有C到Rust翻译方法的局限性\n\nRust的编译时安全保证使其成为安全关键系统的理想选择，因此将遗留C代码库翻译成Rust的需求日益增长。尽管已出现多种翻译方法，但它们面临固有的权衡：\n\n*   **规则基解决方案：** 难以满足代码安全性和惯用性要求。\n*   **LLM（大型语言模型）基解决方案：** 由于模块在整个代码库中存在重度依赖，通常无法生成语义等效的Rust代码。\n*   **共同局限：** 近期研究表明，这两种解决方案都仅限于小规模程序。\n\n### EvoC2Rust框架介绍\n\n本文提出了EvoC2Rust，一个自动化框架，旨在将整个C项目转换为等效的Rust项目。EvoC2Rust采用骨架引导的翻译策略，用于项目级别的翻译。其流程包括三个演进阶段：\n\n1.  **阶段一：生成可编译的Rust骨架**\n    *   首先将C项目分解为功能模块。\n    *   采用特征映射增强的LLM来转换定义和宏。\n    *   生成类型检查的函数存根，形成一个可编译的Rust骨架。\n\n2.  **阶段二：增量函数翻译**\n    *   随后逐步翻译函数，替换相应的存根占位符。\n\n3.  **阶段三：编译错误修复**\n    *   最后，通过整合LLM和静态分析来修复编译错误。\n\n### EvoC2Rust的优势\n\n通过演进式增强，EvoC2Rust结合了规则基和LLM基解决方案的优点，有效克服了现有方法的局限性。\n\n### 评估与性能\n\nEvoC2Rust在开源基准测试和六个工业项目上的评估结果表明，其在项目级C到Rust翻译方面表现卓越：\n\n*   **与LLM基方法相比：**\n    *   语法准确性平均提高17.24%。\n    *   语义准确性平均提高14.32%。\n*   **与规则基工具相比：**\n    *   代码安全率高96.79%。\n*   **在模块级别（工业项目）：**\n    *   编译通过率达到92.25%。\n    *   测试通过率达到89.53%。\n\n这些结果表明，即使对于复杂的代码库和长函数，EvoC2Rust也能表现良好。",
      "shortSummary": "EvoC2Rust是一个自动化框架，旨在将整个C项目转换为Rust项目。它采用骨架引导的翻译策略，通过分解C项目、生成Rust骨架、增量翻译函数和修复编译错误三个演进阶段进行。该框架结合了规则基和LLM基方法的优点，解决了现有方案在规模和准确性上的局限。评估显示，EvoC2Rust在项目级C到Rust翻译方面表现卓越，显著提高了语法和语义准确性，并大幅提升了代码安全率，尤其在工业项目中展现出高编译和测试通过率。",
      "translated_title": "EVOC2RUST：一个用于项目级C到Rust翻译的骨架引导框架",
      "images": [],
      "contentSource": "完整文章",
      "content": "Rust's compile-time safety guarantees make it ideal for safety-critical systems, creating demand for translating legacy C codebases to Rust. While various approaches have emerged for this task, they face inherent trade-offs: rule-based solutions face challenges in meeting code safety and idiomaticity requirements, while LLM-based solutions often fail to generate semantically equivalent Rust code, due to the heavy dependencies of modules across the entire codebase. Recent studies have revealed that both solutions are limited to small-scale programs. In this paper, we propose EvoC2Rust, an automated framework for converting entire C projects to equivalent Rust ones. EvoC2Rust employs a skeleton-guided translation strategy for project-level translation. The pipeline consists of three evolutionary stages: 1) it first decomposes the C project into functional modules, employs a feature-mapping-enhanced LLM to transform definitions and macros and generates type-checked function stubs, which form a compilable Rust skeleton; 2) it then incrementally translates the function, replacing the corresponding stub placeholder; 3) finally, it repairs compilation errors by integrating LLM and static analysis. Through evolutionary augmentation, EvoC2Rust combines the advantages of both rule-based and LLM-based solutions. Our evaluation on open-source benchmarks and six industrial projects demonstrates EvoC2Rust's superior performance in project-level C-to-Rust translation. On average, it achieves 17.24% and 14.32% improvements in syntax and semantic accuracy over the LLM-based approaches, along with a 96.79% higher code safety rate than the rule-based tools. At the module level, EvoC2Rust reaches 92.25% compilation and 89.53% test pass rates on industrial projects, even for complex codebases and long functions."
    },
    {
      "title": "RPCANet++: 深度可解释鲁棒主成分分析用于稀疏目标分割 (原标题: RPCANet++: Deep Interpretable Robust PCA for Sparse Object Segmentation)",
      "link": "https://arxiv.org/abs/2508.04190",
      "pubDate": "Wed, 06 Aug 2025 04:19:37 GMT",
      "isoDate": "2025-08-06T04:19:37.000Z",
      "creator": "Fengyi Wu, Yimian Dai, Tianfang Zhang, Yixuan Ding, Jian Yang, Ming-Ming Cheng, Zhenming Peng",
      "summary": "# RPCANet++: 深度可解释鲁棒主成分分析用于稀疏目标分割\n\n## 1. 引言与背景\n\n*   **鲁棒主成分分析 (RPCA)**：RPCA 是一种强大的数学工具，能够将观测矩阵分解为低秩背景和稀疏目标两部分。这一能力使其在图像恢复和分割等多种任务中得到广泛应用。\n*   **传统 RPCA 的局限性**：尽管功能强大，但传统的 RPCA 模型存在以下挑战：\n    *   **计算负担**：由于涉及复杂的矩阵运算，计算成本高昂。\n    *   **超参数依赖**：其性能严重依赖于需要精细调整的超参数。\n    *   **刚性先验**：固定的先验假设限制了其在动态或复杂场景中的适应性。\n\n## 2. RPCANet++ 框架\n\n*   **核心思想**：为解决传统 RPCA 的局限性，我们提出了 RPCANet++。这是一个稀疏目标分割框架，旨在将 RPCA 的可解释性与深度学习架构的高效性相结合。\n*   **网络结构**：RPCANet++ 将一个松弛的 RPCA 模型展开为一个结构化的深度网络，主要包含以下三个核心模块：\n    *   **背景近似模块 (Background Approximation Module, BAM)**：负责估计并近似图像中的低秩背景成分。\n    *   **目标提取模块 (Object Extraction Module, OEM)**：专注于从观测数据中精确提取稀疏目标成分。\n    *   **图像恢复模块 (Image Restoration Module, IRM)**：用于最终的图像重建或精炼。\n\n## 3. 关键创新与增强\n\n为了进一步提升性能和鲁棒性，RPCANet++ 引入了两个关键的增强模块：\n\n*   **记忆增强模块 (Memory-Augmented Module, MAM)**：\n    *   该模块被引入到背景近似模块 (BAM) 中。\n    *   其主要目的是缓解模块间传输过程中可能出现的特征损失。\n    *   通过增强背景特征的保留能力，确保背景信息的完整性。\n*   **深度对比先验模块 (Deep Contrast Prior Module, DCPM)**：\n    *   该模块在目标提取模块 (OEM) 中发挥作用。\n    *   它利用图像中的显著性线索（saliency cues）。\n    *   通过利用这些先验信息，显著加速了稀疏目标的提取过程。\n\n## 4. 性能与可解释性\n\n*   **卓越性能**：在多样化的数据集上进行了广泛的实验验证，结果表明 RPCANet++ 在各种成像场景下均实现了最先进 (state-of-the-art) 的性能。\n*   **增强可解释性**：该方法通过提供视觉和数值上的低秩性与稀疏性度量，进一步提升了模型的内在可解释性，使得用户能更好地理解模型的工作原理。\n*   **新基准**：通过巧妙地结合 RPCA 的理论优势和深度网络的计算效率，RPCANet++ 为可靠且可解释的稀疏目标分割任务设定了新的性能基准。\n\n## 5. 代码可用性\n\n*   项目的相关代码已在其项目网页上公开，方便研究人员和开发者进行复现和进一步研究。",
      "shortSummary": "RPCANet++是一个深度可解释的鲁棒主成分分析（RPCA）框架，用于稀疏目标分割。它解决了传统RPCA计算量大、超参数依赖和先验限制等问题。该框架将RPCA模型展开为深度网络，包含背景近似、目标提取和图像恢复模块，并通过记忆增强和深度对比先验模块优化性能。RPCANet++在多个数据集上实现了最先进的性能，并提升了可解释性，为可靠的稀疏目标分割设定了新基准。",
      "translated_title": "RPCANet++: 深度可解释鲁棒主成分分析用于稀疏目标分割",
      "images": [],
      "contentSource": "完整文章",
      "content": "Robust principal component analysis (RPCA) decomposes an observation matrix into low-rank background and sparse object components. This capability has enabled its application in tasks ranging from image restoration to segmentation. However, traditional RPCA models suffer from computational burdens caused by matrix operations, reliance on finely tuned hyperparameters, and rigid priors that limit adaptability in dynamic scenarios. To solve these limitations, we propose RPCANet++, a sparse object segmentation framework that fuses the interpretability of RPCA with efficient deep architectures. Our approach unfolds a relaxed RPCA model into a structured network comprising a Background Approximation Module (BAM), an Object Extraction Module (OEM), and an Image Restoration Module (IRM). To mitigate inter-stage transmission loss in the BAM, we introduce a Memory-Augmented Module (MAM) to enhance background feature preservation, while a Deep Contrast Prior Module (DCPM) leverages saliency cues to expedite object extraction. Extensive experiments on diverse datasets demonstrate that RPCANet++ achieves state-of-the-art performance under various imaging scenarios. We further improve interpretability via visual and numerical low-rankness and sparsity measurements. By combining the theoretical strengths of RPCA with the efficiency of deep networks, our approach sets a new baseline for reliable and interpretable sparse object segmentation. Codes are available at our Project Webpage https://fengyiwu98.github.io/rpcanetx."
    },
    {
      "title": "VeriGUI：可验证的长链GUI数据集 (原标题: VeriGUI: Verifiable Long-Chain GUI Dataset)",
      "link": "https://arxiv.org/abs/2508.04026",
      "pubDate": "Tue, 05 Aug 2025 22:38:18 GMT",
      "isoDate": "2025-08-05T22:38:18.000Z",
      "creator": "Shunyu Liu, Minghao Liu, Huichi Zhou, Zhenyu Cui, Yang Zhou, Yuhao Zhou, Wendong Fan, Ge Zhang, Jiajun Shi, Weihao Xuan, Jiaxing Huang, Shuang Luo, Fang Wu, Heli Qi, Qingcheng Zeng, Ziqi Ren, Jialiang Gao, Jindi Lv, Junjie Wang, Aosong Feng, Heng Zhou, Wangchunshu Zhou, Zhenfei Yin, Wenlong Zhang, Guohao Li, Wenhao Yu, Irene Li, Lei Ma, Lei Bai, Qunshu Lin, Mingli Song, Dacheng Tao",
      "summary": "# VeriGUI：可验证的长链GUI数据集\n\n## 引言与背景\n当前，构建能够执行复杂图形用户界面（GUI）任务的自主代理是人机交互领域的研究热点。尽管已取得令人鼓舞的成果，但现有研究主要集中于短期交互，并依赖于仅基于结果的验证。这限制了它们在需要长期任务分解和执行的真实世界GUI应用中的可扩展性。\n\n## VeriGUI数据集介绍\n为了解决上述挑战，本研究引入了VeriGUI，一个新颖的可验证长链GUI数据集。VeriGUI旨在促进在真实计算机环境中运行的通用GUI代理的开发和评估。该数据集强调两个关键维度：\n\n*   **长链复杂性：** 任务被分解为一系列相互依赖的子任务，这些子任务跨越数百个步骤。数据集经过精心设计，允许任何子任务作为有效的起始点，从而支持更灵活的任务规划和执行。\n*   **子任务级可验证性：** 确保在每个子任务内部可以采用多样化的探索策略，同时每个子任务级别的目标都保持可验证性和一致性。这有助于更细粒度的评估和调试。\n\n## 数据集构成\nVeriGUI数据集包含由人类专家标注的GUI任务轨迹，涵盖桌面和网页环境。\n\n## 实验与发现\n研究人员使用不同基础模型的各种代理在VeriGUI数据集上进行了广泛的实验。结果揭示了在处理长周期任务方面存在显著的性能差距，这突出表明GUI代理需要更强大的规划和决策能力。\n\n## 结论与意义\nVeriGUI数据集的推出，为开发和评估能够处理复杂、长期GUI任务的通用代理提供了重要的资源，有望推动自主代理在人机交互领域的进一步发展。",
      "shortSummary": "VeriGUI是一个新颖的可验证长链GUI数据集，旨在解决现有GUI代理研究在处理长期复杂任务时的局限性。它通过将任务分解为数百个可验证的子任务，并支持桌面和网页环境，来促进通用GUI代理的开发和评估。实验表明，当前代理在处理长周期任务时表现出显著的性能差距，凸显了提升规划和决策能力的需求。VeriGUI为推动人机交互领域的自主代理发展提供了重要资源。",
      "translated_title": "VeriGUI：可验证的长链GUI数据集",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent studies have delved into constructing autonomous agents capable of performing complex Graphical User Interface (GUI)-based computer tasks, with the potential to revolutionize human-computer interaction. Despite encouraging results, existing efforts mainly focus on short-term interactions and rely on outcome-only verification, thereby limiting their scalability in real-world GUI applications that demand long-horizon task decomposition and execution. In this work, we introduce VeriGUI, a novel verifiable long-chain GUI dataset designed to facilitate the development and evaluation of generalist GUI agents operating in realistic computer environments. Our dataset emphasizes two critical dimensions: (1) long-chain complexity, with tasks decomposed into a sequence of interdependent subtasks spanning hundreds of steps, explicitly designed to allow any subtask to serve as a valid starting point; and (2) subtask-level verifiability, which enables diverse exploration strategies within each subtask, while ensuring that each subtask-level goal remains verifiable and consistent. The dataset consists of GUI task trajectories across both desktop and web, annotated by human experts. Extensive experiments on VeriGUI using various agents with different foundation models reveal significant performance gaps in handling long-horizon tasks, highlighting the need for more robust planning and decision-making capabilities in GUI agents."
    },
    {
      "title": "大型多模态模型能否主动识别错误输入？对其输入审查能力的系统评估框架 (原标题: Can Large Multimodal Models Actively Recognize Faulty Inputs? A Systematic Evaluation Framework of Their Input Scrutiny Ability)",
      "link": "https://arxiv.org/abs/2508.04017",
      "pubDate": "Tue, 05 Aug 2025 22:13:46 GMT",
      "isoDate": "2025-08-05T22:13:46.000Z",
      "creator": "Haiqi Yang, Jinzhe Li, Gengxu Li, Yi Chang, Yuan Wu",
      "summary": "# 大型多模态模型输入审查能力评估\n\n## 引言\n大型多模态模型（LMMs）近年来取得了显著发展，在处理复杂多模态任务方面展现出卓越的性能。然而，近期研究指出大型语言模型（LLMs）倾向于被动接受有缺陷的输入，这常导致对无效提示进行徒劳的推理。对于LMMs而言，它们能否主动检测并审查错误输入这一关键问题，目前仍未得到充分探索。\n\n## ISEval评估框架\n为了弥补这一研究空白，本文引入了**输入审查能力评估框架（ISEval）**。该框架包含：\n*   **七类缺陷前提**：用于定义不同类型的错误输入。\n*   **三种评估指标**：用于量化模型的审查能力。\n\n## 评估与主要发现\n研究团队对十个先进的LMMs进行了广泛评估，并得出了以下关键发现：\n\n*   **对显式提示的依赖性强**：大多数模型在没有明确引导的情况下，难以主动检测文本前提中的缺陷。这表明LMMs在识别前提错误时，强烈依赖于用户提供的显式提示。\n*   **错误类型影响性能**：模型识别错误的能力受错误类型的影响。\n    *   **擅长**：识别逻辑谬误。\n    *   **挣扎**：处理表面层面的语言错误和某些条件性缺陷。\n*   **模态信任度差异**：不同模型在处理视觉和文本信息冲突时的信任度表现各异。\n    *   **平衡型**：Gemini 2.5 pro 和 Claude Sonnet 4 能够较好地平衡视觉和文本信息。\n    *   **过度依赖文本型**：aya-vision-8b 在信息冲突时过度依赖文本信息。\n\n## 结论与展望\n这些研究洞察强调了迫切需要增强LMMs主动验证输入有效性的能力。本文为缓解LMMs被动接受缺陷输入的问题提供了新的见解。\n\n## 资源\n相关代码已公开。",
      "shortSummary": "这项研究引入了ISEval框架，系统评估大型多模态模型（LMMs）主动识别错误输入的能力。对十个先进LMMs的评估发现，多数模型在无引导下难以检测文本缺陷，性能受错误类型影响，且模态信任度各异。研究强调迫切需要提升LMMs主动验证输入有效性的能力，以避免无效推理。",
      "translated_title": "大型多模态模型能否主动识别错误输入？对其输入审查能力的系统评估框架",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Multimodal Models (LMMs) have witnessed remarkable growth, showcasing formidable capabilities in handling intricate multimodal tasks with exceptional performance. Recent research has underscored the inclination of large language models to passively accept defective inputs, often resulting in futile reasoning on invalid prompts. However, the same critical question of whether LMMs can actively detect and scrutinize erroneous inputs still remains unexplored. To address this gap, we introduce the Input Scrutiny Ability Evaluation Framework (ISEval), which encompasses seven categories of flawed premises and three evaluation metrics. Our extensive evaluation of ten advanced LMMs has identified key findings. Most models struggle to actively detect flawed textual premises without guidance, which reflects a strong reliance on explicit prompts for premise error identification. Error type affects performance: models excel at identifying logical fallacies but struggle with surface-level linguistic errors and certain conditional flaws. Modality trust varies-Gemini 2.5 pro and Claude Sonnet 4 balance visual and textual info, while aya-vision-8b over-rely on text in conflicts. These insights underscore the urgent need to enhance LMMs' proactive verification of input validity and shed novel insights into mitigating the problem. The code is available at https://github.com/MLGroupJLU/LMM_ISEval."
    },
    {
      "title": "当今的大语言模型是否已准备好解释幸福感概念？ (原标题: Are Today's LLMs Ready to Explain Well-Being Concepts?)",
      "link": "https://arxiv.org/abs/2508.03990",
      "pubDate": "Tue, 05 Aug 2025 20:45:02 GMT",
      "isoDate": "2025-08-05T20:45:02.000Z",
      "creator": "Bohan Jiang, Dawei Li, Zhen Tan, Chengshuai Zhao, Huan Liu",
      "summary": "## 当今大语言模型解释幸福感概念的能力研究\n\n### 引言\n\n*   幸福感是一个多维度的概念，涵盖心理、生理和社会层面，对个人成长和做出明智的生活决策至关重要。\n*   随着越来越多的人转向大语言模型（LLM）寻求对幸福感的理解，一个核心挑战浮现：LLM能否生成不仅准确，而且能根据不同受众需求量身定制的解释？\n*   高质量的解释要求模型既能提供事实正确的信息，又能满足具有不同专业知识水平用户的期望。\n\n### 研究方法\n\n*   **大规模数据集构建：** 本研究构建了一个大型数据集，其中包含来自十个不同LLM生成的2,194个幸福感概念的43,880个解释。\n*   **LLM作为评判者的评估框架：** 引入了一个基于原则的“LLM作为评判者”评估框架，该框架采用双重评判机制来评估解释的质量。\n*   **模型微调：** 研究表明，通过使用监督微调（SFT）和直接偏好优化（DPO）对开源LLM进行微调，可以显著提升其生成解释的质量。\n\n### 主要发现\n\n1.  **LLM评判者与人类评估的一致性：** 研究所提出的LLM评判者与人类评估结果表现出高度一致性。\n2.  **解释质量的显著差异：** 解释的质量在不同模型、不同受众和不同概念类别之间存在显著差异。\n3.  **微调模型的优越性：** 经过DPO和SFT微调的模型表现优于其规模更大的对应模型，这有力地证明了基于偏好学习在专业解释任务中的有效性。",
      "shortSummary": "本研究探讨了当前大语言模型（LLM）解释幸福感概念的能力。研究团队构建了一个包含43,880个解释的大型数据集，并引入了基于LLM的评估框架。结果显示，LLM评判结果与人类评估一致，且解释质量因模型、受众和类别而异。此外，通过监督微调（SFT）和直接偏好优化（DPO）微调的开源LLM在解释质量上显著优于大型模型，证明了偏好学习在专业解释任务中的有效性。",
      "translated_title": "当今的大语言模型是否已准备好解释幸福感概念？",
      "images": [],
      "contentSource": "完整文章",
      "content": "Well-being encompasses mental, physical, and social dimensions essential to personal growth and informed life decisions. As individuals increasingly consult Large Language Models (LLMs) to understand well-being, a key challenge emerges: Can LLMs generate explanations that are not only accurate but also tailored to diverse audiences? High-quality explanations require both factual correctness and the ability to meet the expectations of users with varying expertise. In this work, we construct a large-scale dataset comprising 43,880 explanations of 2,194 well-being concepts, generated by ten diverse LLMs. We introduce a principle-guided LLM-as-a-judge evaluation framework, employing dual judges to assess explanation quality. Furthermore, we show that fine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) can significantly enhance the quality of generated explanations. Our results reveal: (1) The proposed LLM judges align well with human evaluations; (2) explanation quality varies significantly across models, audiences, and categories; and (3) DPO- and SFT-finetuned models outperform their larger counterparts, demonstrating the effectiveness of preference-based learning for specialized explanation tasks."
    }
  ],
  "lastUpdated": "2025-08-08T09:39:59.332Z"
}
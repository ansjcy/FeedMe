{
  "sourceUrl": "https://rsshub.rssforever.com/huggingface/daily-papers",
  "title": "Huggingface Daily Papers",
  "description": "Huggingface Daily Papers - Powered by RSSHub",
  "link": "https://huggingface.co/papers",
  "items": [
    {
      "title": "WinT3R：基于窗口的流式重建与相机令牌池 (原标题: WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool)",
      "link": "https://arxiv.org/abs/2509.05296",
      "pubDate": "Fri, 05 Sep 2025 13:59:47 GMT",
      "isoDate": "2025-09-05T13:59:47.000Z",
      "creator": "Zizun Li, Jianjun Zhou, Yifan Wang, Haoyu Guo, Wenzheng Chang, Yang Zhou, Haoyi Zhu, Junyi Chen, Chunhua Shen, Tong He",
      "summary": "# WinT3R：基于窗口的流式重建与相机令牌池\n\n## 摘要\n本文介绍了WinT3R，一个前馈重建模型，能够在线预测精确的相机姿态和高质量的点云图。\n\n## 现有问题\n*   以往的方法在重建质量和实时性能之间存在权衡，难以同时达到高水平。\n\n## WinT3R 的核心创新与解决方案\nWinT3R模型旨在解决上述问题，其主要设计包括：\n\n1.  **滑动窗口机制：**\n    *   **目的：** 确保窗口内帧之间有足够的信息交换，从而在不增加大量计算的情况下提高几何预测的质量。\n    *   **优势：** 改善重建质量，同时保持计算效率。\n2.  **紧凑的相机表示与全局相机令牌池：**\n    *   **目的：** 增强相机姿态估计的可靠性。\n    *   **优势：** 在不牺牲效率的前提下，提高相机姿态估计的准确性。\n\n## 性能与验证\n*   **成果：** 这些设计使WinT3R在在线重建质量、相机姿态估计和重建速度方面达到了最先进的性能。\n*   **验证：** 通过在各种数据集上进行的大量实验验证了其卓越性能。\n\n## 可用性\n*   WinT3R的代码和模型已公开提供。",
      "shortSummary": "WinT3R是一个前馈模型，用于在线预测精确的相机姿态和高质量点云图。它通过引入滑动窗口机制来增强帧间信息交换，并在不牺牲效率的情况下，利用紧凑的相机表示和全局相机令牌池提高相机姿态估计的可靠性。WinT3R在在线重建质量、相机姿态估计和重建速度方面均达到了最先进的性能。",
      "translated_title": "WinT3R：基于窗口的流式重建与相机令牌池",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present WinT3R, a feed-forward reconstruction model capable of online prediction of precise camera poses and high-quality point maps. Previous methods suffer from a trade-off between reconstruction quality and real-time performance. To address this, we first introduce a sliding window mechanism that ensures sufficient information exchange among frames within the window, thereby improving the quality of geometric predictions without large computation. In addition, we leverage a compact representation of cameras and maintain a global camera token pool, which enhances the reliability of camera pose estimation without sacrificing efficiency. These designs enable WinT3R to achieve state-of-the-art performance in terms of online reconstruction quality, camera pose estimation, and reconstruction speed, as validated by extensive experiments on diverse datasets. Code and model are publicly available at https://github.com/LiZizun/WinT3R."
    },
    {
      "title": "LatticeWorld: 一个由多模态大型语言模型驱动的交互式复杂世界生成框架 (原标题: LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation)",
      "link": "https://arxiv.org/abs/2509.05263",
      "pubDate": "Fri, 05 Sep 2025 13:22:33 GMT",
      "isoDate": "2025-09-05T13:22:33.000Z",
      "creator": "Yinglin Duan, Zhengxia Zou, Tongwei Gu, Wei Jia, Zhan Zhao, Luyi Xu, Xinzhu Liu, Hao Jiang, Kang Chen, Shuang Qiu",
      "summary": "### LatticeWorld: 多模态大型语言模型赋能的交互式复杂世界生成框架\n\n#### 背景与挑战\n*   **研究焦点**: 近期研究日益关注开发模拟复杂现实世界场景的3D世界模型。\n*   **应用领域**: 世界模型在具身AI、自动驾驶、娱乐等多个领域有广泛应用。\n*   **目标**: 通过更真实的模拟和精确的物理效果，有效缩小“模拟到现实”的差距，并方便地获取关于现实世界的丰富信息。\n*   **传统方法局限**: 传统手动建模虽然能创建虚拟3D场景，但效率不高。\n*   **现代方法**: 现代方法利用先进的机器学习算法进行3D世界生成，最新进展集中于根据用户指令创建虚拟世界的生成式方法。\n\n#### LatticeWorld框架介绍\n*   **核心理念**: 本文提出了LatticeWorld，一个简单而有效的3D世界生成框架，旨在简化3D环境的工业生产流程。\n*   **技术构成**: \n    *   利用轻量级大型语言模型（LLM，如LLaMA-2-7B）。\n    *   结合工业级渲染引擎（如Unreal Engine 5）。\n    *   共同生成动态环境。\n*   **多模态输入**: LatticeWorld接受文本描述和视觉指令作为多模态输入。\n*   **生成内容**: 创建大规模的3D交互式世界，其中包含动态智能体。\n*   **关键特性**: \n    *   具有竞争力的多智能体交互。\n    *   高保真物理模拟。\n    *   实时渲染。\n\n#### 实验与成果\n*   **评估**: 对LatticeWorld进行了全面的实验评估。\n*   **准确性与视觉保真度**: 结果表明，LatticeWorld在场景布局生成和视觉保真度方面表现出色。\n*   **生产效率提升**: 相较于传统手动生产方法，LatticeWorld在保持高创造性质量的同时，将工业生产效率提高了90倍以上。",
      "shortSummary": "LatticeWorld是一个由多模态大型语言模型（如LLaMA-2-7B）和工业级渲染引擎（如Unreal Engine 5）驱动的3D世界生成框架。它接受文本和视觉指令，能高效生成包含动态智能体、高保真物理模拟和实时渲染的大规模交互式3D世界。实验证明，LatticeWorld在场景布局准确性和视觉保真度上表现优异，并能将工业生产效率提升90倍以上，同时保持高创造性质量。",
      "translated_title": "LatticeWorld: 一个由多模态大型语言模型驱动的交互式复杂世界生成框架",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real world conveniently. While traditional manual modeling has enabled the creation of virtual 3D scenes, modern approaches have leveraged advanced machine learning algorithms for 3D world generation, with most recent advances focusing on generative methods that can create virtual worlds based on user instructions. This work explores such a research direction by proposing LatticeWorld, a simple yet effective 3D world generation framework that streamlines the industrial production pipeline of 3D environments. LatticeWorld leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed framework accepts textual descriptions and visual instructions as multimodal inputs and creates large-scale 3D interactive worlds with dynamic agents, featuring competitive multi-agent interaction, high-fidelity physics simulation, and real-time rendering. We conduct comprehensive experiments to evaluate LatticeWorld, showing that it achieves superior accuracy in scene layout generation and visual fidelity. Moreover, LatticeWorld achieves over a 90times increase in industrial production efficiency while maintaining high creative quality compared with traditional manual production methods. Our demo video is available at https://youtu.be/8VWZXpERR18"
    },
    {
      "title": "大型语言模型下的符号图形编程 (原标题: Symbolic Graphics Programming with Large Language Models)",
      "link": "https://arxiv.org/abs/2509.05208",
      "pubDate": "Fri, 05 Sep 2025 12:10:53 GMT",
      "isoDate": "2025-09-05T12:10:53.000Z",
      "creator": "Yamei Chen, Haoquan Zhang, Yangyi Huang, Zeju Qiu, Kaipeng Zhang, Yandong Wen, Weiyang Liu",
      "summary": "## 大型语言模型下的符号图形编程研究\n\n### 引言与研究背景\n\n大型语言模型（LLMs）在程序合成方面表现出色，但其生成能够渲染出精确视觉内容的符号图形程序（SGPs）的能力尚未得到充分探索。本研究旨在探讨符号图形编程，即从自然语言描述生成SGP。这项任务也为我们提供了一个视角，以观察LLMs如何通过生成由SGP渲染的图像来理解视觉世界。在各种SGP中，本文专注于可伸缩矢量图形（SVGs）。\n\n### SGP-GenBench基准测试\n\n为了评估LLMs生成SGP的程度，我们引入了SGP-GenBench，这是一个全面的基准测试，涵盖了以下方面：\n\n*   **对象保真度**：生成对象的准确性。\n*   **场景保真度**：整个场景的准确性。\n*   **组合性**：包括属性绑定、空间关系和数值能力。\n\n在SGP-GenBench上的测试发现，领先的专有模型显著优于开源模型，并且性能与通用编码能力高度相关。\n\n### 提出的方法：基于可验证奖励的强化学习\n\n为了弥补LLMs在SGP生成方面的差距，我们提出了一种基于可验证奖励的强化学习（RL）方法。该方法包含以下关键机制：\n\n*   **格式有效性门**：确保生成的SVG是可渲染的。\n*   **跨模态奖励**：通过强大的视觉编码器（例如，SigLIP用于文本-图像对齐，DINO用于图像-图像对齐）来对齐文本描述和渲染图像，从而提供奖励信号。\n\n### 实验结果与分析\n\n我们将所提出的方法应用于Qwen-2.5-7B模型，结果显示：\n\n*   显著提升了SVG的生成质量和语义。\n*   实现了与领先系统相当的性能。\n\n进一步的训练动态分析表明，强化学习促使：\n\n*   将对象更精细地分解为可控的基元。\n*   引入上下文细节以提高场景的连贯性。\n\n### 结论\n\n我们的研究结果表明，符号图形编程为理解跨模态接地提供了一个精确且可解释的视角。",
      "shortSummary": "本研究探讨大型语言模型（LLMs）生成精确符号图形程序（SGPs），特别是可伸缩矢量图形（SVGs）的能力。我们引入SGP-GenBench基准测试，发现专有模型优于开源模型。为提升LLMs性能，我们提出一种基于可验证奖励的强化学习（RL）方法，通过格式有效性门和跨模态奖励（使用SigLIP和DINO）对齐文本与渲染图像。应用于Qwen-2.5-7B，该方法显著提高了SVG生成质量，达到领先水平，并揭示了RL如何促进对象分解和场景连贯性，为跨模态接地提供了精确视角。",
      "translated_title": "大型语言模型下的符号图形编程",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large language models (LLMs) excel at program synthesis, yet their ability to produce symbolic graphics programs (SGPs) that render into precise visual content remains underexplored. We study symbolic graphics programming, where the goal is to generate an SGP from a natural-language description. This task also serves as a lens into how LLMs understand the visual world by prompting them to generate images rendered from SGPs. Among various SGPs, our paper sticks to scalable vector graphics (SVGs). We begin by examining the extent to which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a comprehensive benchmark covering object fidelity, scene fidelity, and compositionality (attribute binding, spatial relations, numeracy). On SGP-GenBench, we discover that frontier proprietary models substantially outperform open-source models, and performance correlates well with general coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards approach, where a format-validity gate ensures renderable SVG, and a cross-modal reward aligns text and the rendered image via strong vision encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to Qwen-2.5-7B, our method substantially improves SVG generation quality and semantics, achieving performance on par with frontier systems. We further analyze training dynamics, showing that RL induces (i) finer decomposition of objects into controllable primitives and (ii) contextual details that improve scene coherence. Our results demonstrate that symbolic graphics programming offers a precise and interpretable lens on cross-modal grounding."
    },
    {
      "title": "WildScore：真实世界符号音乐推理中多模态大语言模型的基准测试 (原标题: WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning)",
      "link": "https://arxiv.org/abs/2509.04744",
      "pubDate": "Thu, 04 Sep 2025 21:54:50 GMT",
      "isoDate": "2025-09-04T21:54:50.000Z",
      "creator": "Gagan Mundada, Yash Vishe, Amit Namburi, Xin Xu, Zachary Novack, Julian McAuley, Junda Wu",
      "summary": "## WildScore：多模态大语言模型在符号音乐推理中的基准测试\n\n### 引言与背景\n\n*   **MLLMs的进展与局限：** 近期多模态大语言模型（MLLMs）在各类视觉-语言任务中展现出令人印象深刻的能力。然而，它们在多模态符号音乐领域的推理能力仍未被充分探索。\n\n### WildScore基准的引入\n\n*   **首个真实世界基准：** 本文介绍了WildScore，这是首个“真实世界”（in-the-wild）多模态符号音乐推理与分析基准。\n*   **设计目标：** WildScore旨在评估MLLMs解释真实世界乐谱并回答复杂音乐学查询的能力。\n\n### 数据来源与特点\n\n*   **真实性：** WildScore中的每个实例均来源于真实的音乐作品。\n*   **用户生成内容：** 配有真实的用户生成问题和讨论，捕捉了实际音乐分析的复杂性。\n\n### 评估方法\n\n*   **系统分类法：** 为促进系统性评估，研究者提出了一个系统分类法，包含高层和细粒度音乐学本体。\n*   **问题框架：** 将复杂的音乐推理问题构建为多项选择题形式，从而实现对MLLMs符号音乐理解的受控和可扩展评估。\n\n### 实证结果与发现\n\n*   **MLLMs表现：** 对最先进的MLLMs在WildScore上进行的实证基准测试揭示了其视觉-符号推理中引人入胜的模式。\n*   **前景与挑战：** 研究结果揭示了MLLMs在符号音乐推理与分析方面有前景的方向和持续存在的挑战。\n\n### 资源发布与相关主题\n\n*   **可用资源：** 数据集和代码已发布。\n*   **相关研究领域：** 声音（cs.SD）、计算与语言（cs.CL）、音频与语音处理（eess.AS）。",
      "shortSummary": "本文介绍了WildScore，这是首个用于评估多模态大语言模型（MLLMs）在真实世界符号音乐推理与分析能力的基准。该基准利用真实的音乐作品和用户生成的问题，旨在测试MLLMs解释乐谱和回答复杂音乐学查询的能力。通过将推理问题框架为多项选择题，并采用系统分类法，WildScore揭示了现有MLLMs在该领域的潜力和挑战。数据集和代码已公开发布。",
      "translated_title": "WildScore：真实世界符号音乐推理中多模态大语言模型的基准测试",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various vision-language tasks. However, their reasoning abilities in the multimodal symbolic music domain remain largely unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to interpret real-world music scores and answer complex musicological queries. Each instance in WildScore is sourced from genuine musical compositions and accompanied by authentic user-generated questions and discussions, capturing the intricacies of practical music analysis. To facilitate systematic evaluation, we propose a systematic taxonomy, comprising both high-level and fine-grained musicological ontologies. Furthermore, we frame complex music reasoning as multiple-choice question answering, enabling controlled and scalable assessment of MLLMs' symbolic music understanding. Empirical benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns in their visual-symbolic reasoning, uncovering both promising directions and persistent challenges for MLLMs in symbolic music reasoning and analysis. We release the dataset and code."
    },
    {
      "title": "语言模型为何会产生幻觉 (原标题: Why Language Models Hallucinate)",
      "link": "https://arxiv.org/abs/2509.04664",
      "pubDate": "Thu, 04 Sep 2025 17:26:31 GMT",
      "isoDate": "2025-09-04T17:26:31.000Z",
      "creator": "Adam Tauman Kalai, Ofir Nachum, Santosh S. Vempala, Edwin Zhang",
      "summary": "## 语言模型幻觉的成因与解决方案\n\n### 引言\n大型语言模型（LLM）在面对不确定性时，有时会像学生面对难题一样进行“猜测”，从而产生看似合理但实际上不正确的陈述，而非承认其不确定性。这种现象被称为“幻觉”，即使在最先进的系统中也普遍存在，并严重损害了用户对这些系统的信任。\n\n### 幻觉的根本原因\n文章指出，语言模型产生幻觉的根本原因在于当前的训练和评估程序奖励模型进行“猜测”，而不是承认不确定性。\n\n从统计学角度来看，幻觉并非神秘现象，它们本质上是二元分类中的错误。如果在预训练阶段，模型无法有效地区分错误的陈述与事实，那么在自然统计压力的作用下，幻觉就会在预训练的语言模型中产生。\n\n### 幻觉持续存在的原因\n幻觉之所以持续存在，是因为大多数评估基准的评分方式。语言模型被优化为“善于考试者”，而当模型不确定时进行猜测，往往能提高其在这些测试中的表现。这种“惩罚不确定性回应”的现象导致了幻觉的持续存在。\n\n### 提出的解决方案\n为了解决这种“幻觉流行病”，文章提出了一种社会技术层面的缓解措施，而非仅仅引入更多的幻觉评估。核心建议是：\n*   **修改现有基准测试的评分方式**：针对那些目前存在偏差但主导着排行榜的基准测试，对其评分机制进行调整。\n*   **避免引入额外评估**：不应简单地增加更多的幻觉评估，因为这可能无法从根本上解决问题。\n\n### 目标\n通过上述改变，该领域有望被引导向开发出更值得信赖的AI系统。",
      "shortSummary": "大型语言模型（LLM）产生“幻觉”是因为训练和评估机制奖励猜测而非承认不确定性。从统计学角度看，幻觉是二元分类错误，源于预训练中无法区分事实与错误陈述。幻觉持续存在是因为模型被优化为善于考试，猜测能提高表现。解决之道在于修改现有基准测试的评分方式，而非增加新的幻觉评估，以促进更值得信赖的AI系统发展。",
      "translated_title": "语言模型为何会产生幻觉",
      "images": [],
      "contentSource": "完整文章",
      "content": "Like students facing hard exam questions, large language models sometimes guess when uncertain, producing plausible yet incorrect statements instead of admitting uncertainty. Such \"hallucinations\" persist even in state-of-the-art systems and undermine trust. We argue that language models hallucinate because the training and evaluation procedures reward guessing over acknowledging uncertainty, and we analyze the statistical causes of hallucinations in the modern training pipeline. Hallucinations need not be mysterious -- they originate simply as errors in binary classification. If incorrect statements cannot be distinguished from facts, then hallucinations in pretrained language models will arise through natural statistical pressures. We then argue that hallucinations persist due to the way most evaluations are graded -- language models are optimized to be good test-takers, and guessing when uncertain improves test performance. This \"epidemic\" of penalizing uncertain responses can only be addressed through a socio-technical mitigation: modifying the scoring of existing benchmarks that are misaligned but dominate leaderboards, rather than introducing additional hallucination evaluations. This change may steer the field toward more trustworthy AI systems."
    },
    {
      "title": "Delta激活：一种微调大型语言模型的表示方法 (原标题: Delta Activations: A Representation for Finetuned Large Language Models)",
      "link": "https://arxiv.org/abs/2509.04442",
      "pubDate": "Thu, 04 Sep 2025 13:59:06 GMT",
      "isoDate": "2025-09-04T13:59:06.000Z",
      "creator": "Zhiqiu Xu, Amish Sethi, Mayur Naik, Ser-Nam Lim",
      "summary": "## Delta激活：一种微调大型语言模型的表示方法\n\n### 背景与挑战\n*   强大的开源大型语言模型（LLMs）的成功，使得社区能够创建大量针对特定任务和领域进行微调的模型。\n*   然而，由于元数据不一致和存储库结构化不足，理解和管理这些模型仍然具有挑战性。\n\n### Delta激活方法介绍\n*   本文提出了一种名为“Delta激活”（Delta Activations）的新方法。\n*   该方法通过测量微调模型相对于基础模型的内部激活变化，将微调模型表示为向量嵌入。\n\n### Delta激活的特性与优势\n*   **有效聚类：** 这种表示方法能够有效地按领域和任务对模型进行聚类，从而揭示模型格局中的结构。\n*   **鲁棒性：** Delta激活在不同的微调设置下表现出鲁棒性。\n*   **可加性：** 当微调数据集混合时，Delta激活展现出可加性。\n*   **任务嵌入：** Delta激活还可以通过少样本微调来嵌入任务。\n*   **应用潜力：** 进一步探索了其在模型选择和模型合并方面的应用。\n\n### 目标与资源\n*   作者希望Delta激活能够促进对现有公开模型的重用。\n*   相关代码已公开。\n\n### 研究领域\n*   机器学习 (cs.LG)\n*   人工智能 (cs.AI)\n*   计算与语言 (cs.CL)\n*   信息检索 (cs.IR)",
      "shortSummary": "“Delta激活”是一种新方法，通过测量微调模型相对于基础模型的内部激活变化，将其表示为向量嵌入。这解决了微调LLM难以管理和理解的问题。该方法能有效按领域和任务聚类模型，揭示模型结构，并具有鲁棒性和可加性。它还可用于任务嵌入、模型选择和合并，旨在促进公开模型的重用。",
      "translated_title": "Delta激活：一种微调大型语言模型的表示方法",
      "images": [],
      "contentSource": "完整文章",
      "content": "The success of powerful open source Large Language Models (LLMs) has enabled the community to create a vast collection of post-trained models adapted to specific tasks and domains. However, navigating and understanding these models remains challenging due to inconsistent metadata and unstructured repositories. We introduce Delta Activations, a method to represent finetuned models as vector embeddings by measuring shifts in their internal activations relative to a base model. This representation allows for effective clustering by domain and task, revealing structure in the model landscape. Delta Activations also demonstrate desirable properties: it is robust across finetuning settings and exhibits an additive property when finetuning datasets are mixed. In addition, we show that Delta Activations can embed tasks via few-shot finetuning, and further explore its use for model selection and merging. We hope Delta Activations can facilitate the practice of reusing publicly available models. Code is available at https://github.com/OscarXZQ/delta_activations."
    },
    {
      "title": "榴莲：双参考引导的人像动画与属性迁移 (原标题: Durian: Dual Reference-guided Portrait Animation with Attribute Transfer)",
      "link": "https://arxiv.org/abs/2509.04434",
      "pubDate": "Thu, 04 Sep 2025 13:53:03 GMT",
      "isoDate": "2025-09-04T13:53:03.000Z",
      "creator": "Hyunsoo Cha, Byungjun Kim, Hanbyul Joo",
      "summary": "## Durian：双参考引导的人像动画与属性迁移\n\n### 概述\n\nDurian 是一种开创性的方法，首次实现了从给定参考图像向目标人像进行零样本（zero-shot）面部属性迁移，并生成高质量的人像动画视频。\n\n### 核心技术与方法\n\n*   **双参考网络（Dual Reference Networks）**\n    *   为确保跨帧属性迁移的高保真度和空间一致性，Durian 引入了双参考网络。\n    *   这些网络能够将来自人像图像和属性图像的空间特征注入到扩散模型的去噪过程中。\n\n*   **自重建训练范式（Self-reconstruction Formulation）**\n    *   模型采用独特的自重建方式进行训练。\n    *   具体而言，从同一人像视频中采样两帧：一帧被视为属性参考，另一帧作为目标人像。\n    *   模型随后根据这些输入及其对应的掩码重建视频中的剩余帧。\n\n*   **掩码扩展策略（Mask Expansion Strategy）**\n    *   为了有效支持具有不同空间范围的属性迁移，Durian 提出了一种基于关键点条件图像生成（keypoint-conditioned image generation）的掩码扩展策略，应用于训练阶段。\n\n*   **鲁棒性增强（Robustness Augmentation）**\n    *   为了提高模型对属性图像和人像图像之间可能存在的姿态或位置不对齐的鲁棒性，Durian 进一步通过空间和外观级别的变换来增强这些图像。\n\n### 主要成果与优势\n\n*   **强大的泛化能力**\n    *   尽管在训练时没有明确的三元组监督，上述策略使得 Durian 模型能够有效地泛化到多样化的属性和“野外”（in-the-wild）参考组合。\n\n*   **最先进的性能**\n    *   Durian 在带属性迁移的人像动画领域取得了最先进的性能。\n\n*   **多属性组合能力**\n    *   值得注意的是，其独特的双参考设计使得在单次生成过程中即可实现多属性的组合，而无需进行额外的训练或模型调整。",
      "shortSummary": "Durian 是一种创新方法，首次实现了从参考图像向目标人像进行零样本面部属性迁移，并生成人像动画。它通过引入双参考网络，将人像和属性特征注入扩散模型，并采用自重建和掩码扩展策略进行训练。Durian 在属性迁移人像动画方面取得了最先进的性能，并能实现多属性组合，无需额外训练，展现了强大的泛化能力。",
      "translated_title": "榴莲：双参考引导的人像动画与属性迁移",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present Durian, the first method for generating portrait animation videos with facial attribute transfer from a given reference image to a target portrait in a zero-shot manner. To enable high-fidelity and spatially consistent attribute transfer across frames, we introduce dual reference networks that inject spatial features from both the portrait and attribute images into the denoising process of a diffusion model. We train the model using a self-reconstruction formulation, where two frames are sampled from the same portrait video: one is treated as the attribute reference and the other as the target portrait, and the remaining frames are reconstructed conditioned on these inputs and their corresponding masks. To support the transfer of attributes with varying spatial extent, we propose a mask expansion strategy using keypoint-conditioned image generation for training. In addition, we further augment the attribute and portrait images with spatial and appearance-level transformations to improve robustness to positional misalignment between them. These strategies allow the model to effectively generalize across diverse attributes and in-the-wild reference combinations, despite being trained without explicit triplet supervision. Durian achieves state-of-the-art performance on portrait animation with attribute transfer, and notably, its dual reference design enables multi-attribute composition in a single generation pass without additional training."
    },
    {
      "title": "迈向大语言模型后训练的统一视角 (原标题: Towards a Unified View of Large Language Model Post-Training)",
      "link": "https://arxiv.org/abs/2509.04419",
      "pubDate": "Thu, 04 Sep 2025 13:40:33 GMT",
      "isoDate": "2025-09-04T13:40:33.000Z",
      "creator": "Xingtai Lv, Yuxin Zuo, Youbang Sun, Hongyi Liu, Yuntian Wei, Zhekai Chen, Lixuan He, Xuekai Zhu, Kaiyan Zhang, Bingning Wang, Ning Ding, Bowen Zhou",
      "summary": "## 迈向大语言模型后训练的统一视角：核心发现与HPT算法\n\n本文深入探讨了现代大语言模型（LLM）后训练的两种主要方法——强化学习（RL）和监督微调（SFT），并提出了一个统一的理论框架和相应的算法。\n\n### 1. 后训练数据源与现有方法\n\n*   **数据源**：LLM的后训练主要依赖两种类型的训练数据：\n    *   **在线数据**：通常指模型自身生成的“回滚数据”（rollouts）。\n    *   **离线数据**：通常指人类或其它模型提供的“演示数据”（demonstrations）。\n*   **典型方法**：\n    *   **强化学习（RL）**：常用于处理在线数据。\n    *   **监督微调（SFT）**：常用于处理离线数据。\n\n### 2. 核心理论贡献：统一策略梯度估计器\n\n*   **统一视角**：本文的核心观点是，RL和SFT这两种看似不同的方法并非相互矛盾，而是单一优化过程的不同实例。\n*   **理论推导**：作者推导出了一个“统一策略梯度估计器”（Unified Policy Gradient Estimator）。\n    *   该估计器能够将广泛的后训练方法计算表示为在不同数据分布假设和各种偏差-方差权衡下，一个共同目标函数的梯度。\n*   **估计器构成**：该梯度估计器由四个可互换的部分构成：\n    *   **稳定化掩码**（stabilization mask）\n    *   **参考策略分母**（reference policy denominator）\n    *   **优势估计**（advantage estimate）\n    *   **似然梯度**（likelihood gradient）\n\n### 3. 提出的算法：混合后训练（Hybrid Post-Training, HPT）\n\n*   **算法动机**：受上述理论发现的启发，本文提出了一种名为“混合后训练”（HPT）的新算法。\n*   **设计目标**：\n    *   HPT旨在动态选择不同的训练信号，以实现最佳效果。\n    *   它被设计为能够有效利用演示数据（exploitation）。\n    *   同时，HPT也能实现稳定的探索（exploration）。\n    *   在上述过程中，HPT致力于不牺牲模型已学习到的推理模式。\n\n### 4. 实验验证与成果\n\n*   **广泛实验**：通过大量的实验和消融研究，本文验证了其统一理论框架和HPT算法的有效性。\n*   **卓越性能**：在六个数学推理基准测试和两个分布外（out-of-distribution）套件上，HPT算法持续超越了不同规模和家族模型的强大基线，展现出其优越性。",
      "shortSummary": "本文提出大语言模型后训练中的强化学习（RL）和监督微调（SFT）并非矛盾，而是单一优化过程的实例。作者推导了统一策略梯度估计器，将多种后训练方法统一在一个共同目标函数下。受此启发，提出混合后训练（HPT）算法，旨在动态选择训练信号，有效利用演示数据并实现稳定探索，同时保留推理模式。实验证明，HPT在多个数学推理基准上持续超越现有基线。",
      "translated_title": "迈向大语言模型后训练的统一视角",
      "images": [],
      "contentSource": "完整文章",
      "content": "Two major sources of training data exist for post-training modern language models: online (model-generated rollouts) data, and offline (human or other-model demonstrations) data. These two types of data are typically used by approaches like Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT), respectively. In this paper, we show that these approaches are not in contradiction, but are instances of a single optimization process. We derive a Unified Policy Gradient Estimator, and present the calculations of a wide spectrum of post-training approaches as the gradient of a common objective under different data distribution assumptions and various bias-variance tradeoffs. The gradient estimator is constructed with four interchangeable parts: stabilization mask, reference policy denominator, advantage estimate, and likelihood gradient. Motivated by our theoretical findings, we propose Hybrid Post-Training (HPT), an algorithm that dynamically selects different training signals. HPT is designed to yield both effective exploitation of demonstration and stable exploration without sacrificing learned reasoning patterns. We provide extensive experiments and ablation studies to verify the effectiveness of our unified theoretical framework and HPT. Across six mathematical reasoning benchmarks and two out-of-distribution suites, HPT consistently surpasses strong baselines across models of varying scales and families."
    },
    {
      "title": "通过边际数据传输蒸馏实现三维生成的少步流 (原标题: Few-step Flow for 3D Generation via Marginal-Data Transport Distillation)",
      "link": "https://arxiv.org/abs/2509.04406",
      "pubDate": "Thu, 04 Sep 2025 13:24:31 GMT",
      "isoDate": "2025-09-04T13:24:31.000Z",
      "creator": "Zanwei Zhou, Taoran Yi, Jiemin Fang, Chen Yang, Lingxi Xie, Xinggang Wang, Wei Shen, Qi Tian",
      "summary": "### 引言\n\n*   流式三维生成模型在推理过程中通常需要数十个采样步骤。\n*   尽管少步蒸馏方法，特别是“一致性模型”（Consistency Models, CMs），在加速二维扩散模型方面取得了显著进展，但它们在更复杂的三维生成任务中仍未得到充分探索。\n\n### MDT-dist 框架\n\n*   本研究提出了一种新颖的框架 MDT-dist，用于少步三维流蒸馏。\n*   其核心目标是：蒸馏预训练模型以学习“边际数据传输”（Marginal-Data Transport）。\n*   直接学习此目标需要整合速度场，但这种积分在实现上是难以处理的。\n\n### 优化目标\n\n为了解决积分难题，研究提出了两个可优化的目标，将优化目标从传输层面等效地转换到速度和分布层面：\n\n*   **速度匹配 (Velocity Matching, VM)**：\n    *   学习稳定地匹配学生模型和教师模型之间的速度场。\n    *   然而，VM 不可避免地会提供有偏的梯度估计。\n*   **速度蒸馏 (Velocity Distillation, VD)**：\n    *   通过利用学习到的速度场执行概率密度蒸馏，进一步增强了优化过程。\n\n### 实验结果\n\n*   在先驱三维生成框架 TRELLIS 上进行评估。\n*   方法将每个流变压器的采样步骤从 25 减少到 1 或 2。\n*   在 A800 上实现了 0.68 秒（1 步 x 2）和 0.94 秒（2 步 x 2）的延迟，分别带来了 9.0 倍和 6.5 倍的速度提升。\n*   同时，保持了高视觉和几何保真度。\n*   广泛的实验表明，该方法显著优于现有的一致性模型蒸馏方法，并使 TRELLIS 在少步三维生成中实现了卓越性能。",
      "shortSummary": "本研究提出 MDT-dist 框架，旨在通过边际数据传输蒸馏实现少步三维生成。针对直接学习传输的积分难题，引入了速度匹配（VM）和速度蒸馏（VD）两种优化目标。实验表明，MDT-dist 在 TRELLIS 框架上将采样步骤从 25 减少到 1 或 2，在 A800 上实现了高达 9.0 倍的速度提升，同时保持了高视觉和几何保真度，显著优于现有方法。",
      "translated_title": "通过边际数据传输蒸馏实现三维生成的少步流",
      "images": [],
      "contentSource": "完整文章",
      "content": "Flow-based 3D generation models typically require dozens of sampling steps during inference. Though few-step distillation methods, particularly Consistency Models (CMs), have achieved substantial advancements in accelerating 2D diffusion models, they remain under-explored for more complex 3D generation tasks. In this study, we propose a novel framework, MDT-dist, for few-step 3D flow distillation. Our approach is built upon a primary objective: distilling the pretrained model to learn the Marginal-Data Transport. Directly learning this objective needs to integrate the velocity fields, while this integral is intractable to be implemented. Therefore, we propose two optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD), to equivalently convert the optimization target from the transport level to the velocity and the distribution level respectively. Velocity Matching (VM) learns to stably match the velocity fields between the student and the teacher, but inevitably provides biased gradient estimates. Velocity Distillation (VD) further enhances the optimization process by leveraging the learned velocity fields to perform probability density distillation. When evaluated on the pioneer 3D generation framework TRELLIS, our method reduces sampling steps of each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s (2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high visual and geometric fidelity. Extensive experiments demonstrate that our method significantly outperforms existing CM distillation methods, and enables TRELLIS to achieve superior performance in few-step 3D generation."
    },
    {
      "title": "转换模型：重新思考生成式学习目标 (原标题: Transition Models: Rethinking the Generative Learning Objective)",
      "link": "https://arxiv.org/abs/2509.04394",
      "pubDate": "Thu, 04 Sep 2025 13:05:59 GMT",
      "isoDate": "2025-09-04T13:05:59.000Z",
      "creator": "Zidong Wang, Yiyuan Zhang, Xiaoyu Yue, Xiangyu Yue, Yangguang Li, Wanli Ouyang, Lei Bai",
      "summary": "## 转换模型 (TiM)：重新定义生成式学习\n\n### 引言：生成式建模的挑战\n\n生成式建模领域长期存在一个核心困境：\n\n*   **迭代扩散模型**：能够实现卓越的保真度，但其计算成本非常高昂。\n*   **高效少步替代方案**：虽然效率更高，但其生成质量受到严格的上限限制。\n\n这种生成步数与输出质量之间的矛盾，根源在于现有的训练目标过于局限，它们要么只关注无穷小动态（如PF-ODEs），要么仅限于直接的端点预测。\n\n### 转换模型 (TiM) 的核心创新\n\n为解决上述挑战，研究人员引入了一种**精确的、连续时间动态方程**。该方程能够解析地定义任意有限时间间隔内的状态转换，从而催生了一种全新的生成范式——**转换模型 (TiM)**。\n\nTiM 的关键特性包括：\n\n*   **适应任意步长转换**：TiM 能够灵活适应从单步跳跃到多步精细化的任意步长转换。\n*   **无缝遍历生成轨迹**：它能够无缝地在生成轨迹上进行操作，无论是快速生成还是逐步优化。\n\n### TiM 的卓越性能与效率\n\n尽管 TiM 仅拥有 **8.65 亿参数**，但其性能表现达到了最先进水平：\n\n*   **超越领先模型**：在所有评估的步数下，TiM 均超越了参数量更大的领先模型，例如 SD3.5 (80 亿参数) 和 FLUX.1 (120 亿参数)。\n*   **单调质量提升**：与以往的少步生成器不同，TiM 展现出随着采样预算（即生成步数）的增加，输出质量呈现**单调提升**的特性。\n*   **高分辨率能力**：当采用其原生分辨率策略时，TiM 能够在高达 **4096x4096** 的分辨率下提供卓越的图像保真度。\n\n### 资源\n\n*   相关代码已发布。",
      "shortSummary": "转换模型（TiM）旨在解决生成式建模中扩散模型高保真度但高成本，以及少步模型效率高但质量受限的矛盾。TiM 引入精确的连续时间动态方程，能够适应任意步长转换，实现从单步到精细化的生成。TiM 仅用 8.65 亿参数，便超越了 SD3.5 和 FLUX.1 等大型模型，并在增加采样步数时展现出单调的质量提升，支持高达 4096x4096 的高分辨率生成，达到了最先进的性能。",
      "translated_title": "转换模型：重新思考生成式学习目标",
      "images": [],
      "contentSource": "完整文章",
      "content": "A fundamental dilemma in generative modeling persists: iterative diffusion models achieve outstanding fidelity, but at a significant computational cost, while efficient few-step alternatives are constrained by a hard quality ceiling. This conflict between generation steps and output quality arises from restrictive training objectives that focus exclusively on either infinitesimal dynamics (PF-ODEs) or direct endpoint prediction. We address this challenge by introducing an exact, continuous-time dynamics equation that analytically defines state transitions across any finite time interval. This leads to a novel generative paradigm, Transition Models (TiM), which adapt to arbitrary-step transitions, seamlessly traversing the generative trajectory from single leaps to fine-grained refinement with more steps. Despite having only 865M parameters, TiM achieves state-of-the-art performance, surpassing leading models such as SD3.5 (8B parameters) and FLUX.1 (12B parameters) across all evaluated step counts. Importantly, unlike previous few-step generators, TiM demonstrates monotonic quality improvement as the sampling budget increases. Additionally, when employing our native-resolution strategy, TiM delivers exceptional fidelity at resolutions up to 4096x4096."
    },
    {
      "title": "从编辑器到密集几何估计器 (原标题: From Editor to Dense Geometry Estimator)",
      "link": "https://arxiv.org/abs/2509.04338",
      "pubDate": "Thu, 04 Sep 2025 11:58:50 GMT",
      "isoDate": "2025-09-04T11:58:50.000Z",
      "creator": "JiYuan Wang, Chunyu Lin, Lei Sun, Rongying Liu, Lang Nie, Mingxing Li, Kang Liao, Xiangxiang Chu, Yao Zhao",
      "summary": "## 从编辑器到密集几何估计器：FE2E框架\n\n### 摘要\n本文介绍了一种名为FE2E（From Editor to Dense Geometry Estimator）的新型框架，该框架开创性地将基于Diffusion Transformer (DiT) 架构的先进图像编辑模型应用于密集几何估计任务。研究发现，图像编辑模型相比文本到图像（T2I）生成模型，更适合处理图像到图像的密集预测任务，并能取得更优异的性能。\n\n### 背景与动机\n尽管预训练的文本到图像（T2I）生成模型在密集预测任务中取得了一定成功，但密集预测本质上是一个图像到图像的任务。这促使研究人员思考，图像编辑模型而非T2I生成模型，可能作为微调的基础更为合适。\n\n### 核心发现\n研究人员对编辑模型和生成模型在密集几何估计任务中的微调行为进行了系统分析。结果表明：\n*   **固有结构先验**：编辑模型拥有固有的结构先验。\n*   **稳定收敛**：这些先验使得编辑模型能够通过“精炼”其内在特征，实现更稳定的收敛。\n*   **更高性能**：最终，编辑模型比其生成模型对应物取得了更高的性能。\n\n### FE2E框架介绍\n基于上述发现，FE2E框架被提出，它将一个先进的、基于Diffusion Transformer (DiT) 架构的编辑模型适配到密集几何预测任务中。FE2E的关键创新和技术细节包括：\n\n1.  **损失函数重构**：为了使编辑模型适应确定性任务，FE2E将编辑模型原始的流匹配损失（flow matching loss）重构为“一致速度”（consistent velocity）训练目标。\n2.  **精度冲突解决**：针对编辑模型原生BFloat16格式与几何任务所需高精度之间的冲突，FE2E采用了对数量化（logarithmic quantization）来解决。\n3.  **深度与法线联合估计**：FE2E利用DiT模型的全局注意力机制，实现了深度和法线的无成本联合估计，在一个前向传播中同时完成。这使得它们的监督信号能够相互增强，提升估计精度。\n\n### 实验结果与性能\nFE2E在零样本单目深度和法线估计任务中展现了令人印象深刻的性能提升，并在多个数据集上取得了优异表现：\n*   **无需扩展训练数据**：在不增加训练数据量的情况下，FE2E实现了显著的性能提升。\n*   **ETH3D数据集**：在ETH3D数据集上，性能提升超过35%。\n*   **超越现有SOTA**：FE2E的性能超越了DepthAnything系列模型，后者使用了100倍的数据进行训练。",
      "shortSummary": "本文提出了FE2E框架，将基于Diffusion Transformer (DiT) 的图像编辑模型应用于密集几何估计。研究发现，编辑模型因其固有的结构先验，比文本到图像生成模型更适合此任务，能实现更稳定的收敛和更高的性能。FE2E通过重构损失、解决精度冲突和联合估计深度与法线，在零样本单目深度和法线估计上取得显著进展。它在ETH3D数据集上性能提升超35%，并在不增加训练数据量的情况下超越了使用100倍数据训练的DepthAnything系列。",
      "translated_title": "从编辑器到密集几何估计器",
      "images": [],
      "contentSource": "完整文章",
      "content": "Leveraging visual priors from pre-trained text-to-image (T2I) generative models has shown success in dense prediction. However, dense prediction is inherently an image-to-image task, suggesting that image editing models, rather than T2I generative models, may be a more suitable foundation for fine-tuning.   Motivated by this, we conduct a systematic analysis of the fine-tuning behaviors of both editors and generators for dense geometry estimation. Our findings show that editing models possess inherent structural priors, which enable them to converge more stably by ``refining\" their innate features, and ultimately achieve higher performance than their generative counterparts.   Based on these findings, we introduce FE2E, a framework that pioneeringly adapts an advanced editing model based on Diffusion Transformer (DiT) architecture for dense geometry prediction. Specifically, to tailor the editor for this deterministic task, we reformulate the editor's original flow matching loss into the ``consistent velocity\" training objective. And we use logarithmic quantization to resolve the precision conflict between the editor's native BFloat16 format and the high precision demand of our tasks. Additionally, we leverage the DiT's global attention for a cost-free joint estimation of depth and normals in a single forward pass, enabling their supervisory signals to mutually enhance each other.   Without scaling up the training data, FE2E achieves impressive performance improvements in zero-shot monocular depth and normal estimation across multiple datasets. Notably, it achieves over 35\\% performance gains on the ETH3D dataset and outperforms the DepthAnything series, which is trained on 100times data. The project page can be accessed https://amap-ml.github.io/FE2E/{here}."
    },
    {
      "title": "逆向IFEval：大型语言模型能否摒弃顽固的训练惯例以遵循真实指令？ (原标题: Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?)",
      "link": "https://arxiv.org/abs/2509.04292",
      "pubDate": "Thu, 04 Sep 2025 11:03:02 GMT",
      "isoDate": "2025-09-04T11:03:02.000Z",
      "creator": "Qinyan Zhang, Xinping Lei, Ruijie Miao, Yu Fu, Haojie Fan, Le Chang, Jiafan Hou, Dingling Zhang, Zhongfei Hou, Ziqiang Yang, Changxin Pu, Fei Hu, Jingkai Liu, Mengyun Liu, Yang Liu, Xiang Gao, Jiaheng Liu, Tong Yang, Zaiyuan Wang, Ge Zhang, Wenhao Huang",
      "summary": "# 逆向IFEval：评估大型语言模型对反直觉指令的遵循能力\n\n## 引言\n大型语言模型（LLMs）在各种任务中表现出强大的性能，但它们常常表现出一种“认知惯性”。这种惯性使得LLMs难以遵循那些与在监督微调（SFT）期间学到的标准化模式相冲突的指令。\n\n## 提出问题与解决方案\n为了评估LLMs的这一局限性，研究团队提出了“逆向IFEval”（Inverse IFEval）基准。该基准旨在衡量模型的“反直觉能力”（Counter-intuitive Ability），即模型克服训练诱导偏见并遵守对抗性指令的能力。\n\n## 逆向IFEval的挑战类型\n逆向IFEval引入了八种挑战类型，以全面测试LLMs的适应性，其中包括：\n*   **问题纠正 (Question Correction)**\n*   **故意文本缺陷 (Intentional Textual Flaws)**\n*   **无注释代码 (Code without Comments)**\n*   **反事实回答 (Counterfactual Answering)**\n\n## 数据集构建与评估框架\n*   研究团队通过“人机协作”（human-in-the-loop）流程，构建了一个包含1012个高质量中英文问题的综合数据集。\n*   这些问题精心设计，涵盖了23个不同的领域，确保了基准的广泛性和代表性。\n*   评估过程采用了一个优化的“LLM作为评判者”（LLM-as-a-Judge）框架，以确保评估的客观性和效率。\n\n## 实验结果与发现\n在现有领先的LLMs上进行的实验充分证明了所提出的逆向IFEval基准的必要性。研究结果强调，未来的模型对齐（alignment）工作不应仅仅追求语言的流畅性和事实的正确性，更应着重考虑模型在非常规和非标准情境下的适应性。\n\n## 研究展望与意义\n研究者希望逆向IFEval能够发挥双重作用：\n1.  **诊断工具：** 帮助识别LLMs在遵循反直觉指令方面的弱点。\n2.  **方法开发基础：** 为开发旨在缓解认知惯性、减少对狭隘模式过拟合的方法提供基础。\n\n最终目标是显著增强LLMs在多样化和不可预测的真实世界场景中遵循指令的可靠性。",
      "shortSummary": "大型语言模型（LLMs）常因“认知惯性”难以遵循与训练模式冲突的指令。为解决此问题，研究者提出了“逆向IFEval”基准，旨在衡量LLMs克服训练偏见、遵循反直觉指令的能力。该基准包含八种挑战类型，并构建了一个涵盖23个领域、1012个中英文问题的数据集。实验表明，现有LLMs缺乏在非常规情境下的适应性。逆向IFEval旨在诊断并改进LLMs的指令遵循可靠性，减少过拟合，以应对真实世界的多样化挑战。",
      "translated_title": "逆向IFEval：大型语言模型能否摒弃顽固的训练惯例以遵循真实指令？",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios."
    },
    {
      "title": "关于基于基准测试的LLM评估的鲁棒性和可靠性 (原标题: On Robustness and Reliability of Benchmark-Based Evaluation of LLMs)",
      "link": "https://arxiv.org/abs/2509.04013",
      "pubDate": "Thu, 04 Sep 2025 04:43:27 GMT",
      "isoDate": "2025-09-04T04:43:27.000Z",
      "creator": "Riccardo Lunardi, Vincenzo Della Mea, Stefano Mizzaro, Kevin Roitero",
      "summary": "## 关于基于基准测试的LLM评估的鲁棒性和可靠性\n\n### 研究背景与问题\n\n*   **传统评估方式**：大型语言模型（LLMs）的有效性通常通过MMLU、ARC-C或HellaSwag等标准化基准测试进行评估。这些测试的问题以固定的、原始的措辞呈现。\n*   **实际应用挑战**：然而，现实世界的应用涉及广泛的语言变异性，要求LLMs在面对同一问题或查询的不同措辞（释义）时，仍能保持其有效性。\n\n### 研究目的与方法\n\n*   **研究目的**：本研究旨在系统性地评估LLMs对释义后基准测试问题的鲁棒性，并探讨基于基准测试的评估是否能可靠地衡量模型的实际能力。\n*   **研究方法**：\n    *   系统地生成了六个不同常见基准测试中所有问题的各种释义版本。\n    *   测量了34个不同规模和有效性的最先进LLMs在这些释义输入下的有效性变化。\n\n### 主要发现\n\n*   **排名稳定性与性能下降**：研究发现，尽管LLM在释义输入下的排名保持相对稳定，但其绝对有效性分数却显著下降。\n*   **语言变异性挑战**：这表明LLMs在处理语言变异性方面存在困难，引发了对其泛化能力和现有评估方法学的担忧。\n*   **基准评估的可靠性问题**：观察到的性能下降挑战了基于基准测试评估的可靠性，指出高基准分数可能无法完全捕捉模型对真实世界输入变化的鲁棒性。\n\n### 研究启示\n\n*   **评估方法学改进**：本研究的发现对LLM评估方法学具有重要意义，强调需要开发“鲁棒性感知”的基准测试。\n*   **反映实际部署场景**：这些新的基准测试应能更好地反映实际部署场景中语言输入的复杂性和多样性，从而提供更全面、更可靠的模型能力评估。",
      "shortSummary": "本研究系统评估了大型语言模型（LLMs）对释义后基准测试问题的鲁棒性。研究发现，尽管LLM排名在释义输入下保持稳定，但其绝对有效性分数显著下降。这表明LLMs难以应对语言变异性，引发对其泛化能力和现有基准评估可靠性的担忧。研究强调，高基准分数可能无法完全反映模型在真实世界中的鲁棒性，呼吁开发更具鲁棒性意识的评估基准，以更好地反映实际部署场景。",
      "translated_title": "关于基于基准测试的LLM评估的鲁棒性和可靠性",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) effectiveness is usually evaluated by means of benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in their original wording, thus in a fixed, standardized format. However, real-world applications involve linguistic variability, requiring models to maintain their effectiveness across diverse rewordings of the same question or query. In this study, we systematically assess the robustness of LLMs to paraphrased benchmark questions and investigate whether benchmark-based evaluations provide a reliable measure of model capabilities. We systematically generate various paraphrases of all the questions across six different common benchmarks, and measure the resulting variations in effectiveness of 34 state-of-the-art LLMs, of different size and effectiveness. Our findings reveal that while LLM rankings remain relatively stable across paraphrased inputs, absolute effectiveness scores change, and decline significantly. This suggests that LLMs struggle with linguistic variability, raising concerns about their generalization abilities and evaluation methodologies. Furthermore, the observed performance drop challenges the reliability of benchmark-based evaluations, indicating that high benchmark scores may not fully capture a model's robustness to real-world input variations. We discuss the implications of these findings for LLM evaluation methodologies, emphasizing the need for robustness-aware benchmarks that better reflect practical deployment scenarios."
    },
    {
      "title": "NER Retriever：基于类型感知嵌入的零样本命名实体检索 (原标题: NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings)",
      "link": "https://arxiv.org/abs/2509.04011",
      "pubDate": "Thu, 04 Sep 2025 04:42:23 GMT",
      "isoDate": "2025-09-04T04:42:23.000Z",
      "creator": "Or Shachar, Uri Katz, Yoav Goldberg, Oren Glickman",
      "summary": "本文介绍了 NER Retriever，一个用于 Ad-hoc 命名实体检索的零样本检索框架。Ad-hoc 命名实体检索是命名实体识别 (NER) 的一种变体，其中感兴趣的类型不是预先提供的，而是使用用户定义的类型描述来检索提及该类型实体的文档。\n\n*   **核心思想：** NER Retriever 没有依赖固定的模式或微调的模型，而是利用大型语言模型 (LLM) 的内部表示，将实体提及和用户提供的开放式类型描述嵌入到共享的语义空间中。\n*   **关键发现：** 研究表明，内部表示，特别是来自中间层 Transformer 块的值向量，比常用的顶层嵌入更有效地编码细粒度的类型信息。\n*   **方法：** 为了改进这些表示，研究人员训练了一个轻量级的对比投影网络，该网络对齐类型兼容的实体，同时分离不相关的类型。生成的实体嵌入是紧凑的、类型感知的，并且非常适合最近邻搜索。\n*   **实验结果：** 在三个基准测试中进行评估，NER Retriever 显著优于词汇和密集句子级别的检索基线。\n*   **意义：** 该研究结果为 LLM 中的表示选择提供了经验支持，并展示了可扩展的、无模式实体检索的实用解决方案。\n*   **代码：** NER Retriever 代码库已公开。",
      "shortSummary": "本文提出了 NER Retriever，一个用于 Ad-hoc 命名实体检索的零样本框架。该框架利用大型语言模型的内部表示，将实体提及和用户定义的类型描述嵌入到共享的语义空间中。通过训练对比投影网络来对齐类型兼容的实体，实现了紧凑且类型感知的实体嵌入，从而显著优于传统检索方法。该方法无需预定义模式，为可扩展的实体检索提供了实用解决方案。NER Retriever 代码库已公开。",
      "translated_title": "NER Retriever：基于类型感知嵌入的零样本命名实体检索",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present NER Retriever, a zero-shot retrieval framework for ad-hoc Named Entity Retrieval, a variant of Named Entity Recognition (NER), where the types of interest are not provided in advance, and a user-defined type description is used to retrieve documents mentioning entities of that type. Instead of relying on fixed schemas or fine-tuned models, our method builds on internal representations of large language models (LLMs) to embed both entity mentions and user-provided open-ended type descriptions into a shared semantic space. We show that internal representations, specifically the value vectors from mid-layer transformer blocks, encode fine-grained type information more effectively than commonly used top-layer embeddings. To refine these representations, we train a lightweight contrastive projection network that aligns type-compatible entities while separating unrelated types. The resulting entity embeddings are compact, type-aware, and well-suited for nearest-neighbor search. Evaluated on three benchmarks, NER Retriever significantly outperforms both lexical and dense sentence-level retrieval baselines. Our findings provide empirical support for representation selection within LLMs and demonstrate a practical solution for scalable, schema-free entity retrieval. The NER Retriever Codebase is publicly available at https://github.com/ShacharOr100/ner_retriever"
    },
    {
      "title": "虚假的安全感：为什么基于探测的恶意输入检测未能泛化 (原标题: False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize)",
      "link": "https://arxiv.org/abs/2509.03888",
      "pubDate": "Thu, 04 Sep 2025 01:15:55 GMT",
      "isoDate": "2025-09-04T01:15:55.000Z",
      "creator": "Cheng Wang, Zeming Wei, Qin Liu, Muhao Chen",
      "summary": "# 虚假的安全感：为什么基于探测的恶意输入检测未能泛化\n\n## 引言与背景\n大型语言模型（LLMs）尽管能力强大，但其服从有害指令的能力引发了严重的安全担忧。为了解决这一问题，近期研究利用基于探测（probing-based）的方法来研究LLMs内部表示中恶意输入和良性输入的可分离性，并提议将这些探测方法用于安全检测。\n\n## 研究问题与假设\n本研究系统地重新审视了这一范式。鉴于现有方法在分布外（out-of-distribution）性能不佳，研究者提出假设：探测器学习的是表层模式，而非语义上的有害性。\n\n## 研究方法与发现\n通过一系列受控实验，本研究证实了上述假设，并识别出探测器学习到的具体模式：\n*   **指令模式（instructional patterns）**\n*   **触发词（trigger words）**\n\n研究遵循系统化的方法，逐步深入：\n1.  **性能比较**：首先，研究展示了简单的n-gram方法能够达到与现有探测方法相当的性能，这暗示了探测器可能依赖于浅层特征。\n2.  **受控实验**：接着，研究使用了经过语义清洗的数据集进行受控实验，以排除表层模式的影响，从而更清晰地揭示探测器学习的本质。\n3.  **模式依赖性分析**：最后，研究对探测器学习的模式依赖性进行了详细分析，进一步确认了其对指令模式和触发词的偏好。\n\n## 结论与启示\n这些结果揭示了当前基于探测的方法所带来的“虚假的安全感”。它们未能真正捕捉到输入的语义有害性，而是依赖于容易被规避的表层特征。\n\n## 未来展望\n本研究强调了重新设计模型和评估协议的必要性。文章提供了进一步的讨论，旨在为该方向上负责任的未来研究提供建议。\n\n## 项目开源\n该项目已在 [this https URL](https://this.https.url/) 开源。",
      "shortSummary": "大型语言模型（LLMs）服从有害指令引发安全担忧。现有基于探测的恶意输入检测方法泛化能力差，本研究发现其学习的是表层模式（如指令模式和触发词），而非语义上的有害性。这导致了虚假的安全感，表明当前方法不足以确保LLM安全。研究强调需重新设计模型和评估协议，以实现更负责任的安全研究。",
      "translated_title": "虚假的安全感：为什么基于探测的恶意输入检测未能泛化",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) can comply with harmful instructions, raising serious safety concerns despite their impressive capabilities. Recent work has leveraged probing-based approaches to study the separability of malicious and benign inputs in LLMs' internal representations, and researchers have proposed using such probing methods for safety detection. We systematically re-examine this paradigm. Motivated by poor out-of-distribution performance, we hypothesize that probes learn superficial patterns rather than semantic harmfulness. Through controlled experiments, we confirm this hypothesis and identify the specific patterns learned: instructional patterns and trigger words. Our investigation follows a systematic approach, progressing from demonstrating comparable performance of simple n-gram methods, to controlled experiments with semantically cleaned datasets, to detailed analysis of pattern dependencies. These results reveal a false sense of security around current probing-based approaches and highlight the need to redesign both models and evaluation protocols, for which we provide further discussions in the hope of suggesting responsible further research in this direction. We have open-sourced the project at https://github.com/WangCheng0116/Why-Probe-Fails."
    },
    {
      "title": "胡言乱语学：挑战大型语言模型深度解读无意义文本的能力 (原标题: Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth)",
      "link": "https://arxiv.org/abs/2509.03867",
      "pubDate": "Wed, 03 Sep 2025 23:58:55 GMT",
      "isoDate": "2025-09-03T23:58:55.000Z",
      "creator": "Yang Wang, Chenghao Xiao, Chia-Yi Hsiao, Zi Yan Chang, Chi-Li Chen, Tyler Loakman, Chenghua Lin",
      "summary": "# 胡言乱语学：挑战大型语言模型深度解读无意义文本的能力\n\n## 1. 概念引入：胡言乱语学 (Drivelology)\n*   **定义**: 胡言乱语学 (Drivelology) 是一种独特的语言现象，被描述为“有深度的无意义文本”。\n*   **特征**: 这类文本在语法上连贯，但在语用上却自相矛盾、情感饱满或具有颠覆性的修辞功能。\n*   **内在含义**: 尽管表面看似无意义，但它们编码了需要上下文推断、道德推理或情感解释的隐含意义。\n\n## 2. 大型语言模型 (LLMs) 的挑战\n*   **现有问题**: 尽管LLMs在许多自然语言处理 (NLP) 任务中表现出色，但它们始终未能理解胡言乱语学文本的深层语义。\n\n## 3. 研究方法与数据集构建\n*   **数据集**: 研究团队构建了一个小而多样化的基准数据集，包含超过1,200个精心策划的示例。\n*   **语言多样性**: 示例涵盖英语、普通话、西班牙语、法语、日语和韩语。\n*   **标注挑战**: 标注过程极具挑战性，每个示例都需要专家进行仔细审查，以验证其是否真正反映了胡言乱语学的特征。由于其微妙和主观的性质，标注涉及多轮讨论和裁决以解决分歧。\n*   **评估任务**: 研究评估了LLMs在分类、生成和推理任务上的表现。\n\n## 4. 主要发现与局限性\n*   **LLMs的局限性**:\n    *   模型经常将胡言乱语学与浅层无意义文本混淆。\n    *   生成不连贯的解释。\n    *   完全未能捕捉到隐含的修辞功能。\n*   **深层含义**: 这些发现揭示了LLMs在语用理解方面存在更深层次的表征鸿沟，并挑战了“统计流畅性意味着认知理解”的假设。\n\n## 5. 贡献与未来展望\n*   **资源发布**: 研究团队发布了其数据集和代码，以促进在超越表面连贯性的语言深度建模方面的进一步研究。\n*   **会议接受**: 该研究已被EMNLP 2025主会议接受进行口头报告。",
      "shortSummary": "本研究引入“胡言乱语学”（Drivelology），一种语法连贯但语用矛盾、情感丰富或修辞颠覆的“有深度的无意义文本”。研究发现，大型语言模型（LLMs）难以理解此类文本的深层语义。通过构建一个包含1200多个多语言示例的基准数据集，并评估LLMs在分类、生成和推理任务上的表现，结果显示LLMs常将其与浅层无意义文本混淆，并错过隐含的修辞功能。这揭示了LLMs在语用理解上的深层缺陷，挑战了统计流畅性等同于认知理解的假设。数据集和代码已发布以促进后续研究。",
      "translated_title": "胡言乱语学：挑战大型语言模型深度解读无意义文本的能力",
      "images": [],
      "contentSource": "完整文章",
      "content": "We introduce Drivelology, a unique linguistic phenomenon characterised as \"nonsense with depth\", utterances that are syntactically coherent yet pragmatically paradoxical, emotionally loaded, or rhetorically subversive. While such expressions may resemble surface-level nonsense, they encode implicit meaning requiring contextual inference, moral reasoning, or emotional interpretation. We find that current large language models (LLMs), despite excelling at many natural language processing (NLP) tasks, consistently fail to grasp the layered semantics of Drivelological text. To investigate this, we construct a small but diverse benchmark dataset of over 1,200 meticulously curated examples, with select instances in English, Mandarin, Spanish, French, Japanese, and Korean. Annotation was especially challenging: each of the examples required careful expert review to verify that it truly reflected Drivelological characteristics. The process involved multiple rounds of discussion and adjudication to address disagreements, highlighting the subtle and subjective nature of the Drivelology. We evaluate a range of LLMs on classification, generation, and reasoning tasks. Our results reveal clear limitations of LLMs: models often confuse Drivelology with shallow nonsense, produce incoherent justifications, or miss the implied rhetorical function altogether. These findings highlight a deeper representational gap in LLMs' pragmatic understanding and challenge the assumption that statistical fluency implies cognitive comprehension. We release our dataset and code to facilitate further research in modelling linguistic depth beyond surface-level coherence."
    },
    {
      "title": "MedVista3D：用于减少3D CT疾病检测、理解和报告中诊断错误的视觉-语言建模 (原标题: MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting)",
      "link": "https://arxiv.org/abs/2509.03800",
      "pubDate": "Wed, 03 Sep 2025 21:28:44 GMT",
      "isoDate": "2025-09-03T21:28:44.000Z",
      "creator": "Yuheng Li, Yenho Chen, Yuxiang Lai, Jike Zhong, Vanessa Wildman, Xiaofeng Yang",
      "summary": "## MedVista3D：减少3D CT诊断错误的视觉-语言建模\n\n### 引言：放射诊断错误及其挑战\n\n放射诊断错误（包括漏诊、注意力盲区和沟通失败）在临床实践中普遍存在。这些问题通常源于以下几个方面：\n\n*   **局部异常的遗漏：** 未能识别出图像中的细微病变。\n*   **全局上下文的限制：** 缺乏对整个扫描体积的整体理解。\n*   **报告语言的变异性：** 放射报告的语言不一致和缺乏标准化。\n\n在3D成像（如CT扫描）中，由于临床医生需要检查数百个切片，这些挑战被进一步放大。现有的3D视觉-语言模型（VLM）未能同时满足精确的局部检测、全局体积级推理和语义一致的自然语言报告这三项需求。它们往往缺乏对空间推理的局部-全局理解能力，并且难以处理未经整理的放射报告中存在的变异性和噪声。\n\n### MedVista3D：解决方案\n\n为了解决上述挑战，研究人员提出了MedVista3D，这是一个多尺度语义增强的视觉-语言预训练框架，专为3D CT分析设计。MedVista3D的核心创新点在于：\n\n*   **联合疾病检测与整体解读：** 为了实现疾病的联合检测和全面的整体解读，MedVista3D在全体积上下文中执行局部和全局的图像-文本对齐，从而实现细粒度的表示学习。\n*   **解决报告变异性：** 为了应对放射报告的变异性问题，MedVista3D采用了语言模型重写技术，并引入了一个“放射语义匹配库”（Radiology Semantic Matching Bank），以实现语义感知的对齐。\n\n### 性能与成果\n\nMedVista3D在多项任务中取得了最先进的性能：\n\n*   **零样本疾病分类：** 在不依赖特定训练数据的情况下，准确识别疾病。\n*   **报告检索：** 能够高效准确地检索相关的放射报告。\n*   **医学视觉问答：** 能够理解医学图像并回答相关问题。\n\n此外，MedVista3D还表现出良好的迁移能力，可以有效地应用于器官分割和预后预测等其他医学任务。\n\n### 后续计划\n\n该项目的代码和相关数据集将公开发布，以促进社区的进一步研究和应用。",
      "shortSummary": "MedVista3D是一个多尺度视觉-语言预训练框架，旨在减少3D CT疾病检测中的诊断错误。针对放射诊断中局部异常遗漏、全局上下文不足及报告语言变异性等挑战，MedVista3D通过执行局部与全局图像-文本对齐，并引入放射语义匹配库来增强细粒度理解和语义一致性。该模型在零样本疾病分类、报告检索和医学视觉问答等任务上取得了最先进的性能，并能有效迁移至器官分割和预后预测。",
      "translated_title": "MedVista3D：用于减少3D CT疾病检测、理解和报告中诊断错误的视觉-语言建模",
      "images": [],
      "contentSource": "完整文章",
      "content": "Radiologic diagnostic errors-under-reading errors, inattentional blindness, and communication failures-remain prevalent in clinical practice. These issues often stem from missed localized abnormalities, limited global context, and variability in report language. These challenges are amplified in 3D imaging, where clinicians must examine hundreds of slices per scan. Addressing them requires systems with precise localized detection, global volume-level reasoning, and semantically consistent natural language reporting. However, existing 3D vision-language models are unable to meet all three needs jointly, lacking local-global understanding for spatial reasoning and struggling with the variability and noise of uncurated radiology reports. We present MedVista3D, a multi-scale semantic-enriched vision-language pretraining framework for 3D CT analysis. To enable joint disease detection and holistic interpretation, MedVista3D performs local and global image-text alignment for fine-grained representation learning within full-volume context. To address report variability, we apply language model rewrites and introduce a Radiology Semantic Matching Bank for semantics-aware alignment. MedVista3D achieves state-of-the-art performance on zero-shot disease classification, report retrieval, and medical visual question answering, while transferring well to organ segmentation and prognosis prediction. Code and datasets will be released."
    },
    {
      "title": "LuxDiT：使用视频扩散变换器进行光照估计 (原标题: LuxDiT: Lighting Estimation with Video Diffusion Transformer)",
      "link": "https://arxiv.org/abs/2509.03680",
      "pubDate": "Wed, 03 Sep 2025 15:59:20 GMT",
      "isoDate": "2025-09-03T15:59:20.000Z",
      "creator": "Ruofan Liang, Kai He, Zan Gojcic, Igor Gilitschenski, Sanja Fidler, Nandita Vijaykumar, Zian Wang",
      "summary": "## LuxDiT：基于视频扩散变换器的光照估计\n\n### 挑战与背景\n\n从单一图像或视频中估计场景光照是计算机视觉和图形学领域的一个长期挑战。现有基于学习的方法面临以下主要限制：\n\n*   **数据稀缺性**：真实的高动态范围（HDR）环境图难以获取，捕获成本高昂，且多样性不足。\n*   **间接线索**：光照估计严重依赖间接视觉线索。\n*   **全局上下文**：需要推断全局（非局部）上下文信息。\n*   **HDR输出**：需要恢复高动态范围的输出。\n\n尽管最新的生成模型为图像合成提供了强大的先验知识，但由于上述挑战，光照估计仍然是一个难题。\n\n### LuxDiT 方法介绍\n\n本文提出了一种名为 **LuxDiT** 的新型数据驱动方法，旨在解决光照估计的难题。LuxDiT 的核心是一个经过微调的视频扩散变换器（video diffusion transformer），其主要功能是根据视觉输入生成 HDR 环境图。\n\n### 训练与泛化能力\n\n*   **训练数据**：LuxDiT 模型在一个包含多样化光照条件的大型合成数据集上进行训练。\n*   **学习机制**：通过训练，模型能够学习如何从间接视觉线索中推断出场景的光照信息。\n*   **泛化能力**：该模型表现出色的泛化能力，能够有效地应用于真实世界场景的光照估计。\n\n### 语义对齐与改进\n\n为了进一步提升输入视觉信息与预测环境图之间的语义对齐，研究人员引入了一种**低秩适应（low-rank adaptation）微调策略**。该策略利用一个收集到的 HDR 全景图数据集进行微调，从而优化了模型对光照细节的理解和生成。\n\n### 性能与成果\n\nLuxDiT 方法在光照估计方面取得了显著成果：\n\n*   **准确性**：生成的光照预测结果准确度高。\n*   **细节表现**：能够产生逼真的角度高频细节。\n*   **超越SOTA**：在定量和定性评估中，LuxDiT 的性能均优于现有最先进（state-of-the-art）的技术。",
      "shortSummary": "LuxDiT是一种新型数据驱动方法，利用微调的视频扩散变换器从视觉输入中估计场景光照并生成HDR环境图。该模型在一个大型合成数据集上训练，并通过低秩适应微调策略增强语义对齐，使其能从间接视觉线索推断光照并泛化到真实场景。LuxDiT在光照预测的准确性和细节方面表现出色，超越了现有最先进技术，解决了HDR环境图稀缺和光照估计复杂性的挑战。",
      "translated_title": "LuxDiT：使用视频扩散变换器进行光照估计",
      "images": [],
      "contentSource": "完整文章",
      "content": "Estimating scene lighting from a single image or video remains a longstanding challenge in computer vision and graphics. Learning-based approaches are constrained by the scarcity of ground-truth HDR environment maps, which are expensive to capture and limited in diversity. While recent generative models offer strong priors for image synthesis, lighting estimation remains difficult due to its reliance on indirect visual cues, the need to infer global (non-local) context, and the recovery of high-dynamic-range outputs. We propose LuxDiT, a novel data-driven approach that fine-tunes a video diffusion transformer to generate HDR environment maps conditioned on visual input. Trained on a large synthetic dataset with diverse lighting conditions, our model learns to infer illumination from indirect visual cues and generalizes effectively to real-world scenes. To improve semantic alignment between the input and the predicted environment map, we introduce a low-rank adaptation finetuning strategy using a collected dataset of HDR panoramas. Our method produces accurate lighting predictions with realistic angular high-frequency details, outperforming existing state-of-the-art techniques in both quantitative and qualitative evaluations."
    },
    {
      "title": "LMEnt：一个用于分析语言模型中知识的套件，涵盖从预训练数据到表示形式 (原标题: LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations)",
      "link": "https://arxiv.org/abs/2509.03405",
      "pubDate": "Wed, 03 Sep 2025 11:31:18 GMT",
      "isoDate": "2025-09-03T11:31:18.000Z",
      "creator": "Daniela Gottesman, Alon Gilae-Dotan, Ido Cohen, Yoav Gur-Arieh, Marius Mosbach, Ori Yoran, Mor Geva",
      "summary": "## LMEnt：分析语言模型中知识的综合套件\n\n### 引言\n\n语言模型（LMs）在现实世界应用中日益依赖世界知识，但其将数据转化为关于世界知识和信念表示的内部过程仍知之甚少。深入了解这些过程对于开发具有更一致、鲁棒和完整知识表示的语言模型至关重要。\n\n### LMEnt 介绍\n\n为促进对这些问题的研究，本文提出了 **LMEnt**，一个用于分析语言模型在预训练期间知识获取的综合套件。LMEnt 引入了以下核心组成部分：\n\n1.  **知识丰富的预训练语料库：**\n    *   基于维基百科构建。\n    *   完全标注了实体提及。\n2.  **基于实体的预训练数据检索方法：**\n    *   该方法在性能上显著优于现有方法，提升高达 80.4%。\n3.  **预训练模型集合：**\n    *   包含 12 个预训练模型，参数量高达 10 亿（1B）。\n    *   提供 4000 个中间检查点。\n    *   在知识基准测试上的表现与流行的开源模型相当。\n\n### 资源用途\n\n这些资源共同提供了一个受控环境，用于：\n\n*   分析预训练中实体提及与下游性能之间的联系。\n*   研究预训练数据中因果干预的影响。\n\n### LMEnt 的实用性展示\n\n通过研究跨检查点的知识获取过程，LMEnt 展示了其实用性。研究发现：\n\n*   事实频率是知识获取的关键因素。\n*   但事实频率并不能完全解释学习趋势。\n\n### 发布目的\n\nLMEnt 已发布，旨在支持对语言模型中知识的深入研究，包括但不限于：\n\n*   知识表示\n*   可塑性\n*   编辑\n*   归因\n*   学习动态",
      "shortSummary": "LMEnt是一个用于分析语言模型预训练期间知识获取的综合套件。它包含一个基于维基百科、标注了实体的知识丰富预训练语料库、一个性能优越的实体检索方法，以及12个带有中间检查点的预训练模型。这些资源提供了一个受控环境，用于研究预训练数据与下游性能之间的关系，并分析知识获取动态。LMEnt的发布旨在支持对语言模型知识表示、可塑性、编辑和学习动态等方面的研究。",
      "translated_title": "LMEnt：一个用于分析语言模型中知识的套件，涵盖从预训练数据到表示形式",
      "images": [],
      "contentSource": "完整文章",
      "content": "Language models (LMs) increasingly drive real-world applications that require world knowledge. However, the internal processes through which models turn data into representations of knowledge and beliefs about the world, are poorly understood. Insights into these processes could pave the way for developing LMs with knowledge representations that are more consistent, robust, and complete. To facilitate studying these questions, we present LMEnt, a suite for analyzing knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a knowledge-rich pretraining corpus, fully annotated with entity mentions, based on Wikipedia, (2) an entity-based retrieval method over pretraining data that outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained models with up to 1B parameters and 4K intermediate checkpoints, with comparable performance to popular open-sourced models on knowledge benchmarks. Together, these resources provide a controlled environment for analyzing connections between entity mentions in pretraining and downstream performance, and the effects of causal interventions in pretraining data. We show the utility of LMEnt by studying knowledge acquisition across checkpoints, finding that fact frequency is key, but does not fully explain learning trends. We release LMEnt to support studies of knowledge in LMs, including knowledge representations, plasticity, editing, attribution, and learning dynamics."
    },
    {
      "title": "Loong：通过验证器大规模合成长链式思考 (原标题: Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers)",
      "link": "https://arxiv.org/abs/2509.03059",
      "pubDate": "Wed, 03 Sep 2025 02:42:40 GMT",
      "isoDate": "2025-09-03T02:42:40.000Z",
      "creator": "Xingyue Huang, Rishabh, Gregor Franke, Ziyi Yang, Jiamu Bai, Weijie Bai, Jinhe Bi, Zifeng Ding, Yiqun Duan, Chengyu Fan, Wendong Fan, Xin Gao, Ruohao Guo, Yuan He, Zhuangzhuang He, Xianglong Hu, Neil Johnson, Bowen Li, Fangru Lin, Siyu Lin, Tong Liu, Yunpu Ma, Hao Shen, Hao Sun, Beibei Wang, Fangyijie Wang, Hao Wang, Haoran Wang, Yang Wang, Yifeng Wang, Zhaowei Wang, Ziyang Wang, Yifan Wu, Zikai Xiao, Chengxing Xie, Fan Yang, Junxiao Yang, Qianshuo Ye, Ziyu Ye, Guangtao Zeng, Yuwen Ebony Zhang, Zeyu Zhang, Zihao Zhu, Bernard Ghanem, Philip Torr, Guohao Li",
      "summary": "# Loong项目：通过验证器大规模合成长链式思考\n\n## 引言\n\n大型语言模型（LLMs）在数学和编程等领域，通过可验证奖励强化学习（RLVR）显著提升了推理能力，因为这些领域可以自动评估其正确性。然而，将这种成功扩展到其他推理密集型领域面临两大挑战：\n\n*   高质量、可验证数据集的稀缺。\n*   人工监督成本高昂。\n\n## Loong项目概述\n\n为解决上述挑战，本文介绍了 **Loong项目**：一个开源框架，旨在实现跨多样化推理密集型领域的可扩展合成数据生成和验证。该框架的核心目标是克服现有数据集限制和高昂的人工成本，从而促进LLM在更广泛推理任务中的发展。\n\n## 核心组件\n\nLoong项目由两个关键组件构成：\n\n### 1. LoongBench\n\n*   **精选种子数据集**：包含8,729个人工验证的示例。\n*   **领域覆盖**：涵盖12个不同的推理密集型领域，例如高等数学、化学和逻辑。\n*   **数据结构**：每个示例都配有可执行代码和丰富的元数据，确保了其可验证性。\n\n### 2. LoongEnv\n\n*   **模块化合成数据生成环境**：支持多种提示策略。\n*   **数据产出**：能够生成新的问题-答案-代码三元组，从而大规模扩展数据集。\n\n## 工作机制：智能体-环境循环\n\nLoongBench和LoongEnv协同工作，形成一个智能体-环境循环，该循环支持强化学习过程：\n\n*   **LLM智能体**：基于LLM的智能体负责生成思维链（CoT）解决方案。\n*   **奖励机制**：当生成的CoT解决方案与代码执行的答案一致时，智能体将获得奖励。这种机制确保了模型学习生成可验证的推理步骤。\n\n## 实证评估\n\n研究人员对Loong项目进行了全面的实证评估：\n\n*   **LoongBench基准测试**：在广泛的开源和专有LLM上对LoongBench进行了基准测试，旨在评估其领域覆盖范围并揭示现有LLM的性能瓶颈。\n*   **LoongEnv合成数据分析**：对LoongEnv生成的合成数据进行了深入分析，重点考察了数据的正确性、难度和多样性，以确保生成数据的质量和实用性。\n\n## 资源可用性\n\nLoong项目的代码和文档已开源，可在指定URL获取，鼓励社区参与和进一步研究。",
      "shortSummary": "Loong项目是一个开源框架，旨在通过可扩展的合成数据生成和验证，解决大型语言模型（LLMs）在推理密集型领域面临的高质量可验证数据集稀缺问题。它包含LoongBench（一个包含8,729个人工验证示例的种子数据集，涵盖12个领域）和LoongEnv（一个模块化的合成数据生成环境）。这两个组件形成一个智能体-环境循环，使LLM能够通过生成与代码执行答案一致的思维链解决方案来学习和改进。该项目对LoongBench进行了基准测试，并分析了LoongEnv生成的合成数据。",
      "translated_title": "Loong：通过验证器大规模合成长链式思考",
      "images": [
        {
          "url": "https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png",
          "alt": "BibSonomy logo",
          "title": "",
          "position": 1
        },
        {
          "url": "https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png",
          "alt": "Reddit logo",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "完整文章",
      "content": "Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at https://github.com/camel-ai/loong."
    }
  ],
  "lastUpdated": "2025-09-08T09:33:42.007Z"
}
{
  "sourceUrl": "https://rsshub.rssforever.com/huggingface/daily-papers",
  "title": "Huggingface Daily Papers",
  "description": "Huggingface Daily Papers - Powered by RSSHub",
  "link": "https://huggingface.co/papers",
  "items": [
    {
      "title": "LLM重排器的效率-效果重排FLOPs (原标题: Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers)",
      "link": "https://arxiv.org/abs/2507.06223",
      "pubDate": "Tue, 08 Jul 2025 13:56:28 GMT",
      "isoDate": "2025-07-08T13:56:28.000Z",
      "creator": "Zhiyuan Peng, Ting-ruen Wei, Tingyu Song, Yilun Zhao, Yi Fang",
      "summary": "# LLM重排器的效率-效果重排FLOPs\n\n## 摘要\n\n本文关注大型语言模型（LLMs）在信息检索重排任务中的应用。尽管LLMs在此类任务中表现出色，但其高昂的计算需求严重阻碍了实际部署。现有评估LLM重排器效率的指标（如延迟、前向传播次数、输入/输出令牌数）存在显著局限性。这些指标不仅依赖于特定的硬件和运行时选择（例如是否并行、批处理大小等），而且往往未能充分考虑模型本身的规模，导致难以准确解释和评估效率与效果之间的权衡。\n\n## 核心贡献与方法\n\n为了解决上述问题，本文提出了 **E²R-FLOPs**（效率-效果重排FLOPs）这一新的指标体系，专门用于评估基于LLM的重排器。该体系包含以下关键组成部分：\n\n*   **新度量标准：**\n    *   **每拍FLOPs的排序指标（RPP - Ranking metrics per PetaFLOP）：** 用于衡量每次计算所获得的相关性，即计算效率与排序效果的结合。\n    *   **每拍FLOPs的查询数（QPP - Queries per PetaFLOP）：** 用于衡量与硬件无关的吞吐量，提供了一个更普适的性能指标。\n*   **可解释的FLOPs估算器：** 伴随这些新指标，本文还构建了一个可解释的FLOPs估算器。该估算器能够在不运行任何实际实验的情况下，预估出基于LLM的重排器的FLOPs，从而大大简化了效率评估过程。\n\n## 实验与目标\n\n基于这些提出的新指标，研究人员对各种不同架构的LLM重排器进行了全面的实验评估。这些实验旨在深入研究LLM重排器在效率与效果之间的权衡关系，并希望通过这项工作，将这一关键且紧迫的问题引起更广泛的研究社区的关注。",
      "shortSummary": "本文提出E²R-FLOPs，旨在解决基于LLM的重排器计算成本高昂且现有效率评估指标不足的问题。通过引入每拍FLOPs的排序指标（RPP）和每拍FLOPs的查询数（QPP），以及一个可解释的FLOPs估算器，该研究旨在提供硬件无关的效率衡量标准。这有助于更准确地评估LLM重排器的效率-效果权衡，并引起研究界对该问题的关注。",
      "translated_title": "LLM重排器的效率-效果重排FLOPs",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have recently been applied to reranking tasks in information retrieval, achieving strong performance. However, their high computational demands often hinder practical deployment. Existing studies evaluate the efficiency of LLM-based rerankers using proxy metrics such as latency, the number of forward passes, input tokens, and output tokens. However, these metrics depend on hardware and running-time choices (\\eg parallel or not, batch size, etc), and often fail to account for model size, making it difficult to interpret and obscuring the evaluation of the efficiency-effectiveness tradeoff. To address this issue, we propose E2R-FLOPs, for LLM-based rerankers: ranking metrics per PetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for hardware-agnostic throughput. Companied with the new metrics, an interpretable FLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even without running any experiments. Based on the proposed metrics, we conduct comprehensive experiments to evaluate a wide range of LLM-based rerankers with different architecture, studying the efficiency-effectiveness trade-off and bringing this issue to the attention of the research community."
    },
    {
      "title": "可扩展机器人操作中，多样性是否足够？ (原标题: Is Diversity All You Need for Scalable Robotic Manipulation?)",
      "link": "https://arxiv.org/abs/2507.06219",
      "pubDate": "Tue, 08 Jul 2025 13:52:44 GMT",
      "isoDate": "2025-07-08T13:52:44.000Z",
      "creator": "Modi Shi, Li Chen, Jin Chen, Yuxiang Lu, Chiming Liu, Guanghui Ren, Ping Luo, Di Huang, Maoqing Yao, Hongyang Li",
      "summary": "# 可扩展机器人操作中数据多样性的作用\n\n## 摘要\n\n数据规模化在自然语言处理（NLP）和计算机视觉（CV）的预训练模型中取得了显著成功，但在机器人操作领域，有效数据规模化的原则仍未被充分理解。本研究深入探讨了数据多样性在机器人学习中的微妙作用，通过考察三个关键维度——任务（做什么）、实体（使用哪个机器人）和专家（谁演示）——挑战了“越多多样性越好”的传统直觉。\n\n## 主要发现\n\n通过在各种机器人平台上进行大量实验，研究揭示了以下关键发现：\n\n1.  **任务多样性至关重要：**\n    *   任务多样性被证明比单个任务的演示数量更为关键。\n    *   它有利于知识从多样化的预训练任务向新颖的下游场景进行迁移。\n\n2.  **多实体预训练数据并非必需：**\n    *   对于跨实体迁移而言，多实体预训练数据是可选的。\n    *   在高质量的单实体数据上训练的模型可以有效地迁移到不同的平台。\n    *   在微调过程中，这些模型表现出比多实体预训练模型更理想的规模化特性。\n\n3.  **专家多样性可能造成混淆：**\n    *   源于个体操作偏好和人类演示中随机变化的专家多样性，可能对策略学习造成混淆。\n    *   速度多模态被认为是关键的促成因素。\n\n## 提出的解决方案\n\n基于对专家多样性问题的深入洞察，研究提出了一种**分布去偏方法**来缓解速度模糊性。该方法显著提升了模型性能：\n\n*   由此产生的GO-1-Pro模型实现了15%的显著性能提升。\n*   这一提升相当于使用了2.5倍的预训练数据。\n\n## 结论与意义\n\n总而言之，这些发现为如何有效扩展机器人操作数据集提供了新的视角和实用指导。\n\n## 其他信息\n\n*   相关代码已开源。\n*   研究主题包括机器人学（cs.RO）、人工智能（cs.AI）和机器学习（cs.LG）。",
      "shortSummary": "本文研究了数据多样性在机器人操作学习中的作用，挑战“多样性越多越好”的直觉。研究发现：任务多样性至关重要，有利于知识迁移；多实体数据对跨实体迁移并非必需，高质量单实体数据表现更好；专家多样性（特别是速度多模态）可能混淆策略学习。为此，提出了一种分布去偏方法，显著提升了模型性能。这些发现为有效扩展机器人操作数据集提供了新视角和实用指导。",
      "translated_title": "可扩展机器人操作中，多样性是否足够？",
      "images": [],
      "contentSource": "完整文章",
      "content": "Data scaling has driven remarkable success in foundation models for Natural Language Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of \"more diverse is better\". Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, the yielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively."
    },
    {
      "title": "差分Mamba (原标题: Differential Mamba)",
      "link": "https://arxiv.org/abs/2507.06204",
      "pubDate": "Tue, 08 Jul 2025 13:30:14 GMT",
      "isoDate": "2025-07-08T13:30:14.000Z",
      "creator": "Nadav Schneider, Itamar Zimerman, Eliya Nachmani",
      "summary": "## 差分Mamba：一种改进序列模型上下文处理的新方法\n\n### 引言与问题背景\n\n*   **序列模型缺陷：** 诸如Transformer和RNN等序列模型常将注意力过度分配给不相关的上下文信息，这导致中间表示中产生大量噪声。\n*   **负面影响：** 这种噪声会降低大型语言模型（LLM）的能力，具体表现为：\n    *   促进“幻觉”现象（生成不真实或不准确的信息）。\n    *   削弱长程依赖和信息检索能力。\n    *   降低模型的整体鲁棒性。\n\n### 现有解决方案与研究动机\n\n*   **Transformer中的差分设计：** 近期研究表明，差分设计（differential design）能够有效缓解Transformer模型中的上述问题，并提升其在各种应用中的效果。\n*   **本文研究目标：** 探索这些最初为Transformer开发的技术是否能应用于Mamba架构。Mamba是一种基于选择性状态空间层的新型架构，其特点是能在达到Transformer级别性能的同时，拥有更高的效率。\n\n### 方法与创新\n\n*   **挑战：** 研究发现，将差分设计简单地应用于Mamba是不足够的，需要进行细致的架构修改。\n*   **本文贡献：** 针对Mamba架构的特点，本文引入了一种新颖的差分机制。\n\n### 实验验证与结果\n\n*   **验证方法：** 新提出的机制在语言建模基准上进行了实证验证。\n*   **实验成果：** 结果表明，该机制显著改进了Mamba模型的检索能力，并且性能优于原始（vanilla）Mamba模型。\n\n### 深入分析与设计依据\n\n*   **分析方法：** 研究人员进行了广泛的消融研究和实证分析，以充分论证其设计选择的合理性。\n*   **核心发现：** 这些分析提供了有力证据，证明所提出的方法能够有效缓解Mamba模型中上下文过度分配的问题。\n\n### 代码可用性\n\n*   本研究的相关代码已公开。\n\n### 研究领域\n\n*   机器学习 (cs.LG)\n*   人工智能 (cs.AI)\n*   计算与语言 (cs.CL)",
      "shortSummary": "序列模型（如Transformer、RNN）因过度关注无关上下文而性能受损。差分设计在Transformer中有效，本文探索将其应用于高效的Mamba架构。研究发现直接应用不足，故提出一种新颖的Mamba差分机制。实验证明，该机制显著提升了Mamba的检索能力和整体性能，有效缓解了上下文过度分配问题。相关代码已公开。",
      "translated_title": "差分Mamba",
      "images": [],
      "contentSource": "完整文章",
      "content": "Sequence models like Transformers and RNNs often overallocate attention to irrelevant context, leading to noisy intermediate representations. This degrades LLM capabilities by promoting hallucinations, weakening long-range and retrieval abilities, and reducing robustness. Recent work has shown that differential design can mitigate this issue in Transformers, improving their effectiveness across various applications. In this paper, we explore whether these techniques, originally developed for Transformers, can be applied to Mamba, a recent architecture based on selective state-space layers that achieves Transformer-level performance with greater efficiency. We show that a naive adaptation of differential design to Mamba is insufficient and requires careful architectural modifications. To address this, we introduce a novel differential mechanism for Mamba, empirically validated on language modeling benchmarks, demonstrating improved retrieval capabilities and superior performance over vanilla Mamba. Finally, we conduct extensive ablation studies and empirical analyses to justify our design choices and provide evidence that our approach effectively mitigates the overallocation problem in Mamba-based models. Our code is publicly available."
    },
    {
      "title": "潜在推理综述 (原标题: A Survey on Latent Reasoning)",
      "link": "https://arxiv.org/abs/2507.06203",
      "pubDate": "Tue, 08 Jul 2025 13:29:07 GMT",
      "isoDate": "2025-07-08T13:29:07.000Z",
      "creator": "Rui-Jie Zhu, Tianhao Peng, Tianhao Cheng, Xingwei Qu, Jinfa Huang, Dawei Zhu, Hao Wang, Kaiwen Xue, Xuanliang Zhang, Yong Shan, Tianle Cai, Taylor Kergan, Assel Kembay, Andrew Smith, Chenghua Lin, Binh Nguyen, Yuqi Pan, Yuhong Chou, Zefan Cai, Zhenhe Wu, Yongchi Zhao, Tianyu Liu, Jian Yang, Wangchunshu Zhou, Chujie Zheng, Chongxuan Li, Yuyin Zhou, Zhoujun Li, Zhaoxiang Zhang, Jiaheng Liu, Ge Zhang, Wenhao Huang, Jason Eshraghian",
      "summary": "### 潜在推理综述\n\n本综述深入探讨了大型语言模型（LLMs）中新兴的“潜在推理”领域。\n\n**背景与动机**\n\n*   大型语言模型（LLMs）在推理能力方面表现出色，尤其是在通过明确的思维链（CoT）推理（即口头表达中间步骤）引导时。\n*   尽管CoT提高了可解释性和准确性，但其对自然语言推理的依赖限制了模型的表达带宽。\n*   潜在推理旨在解决这一瓶颈，它通过在模型的连续隐藏状态中完全执行多步推理，从而消除了对token级别监督的依赖。\n\n**综述内容概述**\n\n本综述旨在为潜在推理研究提供一个全面的概览，并涵盖以下关键方面：\n\n1.  **推理的计算基础**\n    *   探讨神经网络层作为推理计算基底的基础作用。\n    *   强调分层表示如何支持复杂的转换。\n\n2.  **多样化的潜在推理方法**\n    *   **基于激活的循环（Activation-based recurrence）**：利用激活模式进行推理。\n    *   **隐藏状态传播（Hidden state propagation）**：通过隐藏状态在不同步骤间传递信息。\n    *   **微调策略（Fine-tuning strategies）**：包括压缩或内化显式推理轨迹，将CoT的显式步骤转化为模型内部的隐式过程。\n\n3.  **高级范式**\n    *   **无限深度潜在推理（Infinite-depth latent reasoning）**：通过掩码扩散模型实现，这使得全局一致且可逆的推理过程成为可能。\n\n**目标与未来方向**\n\n*   通过统一这些视角，本综述旨在阐明潜在推理的概念图景。\n*   为LLM认知前沿的未来研究方向提供指引。\n\n**图片说明：** 文章内容中未包含有效的实际图片链接，因此详细摘要中不包含任何图片。",
      "shortSummary": "本综述全面审视了大型语言模型（LLMs）中的“潜在推理”领域。潜在推理通过在模型连续隐藏状态中执行多步推理，克服了传统思维链（CoT）对自然语言的依赖限制。文章探讨了推理的计算基础、多样化的潜在推理方法（如基于激活的循环、隐藏状态传播和微调策略），以及无限深度潜在推理等高级范式。其目标是澄清概念并指明未来研究方向。",
      "translated_title": "潜在推理综述",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, especially when guided by explicit chain-of-thought (CoT) reasoning that verbalizes intermediate steps. While CoT improves both interpretability and accuracy, its dependence on natural language reasoning limits the model's expressive bandwidth. Latent reasoning tackles this bottleneck by performing multi-step inference entirely in the model's continuous hidden state, eliminating token-level supervision. To advance latent reasoning research, this survey provides a comprehensive overview of the emerging field of latent reasoning. We begin by examining the foundational role of neural network layers as the computational substrate for reasoning, highlighting how hierarchical representations support complex transformations. Next, we explore diverse latent reasoning methodologies, including activation-based recurrence, hidden state propagation, and fine-tuning strategies that compress or internalize explicit reasoning traces. Finally, we discuss advanced paradigms such as infinite-depth latent reasoning via masked diffusion models, which enable globally consistent and reversible reasoning processes. By unifying these perspectives, we aim to clarify the conceptual landscape of latent reasoning and chart future directions for research at the frontier of LLM cognition. An associated GitHub repository collecting the latest papers and repos is available at: https://github.com/multimodal-art-projection/LatentCoT-Horizon/."
    },
    {
      "title": "CriticLean：评论家引导的数学形式化强化学习 (原标题: CriticLean: Critic-Guided Reinforcement Learning for Mathematical Formalization)",
      "link": "https://arxiv.org/abs/2507.06181",
      "pubDate": "Tue, 08 Jul 2025 13:03:39 GMT",
      "isoDate": "2025-07-08T13:03:39.000Z",
      "creator": "Zhongyuan Peng, Yifan Yao, Kaijing Ma, Shuyue Guo, Yizhe Li, Yichi Zhang, Chenchen Zhang, Yifan Zhang, Zhouliang Yu, Luming Li, Minghao Liu, Yihang Xia, Jiawei Shen, Yuchen Wu, Yixin Cao, Zhaoxiang Zhang, Wenhao Huang, Jiaheng Liu, Ge Zhang",
      "summary": "### CriticLean：评论家引导的数学形式化强化学习\n\n本文介绍了 **CriticLean**，一个新颖的评论家引导的强化学习框架，旨在解决将自然语言数学陈述翻译成形式化、可执行代码这一基本挑战。\n\n**背景与问题：**\n*   在自动化定理证明领域，将自然语言数学陈述转换为形式化代码是一个核心难题。\n*   以往的研究主要集中在代码的生成和编译成功率上。\n*   然而，对于“评论家阶段”（即评估生成的数学形式化是否真正捕捉到原始问题的语义意图）的关注不足。\n\n**CriticLean 框架的核心理念：**\n*   将评论家（critic）的角色从被动的验证者提升为主动的学习组件。\n\n**主要组成部分与贡献：**\n\n1.  **CriticLeanGPT 模型：**\n    *   通过监督微调（supervised fine-tuning）和强化学习（reinforcement learning）进行训练。\n    *   其主要目标是严格评估 Lean 4 形式化的语义忠实度。\n\n2.  **CriticLeanBench 基准测试：**\n    *   一个专门设计的基准，用于衡量模型区分语义正确和不正确形式化的能力。\n    *   研究表明，经过训练的 CriticLeanGPT 模型在该基准上显著优于强大的开源和闭源基线模型。\n\n3.  **FineLeanCorpus 数据集：**\n    *   基于 CriticLean 框架构建。\n    *   包含超过 28.5 万个问题，具有丰富的领域多样性、广泛的难度覆盖范围，并经过人工评估具有高正确性。\n\n**研究发现与展望：**\n*   研究结果强调，优化评论家阶段对于生成可靠的数学形式化至关重要。\n*   作者希望 CriticLean 框架能为未来形式化数学推理的进展提供有价值的见解。",
      "shortSummary": "CriticLean是一个新颖的评论家引导强化学习框架，旨在改进自然语言数学陈述到形式化代码的转换。它通过提升评论家在学习中的作用，解决现有方法对语义评估不足的问题。该框架引入了CriticLeanGPT模型用于评估语义忠实度，并构建了CriticLeanBench基准测试和FineLeanCorpus数据集。研究表明，优化评论家阶段对于生成可靠的数学形式化至关重要，为自动化定理证明提供了新方向。",
      "translated_title": "CriticLean：评论家引导的数学形式化强化学习",
      "images": [],
      "contentSource": "完整文章",
      "content": "Translating natural language mathematical statements into formal, executable code is a fundamental challenge in automated theorem proving. While prior work has focused on generation and compilation success, little attention has been paid to the critic phase-the evaluation of whether generated formalizations truly capture the semantic intent of the original problem. In this paper, we introduce CriticLean, a novel critic-guided reinforcement learning framework that elevates the role of the critic from a passive validator to an active learning component. Specifically, first, we propose the CriticLeanGPT, trained via supervised fine-tuning and reinforcement learning, to rigorously assess the semantic fidelity of Lean 4 formalizations. Then, we introduce CriticLeanBench, a benchmark designed to measure models' ability to distinguish semantically correct from incorrect formalizations, and demonstrate that our trained CriticLeanGPT models can significantly outperform strong open- and closed-source baselines. Building on the CriticLean framework, we construct FineLeanCorpus, a dataset comprising over 285K problems that exhibits rich domain diversity, broad difficulty coverage, and high correctness based on human evaluation. Overall, our findings highlight that optimizing the critic phase is essential for producing reliable formalizations, and we hope our CriticLean will provide valuable insights for future advances in formal mathematical reasoning."
    },
    {
      "title": "OmniPart：具有语义解耦和结构内聚的部件感知3D生成 (原标题: OmniPart: Part-Aware 3D Generation with Semantic Decoupling and Structural Cohesion)",
      "link": "https://arxiv.org/abs/2507.06165",
      "pubDate": "Tue, 08 Jul 2025 12:46:15 GMT",
      "isoDate": "2025-07-08T12:46:15.000Z",
      "creator": "Yunhan Yang, Yufan Zhou, Yuan-Chen Guo, Zi-Xin Zou, Yukun Huang, Ying-Tian Liu, Hao Xu, Ding Liang, Yan-Pei Cao, Xihui Liu",
      "summary": "### OmniPart：具有语义解耦和结构内聚的部件感知3D生成\n\n**1. 引言与问题背景**\n*   为交互式应用创建具有明确、可编辑部件结构的3D资产至关重要。\n*   然而，大多数现有的生成方法仅产生整体形状（monolithic shapes），这限制了它们在需要部件级编辑和控制的应用中的实用性。\n\n**2. OmniPart 框架介绍**\n*   OmniPart 是一种新颖的框架，专为部件感知3D对象生成而设计。\n*   其核心目标是在组件之间实现高语义解耦（semantic decoupling），同时保持强大的结构内聚（structural cohesion）。\n*   OmniPart 独特地将这一复杂任务解耦为两个协同阶段。\n\n**3. 两个协同阶段**\n*   **阶段一：自回归结构规划模块**\n    *   该模块生成一个可控的、可变长度的3D部件边界框序列。\n    *   关键在于，它由灵活的2D部件掩码（part masks）引导，这些掩码允许对部件分解进行直观控制，而无需直接的对应关系或语义标签。\n*   **阶段二：空间条件整流流模型（Spatially-conditioned Rectified Flow Model）**\n    *   该模型从一个预训练的整体3D生成器中高效地改编而来。\n    *   它能够在规划好的布局内，同时且一致地合成所有3D部件。\n\n**4. 优势与应用**\n*   OmniPart 支持用户定义的部件粒度（part granularity）和精确的定位（precise localization）。\n*   它能够实现多样化的下游应用。\n\n**5. 性能与影响**\n*   广泛的实验表明，OmniPart 实现了最先进的性能。\n*   该方法为创建更具可解释性、可编辑性和多功能性的3D内容铺平了道路。",
      "shortSummary": "OmniPart是一种新颖的3D对象生成框架，旨在创建具有明确、可编辑部件结构的资产。它通过将任务解耦为两个协同阶段实现：首先，一个自回归模块利用2D掩码规划3D部件边界框；其次，一个空间条件整流流模型同时合成所有部件。该方法在实现组件语义解耦和结构内聚的同时，支持用户自定义粒度和精确控制，为生成更具可解释性、可编辑性和多功能性的3D内容提供了最先进的解决方案。",
      "translated_title": "OmniPart：具有语义解耦和结构内聚的部件感知3D生成",
      "images": [],
      "contentSource": "完整文章",
      "content": "The creation of 3D assets with explicit, editable part structures is crucial for advancing interactive applications, yet most generative methods produce only monolithic shapes, limiting their utility. We introduce OmniPart, a novel framework for part-aware 3D object generation designed to achieve high semantic decoupling among components while maintaining robust structural cohesion. OmniPart uniquely decouples this complex task into two synergistic stages: (1) an autoregressive structure planning module generates a controllable, variable-length sequence of 3D part bounding boxes, critically guided by flexible 2D part masks that allow for intuitive control over part decomposition without requiring direct correspondences or semantic labels; and (2) a spatially-conditioned rectified flow model, efficiently adapted from a pre-trained holistic 3D generator, synthesizes all 3D parts simultaneously and consistently within the planned layout. Our approach supports user-defined part granularity, precise localization, and enables diverse downstream applications. Extensive experiments demonstrate that OmniPart achieves state-of-the-art performance, paving the way for more interpretable, editable, and versatile 3D content."
    },
    {
      "title": "编码三角：大型语言模型如何理解代码？ (原标题: Coding Triangle: How Does Large Language Model Understand Code?)",
      "link": "https://arxiv.org/abs/2507.06138",
      "pubDate": "Tue, 08 Jul 2025 12:20:43 GMT",
      "isoDate": "2025-07-08T12:20:43.000Z",
      "creator": "Taolin Zhang, Zihan Ma, Maosong Cao, Junnan Liu, Songyang Zhang, Kai Chen",
      "summary": "大型语言模型（LLMs）在代码生成方面取得了显著进展，但其真实的编程能力仍未被充分探索。为了系统评估LLMs的编程能力，本文引入了“编码三角”框架，该框架从三个基本维度进行评估：\n\n*   **编辑分析（Editorial Analysis）**\n*   **代码实现（Code Implementation）**\n*   **测试用例生成（Test Case Generation）**\n\n通过在竞争性编程基准上进行大量实验，研究揭示了以下关键发现：\n\n*   **系统内部一致性与人类差异**：LLMs可以在这三个维度上形成一个自洽的系统，但其解决方案往往缺乏人类程序员所具备的多样性和鲁棒性。\n*   **认知与人类专业知识的分布差异**：模型认知与人类专业知识之间存在显著的分布偏移。模型错误倾向于聚集，这归因于训练数据偏差和有限的推理迁移能力。\n\n研究进一步指出，可以通过以下方法显著提升LLMs的性能和鲁棒性：\n\n*   **整合人类生成的数据**：纳入人类编写的编辑分析、解决方案和多样化的测试用例。\n*   **利用模型混合**：结合不同模型的优势。\n\n此外，研究还揭示了LLMs认知中的一致性和不一致性，这可能有助于模型的自我反思和自我改进，为开发更强大的编码模型提供了潜在方向。",
      "shortSummary": "本文提出了“编码三角”框架，从编辑分析、代码实现和测试用例生成三个维度评估大型语言模型（LLMs）的编程能力。研究发现，LLMs虽能形成自洽系统，但其解决方案缺乏人类的多样性和鲁棒性，且错误因训练数据偏差而聚集。为提升LLMs性能，建议整合人类生成的数据和利用模型混合。LLMs认知的一致性与不一致性也为未来自我改进提供了方向。",
      "translated_title": "编码三角：大型语言模型如何理解代码？",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large language models (LLMs) have achieved remarkable progress in code generation, yet their true programming competence remains underexplored. We introduce the Code Triangle framework, which systematically evaluates LLMs across three fundamental dimensions: editorial analysis, code implementation, and test case generation. Through extensive experiments on competitive programming benchmarks, we reveal that while LLMs can form a self-consistent system across these dimensions, their solutions often lack the diversity and robustness of human programmers. We identify a significant distribution shift between model cognition and human expertise, with model errors tending to cluster due to training data biases and limited reasoning transfer. Our study demonstrates that incorporating human-generated editorials, solutions, and diverse test cases, as well as leveraging model mixtures, can substantially enhance both the performance and robustness of LLMs. Furthermore, we reveal both the consistency and inconsistency in the cognition of LLMs that may facilitate self-reflection and self-improvement, providing a potential direction for developing more powerful coding models."
    },
    {
      "title": "Tora2：用于多实体视频生成的运动与外观定制扩散Transformer (原标题: Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation)",
      "link": "https://arxiv.org/abs/2507.05963",
      "pubDate": "Tue, 08 Jul 2025 09:11:40 GMT",
      "isoDate": "2025-07-08T09:11:40.000Z",
      "creator": "Zhenghao Zhang, Junchao Liao, Xiangyu Meng, Long Qin, Weizhi Wang",
      "summary": "## Tora2：用于多实体视频生成的运动与外观定制扩散Transformer\n\n### 概述\n\n本文介绍了 Tora2，这是在运动引导视频生成领域，对现有扩散Transformer模型 Tora 的增强版本。Tora2 旨在扩展其在外观和运动定制方面的能力，特别关注多实体视频生成。\n\n### 主要改进与创新\n\n1.  **解耦个性化提取器 (Decoupled Personalization Extractor)**\n    *   Tora2 引入了一个解耦的个性化提取器。\n    *   该提取器能够为多个开放集实体生成全面的个性化嵌入 (personalization embeddings)。\n    *   与现有方法相比，它能更好地保留细粒度的视觉细节。\n\n2.  **门控自注意力机制 (Gated Self-Attention Mechanism)**\n    *   基于解耦提取器，Tora2 设计了一种门控自注意力机制。\n    *   该机制用于整合每个实体的轨迹、文本描述和视觉信息。\n    *   这一创新显著减少了训练过程中多模态条件作用中的不对齐问题。\n\n3.  **对比损失 (Contrastive Loss)**\n    *   Tora2 引入了一种对比损失函数。\n    *   该损失函数通过运动嵌入和个性化嵌入之间的显式映射，共同优化轨迹动态和实体一致性。\n\n### 独特能力与贡献\n\n*   据作者所知，Tora2 是第一个实现视频生成中多实体外观和运动同步定制的方法。\n\n### 实验结果\n\n*   实验结果表明，Tora2 在与最先进的定制方法竞争的同时，提供了先进的运动控制能力。\n*   这标志着多条件视频生成领域的一个关键进展。",
      "shortSummary": "Tora2 是对现有扩散Transformer模型 Tora 的增强版本，专注于多实体视频生成中的运动与外观定制。它引入了解耦个性化提取器以保留视觉细节，设计了门控自注意力机制以减少多模态不对齐，并采用对比损失来优化轨迹动态和实体一致性。Tora2 是首个实现多实体外观和运动同步定制的方法，在实验中展现出与最先进技术相当的性能和先进的运动控制能力。",
      "translated_title": "Tora2：用于多实体视频生成的运动与外观定制扩散Transformer",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in diffusion transformer models for motion-guided video generation, such as Tora, have shown significant progress. In this paper, we present Tora2, an enhanced version of Tora, which introduces several design improvements to expand its capabilities in both appearance and motion customization. Specifically, we introduce a decoupled personalization extractor that generates comprehensive personalization embeddings for multiple open-set entities, better preserving fine-grained visual details compared to previous methods. Building on this, we design a gated self-attention mechanism to integrate trajectory, textual description, and visual information for each entity. This innovation significantly reduces misalignment in multimodal conditioning during training. Moreover, we introduce a contrastive loss that jointly optimizes trajectory dynamics and entity consistency through explicit mapping between motion and personalization embeddings. Tora2 is, to our best knowledge, the first method to achieve simultaneous multi-entity customization of appearance and motion for video generation. Experimental results demonstrate that Tora2 achieves competitive performance with state-of-the-art customization methods while providing advanced motion control capabilities, which marks a critical advancement in multi-condition video generation. Project page: https://github.com/alibaba/Tora ."
    },
    {
      "title": "基于多轮定位的强化学习实现高分辨率视觉推理 (原标题: High-Resolution Visual Reasoning via Multi-Turn Grounding-Based Reinforcement Learning)",
      "link": "https://arxiv.org/abs/2507.05920",
      "pubDate": "Tue, 08 Jul 2025 08:05:05 GMT",
      "isoDate": "2025-07-08T08:05:05.000Z",
      "creator": "Xinyu Huang, Yuhao Dong, Weiwei Tian, Bo Li, Rui Feng, Ziwei Liu",
      "summary": "## MGPO：高分辨率视觉推理的新范式\n\n### 背景与挑战\n当前最先进的大型多模态模型（LMMs）在处理高分辨率图像时面临显著挑战。这些图像输入被转换为大量的视觉标记，其中许多与下游任务无关，导致处理效率低下和性能受限。\n\n### 提出的方法：多轮定位策略优化（MGPO）\n为解决上述问题，本文提出了一种名为“多轮定位策略优化”（Multi-turn Grounding-based Policy Optimization, MGPO）的端到端强化学习（RL）框架。MGPO使LMMs能够在一个多轮对话框架内，根据模型预测的定位坐标，自动裁剪子图像，从而迭代地聚焦于关键视觉区域。\n\n### MGPO的关键优势\n*   **无需额外定位标注**：与需要昂贵额外定位标注的监督微调（SFT）方法不同，MGPO在RL训练过程中，仅利用最终答案正确性派生的二元奖励函数，就能使LMMs自主地发展出强大的定位能力。\n*   **解决“冷启动”问题**：研究发现LMMs在推理过程中难以自主触发视觉定位。为解决这一“冷启动”问题，MGPO设计了一种多轮对话模板，并将策略损失计算限制在跨多个对话轮次生成的模型输出上，从而促进了稳定的优化。\n\n### 实验结果与性能\nMGPO在标准视觉问答（VQA）数据集上进行训练，且**不依赖任何定位标注**。实验结果表明：\n*   MGPO相比于GRPO，能够更有效地激发LMMs的定位能力。\n*   在同分布的MME-Realworld数据集上，性能提升了5.4%。\n*   在更具挑战性的异分布（OOD）V* Bench数据集上，性能提升了5.2%。\n*   值得注意的是，在Qwen2.5-VL-7B模型上，经过21K样本的MGPO后训练，其在OOD V* Bench上的表现超越了OpenAI的o1和GPT-4o模型。\n\n### 代码可用性\n相关代码已公开。",
      "shortSummary": "大型多模态模型（LMMs）处理高分辨率图像时面临挑战。本文提出MGPO，一种基于多轮定位的强化学习框架，使LMMs能迭代聚焦关键视觉区域。MGPO无需额外定位标注，仅通过最终答案的二元奖励即可训练，并解决了模型自主触发定位的“冷启动”问题。实验证明，MGPO显著提升了视觉推理能力，在MME-Realworld和V* Bench上表现优异，甚至超越了GPT-4o等模型。",
      "translated_title": "基于多轮定位的强化学习实现高分辨率视觉推理",
      "images": [],
      "contentSource": "完整文章",
      "content": "State-of-the-art large multi-modal models (LMMs) face challenges when processing high-resolution images, as these inputs are converted into enormous visual tokens, many of which are irrelevant to the downstream task. In this paper, we propose Multi-turn Grounding-based Policy Optimization (MGPO), an end-to-end reinforcement learning (RL) framework that enables LMMs to iteratively focus on key visual regions by automatically cropping sub-images, based on model-predicted grounding coordinates within a multi-turn conversation framework. Compared to supervised fine-tuning (SFT), which requires costly additional grounding annotations, our approach highlights that LMMs can emerge robust grounding abilities during the RL training process, leveraging only a binary reward function derived from the correctness of the final answer. Additionally, we observe that LMMs struggle to autonomously trigger visual grounding during the rollout process. To address this cold start problem, we design a multi-turn conversational template and restrict policy loss computation to model outputs generated across multiple dialogue rounds, thereby promoting stable optimization. Extensive experiments demonstrate that, when trained on standard visual-question-short answering data without grounding annotations, MGPO effectively elicits stronger grounding capabilities compared to GRPO, leading to 5.4\\% improvement on in-distribution MME-Realworld and 5.2\\% improvement on the challenging out-of-distribution (OOD) V* Bench. Notably, MGPO post-training on Qwen2.5-VL-7B with 21K samples surpasses OpenAI's o1 and GPT-4o models on the OOD V* Bench. Codes are available at https://github.com/EvolvingLMMs-Lab/MGPO."
    },
    {
      "title": "GTA1：GUI测试时缩放代理 (原标题: GTA1: GUI Test-time Scaling Agent)",
      "link": "https://arxiv.org/abs/2507.05791",
      "pubDate": "Tue, 08 Jul 2025 04:52:18 GMT",
      "isoDate": "2025-07-08T04:52:18.000Z",
      "creator": "Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li",
      "summary": "## GTA1：GUI测试时缩放代理\n\n### 引言\n\n图形用户界面（GUI）代理能够自主地跨平台（如Linux）操作，通过与视觉元素交互来完成任务。具体而言，用户指令被分解为一系列动作提议，每个提议对应一次与GUI的交互。在每次动作之后，代理会观察更新后的GUI环境以规划下一步。然而，GUI代理面临两大主要挑战：\n\n1.  **任务规划模糊性：** 动作提议序列的选择存在歧义。选择一个合适的计划并非易事，因为可能存在许多有效的计划。\n2.  **动作精确接地：** 在复杂和高分辨率的界面中，需要精确地与视觉目标进行交互，即准确地将动作“接地”到对应的视觉元素上。\n\n### GTA1解决方案\n\n本文介绍了我们的GUI测试时缩放代理——GTA1，旨在解决上述两大挑战。\n\n#### 解决任务规划模糊性（挑战一）\n\n为了选择最合适的动作提议，GTA1引入了一种**测试时缩放方法**：\n\n*   在每一步，GTA1会采样多个候选动作提议。\n*   利用一个“判断模型”来评估并选择最合适的提议。\n*   这种方法以计算量为代价，换取更好的决策质量，通过并发采样缩短了任务执行步骤，并提高了整体性能。\n\n#### 解决动作精确接地（挑战二）\n\nGTA1提出了一个模型，旨在提高将选定的动作提议“接地”到其相应视觉元素的准确性。其核心洞察在于：\n\n*   **强化学习（RL）** 通过固有的目标对齐促进视觉接地。\n*   RL机制通过奖励成功点击界面元素来引导和优化接地过程。\n\n### 实验结果与性能\n\n我们的方法在多个基准测试中取得了最先进的性能：\n\n*   **GTA1-7B的准确率：**\n    *   Screenspot-Pro：50.1%\n    *   Screenspot-V2：92.4%\n    *   OSWorld-G：67.7%\n*   当GTA1与采用我们测试时缩放策略的规划器结合时，它展现出最先进的代理性能，例如在**OSWorld**上实现了**45.2%的任务成功率**。\n\n### 开源信息\n\nGTA1的代码和模型已开源。",
      "shortSummary": "GTA1是一个图形用户界面（GUI）测试时缩放代理，旨在提升GUI代理的自主操作能力。它通过引入测试时缩放方法解决任务规划模糊性，即采样并选择最佳动作提议；同时，利用强化学习（RL）提高动作在复杂界面中的精确接地能力。实验证明，GTA1在Screenspot和OSWorld等多个基准测试中达到了最先进的性能，显著提高了任务成功率。该项目已开源。",
      "translated_title": "GTA1：GUI测试时缩放代理",
      "images": [],
      "contentSource": "完整文章",
      "content": "Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.   This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.   Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here."
    },
    {
      "title": "MedGen：通过扩展精细标注的医学视频解锁医学视频生成 (原标题: MedGen: Unlocking Medical Video Generation by Scaling Granularly-annotated Medical Videos)",
      "link": "https://arxiv.org/abs/2507.05675",
      "pubDate": "Tue, 08 Jul 2025 00:58:36 GMT",
      "isoDate": "2025-07-08T00:58:36.000Z",
      "creator": "Rongsheng Wang, Junying Chen, Ke Ji, Zhenyang Cai, Shunian Chen, Yunjin Yang, Benyou Wang",
      "summary": "# MedGen：医学视频生成的新进展\n\n## 引言\n尽管开放领域视频生成技术取得了显著进展，但医学视频生成领域仍未得到充分探索。医学视频在临床培训、教育和模拟等关键应用中至关重要，对视觉保真度和医学准确性有严格要求。然而，现有模型在处理医学提示时常产生不真实或错误的内容，这主要是由于缺乏大规模、高质量的医学领域专用数据集。\n\n## 核心贡献\n\n### 1. MedVideoCap-55K 数据集\n为解决医学视频生成领域的数据空白，研究人员引入了 **MedVideoCap-55K**，这是：\n*   首个大规模、多样化且富含标注的医学视频生成数据集。\n*   包含超过55,000个精选剪辑，涵盖真实的医学场景。\n*   为训练通用医学视频生成模型奠定了坚实基础。\n\n### 2. MedGen 模型\n基于 MedVideoCap-55K 数据集，研究人员开发了 **MedGen** 模型，该模型：\n*   在开源模型中取得了领先性能。\n*   在视觉质量和医学准确性方面，MedGen在多个基准测试中与商业系统相媲美。\n\n## 研究意义与可用性\n*   研究人员希望 MedVideoCap-55K 数据集和 MedGen 模型能成为宝贵的资源，并有助于推动医学视频生成领域的进一步研究。\n*   相关的代码和数据已公开，以促进社区协作和进一步发展。",
      "shortSummary": "该研究介绍了MedVideoCap-55K，首个大规模、多样化且富含标注的医学视频数据集，包含超过55,000个剪辑。基于此，开发了MedGen模型，在医学视频生成方面表现卓越，超越开源模型并媲美商业系统，在视觉质量和医学准确性上均达到领先水平。此工作旨在弥补医学视频生成领域的数据和模型空白，推动该领域的进一步发展。",
      "translated_title": "MedGen：通过扩展精细标注的医学视频解锁医学视频生成",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in video generation have shown remarkable progress in open-domain settings, yet medical video generation remains largely underexplored. Medical videos are critical for applications such as clinical training, education, and simulation, requiring not only high visual fidelity but also strict medical accuracy. However, current models often produce unrealistic or erroneous content when applied to medical prompts, largely due to the lack of large-scale, high-quality datasets tailored to the medical domain. To address this gap, we introduce MedVideoCap-55K, the first large-scale, diverse, and caption-rich dataset for medical video generation. It comprises over 55,000 curated clips spanning real-world medical scenarios, providing a strong foundation for training generalist medical video generation models. Built upon this dataset, we develop MedGen, which achieves leading performance among open-source models and rivals commercial systems across multiple benchmarks in both visual quality and medical accuracy. We hope our dataset and model can serve as a valuable resource and help catalyze further research in medical video generation. Our code and data is available at https://github.com/FreedomIntelligence/MedGen"
    },
    {
      "title": "大型语言模型（LLMs）中记忆化的全景：机制、测量与缓解 (原标题: The Landscape of Memorization in LLMs: Mechanisms, Measurement, and Mitigation)",
      "link": "https://arxiv.org/abs/2507.05578",
      "pubDate": "Mon, 07 Jul 2025 21:30:46 GMT",
      "isoDate": "2025-07-07T21:30:46.000Z",
      "creator": "Alexander Xiong, Xuandong Zhao, Aneesh Pappu, Dawn Song",
      "summary": "大型语言模型（LLMs）在广泛任务中展现出卓越能力，但同时也表现出对其训练数据的记忆化现象。这一现象引发了关于模型行为、隐私风险以及学习与记忆边界的关键问题。\n\n### 论文概述\n\n本论文综合了近期研究，深入探讨了LLMs记忆化的全景、影响因素以及检测和缓解方法。它旨在提供关于LLM记忆化在技术、隐私和性能维度上的研究现状的全面概述，并指明未来的关键研究方向。\n\n### 记忆化的关键驱动因素\n\n文章探讨了影响数据记忆化的主要驱动因素，包括：\n\n*   **训练数据重复**：数据集中重复出现的内容会增加模型记忆的可能性。\n*   **训练动态**：模型训练过程中的特定行为和阶段可能导致记忆化。\n*   **微调程序**：特定的微调方法可能加剧或缓解记忆化。\n\n### 记忆化的检测与测量方法\n\n论文审查了多种用于检测和测量记忆化内容的方法，评估了它们的有效性：\n\n*   **基于前缀的提取**：通过提供数据前缀来尝试提取完整的记忆内容。\n*   **成员推断**：判断特定数据点是否属于模型的训练集。\n*   **对抗性提示**：设计特定的提示来诱导模型泄露记忆信息。\n\n### 记忆化的更广泛影响\n\n除了技术分析，论文还探讨了记忆化带来的更广泛影响，包括：\n\n*   **法律影响**：涉及版权、数据使用协议和法规遵从性。\n*   **伦理影响**：关于隐私侵犯、数据滥用和模型责任。\n\n### 记忆化的缓解策略\n\n论文讨论了多种缓解记忆化的策略，同时强调了在最小化有害记忆化与保持模型效用之间取得平衡的开放挑战：\n\n*   **数据清洗**：在训练前识别并移除重复或敏感数据。\n*   **差分隐私**：在训练过程中引入噪声，以保护个体数据隐私。\n*   **训练后遗忘**：在模型训练完成后，选择性地消除特定数据的记忆。\n\n### 挑战与未来方向\n\n研究指出，在平衡记忆化最小化与模型实用性方面仍存在挑战。论文最后识别了未来研究的关键方向，涵盖技术、隐私和性能维度。",
      "shortSummary": "该论文全面探讨了大型语言模型（LLMs）的训练数据记忆化现象。文章分析了数据重复、训练动态等记忆化驱动因素，并介绍了前缀提取、成员推断等检测方法。同时，论文讨论了数据清洗、差分隐私等缓解策略，并审视了记忆化的法律伦理影响。研究旨在平衡有害记忆化与模型效用，并为未来研究指明方向。",
      "translated_title": "大型语言模型（LLMs）中记忆化的全景：机制、测量与缓解",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet they also exhibit memorization of their training data. This phenomenon raises critical questions about model behavior, privacy risks, and the boundary between learning and memorization. Addressing these concerns, this paper synthesizes recent studies and investigates the landscape of memorization, the factors influencing it, and methods for its detection and mitigation. We explore key drivers, including training data duplication, training dynamics, and fine-tuning procedures that influence data memorization. In addition, we examine methodologies such as prefix-based extraction, membership inference, and adversarial prompting, assessing their effectiveness in detecting and measuring memorized content. Beyond technical analysis, we also explore the broader implications of memorization, including the legal and ethical implications. Finally, we discuss mitigation strategies, including data cleaning, differential privacy, and post-training unlearning, while highlighting open challenges in balancing the minimization of harmful memorization with utility. This paper provides a comprehensive overview of the current state of research on LLM memorization across technical, privacy, and performance dimensions, identifying critical directions for future work."
    },
    {
      "title": "SingLoRA：使用单个矩阵的低秩适应 (原标题: SingLoRA: Low Rank Adaptation Using a Single Matrix)",
      "link": "https://arxiv.org/abs/2507.05566",
      "pubDate": "Mon, 07 Jul 2025 21:11:30 GMT",
      "isoDate": "2025-07-07T21:11:30.000Z",
      "creator": "David Bensaïd, Noam Rotstein, Roy Velich, Daniel Bensaïd, Ron Kimmel",
      "summary": "### SingLoRA：使用单个矩阵的低秩适应\n\n本文介绍了一种名为 SingLoRA 的新型低秩适应（Low-Rank Adaptation, LoRA）方法，旨在解决现有 LoRA 技术在大型预训练模型参数高效微调中存在的稳定性问题并提升性能。\n\n#### LoRA 的背景与局限性\n\n低秩适应（LoRA）是当前参数高效微调大型预训练模型的重要技术。它通过在预训练权重上添加两个较小矩阵的乘积来更新模型，这两个矩阵共同形成一个低秩矩阵更新。然而，近期研究发现，这两个矩阵之间的尺度差异常常导致训练动态不稳定，进而影响模型性能。\n\n#### SingLoRA 的核心思想与机制\n\n为了解决上述问题，SingLoRA 重新构建了低秩适应的范式。它将权重更新学习为单个低秩矩阵与其转置的乘积分解。这种简洁的设计带来了以下显著优势：\n\n*   **消除矩阵间尺度冲突**：通过使用单个矩阵及其转置，SingLoRA 从根本上消除了 LoRA 中两个独立矩阵之间可能存在的尺度不匹配问题。\n*   **确保优化稳定性**：由于移除了尺度冲突，SingLoRA 能够保证更稳定的优化过程，从而避免训练过程中的不确定性和性能下降。\n*   **参数量减半**：与传统的 LoRA 相比，SingLoRA 大约将参数数量减少了一半，进一步提升了参数效率。\n\n#### 理论分析\n\n研究人员在无限宽度神经网络框架内对 SingLoRA 进行了分析，结果表明其设计结构能够确保稳定的特征学习，为其实际应用提供了坚实的理论基础。\n\n#### 实验验证与性能提升\n\nSingLoRA 在多个任务上进行了广泛的实验验证，结果显示其性能显著优于现有方法：\n\n*   **常识推理任务（LLama 7B 在 MNLI 数据集上微调）**：\n    *   SingLoRA 达到了 91.3% 的准确率。\n    *   LoRA 的准确率为 89.1%。\n    *   LoRA+ 的准确率为 90.2%。\n    *   值得注意的是，SingLoRA 在取得更高性能的同时，仅使用了 LoRA 和 LoRA+ 约 60% 的参数预算。\n*   **图像生成任务（Stable Diffusion 在 DreamBooth 上微调）**：\n    *   SingLoRA 在图像保真度方面表现出色，DINO 相似度得分为 0.151。\n    *   DoRA 的得分为 0.148。\n    *   LoRA 的得分为 0.143。\n    *   更高的 DINO 相似度分数表示更好的图像保真度，这表明 SingLoRA 在生成高质量图像方面具有优势。\n\n#### 结论\n\nSingLoRA 通过其创新的单矩阵分解方法，有效解决了传统 LoRA 的尺度冲突问题，显著提升了模型微调的稳定性和效率。实验结果证明，SingLoRA 在多种任务上均能以更少的参数预算实现超越 LoRA 及其变体的性能，为大型预训练模型的参数高效微调提供了新的、更优的解决方案。",
      "shortSummary": "SingLoRA 是一种新型低秩适应方法，通过将权重更新表示为单个低秩矩阵与其转置的乘积，解决了传统 LoRA 中矩阵间尺度冲突导致的训练不稳定问题。该方法确保了优化稳定性，并能将参数量减半。实验证明，SingLoRA 在常识推理（LLM）和图像生成（Stable Diffusion）任务上均超越了 LoRA 及其变体，同时使用了更少的参数，显著提升了微调效率和性能。",
      "translated_title": "SingLoRA：使用单个矩阵的低秩适应",
      "images": [],
      "contentSource": "完整文章",
      "content": "Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient fine-tuning of large pretrained models. LoRA augments the pre-trained weights of a model by adding the product of two smaller matrices that together form a low-rank matrix update. Recent research has shown that scale disparities between these two matrices often cause unstable training dynamics, leading to suboptimal performance. In this paper, we propose SingLoRA, which reformulates low-rank adaptation by learning the weights update as a decomposition of a single low-rank matrix multiplied by its transpose. This simple design inherently removes inter-matrix scale conflicts, ensuring stable optimization, and roughly halves the parameter count. We analyze SingLoRA within the infinite-width neural network framework, showing that it guarantees stable feature learning by construction. Extensive experiments on multiple tasks validate these benefits. In common sense reasoning, fine-tuning LLama 7B on MNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+ (90.2%) - while using only 60% of their parameter budget. In image generation, fine-tuning Stable Diffusion with SingLoRA significantly improves image fidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to scores of 0.148 and 0.143 for DoRA and LoRA, respectively."
    },
    {
      "title": "AXLearn：异构基础设施上的模块化大型模型训练 (原标题: AXLearn: Modular Large Model Training on Heterogeneous Infrastructure)",
      "link": "https://arxiv.org/abs/2507.05411",
      "pubDate": "Mon, 07 Jul 2025 14:50:58 GMT",
      "isoDate": "2025-07-07T14:50:58.000Z",
      "creator": "Mark Lee, Tom Gunter, Chang Lan, John Peebles, Hanzhi Zhou, Kelvin Zou, Sneha Bangalore, Chung-Cheng Chiu, Nan Du, Xianzhi Du, Philipp Dufter, Ruixuan Hou, Haoshuo Huang, Dongseong Hwang, Xiang Kong, Jinhao Lei, Tao Lei, Meng Li, Li Li, Jiarui Lu, Zhiyun Lu, Yiping Ma, David Qiu, Vivek Rathod, Senyu Tong, Zhucheng Tu, Jianyu Wang, Yongqiang Wang, Zirui Wang, Floris Weers, Sam Wiseman, Guoli Yin, Bowen Zhang, Xiyou Zhou, Danyang Zhuo, Cheng Leong, Ruoming Pang",
      "summary": "## AXLearn：异构基础设施上的模块化大型模型训练系统\n\nAXLearn 是一个为大型深度学习模型提供可扩展、高性能训练而设计和实现的生产级深度学习系统。该系统由多位作者共同开发，旨在解决当前深度学习系统在模块化和异构硬件支持方面的挑战。\n\n### 核心特点\n\n*   **模块化设计**：AXLearn 的独特之处在于其对模块化的高度重视。系统内部的软件组件接口遵循严格的封装原则，这使得不同的组件可以灵活地组合，从而加速模型开发和实验过程。\n*   **支持异构硬件基础设施**：系统能够有效地在多种不同类型的计算硬件上运行和训练模型，提高了资源利用率和灵活性。\n\n### 模块化量化与优势\n\nAXLearn 引入了一种新颖的模块化量化方法——**代码行数（LoC）复杂度**。通过这种方法，研究人员证明了随着系统组件的扩展，AXLearn 的复杂度保持恒定，这与传统系统中常见的线性或二次复杂度形成了鲜明对比。这一优势带来了显著的开发效率提升：\n\n*   **高效集成**：例如，将旋转位置嵌入（Rotary Position Embeddings, RoPE）功能集成到 AXLearn 的数百个模块中，仅需约10行代码，而其他系统可能需要数百行代码。\n\n### 性能表现\n\n尽管专注于模块化和易用性，AXLearn 在性能方面仍能与当前最先进的训练系统保持同等水平，确保了训练效率不打折扣。\n\n### 开发与运营经验\n\n文章还分享了 AXLearn 在开发和实际运营中的经验，为未来的系统设计和改进提供了宝贵的见解。\n\n### 相关信息\n\n*   **主题**：机器学习 (cs.LG)\n*   **引用**：arXiv:2507.05411 [cs.LG]",
      "shortSummary": "AXLearn是一个生产级深度学习系统，专注于大型模型的模块化和异构基础设施训练。它通过严格封装的接口实现高模块化，并引入LoC-复杂度量化方法，证明了其在组件扩展时能保持常数复杂度，显著简化了功能集成（如RoPE仅需10行代码）。同时，AXLearn保持了与最先进系统相当的性能，提升了开发效率和灵活性。",
      "translated_title": "AXLearn：异构基础设施上的模块化大型模型训练",
      "images": [],
      "contentSource": "完整文章",
      "content": "We design and implement AXLearn, a production deep learning system that facilitates scalable and high-performance training of large deep learning models. Compared to other state-of-the-art deep learning systems, AXLearn has a unique focus on modularity and support for heterogeneous hardware infrastructure. AXLearn's internal interfaces between software components follow strict encapsulation, allowing different components to be assembled to facilitate rapid model development and experimentation on heterogeneous compute infrastructure. We introduce a novel method of quantifying modularity via Lines-of-Code (LoC)-complexity, which demonstrates how our system maintains constant complexity as we scale the components in the system, compared to linear or quadratic complexity in other systems. This allows integrating features such as Rotary Position Embeddings (RoPE) into AXLearn across hundred of modules with just 10 lines of code, compared to hundreds as required in other systems. At the same time, AXLearn maintains equivalent performance compared to state-of-the-art training systems. Finally, we share our experience in the development and operation of AXLearn."
    },
    {
      "title": "StreamVLN：通过慢快上下文建模实现的流式视觉-语言导航 (原标题: StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling)",
      "link": "https://arxiv.org/abs/2507.05240",
      "pubDate": "Mon, 07 Jul 2025 13:49:41 GMT",
      "isoDate": "2025-07-07T13:49:41.000Z",
      "creator": "Meng Wei, Chenyang Wan, Xiqian Yu, Tai Wang, Yuqiang Yang, Xiaohan Mao, Chenming Zhu, Wenzhe Cai, Hanqing Wang, Yilun Chen, Xihui Liu, Jiangmiao Pang",
      "summary": "## StreamVLN：流式视觉-语言导航框架\n\n### 核心挑战\n\n在真实世界环境中，视觉-语言导航（VLN）要求智能体能够处理连续的视觉流，并根据语言指令以低延迟生成动作。尽管基于视频的大型语言模型（Video-LLMs）推动了近期进展，但当前的VLN方法在细粒度视觉理解、长期上下文建模和计算效率之间往往面临权衡。\n\n### StreamVLN的解决方案\n\nStreamVLN是一个流式VLN框架，它采用混合的“慢快（SlowFast）”上下文建模策略，以支持对交错的视觉、语言和动作输入进行多模态推理。\n\n### 慢快上下文建模策略\n\n1.  **快速流式对话上下文（Fast-streaming Dialogue Context）**：\n    *   通过一个活跃对话的滑动窗口来促进响应式动作生成。\n\n2.  **慢速更新记忆上下文（Slow-updating Memory Context）**：\n    *   使用3D感知令牌剪枝策略来压缩历史视觉状态。\n\n### 主要优势\n\n*   **连贯的多轮对话**：通过高效的KV缓存重用实现。\n*   **支持长视频流**：在上下文大小和推理成本受限的情况下。\n*   **稳定低延迟**：确保在实际部署中的鲁棒性和效率。\n\n### 实验结果\n\n在VLN-CE基准测试中，StreamVLN展示了最先进的性能，并保持了稳定的低延迟，从而确保了在真实世界部署中的鲁棒性和效率。",
      "shortSummary": "StreamVLN是一个创新的流式视觉-语言导航（VLN）框架，旨在解决现有Video-LLM方法在细粒度理解、长期上下文和效率之间的权衡。它采用独特的“慢快”上下文建模策略，通过快速流式对话和慢速更新记忆来高效处理视觉和语言输入。该设计实现了连贯的多轮对话、支持长视频流，并在VLN-CE基准测试中取得了最先进的性能和稳定的低延迟，提升了真实世界部署的鲁棒性和效率。",
      "translated_title": "StreamVLN：通过慢快上下文建模实现的流式视觉-语言导航",
      "images": [],
      "contentSource": "完整文章",
      "content": "Vision-and-Language Navigation (VLN) in real-world settings requires agents to process continuous visual streams and generate actions with low latency grounded in language instructions. While Video-based Large Language Models (Video-LLMs) have driven recent progress, current VLN methods based on Video-LLM often face trade-offs among fine-grained visual understanding, long-term context modeling and computational efficiency. We introduce StreamVLN, a streaming VLN framework that employs a hybrid slow-fast context modeling strategy to support multi-modal reasoning over interleaved vision, language and action inputs. The fast-streaming dialogue context facilitates responsive action generation through a sliding-window of active dialogues, while the slow-updating memory context compresses historical visual states using a 3D-aware token pruning strategy. With this slow-fast design, StreamVLN achieves coherent multi-turn dialogue through efficient KV cache reuse, supporting long video streams with bounded context size and inference cost. Experiments on VLN-CE benchmarks demonstrate state-of-the-art performance with stable low latency, ensuring robustness and efficiency in real-world deployment. The project page is: https://streamvln.github.io/{https://streamvln.github.io/}."
    },
    {
      "title": "PRING：重新思考蛋白质-蛋白质相互作用预测：从对到图 (原标题: PRING: Rethinking Protein-Protein Interaction Prediction from Pairs to Graphs)",
      "link": "https://arxiv.org/abs/2507.05101",
      "pubDate": "Mon, 07 Jul 2025 11:21:05 GMT",
      "isoDate": "2025-07-07T11:21:05.000Z",
      "creator": "Xinzhe Zheng, Hao Du, Fanding Xu, Jinzhe Li, Zhiyuan Liu, Wenkang Wang, Tao Chen, Wanli Ouyang, Stan Z. Li, Yan Lu, Nanqing Dong, Yang Zhang",
      "summary": "## PRING：重新思考蛋白质-蛋白质相互作用预测：从对到图\n\n### 引言：现有PPI预测方法的局限性\n\n深度学习在蛋白质-蛋白质相互作用（PPI）预测方面取得了显著进展。然而，现有基准测试主要侧重于孤立的成对评估，忽视了模型重建具有生物学意义的PPI网络的能力。这种网络重建能力对于生物学研究至关重要，但目前的方法未能充分解决这一需求。\n\n### PRING的引入：解决现有问题\n\n为了弥补这一空白，研究人员引入了PRING，这是首个从图级别视角评估蛋白质-蛋白质相互作用预测的综合基准。PRING旨在提供一个更全面、更贴近实际生物学应用的评估平台。\n\n### PRING数据集：高质量与多物种\n\nPRING精心策划了一个高质量、多物种的PPI网络数据集，包含：\n*   **蛋白质数量**：21,484个\n*   **相互作用数量**：186,818个\n\n该数据集设计了精良的策略，以解决数据冗余和数据泄露问题，确保了数据的可靠性和评估的公正性。\n\n### PRING评估范式：拓扑导向与功能导向\n\n基于这一“黄金标准”数据集，PRING建立了两种互补的评估范式：\n\n1.  **拓扑导向任务**：\n    *   评估物种内和跨物种的PPI网络构建能力。\n    *   旨在反映模型对网络拓扑结构的理解能力。\n\n2.  **功能导向任务**：\n    *   蛋白质复合物通路预测。\n    *   GO（基因本体论）模块分析。\n    *   必需蛋白质鉴定。\n    *   这些任务不仅反映了模型理解网络拓扑的能力，还有助于蛋白质功能注释、生物模块检测，甚至疾病机制分析。\n\n### 实验结果：当前模型的局限性\n\n研究人员对四类代表性模型进行了广泛实验，包括：\n*   基于序列相似性的方法\n*   朴素的基于序列的方法\n*   基于蛋白质语言模型的方法\n*   基于结构的方法\n\n实验结果表明，当前的PPI模型在恢复PPI网络的结构和功能特性方面存在潜在局限性。这突出表明，现有模型在支持真实世界生物学应用方面仍存在差距。\n\n### 结论与展望：PRING的贡献\n\n研究人员相信，PRING为社区提供了一个可靠的平台，以指导开发更有效的PPI预测模型。它将推动该领域的研究，使其更贴近生物学实际需求。\n\n### 资源可用性\n\nPRING的数据集和源代码已公开提供。",
      "shortSummary": "PRING是一个新的综合基准，旨在从图级别重新评估蛋白质-蛋白质相互作用（PPI）预测，以弥补现有成对评估的不足。它构建了一个包含21,484个蛋白质和186,818个相互作用的高质量多物种PPI数据集，并建立了拓扑导向和功能导向两种评估范式。实验结果显示，当前PPI模型在恢复网络结构和功能特性方面存在局限性，表明与实际生物学应用存在差距。PRING旨在指导更有效PPI预测模型的开发。",
      "translated_title": "PRING：重新思考蛋白质-蛋白质相互作用预测：从对到图",
      "images": [],
      "contentSource": "完整文章",
      "content": "Deep learning-based computational methods have achieved promising results in predicting protein-protein interactions (PPIs). However, existing benchmarks predominantly focus on isolated pairwise evaluations, overlooking a model's capability to reconstruct biologically meaningful PPI networks, which is crucial for biology research. To address this gap, we introduce PRING, the first comprehensive benchmark that evaluates protein-protein interaction prediction from a graph-level perspective. PRING curates a high-quality, multi-species PPI network dataset comprising 21,484 proteins and 186,818 interactions, with well-designed strategies to address both data redundancy and leakage. Building on this golden-standard dataset, we establish two complementary evaluation paradigms: (1) topology-oriented tasks, which assess intra and cross-species PPI network construction, and (2) function-oriented tasks, including protein complex pathway prediction, GO module analysis, and essential protein justification. These evaluations not only reflect the model's capability to understand the network topology but also facilitate protein function annotation, biological module detection, and even disease mechanism analysis. Extensive experiments on four representative model categories, consisting of sequence similarity-based, naive sequence-based, protein language model-based, and structure-based approaches, demonstrate that current PPI models have potential limitations in recovering both structural and functional properties of PPI networks, highlighting the gap in supporting real-world biological applications. We believe PRING provides a reliable platform to guide the development of more effective PPI prediction models for the community. The dataset and source code of PRING are available at https://github.com/SophieSarceau/PRING."
    },
    {
      "title": "LOOM-Scope：一个全面高效的长上下文模型评估框架 (原标题: LOOM-Scope: a comprehensive and efficient LOng-cOntext Model evaluation framework)",
      "link": "https://arxiv.org/abs/2507.04723",
      "pubDate": "Mon, 07 Jul 2025 03:33:24 GMT",
      "isoDate": "2025-07-07T03:33:24.000Z",
      "creator": "Zecheng Tang, Haitian Wang, Quantong Qiu, Baibei Ji, Ruoxi Sun, Keyan Zhou, Juntao Li, Min Zhang",
      "summary": "## LOOM-Scope：长上下文模型评估框架\n\n### 背景与挑战\n\n大型语言模型（LLMs）的长上下文处理能力已成为其核心功能。为了评估模型在此方面的表现，研究界提出了许多长上下文评估基准。然而，这些基准在评估设置上存在差异，导致结果不一致，难以进行可靠的模型比较。此外，长上下文评估的高计算成本也给社区全面评估长上下文模型带来了显著障碍。\n\n### LOOM-Scope 框架\n\n为了解决上述问题，本文提出了 **LOOM-Scope**，一个全面且高效的长上下文评估框架。LOOM-Scope 旨在提供一个标准化的解决方案，以克服现有评估方法的局限性。其主要特点包括：\n\n*   **标准化评估设置**：LOOM-Scope 统一了不同基准之间的评估设置，确保评估结果的一致性和可比性。\n*   **支持高效推理加速**：该框架支持部署高效的长上下文推理加速方法，从而显著降低评估所需的计算成本。\n\n*   **全面且轻量级的基准套件**：LOOM-Scope 引入了一个整体但轻量级的基准套件，用于对模型进行全面评估，同时保持评估过程的效率。",
      "shortSummary": "本文提出了LOOM-Scope，一个全面高效的长上下文模型评估框架。针对现有长上下文评估基准设置不一致和计算成本高昂的问题，LOOM-Scope通过标准化评估设置、支持高效推理加速方法，并引入轻量级基准套件，旨在提供一个更可靠、更经济的LLM长上下文性能评估方案。",
      "translated_title": "LOOM-Scope：一个全面高效的长上下文模型评估框架",
      "images": [],
      "contentSource": "完整文章",
      "content": "Long-context processing has become a fundamental capability for large language models~(LLMs). To assess model's long-context performance, numerous long-context evaluation benchmarks have been proposed. However, variations in evaluation settings across these benchmarks lead to inconsistent results, making it difficult to draw reliable comparisons. Besides, the high computational cost of long-context evaluation poses a significant barrier for the community to conduct comprehensive assessments of long-context models. In this paper, we propose LOOM-Scope, a comprehensive and efficient framework for long-context evaluation. LOOM-Scope standardizes evaluation settings across diverse benchmarks, supports deployment of efficient long-context inference acceleration methods, and introduces a holistic yet lightweight benchmark suite to evaluate models comprehensively. Homepage: https://loomscope.github.io"
    },
    {
      "title": "any4：LLM的学习型4比特数值表示 (原标题: any4: Learned 4-bit Numeric Representation for LLMs)",
      "link": "https://arxiv.org/abs/2507.04610",
      "pubDate": "Sun, 06 Jul 2025 21:59:47 GMT",
      "isoDate": "2025-07-06T21:59:47.000Z",
      "creator": "Mostafa Elhoushi, Jeff Johnson",
      "summary": "any4是一种针对大型语言模型（LLM）的创新性4比特权重量化解决方案。该方法提供任意数值表示，且无需对权重或激活进行预处理。\n\n**主要特性与优势：**\n\n*   **卓越的准确性**：在对Llama 2、Llama 3、Mistral和Mixtral等多种模型尺寸、代际和家族进行评估后，any4展现出比其他相关4比特数值表示类型（如int4、fp4和nf4）更高的准确性。\n*   **无需预处理**：any4无需对权重或激活进行预处理，同时仍能与需要此类预处理的正交技术（如AWQ和GPTQ）保持竞争力。\n*   **低比特量化能力**：研究还扩展到any3和any2，并展示了在更低比特率下的竞争力。\n*   **高效校准**：any4的校准过程仅需一个精心策划的多元样本，这与大多数量化方法通常需要来自数据集的数百个样本形成鲜明对比。\n\n**开源贡献：**\n\n*   **tinygemm库**：该项目还开源了tinygemm，这是一个针对LLM的延迟优化GPU矩阵乘法库。\n*   **实现策略**：tinygemm使用GPU高效的查找表策略来实现any4，并支持其他常见的量化方法。\n*   **代码可用性**：相关代码已开源。\n\n**背景信息：**\n\n*   该研究已提交至ICML 2025。\n*   文章可在arXiv上查阅，引用号为arXiv:2507.04610。",
      "shortSummary": "any4是一种创新的4比特权重量化解决方案，专为大型语言模型（LLM）设计。它提供任意数值表示，无需预处理权重或激活，并在多种LLM上展现出比现有4比特方法更高的准确性。any4仅需少量样本即可完成校准，并与需要预处理的技术具有竞争力。此外，项目还开源了用于GPU矩阵乘法的优化库tinygemm。",
      "translated_title": "any4：LLM的学习型4比特数值表示",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present any4, a learned 4-bit weight quantization solution for large language models (LLMs) providing arbitrary numeric representations without requiring pre-processing of weights or activations. any4 yields higher accuracy compared to other related 4-bit numeric representation types: int4, fp4 and nf4, as evaluated on a range of model sizes, generations and families (Llama 2, Llama 3, Mistral and Mixtral). While any4 does not require preprocessing of weights or activations, it is also competitive with orthogonal techniques that require such preprocessing (e.g., AWQ and GPTQ). We also experiment with any3 and any2 and show competitiveness at lower bits. Additionally, we show that we can calibrate using a single curated diverse sample rather than hundreds of samples from a dataset as done in most quantization approaches. We also open source tinygemm, a latency optimized GPU matrix multiplication library for LLMs, that implements any4 using a GPU-efficient lookup table strategy along with other common quantization methods. We open source our code at https://github.com/facebookresearch/any4 ."
    },
    {
      "title": "Nile-Chat：适用于阿拉伯语和拉丁语脚本的埃及语言模型 (原标题: Nile-Chat: Egyptian Language Models for Arabic and Latin Scripts)",
      "link": "https://arxiv.org/abs/2507.04569",
      "pubDate": "Sun, 06 Jul 2025 18:53:41 GMT",
      "isoDate": "2025-07-06T18:53:41.000Z",
      "creator": "Guokan Shang, Hadi Abdine, Ahmad Chamma, Amr Mohamed, Mohamed Anwar, Abdelaziz Bounhar, Omar El Herraoui, Preslav Nakov, Michalis Vazirgiannis, Eric Xing",
      "summary": "# Nile-Chat：适用于阿拉伯语和拉丁语脚本的埃及语言模型\n\n## 概述\n本文介绍了Nile-Chat系列大型语言模型（LLMs），包括Nile-Chat-4B、3x4B-A6B和12B。这些模型专为埃及方言设计，并具有独特的能力，能够理解和生成阿拉伯语和拉丁语两种脚本的文本。\n\n## 核心创新与方法\n*   **双脚本支持：** Nile-Chat模型的核心特点是其能够同时处理阿拉伯语和拉丁语脚本，这在现代LLM开发中是一个经常被忽视的方面。\n*   **Branch-Train-MiX策略：** 特别是Nile-Chat-3x4B-A6B模型，引入了一种新颖的语言适应方法。该方法利用Branch-Train-MiX策略，将专门针对不同脚本的专家模型融合到一个单一的MoE（Mixture of Experts）模型中。\n\n## 性能表现\n*   **超越现有模型：** Nile-Chat模型在作者新引入的埃及语评估基准测试中（涵盖理解和生成任务），显著优于领先的多语言和阿拉伯语LLMs，例如LLaMa、Jais和ALLaM。\n*   **拉丁语脚本优势：** 值得注意的是，Nile-Chat 12B模型在拉丁语脚本基准测试上，比Qwen2.5-14B-Instruct模型取得了14.4%的性能提升。\n\n## 资源可用性与意义\n*   **公开可用：** 所有Nile-Chat资源均已公开。\n*   **方法论贡献：** 作者认为这项工作为将LLMs适应双脚本语言提供了一套全面的方法论，填补了当前LLM开发中的一个空白。\n\n## 相关主题\n*   计算与语言 (cs.CL)\n*   人工智能 (cs.AI)\n*   机器学习 (cs.LG)",
      "shortSummary": "Nile-Chat系列（4B、3x4B-A6B、12B）是专为埃及方言设计的大型语言模型，独特之处在于能理解和生成阿拉伯语及拉丁语两种脚本的文本。其中，Nile-Chat-3x4B-A6B采用Branch-Train-MiX策略融合脚本专家。这些模型在埃及语基准测试中显著超越了LLaMa、Jais和ALLaM等现有模型，其12B模型在拉丁语脚本上比Qwen2.5-14B-Instruct提升14.4%。所有资源均已公开，为双脚本语言的LLM适应提供了全面方法。",
      "translated_title": "Nile-Chat：适用于阿拉伯语和拉丁语脚本的埃及语言模型",
      "images": [],
      "contentSource": "完整文章",
      "content": "We introduce Nile-Chat-4B, 3x4B-A6B, and 12B, a collection of LLMs for Egyptian dialect, uniquely designed to understand and generate texts written in both Arabic and Latin scripts. Specifically, with Nile-Chat-3x4B-A6B, we introduce a novel language adaptation approach by leveraging the Branch-Train-MiX strategy to merge script-specialized experts, into a single MoE model. Our Nile-Chat models significantly outperform leading multilingual and Arabic LLMs, such as LLaMa, Jais, and ALLaM, on our newly introduced Egyptian evaluation benchmarks, which span both understanding and generative tasks. Notably, our 12B model yields a 14.4% performance gain over Qwen2.5-14B-Instruct on Latin-script benchmarks. All our resources are publicly available. We believe this work presents a comprehensive methodology for adapting LLMs to dual-script languages, addressing an often overlooked aspect in modern LLM development."
    },
    {
      "title": "如何训练你的LLM网络代理：一项统计诊断 (原标题: How to Train Your LLM Web Agent: A Statistical Diagnosis)",
      "link": "https://arxiv.org/abs/2507.04103",
      "pubDate": "Sat, 05 Jul 2025 13:12:33 GMT",
      "isoDate": "2025-07-05T13:12:33.000Z",
      "creator": "Dheeraj Vattikonda, Santhoshi Ravichandran, Emiliano Penaloza, Hadi Nekoei, Megh Thakkar, Thibault Le Sellier de Chezelles, Nicolas Gontier, Miguel Muñoz-Mármol, Sahar Omidi Shayegan, Stefania Raimondo, Xue Liu, Alexandre Drouin, Laurent Charlin, Alexandre Piché, Alexandre Lacoste, Massimo Caccia",
      "summary": "## 如何训练你的LLM网络代理：一项统计诊断\n\n### 摘要\n\n本文针对当前LLM（大型语言模型）网络代理在开源领域面临的挑战，提出了一项关于计算资源分配的统计学研究，旨在优化LLM网络代理的后训练过程。\n\n### 当前挑战\n\nLLM网络代理在闭源系统中取得了显著进展，但开源替代方案的进步受限于两大关键挑战：\n\n*   **任务范围狭窄**：过度关注单步任务，忽视了多步网络交互的复杂性。\n*   **高计算成本**：LLM网络代理的后训练需要高昂的计算资源。\n\n### 解决方案与方法\n\n为了解决这些问题，作者团队提出了首个基于统计学的计算分配研究，用于LLM网络代理的后训练。其方法采用两阶段流水线：\n\n1.  **监督微调（SFT）**：训练一个Llama 3.1 8B学生模型，使其模仿一个Llama 3.3 70B教师模型。\n2.  **在策略强化学习（on-policy RL）**：在SFT之后进行。\n\n该研究发现，此过程对超参数选择高度敏感，使得穷举搜索不切实际。为避免昂贵的试错，研究人员采样了1,370种配置，并使用自举法（bootstrapping）来估计有效的超参数。\n\n### 主要发现与成果\n\n研究结果表明：\n\n*   **性能提升**：将SFT与在策略强化学习相结合，在WorkArena和MiniWob++数据集上始终优于单独使用任何一种方法。\n*   **计算效率**：这种组合策略在MiniWob++上仅需55%的计算资源，即可达到纯SFT的峰值性能，有效推动了计算-性能的帕累托前沿。\n*   **缩小差距**：该策略是唯一能够缩小与闭源模型之间差距的方法。",
      "shortSummary": "本文提出了一项统计学研究，旨在优化开源LLM网络代理的训练效率。研究发现，将监督微调（SFT）与在策略强化学习（on-policy RL）相结合，能显著提升LLM网络代理的性能，并在MiniWob++数据集上仅用55%的计算资源即可达到纯SFT的峰值表现。这种方法不仅推动了计算-性能的帕累托前沿，也是唯一能缩小与闭源模型差距的策略。",
      "translated_title": "如何训练你的LLM网络代理：一项统计诊断",
      "images": [],
      "contentSource": "完整文章",
      "content": "LLM-based web agents have recently made significant progress, but much of it has occurred in closed-source systems, widening the gap with open-source alternatives. Progress has been held back by two key challenges: first, a narrow focus on single-step tasks that overlooks the complexity of multi-step web interactions; and second, the high compute costs required to post-train LLM-based web agents. To address this, we present the first statistically grounded study on compute allocation for LLM web-agent post-training. Our approach uses a two-stage pipeline, training a Llama 3.1 8B student to imitate a Llama 3.3 70B teacher via supervised fine-tuning (SFT), followed by on-policy reinforcement learning. We find this process highly sensitive to hyperparameter choices, making exhaustive sweeps impractical. To spare others from expensive trial-and-error, we sample 1,370 configurations and use bootstrapping to estimate effective hyperparameters. Our results show that combining SFT with on-policy RL consistently outperforms either approach alone on both WorkArena and MiniWob++. Further, this strategy requires only 55% of the compute to match the peak performance of pure SFT on MiniWob++, effectively pushing the compute-performance Pareto frontier, and is the only strategy that can close the gap with closed-source models."
    }
  ],
  "lastUpdated": "2025-07-09T09:36:51.096Z"
}
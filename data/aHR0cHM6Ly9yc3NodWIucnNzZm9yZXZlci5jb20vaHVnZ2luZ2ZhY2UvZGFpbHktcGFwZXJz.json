{
  "sourceUrl": "https://rsshub.rssforever.com/huggingface/daily-papers",
  "title": "Huggingface Daily Papers",
  "description": "Huggingface Daily Papers - Powered by RSSHub",
  "link": "https://huggingface.co/papers",
  "items": [
    {
      "title": "4KAgent：代理式任意图像4K超分辨率 (原标题: 4KAgent: Agentic Any Image to 4K Super-Resolution)",
      "link": "https://arxiv.org/abs/2507.07105",
      "pubDate": "Wed, 09 Jul 2025 13:59:19 GMT",
      "isoDate": "2025-07-09T13:59:19.000Z",
      "creator": "Yushen Zuo, Qi Zheng, Mingyang Wu, Xinrui Jiang, Renjie Li, Jian Wang, Yide Zhang, Gengchen Mai, Lihong V. Wang, James Zou, Xiaoyu Wang, Ming-Hsuan Yang, Zhengzhong Tu",
      "summary": "## 4KAgent：代理式任意图像4K超分辨率系统\n\n4KAgent是一个统一的、代理式的超分辨率通用系统，旨在将任意图像普遍提升至4K分辨率，甚至通过迭代应用可达到更高分辨率。该系统能够将来自极低分辨率且严重退化的输入（例如256x256的高度扭曲图像）转换为晶莹剔透、照片般逼真的4K输出。\n\n### 核心组件\n4KAgent由三个核心组件构成，协同工作以实现高质量的图像超分辨率：\n\n1.  **Profiling（分析模块）**：\n    *   根据特定的用例需求，定制4KAgent的管道流程，确保系统能够适应不同的应用场景。\n\n2.  **Perception Agent（感知代理）**：\n    *   利用视觉-语言模型（VLM）和图像质量评估专家，对输入图像进行深入分析。\n    *   根据分析结果，制定量身定制的图像修复计划，为后续的修复工作提供指导。\n\n3.  **Restoration Agent（修复代理）**：\n    *   执行由感知代理制定的修复计划。\n    *   遵循递归式的执行-反思范式，即在每一步执行后进行评估和调整。\n    *   由质量驱动的专家混合策略（mixture-of-expert policy）指导，以在每一步中选择最优的输出结果。\n\n### 特色功能\n*   **专业面部修复管道**：4KAgent内置了一个专门的面部修复管道，显著增强了肖像和自拍照片中的面部细节，提升了人像图像的质量。\n\n### 性能评估\n*   **广泛的评估范围**：研究人员对4KAgent进行了严格的评估，涵盖了11个不同的任务类别，总计26个多样化的基准测试。\n*   **领先的性能**：在广泛的成像领域（包括自然图像、肖像照片、AI生成内容、卫星图像、荧光显微镜以及眼底镜、超声波和X射线等医学影像）中，4KAgent均达到了新的最先进水平（state-of-the-art）。\n*   **综合指标表现**：在感知指标（如NIQE、MUSIQ）和保真度指标（如PSNR）方面均表现出卓越的性能。\n\n### 意义与展望\n通过为低级视觉任务建立一种新颖的代理范式，4KAgent旨在激发不同研究社区对以视觉为中心的自主代理的更广泛兴趣和创新。",
      "shortSummary": "4KAgent是一个统一的代理式超分辨率系统，旨在将任意图像（包括低分辨率和严重退化的图像）提升至4K分辨率。它由Profiling、感知代理和修复代理三个核心组件构成，并内置了专门的面部修复功能。该系统在11个任务类别、26个基准测试中表现出色，在自然图像、医学影像等多个领域达到了最先进水平，为低级视觉任务开创了新的代理范式。",
      "translated_title": "4KAgent：代理式任意图像4K超分辨率",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present 4KAgent, a unified agentic super-resolution generalist system designed to universally upscale any image to 4K resolution (and even higher, if applied iteratively). Our system can transform images from extremely low resolutions with severe degradations, for example, highly distorted inputs at 256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three core components: (1) Profiling, a module that customizes the 4KAgent pipeline based on bespoke use cases; (2) A Perception Agent, which leverages vision-language models alongside image quality assessment experts to analyze the input image and make a tailored restoration plan; and (3) A Restoration Agent, which executes the plan, following a recursive execution-reflection paradigm, guided by a quality-driven mixture-of-expert policy to select the optimal output for each step. Additionally, 4KAgent embeds a specialized face restoration pipeline, significantly enhancing facial details in portrait and selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task categories encompassing a total of 26 diverse benchmarks, setting new state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover natural images, portrait photos, AI-generated content, satellite imagery, fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and X-ray, demonstrating superior performance in terms of both perceptual (e.g., NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic paradigm for low-level vision tasks, we aim to catalyze broader interest and innovation within vision-centric autonomous agents across diverse research communities. We will release all the code, models, and results at: https://4kagent.github.io."
    },
    {
      "title": "走向零：利用百万级数据实现零样本运动生成 (原标题: Go to Zero: Towards Zero-shot Motion Generation with Million-scale Data)",
      "link": "https://arxiv.org/abs/2507.07095",
      "pubDate": "Wed, 09 Jul 2025 13:52:04 GMT",
      "isoDate": "2025-07-09T13:52:04.000Z",
      "creator": "Ke Fan, Shunlin Lu, Minyue Dai, Runyi Yu, Lixing Xiao, Zhiyang Dou, Junting Dong, Lizhuang Ma, Jingbo Wang",
      "summary": "### 走向零：利用百万级数据实现零样本运动生成\n\n#### 引言与背景\n文本描述生成多样化、自然的人体运动序列是计算机视觉、图形学和机器人学领域一个基础且极具挑战性的研究方向。尽管该领域取得了显著进展，但现有方法在零样本泛化能力方面仍面临挑战，这主要归因于训练数据集规模的限制。此外，缺乏全面的评估框架也阻碍了该任务的进一步发展，未能有效指明改进方向。\n\n#### 研究目标\n本研究旨在将文本到运动生成领域推向一个新时代，即实现零样本泛化能力。\n\n#### 主要贡献与方法\n为了实现这一目标，本研究提出了以下关键贡献：\n\n*   **高效标注流程的开发**\n    研究团队开发了一种高效的标注流程，为大规模数据收集奠定了基础。\n\n*   **MotionMillion数据集的引入**\n    本研究引入了迄今为止最大的人体运动数据集——**MotionMillion**。该数据集包含超过2000小时和200万条高质量的运动序列，极大地扩充了可用于训练的数据规模，从而有望提升模型的泛化能力。\n\n*   **MotionMillion-Eval评估基准的提出**\n    为了解决评估框架不足的问题，研究团队提出了**MotionMillion-Eval**，这是目前最全面的零样本运动生成评估基准。该基准旨在更准确地衡量模型在未知或复杂场景下的泛化表现。\n\n*   **可扩展架构与大规模模型训练**\n    研究利用一种可扩展的架构，将模型参数规模扩展至70亿（7B）。这种大规模的模型训练旨在充分利用MotionMillion数据集的丰富信息，进一步提升模型的性能和泛化能力。\n\n#### 实验与结果\n研究团队在MotionMillion-Eval基准上验证了所提出模型的性能。结果表明，该模型在处理域外（out-of-domain）和复杂组合运动（complex compositional motions）方面展现出强大的泛化能力。这标志着在实现零样本人体运动生成方面迈出了重要一步。\n\n#### 结论\n本研究通过构建大规模数据集、提出全面的评估基准以及训练大规模模型，显著推动了文本到运动生成领域向零样本泛化能力迈进。",
      "shortSummary": "该研究旨在解决文本到运动生成中零样本泛化能力不足的问题。通过构建迄今最大的MotionMillion数据集（包含200万运动序列）和最全面的MotionMillion-Eval评估基准，并利用可扩展架构将模型扩展至70亿参数，研究团队显著提升了模型对域外和复杂组合运动的泛化能力。这标志着零样本人体运动生成领域取得了重要进展。",
      "translated_title": "走向零：利用百万级数据实现零样本运动生成",
      "images": [],
      "contentSource": "完整文章",
      "content": "Generating diverse and natural human motion sequences based on textual descriptions constitutes a fundamental and challenging research area within the domains of computer vision, graphics, and robotics. Despite significant advancements in this field, current methodologies often face challenges regarding zero-shot generalization capabilities, largely attributable to the limited size of training datasets. Moreover, the lack of a comprehensive evaluation framework impedes the advancement of this task by failing to identify directions for improvement. In this work, we aim to push text-to-motion into a new era, that is, to achieve the generalization ability of zero-shot. To this end, firstly, we develop an efficient annotation pipeline and introduce MotionMillion-the largest human motion dataset to date, featuring over 2,000 hours and 2 million high-quality motion sequences. Additionally, we propose MotionMillion-Eval, the most comprehensive benchmark for evaluating zero-shot motion generation. Leveraging a scalable architecture, we scale our model to 7B parameters and validate its performance on MotionMillion-Eval. Our results demonstrate strong generalization to out-of-domain and complex compositional motions, marking a significant step toward zero-shot human motion generation. The code is available at https://github.com/VankouF/MotionMillion-Codes."
    },
    {
      "title": "首次返回，熵启发式探索 (原标题: First Return, Entropy-Eliciting Explore)",
      "link": "https://arxiv.org/abs/2507.07017",
      "pubDate": "Wed, 09 Jul 2025 12:45:48 GMT",
      "isoDate": "2025-07-09T12:45:48.000Z",
      "creator": "Tianyu Zheng, Tianshun Xing, Qingshui Gu, Taoran Liang, Xingwei Qu, Xin Zhou, Yizhi Li, Zhoufutu Wen, Chenghua Lin, Wenhao Huang, Qian Liu, Ge Zhang, Zejun Ma",
      "summary": "## FR3E：一种用于LLM推理的结构化探索框架\n\n### 摘要\n\n本文介绍了FR3E（First Return, Entropy-Eliciting Explore），一个旨在解决大型语言模型（LLMs）在强化学习从可验证奖励（RLVR）中探索不稳定问题的结构化探索框架。\n\n### 背景与问题\n\n*   **强化学习从可验证奖励（RLVR）**：该方法能够有效提升大型语言模型（LLMs）的推理能力。\n*   **主要挑战**：RLVR在实际应用中面临探索不稳定的问题，这限制了其在复杂推理任务中的表现。\n\n### FR3E 方法介绍\n\n*   **核心理念**：FR3E，即“首次返回，熵启发式探索”，提出了一种新颖的结构化探索框架，旨在提供更稳定和有针对性的探索。\n*   **工作原理**：\n    *   **识别高不确定性决策点**：该框架能够识别推理轨迹中那些具有高不确定性的决策点。\n    *   **执行有针对性的Rollouts**：针对这些不确定点，FR3E会执行有目标的“rollouts”（展开），以收集更多信息。\n    *   **构建语义接地中间反馈**：通过这些rollouts，系统能够构建出语义上接地（semantically grounded）的中间反馈。\n    *   **无需密集监督**：FR3E的独特之处在于，它能够在不依赖密集监督的情况下提供有针对性的指导，从而降低了对大量标注数据的需求。\n\n### 实验结果\n\n*   **基准测试**：FR3E在数学推理基准（AIME24）上进行了实证评估。\n*   **主要发现**：\n    *   **训练稳定性**：FR3E显著促进了更稳定的模型训练。\n    *   **响应质量**：模型能够生成更长、更连贯的响应。\n    *   **正确轨迹比例**：完全正确推理轨迹的比例有所增加。\n\n### 结论\n\n这些实证结果充分证明了FR3E框架的有效性。通过提供更鲁棒和结构化的探索机制，FR3E成功提升了大型语言模型的推理能力。\n\n### 作者与引用信息\n\n*   **作者**：Tianyu Zheng, Tianshun Xing, Qingshui Gu, Taoran Liang, Xingwei Qu, Xin Zhou, Yizhi Li, Zhoufutu Wen, Chenghua Lin, Wenhao Huang, Qian Liu, Ge Zhang, Zejun Ma\n*   **研究领域**：人工智能 (cs.AI)\n*   **引用**：arXiv:2507.07017 [cs.AI]\n*   **提交历史**：2025年7月9日星期三 16:45:48 UTC",
      "shortSummary": "FR3E (First Return, Entropy-Eliciting Explore) 旨在解决大型语言模型（LLMs）在强化学习中探索不稳定的问题。它通过识别高不确定性决策点并进行有针对性的rollouts，构建语义接地中间反馈，提供指导。在数学推理基准（AIME24）上的实验表明，FR3E促进了更稳定的训练，生成了更长、更连贯的响应，并提高了完全正确轨迹的比例，有效提升了LLM的推理能力。",
      "translated_title": "首次返回，熵启发式探索",
      "images": [],
      "contentSource": "完整文章",
      "content": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning abilities of Large Language Models (LLMs) but it struggles with unstable exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a structured exploration framework that identifies high-uncertainty decision points in reasoning trajectories and performs targeted rollouts to construct semantically grounded intermediate feedback. Our method provides targeted guidance without relying on dense supervision. Empirical results on mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable training, produces longer and more coherent responses, and increases the proportion of fully correct trajectories. These results highlight the framework's effectiveness in improving LLM reasoning through more robust and structured exploration."
    },
    {
      "title": "重新思考LLM代码生成的验证：从生成到测试 (原标题: Rethinking Verification for LLM Code Generation: From Generation to Testing)",
      "link": "https://arxiv.org/abs/2507.06920",
      "pubDate": "Wed, 09 Jul 2025 10:58:47 GMT",
      "isoDate": "2025-07-09T10:58:47.000Z",
      "creator": "Zihan Ma, Taolin Zhang, Maosong Cao, Wenwei Zhang, Minnan Luo, Songyang Zhang, Kai Chen",
      "summary": "## 重新思考LLM代码生成的验证\n\n### 引言与问题背景\n\n大型语言模型（LLM）在HumanEval和LiveCodeBench等代码生成基准测试中取得了显著成功。然而，深入研究发现，这些评估套件通常只包含数量有限且同质的测试用例，导致细微的错误未能被检测出来。这不仅人为地夸大了测量的性能，也损害了在利用可验证奖励的强化学习框架（RLVR）中准确估计奖励的能力。\n\n### 研究目标与方法\n\n为解决这些关键缺陷，本研究系统地调查了测试用例生成（TCG）任务，并提出了以下创新：\n\n*   **多维度指标：** 设计了多维度指标，旨在严格量化测试套件的彻底性。\n*   **SAGA方法：** 引入了一种人机协作方法（SAGA），该方法结合了人类编程专业知识与LLM的推理能力，旨在显著增强生成测试用例的覆盖率和质量。\n*   **TCGBench基准：** 开发了一个名为TCGBench的基准，以促进对TCG任务的研究。\n\n### 实验结果\n\n实验结果证明了所提出方法的有效性：\n\n*   SAGA在TCGBench上实现了90.62%的检测率。\n*   SAGA在TCGBench上实现了32.58%的验证器准确率。\n*   SAGA合成的代码生成评估基准的验证器准确率（Verifier Acc）比LiveCodeBench-v6高10.78%。\n\n### 结论与贡献\n\n这些结果表明了我们所提出方法的有效性。本研究期望能为构建可靠的LLM代码评估提供一个可扩展的基础，进一步推动代码生成领域的RLVR发展，并为自动化对抗性测试合成和自适应基准集成铺平道路。",
      "shortSummary": "本文重新思考LLM代码生成验证，指出现有基准测试用例不足，导致错误未被发现和性能虚报。为解决此问题，研究提出多维度指标量化测试彻底性，并引入人机协作方法SAGA，结合人类专业知识与LLM推理能力，以提升测试用例质量。同时开发了TCGBench。实验表明SAGA在检测率和验证器准确率上表现出色，显著优于现有基准，为可靠的LLM代码评估奠定基础。",
      "translated_title": "重新思考LLM代码生成的验证：从生成到测试",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large language models (LLMs) have recently achieved notable success in code-generation benchmarks such as HumanEval and LiveCodeBench. However, a detailed examination reveals that these evaluation suites often comprise only a limited number of homogeneous test cases, resulting in subtle faults going undetected. This not only artificially inflates measured performance but also compromises accurate reward estimation in reinforcement learning frameworks utilizing verifiable rewards (RLVR). To address these critical shortcomings, we systematically investigate the test-case generation (TCG) task by proposing multi-dimensional metrics designed to rigorously quantify test-suite thoroughness. Furthermore, we introduce a human-LLM collaborative method (SAGA), leveraging human programming expertise with LLM reasoning capability, aimed at significantly enhancing both the coverage and the quality of generated test cases. In addition, we develop a TCGBench to facilitate the study of the TCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a verifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc) of the code generation evaluation benchmark synthesized by SAGA is 10.78% higher than that of LiveCodeBench-v6. These results demonstrate the effectiveness of our proposed method. We hope this work contributes to building a scalable foundation for reliable LLM code evaluation, further advancing RLVR in code generation, and paving the way for automated adversarial test synthesis and adaptive benchmark integration."
    },
    {
      "title": "DiffSpectra：使用扩散模型从光谱中解析分子结构 (原标题: DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models)",
      "link": "https://arxiv.org/abs/2507.06853",
      "pubDate": "Wed, 09 Jul 2025 09:57:20 GMT",
      "isoDate": "2025-07-09T09:57:20.000Z",
      "creator": "Liang Wang, Yu Rong, Tingyang Xu, Zhenyi Zhong, Zhiyuan Liu, Pengju Wang, Deli Zhao, Qiang Liu, Shu Wu, Liang Wang",
      "summary": "# DiffSpectra：基于扩散模型的光谱分子结构解析\n\n本文介绍了 **DiffSpectra**，一个创新的生成式框架，旨在通过扩散模型直接从多模态光谱数据中推断分子的二维（2D）和三维（3D）结构。这项工作解决了化学领域中分子结构解析这一基础性问题所面临的挑战。\n\n## 背景与挑战\n\n*   **传统方法局限性：** 传统的分子结构解析方法高度依赖专家解读，难以扩展到大规模应用。\n*   **现有机器学习方法不足：**\n    *   **基于检索的策略：** 依赖有限的分子库，限制了对新型分子的泛化能力。\n    *   **生成模型（SMILES-based）：** 大多数采用自回归SMILES架构，忽略了分子的3D几何信息，并且难以有效整合多样化的光谱模态。\n\n## DiffSpectra 框架概述\n\nDiffSpectra 将分子结构解析公式化为一个条件生成过程，其核心在于利用扩散模型进行去噪。\n\n### 核心组件\n\n1.  **去噪网络：Diffusion Molecule Transformer**\n    *   该网络参数化为 **Diffusion Molecule Transformer**，这是一种 **SE(3) 等变架构**。\n    *   它能够有效地整合分子的拓扑（2D）和几何（3D）信息，确保在三维空间中的变换不变性。\n\n2.  **条件编码器：SpecFormer**\n    *   条件信息由 **SpecFormer** 提供，这是一个基于 Transformer 的光谱编码器。\n    *   SpecFormer 能够从多模态光谱数据中捕获光谱内部（intra-spectral）和光谱之间（inter-spectral）的依赖关系，为结构生成提供丰富的上下文信息。\n\n## 实验结果与优势\n\n广泛的实验证明，DiffSpectra 在结构解析方面取得了高精度：\n\n*   **准确率：** 通过采样，实现了 **16.01% 的 Top-1 准确率** 和 **96.86% 的 Top-20 准确率**。\n*   **关键贡献因素：**\n    *   **3D 几何建模：** 模型从对3D几何信息的建模中显著受益。\n    *   **SpecFormer 预训练：** SpecFormer 的预训练对于提升模型性能至关重要。\n    *   **多模态条件化：** 整合多种光谱模态作为条件信息，进一步增强了模型的解析能力。\n\n## 创新性与意义\n\n*   **开创性统一：** 据作者所知，DiffSpectra 是首个将多模态光谱推理与联合2D/3D生成建模相结合，用于 *de novo*（从头开始）分子结构解析的框架。\n*   **有效性验证：** 这些结果突显了光谱条件扩散模型在解决分子结构解析挑战方面的有效性。\n*   **深远影响：** 这项技术对化合物识别、合成以及药物开发等领域具有深远意义。",
      "shortSummary": "DiffSpectra是一种创新的生成式框架，利用扩散模型直接从多模态光谱数据中解析2D和3D分子结构。它通过SE(3)等变的Diffusion Molecule Transformer进行去噪，并使用SpecFormer编码多模态光谱作为条件。该模型在结构解析中表现出高准确率（Top-1 16.01%，Top-20 96.86%），并受益于3D几何建模和多模态条件化。DiffSpectra是首个统一多模态光谱推理与2D/3D生成建模的框架，对化学和药物开发具有重要意义。",
      "translated_title": "DiffSpectra：使用扩散模型从光谱中解析分子结构",
      "images": [],
      "contentSource": "完整文章",
      "content": "Molecular structure elucidation from spectra is a foundational problem in chemistry, with profound implications for compound identification, synthesis, and drug development. Traditional methods rely heavily on expert interpretation and lack scalability. Pioneering machine learning methods have introduced retrieval-based strategies, but their reliance on finite libraries limits generalization to novel molecules. Generative models offer a promising alternative, yet most adopt autoregressive SMILES-based architectures that overlook 3D geometry and struggle to integrate diverse spectral modalities. In this work, we present DiffSpectra, a generative framework that directly infers both 2D and 3D molecular structures from multi-modal spectral data using diffusion models. DiffSpectra formulates structure elucidation as a conditional generation process. Its denoising network is parameterized by Diffusion Molecule Transformer, an SE(3)-equivariant architecture that integrates topological and geometric information. Conditioning is provided by SpecFormer, a transformer-based spectral encoder that captures intra- and inter-spectral dependencies from multi-modal spectra. Extensive experiments demonstrate that DiffSpectra achieves high accuracy in structure elucidation, recovering exact structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through sampling. The model benefits significantly from 3D geometric modeling, SpecFormer pre-training, and multi-modal conditioning. These results highlight the effectiveness of spectrum-conditioned diffusion modeling in addressing the challenge of molecular structure elucidation. To our knowledge, DiffSpectra is the first framework to unify multi-modal spectral reasoning and joint 2D/3D generative modeling for de novo molecular structure elucidation."
    },
    {
      "title": "混合线性注意力机制的系统分析 (原标题: A Systematic Analysis of Hybrid Linear Attention)",
      "link": "https://arxiv.org/abs/2507.06457",
      "pubDate": "Tue, 08 Jul 2025 19:54:11 GMT",
      "isoDate": "2025-07-08T19:54:11.000Z",
      "creator": "Dustin Wang, Rui-Jie Zhu, Steven Abreu, Yong Shan, Taylor Kergan, Yuqi Pan, Yuhong Chou, Zheng Li, Ge Zhang, Wenhao Huang, Jason Eshraghian",
      "summary": "## 混合线性注意力机制的系统分析\n\n### 引言\nTransformer模型在处理长序列时面临二次复杂度与内存消耗问题。为解决此问题，研究人员引入了使用固定大小隐藏状态的线性注意力机制。然而，线性模型通常在召回性能上表现有限，这促使了结合线性注意力层和全注意力层的混合架构的出现。尽管对混合架构进行了广泛研究，但其中线性注意力组件的选择尚未得到深入探索。\n\n### 研究目的\n本研究旨在系统地评估不同代际的线性注意力模型（从向量递归到高级门控机制），无论是独立使用还是与全注意力层混合使用，以填补现有研究空白。\n\n### 研究方法\n为了实现这一全面的分析，研究团队进行了以下工作：\n\n1.  **模型训练与开源：** 训练并开源了72个模型。\n    *   其中36个模型参数量为3.4亿，在200亿个token上进行训练。\n    *   另外36个模型参数量为13亿，在1000亿个token上进行训练。\n2.  **变量控制：** 研究涵盖了六种线性注意力变体和五种不同的混合比例（线性注意力层与全注意力层的比例）。\n3.  **基准测试：** 在标准语言建模和召回任务上对所有模型进行了性能评估。\n\n### 主要发现\n本研究的基准测试揭示了以下关键发现：\n\n*   **独立性能与混合性能：** 独立表现优异的线性模型在混合架构中不一定能保持其优势。\n*   **语言建模稳定性：** 语言建模性能在不同的线性-全注意力比例下保持稳定。\n*   **召回性能提升：** 召回性能随全注意力层比例的增加而显著提升，尤其是在线性-全注意力比例低于3:1时。\n*   **关键因素：** 研究强调，选择性门控（selective gating）、分层递归（hierarchical recurrence）和受控遗忘（controlled forgetting）是构建有效混合模型的关键。\n\n### 研究建议\n基于上述发现，研究团队推荐以下架构和配置，以高效实现Transformer级别的召回性能：\n\n*   **推荐架构：** HGRN-2或GatedDeltaNet。\n*   **推荐比例：** 线性注意力层与全注意力层的比例在3:1到6:1之间。\n\n### 数据可用性\n本研究中训练的所有模型均已开源。",
      "shortSummary": "本研究系统分析了混合线性注意力机制，旨在解决Transformer在长序列处理中的复杂性问题。通过训练并开源72个模型，涵盖多种线性注意力变体和混合比例，研究发现独立表现优异的线性模型在混合架构中不一定出色。语言建模性能稳定，但召回性能随全注意力层增加而显著提升，尤其在特定比例下。选择性门控、分层递归和受控遗忘对有效混合模型至关重要。研究建议采用HGRN-2或GatedDeltaNet，线性-全注意力比例为3:1至6:1，以高效实现Transformer级召回。",
      "translated_title": "混合线性注意力机制的系统分析",
      "images": [],
      "contentSource": "完整文章",
      "content": "Transformers face quadratic complexity and memory issues with long sequences, prompting the adoption of linear attention mechanisms using fixed-size hidden states. However, linear models often suffer from limited recall performance, leading to hybrid architectures that combine linear and full attention layers. Despite extensive hybrid architecture research, the choice of linear attention component has not been deeply explored. We systematically evaluate various linear attention models across generations - vector recurrences to advanced gating mechanisms - both standalone and hybridized. To enable this comprehensive analysis, we trained and open-sourced 72 models: 36 at 340M parameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six linear attention variants across five hybridization ratios. Benchmarking on standard language modeling and recall tasks reveals that superior standalone linear models do not necessarily excel in hybrids. While language modeling remains stable across linear-to-full attention ratios, recall significantly improves with increased full attention layers, particularly below a 3:1 ratio. Our study highlights selective gating, hierarchical recurrence, and controlled forgetting as critical for effective hybrid models. We recommend architectures such as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1 to achieve Transformer-level recall efficiently. Our models are open-sourced at https://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e."
    },
    {
      "title": "面向多模态推理的感知感知策略优化 (原标题: Perception-Aware Policy Optimization for Multimodal Reasoning)",
      "link": "https://arxiv.org/abs/2507.06448",
      "pubDate": "Tue, 08 Jul 2025 19:22:34 GMT",
      "isoDate": "2025-07-08T19:22:34.000Z",
      "creator": "Zhenhailong Wang, Xuehang Guo, Sofia Stoica, Haiyang Xu, Hongru Wang, Hyeonjeong Ha, Xiusi Chen, Yangyi Chen, Ming Yan, Fei Huang, Heng Ji",
      "summary": "## 面向多模态推理的感知感知策略优化 (PAPO)\n\n本文提出了一种名为“感知感知策略优化 (Perception-Aware Policy Optimization, PAPO)”的新方法，旨在解决大型语言模型 (LLMs) 在多模态推理任务中，特别是视觉输入感知方面的性能瓶颈。\n\n### 背景与问题\n\n*   **可验证奖励强化学习 (RLVR)**：RLVR 在赋予 LLMs 强大的多步推理能力方面表现出色，尤其在纯文本领域。\n*   **多模态推理的挑战**：然而，RLVR 的设计和优化主要针对文本领域，导致其在多模态推理任务中表现不佳。\n*   **主要错误来源**：当前多模态推理中的一个主要错误来源是对视觉输入的感知不足。\n\n### PAPO 方法\n\n*   **核心思想**：PAPO 是 GRPO 的一个简单而有效的扩展，它鼓励模型在学习推理的同时学习感知，并且完全依赖于内部监督信号。\n*   **独立性**：PAPO 不依赖于额外的数据整理、外部奖励模型或专有模型。\n*   **技术细节**：通过将“隐式感知损失 (Implicit Perception Loss)”（以 KL 散度项的形式）引入 GRPO 目标函数中，PAPO 实现了这一目标。\n\n### 实验结果与影响\n\n*   **显著改进**：尽管方法简单，PAPO 在各种多模态基准测试中取得了显著的整体改进 (4.4%)。\n*   **视觉依赖任务表现**：在视觉依赖度高的任务上，改进更为显著，接近 8.0%。\n*   **感知能力提升**：PAPO 显著减少了感知错误 (30.5%)，表明其提升了模型的感知能力。\n\n### 进一步分析与缓解\n\n*   **发现问题**：研究人员在 PAPO 中发现了一个独特的“损失攻击 (loss hacking)”问题。\n*   **解决方案**：通过引入“双熵损失 (Double Entropy Loss)”对该问题进行了严格分析和缓解。\n\n### 总结\n\n这项工作将感知感知监督更深层次地整合到 RLVR 学习目标中，为鼓励视觉接地推理的新型强化学习框架奠定了基础。",
      "shortSummary": "本文提出“感知感知策略优化 (PAPO)”，旨在解决大型语言模型在多模态推理中视觉感知不足的问题。PAPO 是 GRPO 的扩展，通过引入隐式感知损失，使模型在推理时同步学习感知，且不依赖外部数据或模型。实验表明，PAPO 在多模态基准测试中实现了显著性能提升（整体4.4%，高视觉依赖任务近8.0%），并大幅减少了感知错误（30.5%）。研究还通过双熵损失缓解了特有的“损失攻击”问题，为视觉接地推理的强化学习框架奠定了基础。",
      "translated_title": "面向多模态推理的感知感知策略优化",
      "images": [],
      "contentSource": "完整文章",
      "content": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a highly effective strategy for endowing Large Language Models (LLMs) with robust multi-step reasoning abilities. However, its design and optimizations remain tailored to purely textual domains, resulting in suboptimal performance when applied to multimodal reasoning tasks. In particular, we observe that a major source of error in current multimodal reasoning lies in the perception of visual inputs. To address this bottleneck, we propose Perception-Aware Policy Optimization (PAPO), a simple yet effective extension of GRPO that encourages the model to learn to perceive while learning to reason, entirely from internal supervision signals. Notably, PAPO does not rely on additional data curation, external reward models, or proprietary models. Specifically, we introduce the Implicit Perception Loss in the form of a KL divergence term to the GRPO objective, which, despite its simplicity, yields significant overall improvements (4.4%) on diverse multimodal benchmarks. The improvements are more pronounced, approaching 8.0%, on tasks with high vision dependency. We also observe a substantial reduction (30.5%) in perception errors, indicating improved perceptual capabilities with PAPO. We conduct comprehensive analysis of PAPO and identify a unique loss hacking issue, which we rigorously analyze and mitigate through a Double Entropy Loss. Overall, our work introduces a deeper integration of perception-aware supervision into RLVR learning objectives and lays the groundwork for a new RL framework that encourages visually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO."
    },
    {
      "title": "LLM重排器的效率-效果重排FLOPs (原标题: Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers)",
      "link": "https://arxiv.org/abs/2507.06223",
      "pubDate": "Tue, 08 Jul 2025 13:56:28 GMT",
      "isoDate": "2025-07-08T13:56:28.000Z",
      "creator": "Zhiyuan Peng, Ting-ruen Wei, Tingyu Song, Yilun Zhao, Yi Fang",
      "summary": "# LLM重排器的效率-效果重排FLOPs\n\n## 摘要\n\n本文关注大型语言模型（LLMs）在信息检索重排任务中的应用。尽管LLMs在此类任务中表现出色，但其高昂的计算需求严重阻碍了实际部署。现有评估LLM重排器效率的指标（如延迟、前向传播次数、输入/输出令牌数）存在显著局限性。这些指标不仅依赖于特定的硬件和运行时选择（例如是否并行、批处理大小等），而且往往未能充分考虑模型本身的规模，导致难以准确解释和评估效率与效果之间的权衡。\n\n## 核心贡献与方法\n\n为了解决上述问题，本文提出了 **E²R-FLOPs**（效率-效果重排FLOPs）这一新的指标体系，专门用于评估基于LLM的重排器。该体系包含以下关键组成部分：\n\n*   **新度量标准：**\n    *   **每拍FLOPs的排序指标（RPP - Ranking metrics per PetaFLOP）：** 用于衡量每次计算所获得的相关性，即计算效率与排序效果的结合。\n    *   **每拍FLOPs的查询数（QPP - Queries per PetaFLOP）：** 用于衡量与硬件无关的吞吐量，提供了一个更普适的性能指标。\n*   **可解释的FLOPs估算器：** 伴随这些新指标，本文还构建了一个可解释的FLOPs估算器。该估算器能够在不运行任何实际实验的情况下，预估出基于LLM的重排器的FLOPs，从而大大简化了效率评估过程。\n\n## 实验与目标\n\n基于这些提出的新指标，研究人员对各种不同架构的LLM重排器进行了全面的实验评估。这些实验旨在深入研究LLM重排器在效率与效果之间的权衡关系，并希望通过这项工作，将这一关键且紧迫的问题引起更广泛的研究社区的关注。",
      "shortSummary": "本文提出E²R-FLOPs，旨在解决基于LLM的重排器计算成本高昂且现有效率评估指标不足的问题。通过引入每拍FLOPs的排序指标（RPP）和每拍FLOPs的查询数（QPP），以及一个可解释的FLOPs估算器，该研究旨在提供硬件无关的效率衡量标准。这有助于更准确地评估LLM重排器的效率-效果权衡，并引起研究界对该问题的关注。",
      "translated_title": "LLM重排器的效率-效果重排FLOPs",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have recently been applied to reranking tasks in information retrieval, achieving strong performance. However, their high computational demands often hinder practical deployment. Existing studies evaluate the efficiency of LLM-based rerankers using proxy metrics such as latency, the number of forward passes, input tokens, and output tokens. However, these metrics depend on hardware and running-time choices (\\eg parallel or not, batch size, etc), and often fail to account for model size, making it difficult to interpret and obscuring the evaluation of the efficiency-effectiveness tradeoff. To address this issue, we propose E2R-FLOPs, for LLM-based rerankers: ranking metrics per PetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for hardware-agnostic throughput. Companied with the new metrics, an interpretable FLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even without running any experiments. Based on the proposed metrics, we conduct comprehensive experiments to evaluate a wide range of LLM-based rerankers with different architecture, studying the efficiency-effectiveness trade-off and bringing this issue to the attention of the research community."
    },
    {
      "title": "可扩展机器人操作中，多样性是否足够？ (原标题: Is Diversity All You Need for Scalable Robotic Manipulation?)",
      "link": "https://arxiv.org/abs/2507.06219",
      "pubDate": "Tue, 08 Jul 2025 13:52:44 GMT",
      "isoDate": "2025-07-08T13:52:44.000Z",
      "creator": "Modi Shi, Li Chen, Jin Chen, Yuxiang Lu, Chiming Liu, Guanghui Ren, Ping Luo, Di Huang, Maoqing Yao, Hongyang Li",
      "summary": "# 可扩展机器人操作中数据多样性的作用\n\n## 摘要\n\n数据规模化在自然语言处理（NLP）和计算机视觉（CV）的预训练模型中取得了显著成功，但在机器人操作领域，有效数据规模化的原则仍未被充分理解。本研究深入探讨了数据多样性在机器人学习中的微妙作用，通过考察三个关键维度——任务（做什么）、实体（使用哪个机器人）和专家（谁演示）——挑战了“越多多样性越好”的传统直觉。\n\n## 主要发现\n\n通过在各种机器人平台上进行大量实验，研究揭示了以下关键发现：\n\n1.  **任务多样性至关重要：**\n    *   任务多样性被证明比单个任务的演示数量更为关键。\n    *   它有利于知识从多样化的预训练任务向新颖的下游场景进行迁移。\n\n2.  **多实体预训练数据并非必需：**\n    *   对于跨实体迁移而言，多实体预训练数据是可选的。\n    *   在高质量的单实体数据上训练的模型可以有效地迁移到不同的平台。\n    *   在微调过程中，这些模型表现出比多实体预训练模型更理想的规模化特性。\n\n3.  **专家多样性可能造成混淆：**\n    *   源于个体操作偏好和人类演示中随机变化的专家多样性，可能对策略学习造成混淆。\n    *   速度多模态被认为是关键的促成因素。\n\n## 提出的解决方案\n\n基于对专家多样性问题的深入洞察，研究提出了一种**分布去偏方法**来缓解速度模糊性。该方法显著提升了模型性能：\n\n*   由此产生的GO-1-Pro模型实现了15%的显著性能提升。\n*   这一提升相当于使用了2.5倍的预训练数据。\n\n## 结论与意义\n\n总而言之，这些发现为如何有效扩展机器人操作数据集提供了新的视角和实用指导。\n\n## 其他信息\n\n*   相关代码已开源。\n*   研究主题包括机器人学（cs.RO）、人工智能（cs.AI）和机器学习（cs.LG）。",
      "shortSummary": "本文研究了数据多样性在机器人操作学习中的作用，挑战“多样性越多越好”的直觉。研究发现：任务多样性至关重要，有利于知识迁移；多实体数据对跨实体迁移并非必需，高质量单实体数据表现更好；专家多样性（特别是速度多模态）可能混淆策略学习。为此，提出了一种分布去偏方法，显著提升了模型性能。这些发现为有效扩展机器人操作数据集提供了新视角和实用指导。",
      "translated_title": "可扩展机器人操作中，多样性是否足够？",
      "images": [],
      "contentSource": "完整文章",
      "content": "Data scaling has driven remarkable success in foundation models for Natural Language Processing (NLP) and Computer Vision (CV), yet the principles of effective data scaling in robotic manipulation remain insufficiently understood. In this work, we investigate the nuanced role of data diversity in robot learning by examining three critical dimensions-task (what to do), embodiment (which robot to use), and expert (who demonstrates)-challenging the conventional intuition of \"more diverse is better\". Throughout extensive experiments on various robot platforms, we reveal that (1) task diversity proves more critical than per-task demonstration quantity, benefiting transfer from diverse pre-training tasks to novel downstream scenarios; (2) multi-embodiment pre-training data is optional for cross-embodiment transfer-models trained on high-quality single-embodiment data can efficiently transfer to different platforms, showing more desirable scaling property during fine-tuning than multi-embodiment pre-trained models; and (3) expert diversity, arising from individual operational preferences and stochastic variations in human demonstrations, can be confounding to policy learning, with velocity multimodality emerging as a key contributing factor. Based on this insight, we propose a distribution debiasing method to mitigate velocity ambiguity, the yielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to using 2.5 times pre-training data. Collectively, these findings provide new perspectives and offer practical guidance on how to scale robotic manipulation datasets effectively."
    },
    {
      "title": "差分Mamba (原标题: Differential Mamba)",
      "link": "https://arxiv.org/abs/2507.06204",
      "pubDate": "Tue, 08 Jul 2025 13:30:14 GMT",
      "isoDate": "2025-07-08T13:30:14.000Z",
      "creator": "Nadav Schneider, Itamar Zimerman, Eliya Nachmani",
      "summary": "## 差分Mamba：一种改进序列模型上下文处理的新方法\n\n### 引言与问题背景\n\n*   **序列模型缺陷：** 诸如Transformer和RNN等序列模型常将注意力过度分配给不相关的上下文信息，这导致中间表示中产生大量噪声。\n*   **负面影响：** 这种噪声会降低大型语言模型（LLM）的能力，具体表现为：\n    *   促进“幻觉”现象（生成不真实或不准确的信息）。\n    *   削弱长程依赖和信息检索能力。\n    *   降低模型的整体鲁棒性。\n\n### 现有解决方案与研究动机\n\n*   **Transformer中的差分设计：** 近期研究表明，差分设计（differential design）能够有效缓解Transformer模型中的上述问题，并提升其在各种应用中的效果。\n*   **本文研究目标：** 探索这些最初为Transformer开发的技术是否能应用于Mamba架构。Mamba是一种基于选择性状态空间层的新型架构，其特点是能在达到Transformer级别性能的同时，拥有更高的效率。\n\n### 方法与创新\n\n*   **挑战：** 研究发现，将差分设计简单地应用于Mamba是不足够的，需要进行细致的架构修改。\n*   **本文贡献：** 针对Mamba架构的特点，本文引入了一种新颖的差分机制。\n\n### 实验验证与结果\n\n*   **验证方法：** 新提出的机制在语言建模基准上进行了实证验证。\n*   **实验成果：** 结果表明，该机制显著改进了Mamba模型的检索能力，并且性能优于原始（vanilla）Mamba模型。\n\n### 深入分析与设计依据\n\n*   **分析方法：** 研究人员进行了广泛的消融研究和实证分析，以充分论证其设计选择的合理性。\n*   **核心发现：** 这些分析提供了有力证据，证明所提出的方法能够有效缓解Mamba模型中上下文过度分配的问题。\n\n### 代码可用性\n\n*   本研究的相关代码已公开。\n\n### 研究领域\n\n*   机器学习 (cs.LG)\n*   人工智能 (cs.AI)\n*   计算与语言 (cs.CL)",
      "shortSummary": "序列模型（如Transformer、RNN）因过度关注无关上下文而性能受损。差分设计在Transformer中有效，本文探索将其应用于高效的Mamba架构。研究发现直接应用不足，故提出一种新颖的Mamba差分机制。实验证明，该机制显著提升了Mamba的检索能力和整体性能，有效缓解了上下文过度分配问题。相关代码已公开。",
      "translated_title": "差分Mamba",
      "images": [],
      "contentSource": "完整文章",
      "content": "Sequence models like Transformers and RNNs often overallocate attention to irrelevant context, leading to noisy intermediate representations. This degrades LLM capabilities by promoting hallucinations, weakening long-range and retrieval abilities, and reducing robustness. Recent work has shown that differential design can mitigate this issue in Transformers, improving their effectiveness across various applications. In this paper, we explore whether these techniques, originally developed for Transformers, can be applied to Mamba, a recent architecture based on selective state-space layers that achieves Transformer-level performance with greater efficiency. We show that a naive adaptation of differential design to Mamba is insufficient and requires careful architectural modifications. To address this, we introduce a novel differential mechanism for Mamba, empirically validated on language modeling benchmarks, demonstrating improved retrieval capabilities and superior performance over vanilla Mamba. Finally, we conduct extensive ablation studies and empirical analyses to justify our design choices and provide evidence that our approach effectively mitigates the overallocation problem in Mamba-based models. Our code is publicly available."
    },
    {
      "title": "潜在推理综述 (原标题: A Survey on Latent Reasoning)",
      "link": "https://arxiv.org/abs/2507.06203",
      "pubDate": "Tue, 08 Jul 2025 13:29:07 GMT",
      "isoDate": "2025-07-08T13:29:07.000Z",
      "creator": "Rui-Jie Zhu, Tianhao Peng, Tianhao Cheng, Xingwei Qu, Jinfa Huang, Dawei Zhu, Hao Wang, Kaiwen Xue, Xuanliang Zhang, Yong Shan, Tianle Cai, Taylor Kergan, Assel Kembay, Andrew Smith, Chenghua Lin, Binh Nguyen, Yuqi Pan, Yuhong Chou, Zefan Cai, Zhenhe Wu, Yongchi Zhao, Tianyu Liu, Jian Yang, Wangchunshu Zhou, Chujie Zheng, Chongxuan Li, Yuyin Zhou, Zhoujun Li, Zhaoxiang Zhang, Jiaheng Liu, Ge Zhang, Wenhao Huang, Jason Eshraghian",
      "summary": "### 潜在推理综述\n\n本综述深入探讨了大型语言模型（LLMs）中新兴的“潜在推理”领域。\n\n**背景与动机**\n\n*   大型语言模型（LLMs）在推理能力方面表现出色，尤其是在通过明确的思维链（CoT）推理（即口头表达中间步骤）引导时。\n*   尽管CoT提高了可解释性和准确性，但其对自然语言推理的依赖限制了模型的表达带宽。\n*   潜在推理旨在解决这一瓶颈，它通过在模型的连续隐藏状态中完全执行多步推理，从而消除了对token级别监督的依赖。\n\n**综述内容概述**\n\n本综述旨在为潜在推理研究提供一个全面的概览，并涵盖以下关键方面：\n\n1.  **推理的计算基础**\n    *   探讨神经网络层作为推理计算基底的基础作用。\n    *   强调分层表示如何支持复杂的转换。\n\n2.  **多样化的潜在推理方法**\n    *   **基于激活的循环（Activation-based recurrence）**：利用激活模式进行推理。\n    *   **隐藏状态传播（Hidden state propagation）**：通过隐藏状态在不同步骤间传递信息。\n    *   **微调策略（Fine-tuning strategies）**：包括压缩或内化显式推理轨迹，将CoT的显式步骤转化为模型内部的隐式过程。\n\n3.  **高级范式**\n    *   **无限深度潜在推理（Infinite-depth latent reasoning）**：通过掩码扩散模型实现，这使得全局一致且可逆的推理过程成为可能。\n\n**目标与未来方向**\n\n*   通过统一这些视角，本综述旨在阐明潜在推理的概念图景。\n*   为LLM认知前沿的未来研究方向提供指引。\n\n**图片说明：** 文章内容中未包含有效的实际图片链接，因此详细摘要中不包含任何图片。",
      "shortSummary": "本综述全面审视了大型语言模型（LLMs）中的“潜在推理”领域。潜在推理通过在模型连续隐藏状态中执行多步推理，克服了传统思维链（CoT）对自然语言的依赖限制。文章探讨了推理的计算基础、多样化的潜在推理方法（如基于激活的循环、隐藏状态传播和微调策略），以及无限深度潜在推理等高级范式。其目标是澄清概念并指明未来研究方向。",
      "translated_title": "潜在推理综述",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, especially when guided by explicit chain-of-thought (CoT) reasoning that verbalizes intermediate steps. While CoT improves both interpretability and accuracy, its dependence on natural language reasoning limits the model's expressive bandwidth. Latent reasoning tackles this bottleneck by performing multi-step inference entirely in the model's continuous hidden state, eliminating token-level supervision. To advance latent reasoning research, this survey provides a comprehensive overview of the emerging field of latent reasoning. We begin by examining the foundational role of neural network layers as the computational substrate for reasoning, highlighting how hierarchical representations support complex transformations. Next, we explore diverse latent reasoning methodologies, including activation-based recurrence, hidden state propagation, and fine-tuning strategies that compress or internalize explicit reasoning traces. Finally, we discuss advanced paradigms such as infinite-depth latent reasoning via masked diffusion models, which enable globally consistent and reversible reasoning processes. By unifying these perspectives, we aim to clarify the conceptual landscape of latent reasoning and chart future directions for research at the frontier of LLM cognition. An associated GitHub repository collecting the latest papers and repos is available at: https://github.com/multimodal-art-projection/LatentCoT-Horizon/."
    },
    {
      "title": "CriticLean：评论家引导的数学形式化强化学习 (原标题: CriticLean: Critic-Guided Reinforcement Learning for Mathematical Formalization)",
      "link": "https://arxiv.org/abs/2507.06181",
      "pubDate": "Tue, 08 Jul 2025 13:03:39 GMT",
      "isoDate": "2025-07-08T13:03:39.000Z",
      "creator": "Zhongyuan Peng, Yifan Yao, Kaijing Ma, Shuyue Guo, Yizhe Li, Yichi Zhang, Chenchen Zhang, Yifan Zhang, Zhouliang Yu, Luming Li, Minghao Liu, Yihang Xia, Jiawei Shen, Yuchen Wu, Yixin Cao, Zhaoxiang Zhang, Wenhao Huang, Jiaheng Liu, Ge Zhang",
      "summary": "### CriticLean：评论家引导的数学形式化强化学习\n\n本文介绍了 **CriticLean**，一个新颖的评论家引导的强化学习框架，旨在解决将自然语言数学陈述翻译成形式化、可执行代码这一基本挑战。\n\n**背景与问题：**\n*   在自动化定理证明领域，将自然语言数学陈述转换为形式化代码是一个核心难题。\n*   以往的研究主要集中在代码的生成和编译成功率上。\n*   然而，对于“评论家阶段”（即评估生成的数学形式化是否真正捕捉到原始问题的语义意图）的关注不足。\n\n**CriticLean 框架的核心理念：**\n*   将评论家（critic）的角色从被动的验证者提升为主动的学习组件。\n\n**主要组成部分与贡献：**\n\n1.  **CriticLeanGPT 模型：**\n    *   通过监督微调（supervised fine-tuning）和强化学习（reinforcement learning）进行训练。\n    *   其主要目标是严格评估 Lean 4 形式化的语义忠实度。\n\n2.  **CriticLeanBench 基准测试：**\n    *   一个专门设计的基准，用于衡量模型区分语义正确和不正确形式化的能力。\n    *   研究表明，经过训练的 CriticLeanGPT 模型在该基准上显著优于强大的开源和闭源基线模型。\n\n3.  **FineLeanCorpus 数据集：**\n    *   基于 CriticLean 框架构建。\n    *   包含超过 28.5 万个问题，具有丰富的领域多样性、广泛的难度覆盖范围，并经过人工评估具有高正确性。\n\n**研究发现与展望：**\n*   研究结果强调，优化评论家阶段对于生成可靠的数学形式化至关重要。\n*   作者希望 CriticLean 框架能为未来形式化数学推理的进展提供有价值的见解。",
      "shortSummary": "CriticLean是一个新颖的评论家引导强化学习框架，旨在改进自然语言数学陈述到形式化代码的转换。它通过提升评论家在学习中的作用，解决现有方法对语义评估不足的问题。该框架引入了CriticLeanGPT模型用于评估语义忠实度，并构建了CriticLeanBench基准测试和FineLeanCorpus数据集。研究表明，优化评论家阶段对于生成可靠的数学形式化至关重要，为自动化定理证明提供了新方向。",
      "translated_title": "CriticLean：评论家引导的数学形式化强化学习",
      "images": [],
      "contentSource": "完整文章",
      "content": "Translating natural language mathematical statements into formal, executable code is a fundamental challenge in automated theorem proving. While prior work has focused on generation and compilation success, little attention has been paid to the critic phase-the evaluation of whether generated formalizations truly capture the semantic intent of the original problem. In this paper, we introduce CriticLean, a novel critic-guided reinforcement learning framework that elevates the role of the critic from a passive validator to an active learning component. Specifically, first, we propose the CriticLeanGPT, trained via supervised fine-tuning and reinforcement learning, to rigorously assess the semantic fidelity of Lean 4 formalizations. Then, we introduce CriticLeanBench, a benchmark designed to measure models' ability to distinguish semantically correct from incorrect formalizations, and demonstrate that our trained CriticLeanGPT models can significantly outperform strong open- and closed-source baselines. Building on the CriticLean framework, we construct FineLeanCorpus, a dataset comprising over 285K problems that exhibits rich domain diversity, broad difficulty coverage, and high correctness based on human evaluation. Overall, our findings highlight that optimizing the critic phase is essential for producing reliable formalizations, and we hope our CriticLean will provide valuable insights for future advances in formal mathematical reasoning."
    },
    {
      "title": "OmniPart：具有语义解耦和结构内聚的部件感知3D生成 (原标题: OmniPart: Part-Aware 3D Generation with Semantic Decoupling and Structural Cohesion)",
      "link": "https://arxiv.org/abs/2507.06165",
      "pubDate": "Tue, 08 Jul 2025 12:46:15 GMT",
      "isoDate": "2025-07-08T12:46:15.000Z",
      "creator": "Yunhan Yang, Yufan Zhou, Yuan-Chen Guo, Zi-Xin Zou, Yukun Huang, Ying-Tian Liu, Hao Xu, Ding Liang, Yan-Pei Cao, Xihui Liu",
      "summary": "### OmniPart：具有语义解耦和结构内聚的部件感知3D生成\n\n**1. 引言与问题背景**\n*   为交互式应用创建具有明确、可编辑部件结构的3D资产至关重要。\n*   然而，大多数现有的生成方法仅产生整体形状（monolithic shapes），这限制了它们在需要部件级编辑和控制的应用中的实用性。\n\n**2. OmniPart 框架介绍**\n*   OmniPart 是一种新颖的框架，专为部件感知3D对象生成而设计。\n*   其核心目标是在组件之间实现高语义解耦（semantic decoupling），同时保持强大的结构内聚（structural cohesion）。\n*   OmniPart 独特地将这一复杂任务解耦为两个协同阶段。\n\n**3. 两个协同阶段**\n*   **阶段一：自回归结构规划模块**\n    *   该模块生成一个可控的、可变长度的3D部件边界框序列。\n    *   关键在于，它由灵活的2D部件掩码（part masks）引导，这些掩码允许对部件分解进行直观控制，而无需直接的对应关系或语义标签。\n*   **阶段二：空间条件整流流模型（Spatially-conditioned Rectified Flow Model）**\n    *   该模型从一个预训练的整体3D生成器中高效地改编而来。\n    *   它能够在规划好的布局内，同时且一致地合成所有3D部件。\n\n**4. 优势与应用**\n*   OmniPart 支持用户定义的部件粒度（part granularity）和精确的定位（precise localization）。\n*   它能够实现多样化的下游应用。\n\n**5. 性能与影响**\n*   广泛的实验表明，OmniPart 实现了最先进的性能。\n*   该方法为创建更具可解释性、可编辑性和多功能性的3D内容铺平了道路。",
      "shortSummary": "OmniPart是一种新颖的3D对象生成框架，旨在创建具有明确、可编辑部件结构的资产。它通过将任务解耦为两个协同阶段实现：首先，一个自回归模块利用2D掩码规划3D部件边界框；其次，一个空间条件整流流模型同时合成所有部件。该方法在实现组件语义解耦和结构内聚的同时，支持用户自定义粒度和精确控制，为生成更具可解释性、可编辑性和多功能性的3D内容提供了最先进的解决方案。",
      "translated_title": "OmniPart：具有语义解耦和结构内聚的部件感知3D生成",
      "images": [],
      "contentSource": "完整文章",
      "content": "The creation of 3D assets with explicit, editable part structures is crucial for advancing interactive applications, yet most generative methods produce only monolithic shapes, limiting their utility. We introduce OmniPart, a novel framework for part-aware 3D object generation designed to achieve high semantic decoupling among components while maintaining robust structural cohesion. OmniPart uniquely decouples this complex task into two synergistic stages: (1) an autoregressive structure planning module generates a controllable, variable-length sequence of 3D part bounding boxes, critically guided by flexible 2D part masks that allow for intuitive control over part decomposition without requiring direct correspondences or semantic labels; and (2) a spatially-conditioned rectified flow model, efficiently adapted from a pre-trained holistic 3D generator, synthesizes all 3D parts simultaneously and consistently within the planned layout. Our approach supports user-defined part granularity, precise localization, and enables diverse downstream applications. Extensive experiments demonstrate that OmniPart achieves state-of-the-art performance, paving the way for more interpretable, editable, and versatile 3D content."
    },
    {
      "title": "编码三角：大型语言模型如何理解代码？ (原标题: Coding Triangle: How Does Large Language Model Understand Code?)",
      "link": "https://arxiv.org/abs/2507.06138",
      "pubDate": "Tue, 08 Jul 2025 12:20:43 GMT",
      "isoDate": "2025-07-08T12:20:43.000Z",
      "creator": "Taolin Zhang, Zihan Ma, Maosong Cao, Junnan Liu, Songyang Zhang, Kai Chen",
      "summary": "大型语言模型（LLMs）在代码生成方面取得了显著进展，但其真实的编程能力仍未被充分探索。为了系统评估LLMs的编程能力，本文引入了“编码三角”框架，该框架从三个基本维度进行评估：\n\n*   **编辑分析（Editorial Analysis）**\n*   **代码实现（Code Implementation）**\n*   **测试用例生成（Test Case Generation）**\n\n通过在竞争性编程基准上进行大量实验，研究揭示了以下关键发现：\n\n*   **系统内部一致性与人类差异**：LLMs可以在这三个维度上形成一个自洽的系统，但其解决方案往往缺乏人类程序员所具备的多样性和鲁棒性。\n*   **认知与人类专业知识的分布差异**：模型认知与人类专业知识之间存在显著的分布偏移。模型错误倾向于聚集，这归因于训练数据偏差和有限的推理迁移能力。\n\n研究进一步指出，可以通过以下方法显著提升LLMs的性能和鲁棒性：\n\n*   **整合人类生成的数据**：纳入人类编写的编辑分析、解决方案和多样化的测试用例。\n*   **利用模型混合**：结合不同模型的优势。\n\n此外，研究还揭示了LLMs认知中的一致性和不一致性，这可能有助于模型的自我反思和自我改进，为开发更强大的编码模型提供了潜在方向。",
      "shortSummary": "本文提出了“编码三角”框架，从编辑分析、代码实现和测试用例生成三个维度评估大型语言模型（LLMs）的编程能力。研究发现，LLMs虽能形成自洽系统，但其解决方案缺乏人类的多样性和鲁棒性，且错误因训练数据偏差而聚集。为提升LLMs性能，建议整合人类生成的数据和利用模型混合。LLMs认知的一致性与不一致性也为未来自我改进提供了方向。",
      "translated_title": "编码三角：大型语言模型如何理解代码？",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large language models (LLMs) have achieved remarkable progress in code generation, yet their true programming competence remains underexplored. We introduce the Code Triangle framework, which systematically evaluates LLMs across three fundamental dimensions: editorial analysis, code implementation, and test case generation. Through extensive experiments on competitive programming benchmarks, we reveal that while LLMs can form a self-consistent system across these dimensions, their solutions often lack the diversity and robustness of human programmers. We identify a significant distribution shift between model cognition and human expertise, with model errors tending to cluster due to training data biases and limited reasoning transfer. Our study demonstrates that incorporating human-generated editorials, solutions, and diverse test cases, as well as leveraging model mixtures, can substantially enhance both the performance and robustness of LLMs. Furthermore, we reveal both the consistency and inconsistency in the cognition of LLMs that may facilitate self-reflection and self-improvement, providing a potential direction for developing more powerful coding models."
    },
    {
      "title": "Tora2：用于多实体视频生成的运动与外观定制扩散Transformer (原标题: Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation)",
      "link": "https://arxiv.org/abs/2507.05963",
      "pubDate": "Tue, 08 Jul 2025 09:11:40 GMT",
      "isoDate": "2025-07-08T09:11:40.000Z",
      "creator": "Zhenghao Zhang, Junchao Liao, Xiangyu Meng, Long Qin, Weizhi Wang",
      "summary": "## Tora2：用于多实体视频生成的运动与外观定制扩散Transformer\n\n### 概述\n\n本文介绍了 Tora2，这是在运动引导视频生成领域，对现有扩散Transformer模型 Tora 的增强版本。Tora2 旨在扩展其在外观和运动定制方面的能力，特别关注多实体视频生成。\n\n### 主要改进与创新\n\n1.  **解耦个性化提取器 (Decoupled Personalization Extractor)**\n    *   Tora2 引入了一个解耦的个性化提取器。\n    *   该提取器能够为多个开放集实体生成全面的个性化嵌入 (personalization embeddings)。\n    *   与现有方法相比，它能更好地保留细粒度的视觉细节。\n\n2.  **门控自注意力机制 (Gated Self-Attention Mechanism)**\n    *   基于解耦提取器，Tora2 设计了一种门控自注意力机制。\n    *   该机制用于整合每个实体的轨迹、文本描述和视觉信息。\n    *   这一创新显著减少了训练过程中多模态条件作用中的不对齐问题。\n\n3.  **对比损失 (Contrastive Loss)**\n    *   Tora2 引入了一种对比损失函数。\n    *   该损失函数通过运动嵌入和个性化嵌入之间的显式映射，共同优化轨迹动态和实体一致性。\n\n### 独特能力与贡献\n\n*   据作者所知，Tora2 是第一个实现视频生成中多实体外观和运动同步定制的方法。\n\n### 实验结果\n\n*   实验结果表明，Tora2 在与最先进的定制方法竞争的同时，提供了先进的运动控制能力。\n*   这标志着多条件视频生成领域的一个关键进展。",
      "shortSummary": "Tora2 是对现有扩散Transformer模型 Tora 的增强版本，专注于多实体视频生成中的运动与外观定制。它引入了解耦个性化提取器以保留视觉细节，设计了门控自注意力机制以减少多模态不对齐，并采用对比损失来优化轨迹动态和实体一致性。Tora2 是首个实现多实体外观和运动同步定制的方法，在实验中展现出与最先进技术相当的性能和先进的运动控制能力。",
      "translated_title": "Tora2：用于多实体视频生成的运动与外观定制扩散Transformer",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in diffusion transformer models for motion-guided video generation, such as Tora, have shown significant progress. In this paper, we present Tora2, an enhanced version of Tora, which introduces several design improvements to expand its capabilities in both appearance and motion customization. Specifically, we introduce a decoupled personalization extractor that generates comprehensive personalization embeddings for multiple open-set entities, better preserving fine-grained visual details compared to previous methods. Building on this, we design a gated self-attention mechanism to integrate trajectory, textual description, and visual information for each entity. This innovation significantly reduces misalignment in multimodal conditioning during training. Moreover, we introduce a contrastive loss that jointly optimizes trajectory dynamics and entity consistency through explicit mapping between motion and personalization embeddings. Tora2 is, to our best knowledge, the first method to achieve simultaneous multi-entity customization of appearance and motion for video generation. Experimental results demonstrate that Tora2 achieves competitive performance with state-of-the-art customization methods while providing advanced motion control capabilities, which marks a critical advancement in multi-condition video generation. Project page: https://github.com/alibaba/Tora ."
    },
    {
      "title": "基于多轮定位的强化学习实现高分辨率视觉推理 (原标题: High-Resolution Visual Reasoning via Multi-Turn Grounding-Based Reinforcement Learning)",
      "link": "https://arxiv.org/abs/2507.05920",
      "pubDate": "Tue, 08 Jul 2025 08:05:05 GMT",
      "isoDate": "2025-07-08T08:05:05.000Z",
      "creator": "Xinyu Huang, Yuhao Dong, Weiwei Tian, Bo Li, Rui Feng, Ziwei Liu",
      "summary": "## MGPO：高分辨率视觉推理的新范式\n\n### 背景与挑战\n当前最先进的大型多模态模型（LMMs）在处理高分辨率图像时面临显著挑战。这些图像输入被转换为大量的视觉标记，其中许多与下游任务无关，导致处理效率低下和性能受限。\n\n### 提出的方法：多轮定位策略优化（MGPO）\n为解决上述问题，本文提出了一种名为“多轮定位策略优化”（Multi-turn Grounding-based Policy Optimization, MGPO）的端到端强化学习（RL）框架。MGPO使LMMs能够在一个多轮对话框架内，根据模型预测的定位坐标，自动裁剪子图像，从而迭代地聚焦于关键视觉区域。\n\n### MGPO的关键优势\n*   **无需额外定位标注**：与需要昂贵额外定位标注的监督微调（SFT）方法不同，MGPO在RL训练过程中，仅利用最终答案正确性派生的二元奖励函数，就能使LMMs自主地发展出强大的定位能力。\n*   **解决“冷启动”问题**：研究发现LMMs在推理过程中难以自主触发视觉定位。为解决这一“冷启动”问题，MGPO设计了一种多轮对话模板，并将策略损失计算限制在跨多个对话轮次生成的模型输出上，从而促进了稳定的优化。\n\n### 实验结果与性能\nMGPO在标准视觉问答（VQA）数据集上进行训练，且**不依赖任何定位标注**。实验结果表明：\n*   MGPO相比于GRPO，能够更有效地激发LMMs的定位能力。\n*   在同分布的MME-Realworld数据集上，性能提升了5.4%。\n*   在更具挑战性的异分布（OOD）V* Bench数据集上，性能提升了5.2%。\n*   值得注意的是，在Qwen2.5-VL-7B模型上，经过21K样本的MGPO后训练，其在OOD V* Bench上的表现超越了OpenAI的o1和GPT-4o模型。\n\n### 代码可用性\n相关代码已公开。",
      "shortSummary": "大型多模态模型（LMMs）处理高分辨率图像时面临挑战。本文提出MGPO，一种基于多轮定位的强化学习框架，使LMMs能迭代聚焦关键视觉区域。MGPO无需额外定位标注，仅通过最终答案的二元奖励即可训练，并解决了模型自主触发定位的“冷启动”问题。实验证明，MGPO显著提升了视觉推理能力，在MME-Realworld和V* Bench上表现优异，甚至超越了GPT-4o等模型。",
      "translated_title": "基于多轮定位的强化学习实现高分辨率视觉推理",
      "images": [],
      "contentSource": "完整文章",
      "content": "State-of-the-art large multi-modal models (LMMs) face challenges when processing high-resolution images, as these inputs are converted into enormous visual tokens, many of which are irrelevant to the downstream task. In this paper, we propose Multi-turn Grounding-based Policy Optimization (MGPO), an end-to-end reinforcement learning (RL) framework that enables LMMs to iteratively focus on key visual regions by automatically cropping sub-images, based on model-predicted grounding coordinates within a multi-turn conversation framework. Compared to supervised fine-tuning (SFT), which requires costly additional grounding annotations, our approach highlights that LMMs can emerge robust grounding abilities during the RL training process, leveraging only a binary reward function derived from the correctness of the final answer. Additionally, we observe that LMMs struggle to autonomously trigger visual grounding during the rollout process. To address this cold start problem, we design a multi-turn conversational template and restrict policy loss computation to model outputs generated across multiple dialogue rounds, thereby promoting stable optimization. Extensive experiments demonstrate that, when trained on standard visual-question-short answering data without grounding annotations, MGPO effectively elicits stronger grounding capabilities compared to GRPO, leading to 5.4\\% improvement on in-distribution MME-Realworld and 5.2\\% improvement on the challenging out-of-distribution (OOD) V* Bench. Notably, MGPO post-training on Qwen2.5-VL-7B with 21K samples surpasses OpenAI's o1 and GPT-4o models on the OOD V* Bench. Codes are available at https://github.com/EvolvingLMMs-Lab/MGPO."
    },
    {
      "title": "GTA1：GUI测试时缩放代理 (原标题: GTA1: GUI Test-time Scaling Agent)",
      "link": "https://arxiv.org/abs/2507.05791",
      "pubDate": "Tue, 08 Jul 2025 04:52:18 GMT",
      "isoDate": "2025-07-08T04:52:18.000Z",
      "creator": "Yan Yang, Dongxu Li, Yutong Dai, Yuhao Yang, Ziyang Luo, Zirui Zhao, Zhiyuan Hu, Junzhe Huang, Amrita Saha, Zeyuan Chen, Ran Xu, Liyuan Pan, Caiming Xiong, Junnan Li",
      "summary": "## GTA1：GUI测试时缩放代理\n\n### 引言\n\n图形用户界面（GUI）代理能够自主地跨平台（如Linux）操作，通过与视觉元素交互来完成任务。具体而言，用户指令被分解为一系列动作提议，每个提议对应一次与GUI的交互。在每次动作之后，代理会观察更新后的GUI环境以规划下一步。然而，GUI代理面临两大主要挑战：\n\n1.  **任务规划模糊性：** 动作提议序列的选择存在歧义。选择一个合适的计划并非易事，因为可能存在许多有效的计划。\n2.  **动作精确接地：** 在复杂和高分辨率的界面中，需要精确地与视觉目标进行交互，即准确地将动作“接地”到对应的视觉元素上。\n\n### GTA1解决方案\n\n本文介绍了我们的GUI测试时缩放代理——GTA1，旨在解决上述两大挑战。\n\n#### 解决任务规划模糊性（挑战一）\n\n为了选择最合适的动作提议，GTA1引入了一种**测试时缩放方法**：\n\n*   在每一步，GTA1会采样多个候选动作提议。\n*   利用一个“判断模型”来评估并选择最合适的提议。\n*   这种方法以计算量为代价，换取更好的决策质量，通过并发采样缩短了任务执行步骤，并提高了整体性能。\n\n#### 解决动作精确接地（挑战二）\n\nGTA1提出了一个模型，旨在提高将选定的动作提议“接地”到其相应视觉元素的准确性。其核心洞察在于：\n\n*   **强化学习（RL）** 通过固有的目标对齐促进视觉接地。\n*   RL机制通过奖励成功点击界面元素来引导和优化接地过程。\n\n### 实验结果与性能\n\n我们的方法在多个基准测试中取得了最先进的性能：\n\n*   **GTA1-7B的准确率：**\n    *   Screenspot-Pro：50.1%\n    *   Screenspot-V2：92.4%\n    *   OSWorld-G：67.7%\n*   当GTA1与采用我们测试时缩放策略的规划器结合时，它展现出最先进的代理性能，例如在**OSWorld**上实现了**45.2%的任务成功率**。\n\n### 开源信息\n\nGTA1的代码和模型已开源。",
      "shortSummary": "GTA1是一个图形用户界面（GUI）测试时缩放代理，旨在提升GUI代理的自主操作能力。它通过引入测试时缩放方法解决任务规划模糊性，即采样并选择最佳动作提议；同时，利用强化学习（RL）提高动作在复杂界面中的精确接地能力。实验证明，GTA1在Screenspot和OSWorld等多个基准测试中达到了最先进的性能，显著提高了任务成功率。该项目已开源。",
      "translated_title": "GTA1：GUI测试时缩放代理",
      "images": [],
      "contentSource": "完整文章",
      "content": "Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.   This paper investigates the two aforementioned challenges with our GUI Test-time Scaling Agent, namely GTA1. First, to select the most appropriate action proposal, we introduce a test-time scaling method. At each step, we sample multiple candidate action proposals and leverage a judge model to evaluate and select the most suitable one. It trades off computation for better decision quality by concurrent sampling, shortening task execution steps, and improving overall performance. Second, we propose a model that achieves improved accuracy when grounding the selected action proposal to its corresponding visual elements. Our key insight is that reinforcement learning (RL) facilitates visual grounding through inherent objective alignments, rewarding successful clicks on interface elements.   Experimentally, our method establishes state-of-the-art performance across diverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7% accuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When paired with a planner applying our test-time scaling strategy, it exhibits state-of-the-art agentic performance (e.g., 45.2% task success rate on OSWorld). We open-source our code and models here."
    },
    {
      "title": "AutoTriton：基于大型语言模型中强化学习的自动Triton编程 (原标题: AutoTriton: Automatic Triton Programming with Reinforcement Learning in LLMs)",
      "link": "https://arxiv.org/abs/2507.05687",
      "pubDate": "Tue, 08 Jul 2025 01:38:24 GMT",
      "isoDate": "2025-07-08T01:38:24.000Z",
      "creator": "Shangzhan Li, Zefan Wang, Ye He, Yuxuan Li, Qi Shi, Jianling Li, Yonggang Hu, Wanxiang Che, Xu Han, Zhiyuan Liu, Maosong Sun",
      "summary": "# AutoTriton：基于大型语言模型中强化学习的自动Triton编程\n\n## 引言与背景\n深度学习中的核（kernel）开发面临复杂挑战，需要针对不同硬件优化计算单元，同时平衡内存管理、并行性以及硬件特定的优化。这通常需要大量的经验性调优。尽管Triton等领域特定语言通过抽象底层细节简化了GPU编程，但开发者仍需手动调优关键参数，如瓦片大小（tile sizes）和内存访问模式，这通过迭代实验完成，极大地阻碍了最佳性能的实现和Triton的广泛采用。\n\n## AutoTriton：解决方案\n本文介绍了AutoTriton，这是首个专门用于Triton编程的模型，其核心驱动力是强化学习（RL）。AutoTriton旨在自动化Triton核的参数调优过程，从而提高开发效率和性能。\n\n## AutoTriton 的方法论\nAutoTriton的开发过程分为两个主要阶段：\n\n1.  **监督微调（SFT）阶段**：\n    *   通过高质量的数据收集管道，对模型进行监督微调，使其具备Triton编程的基本专业知识。这一阶段为模型奠定了编程能力的基础。\n\n2.  **强化学习（RL）阶段**：\n    *   在SFT之后，AutoTriton进一步通过强化学习进行能力提升，采用**组相对策略优化（Group Relative Policy Optimization, GRPO）**算法。\n    *   RL阶段结合了两种奖励机制：\n        *   **基于规则的奖励（rule-based reward）**：根据预设的编程规则和最佳实践提供反馈。\n        *   **基于执行的奖励（execution-based reward）**：根据实际代码执行结果（如性能）提供反馈。\n    *   这两种奖励机制的结合，使得模型能够逐步优化其Triton编程能力。\n\n## 实验与结果\n研究团队在TritonBench和KernelBench的五个评估通道上对AutoTriton进行了广泛实验。\n\n*   **性能表现**：AutoTriton的8B模型展现出与主流大型模型（包括Claude-4-Sonnet和DeepSeek-R1-0528）相当的性能。这表明AutoTriton在自动生成高性能Triton核方面具有竞争力。\n*   **模块作用分析**：进一步的实验分析证实了AutoTriton中每个模块的关键作用，包括SFT阶段、RL阶段以及奖励设计策略。这强调了这些组件对于模型整体性能的重要性。\n\n## 结论与意义\n这些发现突显了强化学习在自动生成高性能核方面的巨大潜力。鉴于高性能核是AI系统的核心组成部分，AutoTriton的突破为构建更高效的AI系统奠定了重要基础。\n\n## 可用性\nAutoTriton的模型和代码将可用。",
      "shortSummary": "AutoTriton是首个利用强化学习（RL）实现自动Triton编程的模型，旨在解决深度学习核开发中手动调优的复杂性。它通过监督微调（SFT）获得编程知识，并结合GRPO算法与规则及执行奖励进行RL优化。实验表明，8B的AutoTriton模型性能可与Claude-4-Sonnet等主流大模型媲美。这项工作展示了RL在自动生成高性能核方面的潜力，为构建更高效的AI系统奠定了基础。",
      "translated_title": "AutoTriton：基于大型语言模型中强化学习的自动Triton编程",
      "images": [],
      "contentSource": "完整文章",
      "content": "Kernel development in deep learning requires optimizing computational units across hardware while balancing memory management, parallelism, and hardware-specific optimizations through extensive empirical tuning. Although domain-specific languages like Triton simplify GPU programming by abstracting low-level details, developers must still manually tune critical parameters such as tile sizes and memory access patterns through iterative experimentation, creating substantial barriers to optimal performance and wider adoption. In this work, we introduce AutoTriton, the first model dedicated to Triton programming powered by reinforcement learning (RL). AutoTriton performs supervised fine-tuning (SFT) to be equipped with essential Triton programming expertise using a high-quality data gathering pipeline, and conducts RL with Group Relative Policy Optimization (GRPO) algorithm, combining a rule-based reward and an execution-based reward to further improve Triton programming ability, sequentially. Experiments across five evaluation channels of TritonBench and KernelBench illustrate that our 8B model AutoTriton achieves performance comparable to mainstream large models, including Claude-4-Sonnet and DeepSeek-R1-0528. Further experimental analysis demonstrates the crucial role of each module within AutoTriton, including the SFT stage, the RL stage, and the reward design strategy. These findings underscore the promise of RL for automatically generating high-performance kernels, and since high-performance kernels are core components of AI systems, this breakthrough establishes an important foundation for building more efficient AI systems. The model and code will be available at https://github.com/AI9Stars/AutoTriton."
    },
    {
      "title": "MedGen：通过扩展精细标注的医学视频解锁医学视频生成 (原标题: MedGen: Unlocking Medical Video Generation by Scaling Granularly-annotated Medical Videos)",
      "link": "https://arxiv.org/abs/2507.05675",
      "pubDate": "Tue, 08 Jul 2025 00:58:36 GMT",
      "isoDate": "2025-07-08T00:58:36.000Z",
      "creator": "Rongsheng Wang, Junying Chen, Ke Ji, Zhenyang Cai, Shunian Chen, Yunjin Yang, Benyou Wang",
      "summary": "# MedGen：医学视频生成的新进展\n\n## 引言\n尽管开放领域视频生成技术取得了显著进展，但医学视频生成领域仍未得到充分探索。医学视频在临床培训、教育和模拟等关键应用中至关重要，对视觉保真度和医学准确性有严格要求。然而，现有模型在处理医学提示时常产生不真实或错误的内容，这主要是由于缺乏大规模、高质量的医学领域专用数据集。\n\n## 核心贡献\n\n### 1. MedVideoCap-55K 数据集\n为解决医学视频生成领域的数据空白，研究人员引入了 **MedVideoCap-55K**，这是：\n*   首个大规模、多样化且富含标注的医学视频生成数据集。\n*   包含超过55,000个精选剪辑，涵盖真实的医学场景。\n*   为训练通用医学视频生成模型奠定了坚实基础。\n\n### 2. MedGen 模型\n基于 MedVideoCap-55K 数据集，研究人员开发了 **MedGen** 模型，该模型：\n*   在开源模型中取得了领先性能。\n*   在视觉质量和医学准确性方面，MedGen在多个基准测试中与商业系统相媲美。\n\n## 研究意义与可用性\n*   研究人员希望 MedVideoCap-55K 数据集和 MedGen 模型能成为宝贵的资源，并有助于推动医学视频生成领域的进一步研究。\n*   相关的代码和数据已公开，以促进社区协作和进一步发展。",
      "shortSummary": "该研究介绍了MedVideoCap-55K，首个大规模、多样化且富含标注的医学视频数据集，包含超过55,000个剪辑。基于此，开发了MedGen模型，在医学视频生成方面表现卓越，超越开源模型并媲美商业系统，在视觉质量和医学准确性上均达到领先水平。此工作旨在弥补医学视频生成领域的数据和模型空白，推动该领域的进一步发展。",
      "translated_title": "MedGen：通过扩展精细标注的医学视频解锁医学视频生成",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in video generation have shown remarkable progress in open-domain settings, yet medical video generation remains largely underexplored. Medical videos are critical for applications such as clinical training, education, and simulation, requiring not only high visual fidelity but also strict medical accuracy. However, current models often produce unrealistic or erroneous content when applied to medical prompts, largely due to the lack of large-scale, high-quality datasets tailored to the medical domain. To address this gap, we introduce MedVideoCap-55K, the first large-scale, diverse, and caption-rich dataset for medical video generation. It comprises over 55,000 curated clips spanning real-world medical scenarios, providing a strong foundation for training generalist medical video generation models. Built upon this dataset, we develop MedGen, which achieves leading performance among open-source models and rivals commercial systems across multiple benchmarks in both visual quality and medical accuracy. We hope our dataset and model can serve as a valuable resource and help catalyze further research in medical video generation. Our code and data is available at https://github.com/FreedomIntelligence/MedGen"
    },
    {
      "title": "大型语言模型（LLMs）中记忆化的全景：机制、测量与缓解 (原标题: The Landscape of Memorization in LLMs: Mechanisms, Measurement, and Mitigation)",
      "link": "https://arxiv.org/abs/2507.05578",
      "pubDate": "Mon, 07 Jul 2025 21:30:46 GMT",
      "isoDate": "2025-07-07T21:30:46.000Z",
      "creator": "Alexander Xiong, Xuandong Zhao, Aneesh Pappu, Dawn Song",
      "summary": "大型语言模型（LLMs）在广泛任务中展现出卓越能力，但同时也表现出对其训练数据的记忆化现象。这一现象引发了关于模型行为、隐私风险以及学习与记忆边界的关键问题。\n\n### 论文概述\n\n本论文综合了近期研究，深入探讨了LLMs记忆化的全景、影响因素以及检测和缓解方法。它旨在提供关于LLM记忆化在技术、隐私和性能维度上的研究现状的全面概述，并指明未来的关键研究方向。\n\n### 记忆化的关键驱动因素\n\n文章探讨了影响数据记忆化的主要驱动因素，包括：\n\n*   **训练数据重复**：数据集中重复出现的内容会增加模型记忆的可能性。\n*   **训练动态**：模型训练过程中的特定行为和阶段可能导致记忆化。\n*   **微调程序**：特定的微调方法可能加剧或缓解记忆化。\n\n### 记忆化的检测与测量方法\n\n论文审查了多种用于检测和测量记忆化内容的方法，评估了它们的有效性：\n\n*   **基于前缀的提取**：通过提供数据前缀来尝试提取完整的记忆内容。\n*   **成员推断**：判断特定数据点是否属于模型的训练集。\n*   **对抗性提示**：设计特定的提示来诱导模型泄露记忆信息。\n\n### 记忆化的更广泛影响\n\n除了技术分析，论文还探讨了记忆化带来的更广泛影响，包括：\n\n*   **法律影响**：涉及版权、数据使用协议和法规遵从性。\n*   **伦理影响**：关于隐私侵犯、数据滥用和模型责任。\n\n### 记忆化的缓解策略\n\n论文讨论了多种缓解记忆化的策略，同时强调了在最小化有害记忆化与保持模型效用之间取得平衡的开放挑战：\n\n*   **数据清洗**：在训练前识别并移除重复或敏感数据。\n*   **差分隐私**：在训练过程中引入噪声，以保护个体数据隐私。\n*   **训练后遗忘**：在模型训练完成后，选择性地消除特定数据的记忆。\n\n### 挑战与未来方向\n\n研究指出，在平衡记忆化最小化与模型实用性方面仍存在挑战。论文最后识别了未来研究的关键方向，涵盖技术、隐私和性能维度。",
      "shortSummary": "该论文全面探讨了大型语言模型（LLMs）的训练数据记忆化现象。文章分析了数据重复、训练动态等记忆化驱动因素，并介绍了前缀提取、成员推断等检测方法。同时，论文讨论了数据清洗、差分隐私等缓解策略，并审视了记忆化的法律伦理影响。研究旨在平衡有害记忆化与模型效用，并为未来研究指明方向。",
      "translated_title": "大型语言模型（LLMs）中记忆化的全景：机制、测量与缓解",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, yet they also exhibit memorization of their training data. This phenomenon raises critical questions about model behavior, privacy risks, and the boundary between learning and memorization. Addressing these concerns, this paper synthesizes recent studies and investigates the landscape of memorization, the factors influencing it, and methods for its detection and mitigation. We explore key drivers, including training data duplication, training dynamics, and fine-tuning procedures that influence data memorization. In addition, we examine methodologies such as prefix-based extraction, membership inference, and adversarial prompting, assessing their effectiveness in detecting and measuring memorized content. Beyond technical analysis, we also explore the broader implications of memorization, including the legal and ethical implications. Finally, we discuss mitigation strategies, including data cleaning, differential privacy, and post-training unlearning, while highlighting open challenges in balancing the minimization of harmful memorization with utility. This paper provides a comprehensive overview of the current state of research on LLM memorization across technical, privacy, and performance dimensions, identifying critical directions for future work."
    }
  ],
  "lastUpdated": "2025-07-10T09:34:42.317Z"
}
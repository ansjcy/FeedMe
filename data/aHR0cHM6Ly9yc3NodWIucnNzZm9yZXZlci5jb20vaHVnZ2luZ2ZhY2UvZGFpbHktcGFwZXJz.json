{
  "sourceUrl": "https://rsshub.rssforever.com/huggingface/daily-papers",
  "title": "Huggingface Daily Papers",
  "description": "Huggingface Daily Papers - Powered by RSSHub",
  "link": "https://huggingface.co/papers",
  "items": [
    {
      "title": "3D感知区域提示视觉语言模型 (原标题: 3D Aware Region Prompted Vision Language Model)",
      "link": "https://arxiv.org/abs/2509.13317",
      "pubDate": "Tue, 16 Sep 2025 13:59:06 GMT",
      "isoDate": "2025-09-16T13:59:06.000Z",
      "creator": "An-Chieh Cheng, Yang Fu, Yukang Chen, Zhijian Liu, Xiaolong Li, Subhashree Radhakrishnan, Song Han, Yao Lu, Jan Kautz, Pavlo Molchanov, Hongxu Yin, Xiaolong Wang, Sifei Liu",
      "summary": "### 3D感知区域提示视觉语言模型 (SR-3D)\n\n本文介绍了一种名为空间区域3D (SR-3D) 感知视觉语言模型，旨在通过共享的视觉令牌空间连接单视图2D图像和多视图3D数据。SR-3D模型在场景理解方面，有效统一了2D和3D表示空间。\n\n#### 核心创新与功能\n\n*   **2D与3D数据统一**：SR-3D通过一个共享的视觉令牌空间，将来自单视图2D图像的特征与多视图3D数据进行关联和整合。\n*   **灵活的区域提示**：该模型支持高度灵活的区域提示功能，用户可以通过多种方式指定感兴趣的区域，包括：\n    *   在任意帧上使用边界框进行标注。\n    *   在任意帧上使用分割掩码进行标注。\n    *   直接在3D空间中进行标注。\n    *   这一特性显著减少了对详尽多帧标注的需求。\n\n#### 技术实现\n\n*   **3D位置嵌入增强2D特征**：SR-3D通过将3D位置嵌入信息融入2D视觉特征中，实现了2D与3D的有效融合。\n*   **利用2D先验进行3D推理**：这种方法使得3D模型能够利用强大的2D先验知识，即使感兴趣的对象不在同一视图中共同出现，也能在不同帧之间进行更准确的空间推理。\n\n#### 性能表现与应用\n\n*   **最先进的性能**：在通用2D视觉语言基准测试和专门的3D空间基准测试中，SR-3D均取得了最先进的性能。这证明了其在统一2D和3D表示空间以实现场景理解方面的有效性。\n*   **广泛的适用性**：该模型还适用于“野外”视频，即使这些视频缺乏感官3D输入或地面实况3D标注，SR-3D也能准确推断空间关系和度量测量。",
      "shortSummary": "SR-3D是一种3D感知区域提示视觉语言模型，通过共享视觉令牌空间统一了2D图像和多视图3D数据。它支持灵活的区域提示，允许用户通过边界框、分割掩码或直接在3D中标注区域，无需详尽的多帧标注。通过将3D位置嵌入到2D特征中，SR-3D利用2D先验进行准确的跨帧空间推理。该模型在2D视觉语言和3D空间基准测试中均达到SOTA性能，并能处理无3D输入的“野外”视频，准确推断空间关系。",
      "translated_title": "3D感知区域提示视觉语言模型",
      "images": [],
      "contentSource": "完整文章",
      "content": "We present Spatial Region 3D (SR-3D) aware vision-language model that connects single-view 2D images and multi-view 3D data through a shared visual token space. SR-3D supports flexible region prompting, allowing users to annotate regions with bounding boxes, segmentation masks on any frame, or directly in 3D, without the need for exhaustive multi-frame labeling. We achieve this by enriching 2D visual features with 3D positional embeddings, which allows the 3D model to draw upon strong 2D priors for more accurate spatial reasoning across frames, even when objects of interest do not co-occur within the same view. Extensive experiments on both general 2D vision language and specialized 3D spatial benchmarks demonstrate that SR-3D achieves state-of-the-art performance, underscoring its effectiveness for unifying 2D and 3D representation space on scene understanding. Moreover, we observe applicability to in-the-wild videos without sensory 3D inputs or ground-truth 3D annotations, where SR-3D accurately infers spatial relationships and metric measurements."
    },
    {
      "title": "ReSum：通过上下文摘要解锁长周期搜索智能 (原标题: ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization)",
      "link": "https://arxiv.org/abs/2509.13313",
      "pubDate": "Tue, 16 Sep 2025 13:57:22 GMT",
      "isoDate": "2025-09-16T13:57:22.000Z",
      "creator": "Xixi Wu, Kuan Li, Yida Zhao, Liwen Zhang, Litu Ou, Huifeng Yin, Zhongwang Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Minhao Cheng, Shuai Wang, Hong Cheng, Jingren Zhou",
      "summary": "### ReSum：通过上下文摘要解锁长周期搜索智能\n\n**核心问题：**\n*   基于大型语言模型（LLM）的网页代理在知识密集型任务中表现出色，但受限于上下文窗口，尤其是在ReAct等范式中。\n*   涉及多个实体、复杂关系和高不确定性的复杂查询需要大量的搜索周期，这会迅速耗尽上下文预算，导致在达到完整解决方案之前受阻。\n\n**解决方案：ReSum范式**\n*   **引入：** ReSum是一种新颖的范式，通过周期性上下文摘要实现无限探索。\n*   **工作原理：** ReSum将不断增长的交互历史转换为紧凑的推理状态，从而在绕过上下文限制的同时保持对先前发现的感知。\n\n**范式适应：ReSum-GRPO**\n*   为了使代理熟悉摘要条件下的推理，研究人员提出了ReSum-GRPO。\n*   **集成：** ReSum-GRPO将GRPO（Generalized Reinforcement Learning with Policy Optimization）与分段轨迹训练和优势广播相结合。\n\n**实验结果与性能提升：**\n*   **基准测试：** 在三个基准测试中，对不同规模的网页代理进行了广泛实验。\n*   **平均提升：** ReSum在ReAct基础上实现了平均4.5%的绝对性能提升。\n*   **ReSum-GRPO的额外增益：** 经过ReSum-GRPO训练后，性能提升高达8.2%。\n*   **显著成就：**\n    *   仅使用1K训练样本，WebResummer-30B（WebSailor-30B的ReSum-GRPO训练版本）在BrowseComp-zh上实现了33.3%的Pass@1，在BrowseComp-en上实现了18.3%的Pass@1。\n    *   这一表现超越了现有的开源网页代理。",
      "shortSummary": "ReSum是一种新范式，通过周期性上下文摘要解决了LLM网页代理在长周期搜索任务中受上下文窗口限制的问题。它将交互历史转化为紧凑的推理状态，实现无限探索。结合ReSum-GRPO训练后，ReSum在ReAct基础上平均提升4.5%，最高达8.2%。WebResummer-30B在仅1K训练样本下，在BrowseComp-zh和BrowseComp-en上分别达到33.3%和18.3%的Pass@1，超越现有开源代理。",
      "translated_title": "ReSum：通过上下文摘要解锁长周期搜索智能",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Model (LLM)-based web agents demonstrate strong performance on knowledge-intensive tasks but are hindered by context window limitations in paradigms like ReAct. Complex queries involving multiple entities, intertwined relationships, and high uncertainty demand extensive search cycles that rapidly exhaust context budgets before reaching complete solutions. To overcome this challenge, we introduce ReSum, a novel paradigm that enables indefinite exploration through periodic context summarization. ReSum converts growing interaction histories into compact reasoning states, maintaining awareness of prior discoveries while bypassing context constraints. For paradigm adaptation, we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and advantage broadcasting to familiarize agents with summary-conditioned reasoning. Extensive experiments on web agents of varying scales across three benchmarks demonstrate that ReSum delivers an average absolute improvement of 4.5\\% over ReAct, with further gains of up to 8.2\\% following ReSum-GRPO training. Notably, with only 1K training samples, our WebResummer-30B (a ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\\% Pass@1 on BrowseComp-zh and 18.3\\% on BrowseComp-en, surpassing existing open-source web agents."
    },
    {
      "title": "WebWeaver：利用动态大纲构建网络规模证据以进行开放式深度研究 (原标题: WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research)",
      "link": "https://arxiv.org/abs/2509.13312",
      "pubDate": "Tue, 16 Sep 2025 13:57:21 GMT",
      "isoDate": "2025-09-16T13:57:21.000Z",
      "creator": "Zijian Li, Xin Guan, Bo Zhang, Shen Huang, Houquan Zhou, Shaopeng Lai, Ming Yan, Yong Jiang, Pengjun Xie, Fei Huang, Jun Zhang, Jingren Zhou",
      "summary": "# WebWeaver：利用动态大纲构建网络规模证据以进行开放式深度研究\n\n本文介绍了一个名为WebWeaver的新型双代理框架，旨在解决开放式深度研究（OEDR）这一复杂挑战。OEDR要求AI代理将海量的网络信息综合成富有洞察力的报告。\n\n## 当前方法的局限性：\n现有的AI代理在处理OEDR时面临双重限制：\n*   **静态研究流程：** 规划与证据获取相互脱节，导致研究过程缺乏灵活性和适应性。\n*   **一次性生成范式：** 容易出现长上下文问题，例如“中间信息丢失”（loss in the middle）和幻觉（hallucinations），影响报告的准确性和完整性。\n\n## WebWeaver框架的核心理念与设计：\nWebWeaver框架模仿人类研究过程，采用双代理结构，以迭代和聚焦的方式进行信息处理：\n\n### 1. 规划器（Planner）：\n*   在一个动态循环中运行，持续优化研究大纲。\n*   迭代地交织证据获取与大纲优化，确保规划与信息收集紧密结合。\n*   生成一个全面、基于来源的大纲，该大纲链接到一个包含所有收集到的证据的记忆库。\n\n### 2. 撰写器（Writer）：\n*   执行分层检索和撰写过程，逐节构建报告。\n*   针对报告的每个部分，从记忆库中进行有针对性的检索，只获取当前部分所需的必要证据。\n*   通过这种聚焦式检索，有效缓解了传统一次性生成范式中常见的长上下文问题，提高了报告的质量和可靠性。\n\n## WebWeaver的优势与成果：\n*   **缓解长上下文问题：** 通过有针对性的分层检索，WebWeaver显著减少了“中间信息丢失”和幻觉的发生。\n*   **卓越的性能：** WebWeaver在主要的OEDR基准测试（包括DeepResearch Bench、DeepConsult和DeepResearchGym）中取得了新的最先进成果。\n*   **方法论验证：** 这些结果验证了WebWeaver以人为中心、迭代式的方法论，证明了自适应规划和聚焦式综合对于生成高质量、可靠且结构良好的报告至关重要。\n\n## 研究领域：\n*   计算与语言 (cs.CL)",
      "shortSummary": "WebWeaver是一个新型双代理框架，旨在解决开放式深度研究（OEDR）中AI代理综合海量网络信息生成报告的挑战。它通过模仿人类研究过程，采用动态规划器迭代优化大纲并获取证据，以及分层撰写器有针对性地检索和合成信息。该框架有效缓解了长上下文问题，并在主要OEDR基准测试中取得了最先进的成果，证明了自适应规划和聚焦式综合对高质量报告的重要性。",
      "translated_title": "WebWeaver：利用动态大纲构建网络规模证据以进行开放式深度研究",
      "images": [],
      "contentSource": "完整文章",
      "content": "This paper tackles open-ended deep research (OEDR), a complex challenge where AI agents must synthesize vast web-scale information into insightful reports. Current approaches are plagued by dual-fold limitations: static research pipelines that decouple planning from evidence acquisition and one-shot generation paradigms that easily suffer from long-context failure issues like \"loss in the middle\" and hallucinations. To address these challenges, we introduce WebWeaver, a novel dual-agent framework that emulates the human research process. The planner operates in a dynamic cycle, iteratively interleaving evidence acquisition with outline optimization to produce a comprehensive, source-grounded outline linking to a memory bank of evidence. The writer then executes a hierarchical retrieval and writing process, composing the report section by section. By performing targeted retrieval of only the necessary evidence from the memory bank for each part, it effectively mitigates long-context issues. Our framework establishes a new state-of-the-art across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and DeepResearchGym. These results validate our human-centric, iterative methodology, demonstrating that adaptive planning and focused synthesis are crucial for producing high-quality, reliable, and well-structured reports."
    },
    {
      "title": "通过环境扩展实现通用智能体智能 (原标题: Towards General Agentic Intelligence via Environment Scaling)",
      "link": "https://arxiv.org/abs/2509.13311",
      "pubDate": "Tue, 16 Sep 2025 13:57:20 GMT",
      "isoDate": "2025-09-16T13:57:20.000Z",
      "creator": "Runnan Fang, Shihao Cai, Baixuan Li, Jialong Wu, Guangyu Li, Wenbiao Yin, Xinyu Wang, Xiaobin Wang, Liangcai Su, Zhen Zhang, Shibin Wu, Zhengwei Tao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",
      "summary": "### 通过环境扩展实现通用智能体智能\n\n**背景与挑战**\n\n*   在实际、真实世界的应用中部署大型语言模型（LLMs）需要先进的智能体智能。\n*   多样化的真实世界API要求智能体具备精确、鲁棒的函数调用能力。\n*   智能体需要通过在各种环境中交互来发展这些能力。\n*   函数调用能力的广度与智能体训练环境的多样性紧密相关。\n\n**研究目标**\n\n*   本研究旨在通过扩展环境，作为推进通用智能体智能的一个步骤。\n\n**核心挑战**\n\n这项工作引出了两个核心挑战：\n\n1.  如何以系统化的方式扩展环境。\n2.  如何有效地从与这些环境的交互经验中训练智能体能力。\n\n**解决方案**\n\n为了解决这些挑战，研究人员设计了一个可扩展的框架和训练策略：\n\n*   **可扩展框架设计**：\n    *   该框架能够自动构建异构的、完全模拟的环境。\n    *   系统性地拓宽了函数调用场景的空间。\n*   **两阶段智能体微调策略**：\n    *   **第一阶段**：赋予智能体基础的智能体能力。\n    *   **第二阶段**：针对特定领域上下文对智能体进行专业化。\n\n**实验与成果**\n\n*   在智能体基准测试（tau-bench、tau2-Bench 和 ACEBench）上进行了广泛的实验。\n*   研究结果表明，他们训练的模型 **AgentScaler** 显著增强了模型的函数调用能力。",
      "shortSummary": "该研究旨在通过扩展训练环境来提升大型语言模型的通用智能体智能。为解决环境扩展和有效训练的挑战，作者设计了一个可扩展框架，自动构建异构模拟环境，并提出两阶段微调策略。实验证明，其模型AgentScaler显著增强了模型在函数调用方面的能力，为LLM在实际应用中的部署奠定了基础。",
      "translated_title": "通过环境扩展实现通用智能体智能",
      "images": [],
      "contentSource": "完整文章",
      "content": "Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practical, real-world applications. Diverse real-world APIs demand precise, robust function-calling intelligence, which needs agents to develop these capabilities through interaction in varied environments. The breadth of function-calling competence is closely tied to the diversity of environments in which agents are trained. In this work, we scale up environments as a step towards advancing general agentic intelligence. This gives rise to two central challenges: (i) how to scale environments in a principled manner, and (ii) how to effectively train agentic capabilities from experiences derived through interactions with these environments. To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated, systematically broadening the space of function-calling scenarios. We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts. Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models."
    },
    {
      "title": "通过持续预训练扩展智能体 (原标题: Scaling Agents via Continual Pre-training)",
      "link": "https://arxiv.org/abs/2509.13310",
      "pubDate": "Tue, 16 Sep 2025 13:57:19 GMT",
      "isoDate": "2025-09-16T13:57:19.000Z",
      "creator": "Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang, Kuan Li, Jialong Wu, Xuanzhong Chen, Zile Qiao, Zhongwang Zhang, Huifeng Yin, Shihao Cai, Runnan Fang, Zhengwei Tao, Wenbiao Yin, Chenxiong Qian, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",
      "summary": "### 通过持续预训练扩展智能体：AgentFounder模型\n\n#### 背景与问题\n\n*   **大型语言模型（LLMs）的智能体能力**：LLMs已发展成为能够自主使用工具并进行多步推理以解决复杂问题的智能体系统。\n*   **现有方法的局限性**：然而，基于通用基础模型构建的后训练方法在智能体任务中表现不佳，尤其是在开源实现中。\n*   **根本原因**：研究人员发现，这种表现不佳的根源在于缺乏强大的智能体基础模型。这导致模型在后训练阶段需要同时学习多样化的智能体行为并将其与专家演示对齐，从而产生根本性的优化冲突。\n\n#### 解决方案：智能体持续预训练（Agentic CPT）\n\n*   **创新性提案**：本文首次提出将智能体持续预训练（Agentic CPT）整合到深度研究智能体训练流程中，旨在构建强大的智能体基础模型。\n\n#### 模型开发：AgentFounder\n\n*   **基于Agentic CPT**：研究团队基于Agentic CPT方法，开发了一个名为AgentFounder的深度研究智能体模型。\n\n#### 性能评估\n\n*   **最先进的性能**：AgentFounder-30B在10个基准测试中进行了评估，并取得了最先进的性能（state-of-the-art）。\n*   **强大的工具使用能力**：该模型同时保持了强大的工具使用能力，具体表现为：\n    *   在BrowseComp-en上达到 **39.9%**\n    *   在BrowseComp-zh上达到 **43.3%**\n    *   在HLE上Pass@1达到 **31.5%**",
      "shortSummary": "大型语言模型作为智能体在后训练中表现不佳，主要原因是缺乏强大的智能体基础模型和优化冲突。为解决此问题，本文首次提出智能体持续预训练（Agentic CPT）方法，并开发了AgentFounder模型。AgentFounder-30B在10个基准测试中取得了最先进的性能，并在BrowseComp-en（39.9%）、BrowseComp-zh（43.3%）和HLE（31.5% Pass@1）等任务上展现出强大的工具使用能力。",
      "translated_title": "通过持续预训练扩展智能体",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE."
    },
    {
      "title": "WebResearcher：在长周期智能体中释放无限推理能力 (原标题: WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents)",
      "link": "https://arxiv.org/abs/2509.13309",
      "pubDate": "Tue, 16 Sep 2025 13:57:17 GMT",
      "isoDate": "2025-09-16T13:57:17.000Z",
      "creator": "Zile Qiao, Guoxin Chen, Xuanzhong Chen, Donglei Yu, Wenbiao Yin, Xinyu Wang, Zhen Zhang, Baixuan Li, Huifeng Yin, Kuan Li, Rui Min, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",
      "summary": "WebResearcher是一个旨在构建能够自主发现和合成知识的AI智能体的创新框架。该框架通过两个核心组件，解决了现有深度研究系统面临的挑战，并显著提升了智能体的推理能力：\n\n### 1. WebResearcher：迭代式深度研究范式\n\n*   **将深度研究重构为马尔可夫决策过程（MDP）**：智能体能够以结构化的方式进行研究。\n*   **周期性整合发现与报告演进**：智能体定期将其研究成果整合到不断更新的报告中，确保知识的积累和组织。\n*   **维护专注的工作空间**：通过保持工作空间的聚焦，有效避免了现有单上下文方法中常见的“上下文窒息”和“噪声污染”问题。\n\n### 2. WebFrontier：可扩展数据合成引擎\n\n*   **生成高质量训练数据**：该引擎通过“工具增强的复杂性升级”机制，系统性地创建高质量的训练数据。\n*   **弥合知识鸿沟**：它能够生成连接被动知识回忆和主动知识构建的研究任务，促进智能体更深层次的学习和理解。\n\n### 主要发现与优势\n\n*   **显著增强工具使用能力**：WebResearcher范式生成的训练数据，即使对于传统的单上下文方法，也能显著提升其工具使用能力。\n*   **支持并行思维与多智能体探索**：该范式天然支持通过并行思维进行扩展，允许多个智能体同时进行探索，从而得出更全面、更深入的结论。\n\n### 性能表现\n\n*   **最先进的性能**：在6个具有挑战性的基准测试中，WebResearcher展现了卓越的性能，达到了当前最先进的水平。\n*   **超越专有系统**：其表现甚至超越了一些前沿的专有系统。\n\n### 相关信息\n\n*   **主题**：计算与语言 (cs.CL)\n*   **引用**：arXiv:2509.13309 [cs.CL]\n\n（文章内容中不包含有效的实际图片链接，因此详细摘要中不包含图片。）",
      "shortSummary": "WebResearcher是一个创新的AI框架，旨在通过其迭代式深度研究范式和可扩展数据合成引擎，在长周期智能体中释放无限推理能力。它将研究建模为马尔可夫决策过程，通过定期整合发现和维护专注工作空间，有效克服了上下文限制和噪声问题。WebFrontier引擎生成高质量训练数据，显著增强了智能体的工具使用能力。该框架支持并行多智能体探索，并在6个挑战性基准测试中取得了超越现有专有系统的最先进性能。",
      "translated_title": "WebResearcher：在长周期智能体中释放无限推理能力",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in deep-research systems have demonstrated the potential for AI agents to autonomously discover and synthesize knowledge from external sources. In this paper, we introduce WebResearcher, a novel framework for building such agents through two key components: (1) WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process, where agents periodically consolidate findings into evolving reports while maintaining focused workspaces, overcoming the context suffocation and noise contamination that plague existing mono-contextual approaches; and (2) WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation, enabling systematic creation of research tasks that bridge the gap between passive knowledge recall and active knowledge construction. Notably, we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods. Furthermore, our paradigm naturally scales through parallel thinking, enabling concurrent multi-agent exploration for more comprehensive conclusions. Extensive experiments across 6 challenging benchmarks demonstrate that WebResearcher achieves state-of-the-art performance, even surpassing frontier proprietary systems."
    },
    {
      "title": "WebSailor-V2：通过合成数据和可扩展强化学习弥合与专有代理之间的鸿沟 (原标题: WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic Data and Scalable Reinforcement Learning)",
      "link": "https://arxiv.org/abs/2509.13305",
      "pubDate": "Tue, 16 Sep 2025 13:57:03 GMT",
      "isoDate": "2025-09-16T13:57:03.000Z",
      "creator": "Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Yida Zhao, Liwen Zhang, Litu Ou, Dingchu Zhang, Xixi Wu, Jialong Wu, Xinyu Wang, Zile Qiao, Zhen Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",
      "summary": "## WebSailor-V2：通过合成数据和可扩展强化学习弥合与专有代理之间的鸿沟\n\n本文介绍了WebSailor，一个旨在提升大型语言模型（LLM）在复杂信息检索任务中处理极端不确定性能力的完整后训练方法。\n\n### 背景与挑战\n\n*   **LLM的局限性**：当前LLM在处理需要超越人类认知限制的复杂信息检索任务时面临挑战。\n*   **专有代理的优势**：DeepResearch等专有代理系统在BrowseComp等极其复杂的基准测试中展现出超人能力，这是开源模型此前无法达到的。\n*   **核心洞察**：专有代理的成功在于其独特的推理模式——在广阔的信息环境中系统性地降低极端不确定性。这种能力在开源模型中缺失。\n\n### WebSailor方法论\n\nWebSailor是一个完整的后训练方法，旨在将上述关键能力灌输给开源模型。其方法包括：\n\n*   **高不确定性任务生成**：通过结构化采样和信息混淆，生成新颖的、高不确定性的任务。\n*   **RFT冷启动**：采用强化微调（RFT）进行冷启动。\n*   **高效的代理强化学习训练算法**：引入了“重复采样策略优化”（Duplicating Sampling Policy Optimization, DUPO）。\n\n### 成果与影响\n\n*   **性能提升**：通过这一整合的流程，WebSailor在复杂信息检索任务中显著超越了所有开源代理。\n*   **弥合差距**：WebSailor的性能达到了专有代理的水平，成功弥合了开源模型与专有代理之间的能力差距。",
      "shortSummary": "WebSailor-V2提出了一种后训练方法，旨在弥合开源大型语言模型（LLM）与专有代理在处理复杂信息检索任务中的能力差距。专有代理通过系统性地降低极端不确定性展现出超人能力。WebSailor通过生成高不确定性任务、RFT冷启动和高效的DUPO强化学习算法，使开源代理获得了类似能力。实验表明，WebSailor显著超越了所有开源代理，并达到了专有代理的性能水平。",
      "translated_title": "WebSailor-V2：通过合成数据和可扩展强化学习弥合与专有代理之间的鸿沟",
      "images": [],
      "contentSource": "完整文章",
      "content": "Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap."
    },
    {
      "title": "单流策略优化 (原标题: Single-stream Policy Optimization)",
      "link": "https://arxiv.org/abs/2509.13232",
      "pubDate": "Tue, 16 Sep 2025 12:39:11 GMT",
      "isoDate": "2025-09-16T12:39:11.000Z",
      "creator": "Zhongwen Xu, Zihan Ding",
      "summary": "## 单流策略优化 (SPO) 详细摘要\n\n本文重新审视了大型语言模型 (LLM) 的策略梯度优化，并提出了一种名为“单流策略优化 (Single-stream Policy Optimization, SPO)”的新方法，旨在解决现有组基方法（如 GRPO）的固有缺陷。\n\n### 现有方法的挑战\n\n当前主流的组基策略梯度方法（例如 GRPO）通过即时基线来减少方差，但存在以下关键问题：\n\n*   **频繁的退化组**：导致学习信号的丢失，浪费计算资源。\n*   **同步障碍**：阻碍了算法的扩展性，尤其是在生成时间差异较大的长序列或工具集成场景中。\n\n### SPO 的核心思想与机制\n\nSPO 从设计上消除了上述问题，其主要创新点包括：\n\n*   **持久的 KL 自适应价值追踪器**：SPO 用一个持久的、KL 自适应的价值追踪器取代了每个组的基线，从而提供了一个更稳定、低方差的学习信号。\n*   **全局优势归一化**：SPO 在整个批次中对优势进行全局归一化，确保每个样本都能获得稳定的学习信号。\n\n### SPO 的优势\n\nSPO 的无组设计带来了多方面的好处：\n\n*   **消除退化组**：避免了因退化组而浪费的计算和学习信号损失。\n*   **更高的吞吐量和可扩展性**：由于没有组同步障碍，SPO 在生成时间差异大的长序列或工具集成设置中能够实现更高的吞吐量和更有效的扩展。\n*   **自适应课程学习**：持久的价值追踪器自然地支持通过优先采样实现自适应课程学习。\n\n### 实验结果与性能提升\n\n研究团队使用 Qwen3-8B 模型进行了实验，结果表明 SPO 相比 GRPO 具有显著优势：\n\n*   **收敛性与准确性**：SPO 的收敛过程更平滑，并取得了更高的准确性。\n*   **计算效率**：SPO 消除了在退化组上浪费的计算。\n*   **数学基准表现**：在五个困难的数学基准测试中，SPO 将 Qwen3-8B 的平均 maj@32 性能比 GRPO 提高了 +3.4 个百分点 (pp)。具体提升包括：\n    *   BRUMO 25：+7.3 pp\n    *   AIME 25：+4.4 pp\n    *   HMMT 25：+3.3 pp\n*   **pass@k 表现**：在所有评估的 k 值上，SPO 在 pass@k 指标上都实现了持续的相对增益。\n\n### 结论与意义\n\n消融研究证实，SPO 的性能提升源于其在基线估计和优势归一化方面的原则性方法，为 LLM 推理提供了一条更稳健、更高效的路径。SPO 的成功挑战了当前强化学习算法中倾向于增加偶然复杂性的趋势，强调了通过基本原理而非架构性变通方案来推动 LLM 推理领域下一波进展的重要性。",
      "shortSummary": "本文提出单流策略优化 (SPO)，一种用于大型语言模型 (LLM) 的新型策略梯度方法。SPO 通过引入持久的 KL 自适应价值追踪器和全局优势归一化，解决了现有组基方法（如 GRPO）中退化组和同步障碍问题，提供更稳定、低方差的学习信号。实验表明，SPO 在 Qwen3-8B 上收敛更平滑，准确性更高，在五个困难数学基准测试中平均 maj@32 比 GRPO 提高了 +3.4 个百分点，展现了更强的鲁棒性和效率。",
      "translated_title": "单流策略优化",
      "images": [],
      "contentSource": "完整文章",
      "content": "We revisit policy-gradient optimization for Large Language Models (LLMs) from a single-stream perspective. Prevailing group-based methods like GRPO reduce variance with on-the-fly baselines but suffer from critical flaws: frequent degenerate groups erase learning signals, and synchronization barriers hinder scalability. We introduce Single-stream Policy Optimization (SPO), which eliminates these issues by design. SPO replaces per-group baselines with a persistent, KL-adaptive value tracker and normalizes advantages globally across the batch, providing a stable, low-variance learning signal for every sample. Being group-free, SPO enables higher throughput and scales effectively in long-horizon or tool-integrated settings where generation times vary. Furthermore, the persistent value tracker naturally enables an adaptive curriculum via prioritized sampling. Experiments using Qwen3-8B show that SPO converges more smoothly and attains higher accuracy than GRPO, while eliminating computation wasted on degenerate groups. Ablation studies confirm that SPO's gains stem from its principled approach to baseline estimation and advantage normalization, offering a more robust and efficient path for LLM reasoning. Across five hard math benchmarks with Qwen3 8B, SPO improves the average maj@32 by +3.4 percentage points (pp) over GRPO, driven by substantial absolute point gains on challenging datasets, including +7.3 pp on BRUMO 25, +4.4 pp on AIME 25, +3.3 pp on HMMT 25, and achieves consistent relative gain in pass@k across the evaluated k values. SPO's success challenges the prevailing trend of adding incidental complexity to RL algorithms, highlighting a path where fundamental principles, not architectural workarounds, drive the next wave of progress in LLM reasoning."
    },
    {
      "title": "混元3D工作室：端到端AI游戏就绪3D资产生成流水线 (原标题: Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation)",
      "link": "https://arxiv.org/abs/2509.12815",
      "pubDate": "Tue, 16 Sep 2025 04:33:03 GMT",
      "isoDate": "2025-09-16T04:33:03.000Z",
      "creator": "Biwen Lei, Yang Li, Xinhai Liu, Shuhui Yang, Lixin Xu, Jingwei Huang, Ruining Tang, Haohan Weng, Jian Liu, Jing Xu, Zhen Zhou, Yiling Zhu, Jiankai Xing, Jiachen Xu, Changfeng Ma, Xinhao Yan, Yunhan Yang, Chunshi Wang, Duoteng Xu, Xueqi Ma, Yuguang Chen, Jing Li, Mingxin Yang, Sheng Zhang, Yifei Feng, Xin Huang, Di Luo, Zebin He, Puhua Jiang, Changrong Hu, Zihan Qin, Shiwei Miao, Haolin Liu, Yunfei Zhao, Zeqiang Lai, Qingxiang Lin, Zibo Zhao, Kunhong Li, Xianghui Yang, Huiwen Shi, Xin Yang, Yuxuan Wang, Zebin Yao, Yihang Lian, Sicong Liu, Xintong Han, Wangchen Qin, Caisheng Ouyang, Jianyin Liu, Tianwen Yuan, Shuai Jiang, Hong Duan, Yanqi Niu, Wencong Lin, Yifu Sun, Shirui Huang, Lin Niu, Gu Gong, Guojian Xiao, Bojian Zheng, Xiang Yuan, Qi Chen, Jie Xiao, Dongyang Zheng, Xiaofeng Yang, Kai Liu, Jianchen Zhu, Lifu Wang, Qinglin Lu, Jie Liu, Liang Dong, Fan Jiang, Ruibin Chen, Lei Wang, Chao Zhang, Jiaxin Lin, Hao Zhang, Zheng Ye, Peng He, Runzhou Wu, Yinhe Wu, Jiayao Du, Jupeng Chen, Xinyue Mao, Dongyuan Guo, Yixuan Tang, Yulin Tsai, Yonghao Tan, Jiaao Yu, Junlin Yu, Keren Zhang, Yifan Li, Peng Chen, Tian Liu, Di Wang, Yuhong Liu, Linus, Jie Jiang, Zhuo Chen, Chunchao Guo",
      "summary": "# 混元3D工作室：端到端AI游戏就绪3D资产生成流水线\n\n## 引言\n高质量3D资产的创建是现代游戏开发的核心环节，但长期以来，这一过程以其劳动密集型和高度专业化的工作流程而著称。\n\n## Hunyuan3D Studio 概述\n本文介绍了Hunyuan3D Studio，这是一个由AI驱动的端到端内容创建平台。它的设计宗旨是通过自动化和简化游戏就绪3D资产的生成，彻底革新当前的游戏生产流水线。\n\n## 核心技术与功能\n*   **集成先进的神经网络模块：** Hunyuan3D Studio 的核心在于它将一系列先进的神经网络模块（例如，部件级3D生成、多边形生成、语义UV等）整合到一个连贯且用户友好的系统中。\n*   **统一框架：** 这一统一的框架使得平台能够将单个概念图像或文本描述快速转换为一个完全实现、达到生产质量标准的3D模型。\n*   **高质量输出：** 生成的3D模型不仅包含优化的几何结构，还配备了高保真PBR（基于物理渲染）纹理，确保了视觉效果的卓越性。\n\n## 优势与影响\n*   **视觉吸引力：** Hunyuan3D Studio 生成的资产不仅在视觉上引人注目。\n*   **符合行业标准：** 它们还能严格遵守当代游戏引擎的技术要求，确保了在实际游戏环境中的可用性。\n*   **效率提升：** 该平台显著减少了3D资产创建的迭代时间，加快了开发周期。\n*   **降低门槛：** 它极大地降低了3D内容创作的准入门槛，使更多创作者能够参与其中。\n*   **无缝衔接：** Hunyuan3D Studio 在创意意图和技术资产之间架起了一座无缝的桥梁，实现了从概念到成品的高效转化。\n\n## 结论\nHunyuan3D Studio 代表了AI辅助工作流程在游戏开发和交互式媒体领域的一个重大飞跃，预示着未来内容创作的新方向。",
      "shortSummary": "Hunyuan3D Studio是一个端到端AI内容创建平台，旨在革新游戏3D资产生成。它通过集成先进的神经网络模块，能将概念图像或文本描述快速转化为符合游戏引擎要求的、具有优化几何和PBR纹理的生产级3D模型。该平台显著减少了迭代时间，降低了3D创作门槛，是AI辅助游戏开发的重要进展。",
      "translated_title": "混元3D工作室：端到端AI游戏就绪3D资产生成流水线",
      "images": [],
      "contentSource": "完整文章",
      "content": "The creation of high-quality 3D assets, a cornerstone of modern game development, has long been characterized by labor-intensive and specialized workflows. This paper presents Hunyuan3D Studio, an end-to-end AI-powered content creation platform designed to revolutionize the game production pipeline by automating and streamlining the generation of game-ready 3D assets. At its core, Hunyuan3D Studio integrates a suite of advanced neural modules (such as Part-level 3D Generation, Polygon Generation, Semantic UV, etc.) into a cohesive and user-friendly system. This unified framework allows for the rapid transformation of a single concept image or textual description into a fully-realized, production-quality 3D model complete with optimized geometry and high-fidelity PBR textures. We demonstrate that assets generated by Hunyuan3D Studio are not only visually compelling but also adhere to the stringent technical requirements of contemporary game engines, significantly reducing iteration time and lowering the barrier to entry for 3D content creation. By providing a seamless bridge from creative intent to technical asset, Hunyuan3D Studio represents a significant leap forward for AI-assisted workflows in game development and interactive media."
    },
    {
      "title": "EconProver：迈向更经济的自动化定理证明测试时扩展 (原标题: EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving)",
      "link": "https://arxiv.org/abs/2509.12603",
      "pubDate": "Mon, 15 Sep 2025 23:00:13 GMT",
      "isoDate": "2025-09-15T23:00:13.000Z",
      "creator": "Mukai Li, Linfeng Song, Zhenwen Liang, Jiahao Xu, Shansan Gong, Qi Liu, Haitao Mi, Dong Yu",
      "summary": "### EconProver：迈向更经济的自动化定理证明测试时扩展\n\n本文探讨了大型语言模型（LLMs）在自动化定理证明（ATP）领域中应用时所面临的计算效率问题，并提出了名为 EconProver 的解决方案。\n\n**背景与问题**\n\n*   **性能提升与计算开销并存**：LLMs通过广泛采用的测试时扩展策略，如反射式思维链（CoT）推理和增加采样次数，显著提升了ATP的性能。\n*   **高昂的推理成本**：这些策略也带来了显著的推理计算开销。\n*   **现有成本分析的局限性**：目前的成本分析通常只关注采样次数，而忽略了不同扩展策略引入的采样成本差异。\n*   **当前SOTA方法的低效**：作者指出，当前最先进的（SOTA）开源方法在效率方面表现不佳。\n\n**研究目标**\n\n*   系统比较ATP模型不同测试时扩展策略的效率。\n*   提出方法以显著减少令牌使用和采样次数，同时保持原始性能。\n\n**EconProver 提出的解决方案**\n\n本文提出了两种互补的方法，可以集成到统一的 EconRL 管道中以放大效益：\n\n1.  **动态思维链（CoT）切换机制**：旨在智能地管理和减轻不必要的令牌消耗，从而提高效率。\n2.  **多样化并行扩展强化学习（RL）与可训练前缀**：在受限的采样次数下，通过增强学习方法和可训练的前缀来提高定理证明的通过率。\n\n**实验结果**\n\n*   在 miniF2F 和 ProofNet 数据集上的实验表明，EconProver 在实现与基线方法相当的性能的同时，仅需 12% 的计算成本。\n\n**结论与意义**\n\n*   这项工作为部署轻量级ATP模型提供了可行的见解，而无需牺牲性能，为ATP领域的高效发展开辟了新途径。",
      "shortSummary": "EconProver 旨在解决大型语言模型在自动化定理证明（ATP）中测试时扩展策略（如思维链和增加采样）带来的高计算成本问题。该研究系统比较了不同策略的效率，并提出了两种互补方法：动态思维链切换机制以减少令牌消耗，以及多样化并行扩展强化学习与可训练前缀以提高通过率。实验证明，EconProver 在保持性能的同时，将计算成本降低至基线方法的12%，为部署轻量级ATP模型提供了高效方案。",
      "translated_title": "EconProver：迈向更经济的自动化定理证明测试时扩展",
      "images": [],
      "contentSource": "完整文章",
      "content": "Large Language Models (LLMs) have recently advanced the field of Automated Theorem Proving (ATP), attaining substantial performance gains through widely adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT) reasoning and increased sampling passes. However, they both introduce significant computational overhead for inference. Moreover, existing cost analyses typically regulate only the number of sampling passes, while neglecting the substantial disparities in sampling costs introduced by different scaling strategies. In this paper, we systematically compare the efficiency of different test-time scaling strategies for ATP models and demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source approaches. We then investigate approaches to significantly reduce token usage and sample passes while maintaining the original performance. Specifically, we propose two complementary methods that can be integrated into a unified EconRL pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching mechanism designed to mitigate unnecessary token consumption, and (2) Diverse parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance pass rates under constrained sampling passes. Experiments on miniF2F and ProofNet demonstrate that our EconProver achieves comparable performance to baseline methods with only 12% of the computational cost. This work provides actionable insights for deploying lightweight ATP models without sacrificing performance."
    },
    {
      "title": "量子格算法的精确陪集采样 (原标题: Exact Coset Sampling for Quantum Lattice Algorithms)",
      "link": "https://arxiv.org/abs/2509.12341",
      "pubDate": "Mon, 15 Sep 2025 14:10:28 GMT",
      "isoDate": "2025-09-15T14:10:28.000Z",
      "creator": "Yifan Zhang",
      "summary": "# 量子格算法中精确陪集采样的改进\n\n本文提出了一种针对近期带有复高斯窗的窗式QFT量子格算法（如`chen2024quantum`所述）中第9步“域扩展”问题的改进方案。\n\n## 核心问题\n\n*   **现有挑战**：该算法第9步中备受争议的“域扩展”方法存在“周期性/支持不匹配”的问题。\n\n## 提出的解决方案\n\n*   **新方法**：作者提供了一个简单、完全正确且假设较少的替代方案。\n*   **关键构造**：该方案采用了一种“对移差分构造”（pair-shift difference construction）。\n\n## 解决方案的机制与成果\n\n*   **抵消偏移**：通过这种构造，可以相干地抵消所有未知的偏移量。\n*   **状态生成**：它能够生成一个在 $\\mathbb{Z}_{P}$ 上精确的均匀CRT陪集状态。\n*   **关系强制**：随后，利用量子傅里叶变换（QFT）来强制执行预期的模线性关系。\n\n## 新酉变换的特性\n\n*   **可逆性**：该酉变换是可逆的。\n*   **门复杂度**：它使用 $\\mathrm{poly}(\\log M_2)$ 个门。\n*   **渐近性**：它保持了原算法的渐近性能。",
      "shortSummary": "本文针对近期窗式QFT量子格算法第9步中“域扩展”的争议问题，提出了一种简单、正确的替代方案。通过对移差分构造，该方法能相干抵消未知偏移，生成$\\mathbb{Z}_{P}$上的精确均匀CRT陪集状态，并利用QFT强制模线性关系。此可逆酉变换使用$\\mathrm{poly}(\\log M_2)$门，保持算法渐近性，解决了周期性/支持不匹配问题。",
      "translated_title": "量子格算法的精确陪集采样",
      "images": [],
      "contentSource": "完整文章",
      "content": "We give a simple, fully correct, and assumption-light replacement for the contested \"domain-extension\" in Step 9 of a recent windowed-QFT lattice algorithm with complex-Gaussian windows~chen2024quantum. The published Step~9 suffers from a periodicity/support mismatch. We present a pair-shift difference construction that coherently cancels all unknown offsets, produces an exact uniform CRT-coset state over Z_{P}, and then uses the QFT to enforce the intended modular linear relation. The unitary is reversible, uses poly(log M_2) gates, and preserves the algorithm's asymptotics. Project Page: https://github.com/yifanzhang-pro/quantum-lattice."
    },
    {
      "title": "LazyDrag：通过显式对应在多模态扩散Transformer上实现稳定的拖拽式编辑 (原标题: LazyDrag: Enabling Stable Drag-Based Editing on Multi-Modal Diffusion Transformers via Explicit Correspondence)",
      "link": "https://arxiv.org/abs/2509.12203",
      "pubDate": "Mon, 15 Sep 2025 13:59:47 GMT",
      "isoDate": "2025-09-15T13:59:47.000Z",
      "creator": "Zixin Yin, Xili Dai, Duomin Wang, Xianfang Zeng, Lionel M. Ni, Gang Yu, Heung-Yeung Shum",
      "summary": "# LazyDrag：通过显式对应实现稳定的拖拽式编辑\n\n## 背景与现有问题\n传统的拖拽式图像编辑方法严重依赖通过注意力机制进行的隐式点匹配。这种依赖性导致了两个核心瓶颈：\n*   **反演强度弱：** 难以实现高保真度的图像反演。\n*   **测试时优化（TTO）成本高昂：** 需要耗费大量计算资源进行优化。\n这些问题共同限制了扩散模型的生成能力，尤其是在高保真度图像修复和文本引导创作等复杂任务中表现不佳。\n\n## LazyDrag 方法介绍\n本文引入了 **LazyDrag**，这是首个专为多模态扩散Transformer设计的拖拽式图像编辑方法。LazyDrag 的核心创新在于它直接消除了对隐式点匹配的依赖。\n\n### 核心机制\nLazyDrag 的工作原理是：\n*   从用户提供的拖拽输入中生成一个 **显式对应图**。\n*   这个显式对应图作为可靠的参考，用于增强模型的注意力控制。\n\n## LazyDrag 的优势与能力\n通过引入显式对应图，LazyDrag 带来了多项显著优势：\n\n### 1. 稳定的全强度反演\n*   LazyDrag 首次在拖拽式编辑任务中实现了 **稳定的全强度反演过程**。这意味着模型能够更准确、更完整地理解和应用编辑指令。\n\n### 2. 消除测试时优化 (TTO)\n*   由于其高效且可靠的机制，LazyDrag **避免了对 TTO 的需求**。这不仅降低了计算成本，还显著提升了编辑效率，并释放了模型的全部生成潜力。\n\n### 3. 统一几何控制与文本引导\n*   LazyDrag 自然地将 **精确的几何控制** 与 **文本引导** 功能相结合。这使得用户可以通过拖拽和文本描述共同完成复杂的编辑任务。\n\n### 4. 实现前所未有的复杂编辑\nLazyDrag 能够完成以前难以实现或无法完成的复杂编辑，例如：\n*   **精细结构编辑：** 打开狗的嘴巴并修复其内部。\n*   **新对象生成：** 生成新的物体，如“网球”。\n*   **上下文感知修改：** 对于模糊的拖拽指令，能够进行上下文感知的改变，例如将手移入口袋。\n\n### 5. 支持多轮工作流\n*   LazyDrag 支持 **多轮编辑工作流**，并能同时进行移动和缩放操作，为用户提供更大的灵活性和控制力。\n\n## 性能评估\n*   在 DragBench 基准测试中，LazyDrag 在 **拖拽精度** 和 **感知质量** 方面均超越了现有基线方法。\n*   其卓越性能得到了 VIEScore 和人工评估的验证。\n\n## 结论与影响\nLazyDrag 不仅在拖拽式图像编辑领域确立了 **新的最先进性能 (State-of-the-Art)**，而且通过其创新的显式对应机制，为未来的编辑范式开辟了新的途径。",
      "shortSummary": "LazyDrag是首个针对多模态扩散Transformer的拖拽式图像编辑方法。它通过从用户输入生成显式对应图，解决了传统方法中隐式点匹配导致的反演弱和测试时优化（TTO）成本高昂的问题。LazyDrag实现了稳定的全强度反演，无需TTO，并自然地统一了精确几何控制与文本引导。它能完成复杂的图像编辑，并在DragBench上表现优异，确立了新的最先进性能，为编辑范式开辟了新途径。",
      "translated_title": "LazyDrag：通过显式对应在多模态扩散Transformer上实现稳定的拖拽式编辑",
      "images": [],
      "contentSource": "完整文章",
      "content": "The reliance on implicit point matching via attention has become a core bottleneck in drag-based editing, resulting in a fundamental compromise on weakened inversion strength and costly test-time optimization (TTO). This compromise severely limits the generative capabilities of diffusion models, suppressing high-fidelity inpainting and text-guided creation. In this paper, we introduce LazyDrag, the first drag-based image editing method for Multi-Modal Diffusion Transformers, which directly eliminates the reliance on implicit point matching. In concrete terms, our method generates an explicit correspondence map from user drag inputs as a reliable reference to boost the attention control. This reliable reference opens the potential for a stable full-strength inversion process, which is the first in the drag-based editing task. It obviates the necessity for TTO and unlocks the generative capability of models. Therefore, LazyDrag naturally unifies precise geometric control with text guidance, enabling complex edits that were previously out of reach: opening the mouth of a dog and inpainting its interior, generating new objects like a ``tennis ball'', or for ambiguous drags, making context-aware changes like moving a hand into a pocket. Additionally, LazyDrag supports multi-round workflows with simultaneous move and scale operations. Evaluated on the DragBench, our method outperforms baselines in drag accuracy and perceptual quality, as validated by VIEScore and human evaluation. LazyDrag not only establishes new state-of-the-art performance, but also paves a new way to editing paradigms."
    },
    {
      "title": "OmniWorld: 用于4D世界建模的多领域和多模态数据集 (原标题: OmniWorld: A Multi-Domain and Multi-Modal Dataset for 4D World Modeling)",
      "link": "https://arxiv.org/abs/2509.12201",
      "pubDate": "Mon, 15 Sep 2025 13:59:19 GMT",
      "isoDate": "2025-09-15T13:59:19.000Z",
      "creator": "Yang Zhou, Yifan Wang, Jianjun Zhou, Wenzheng Chang, Haoyu Guo, Zizun Li, Kaijing Ma, Xinyue Li, Yating Wang, Haoyi Zhu, Mingyu Liu, Dingning Liu, Jiange Yang, Zhoujie Fu, Junyi Chen, Chunhua Shen, Jiangmiao Pang, Kaipeng Zhang, Tong He",
      "summary": "## OmniWorld: 用于4D世界建模的多领域和多模态数据集\n\n本文介绍了一个名为OmniWorld的大规模、多领域、多模态数据集，专门为4D世界建模而设计。4D世界建模旨在共同捕捉空间几何和时间动态，近年来在大型生成模型和多模态学习的推动下取得了显著进展。然而，真正通用的4D世界模型的开发仍然受到高质量数据可用性的根本限制。\n\n**数据集的动机：**\n\n*   现有的数据集和基准通常缺乏动态复杂性、多领域多样性和空间-时间注释，而这些是支持关键任务（如4D几何重建、未来预测和相机控制视频生成）所必需的。\n\n**OmniWorld数据集的组成：**\n\n*   新收集的OmniWorld-Game数据集\n*   多个精选的公共数据集，涵盖不同的领域。\n\n**OmniWorld-Game数据集的优势：**\n\n*   与现有的合成数据集相比，OmniWorld-Game提供了更丰富的模态覆盖、更大的规模和更逼真的动态交互。\n\n**实验与结果：**\n\n*   基于该数据集，作者建立了一个具有挑战性的基准，揭示了当前最先进（SOTA）方法在建模复杂4D环境方面的局限性。\n*   在OmniWorld上微调现有的SOTA方法可以显著提高4D重建和视频生成任务的性能，这有力地验证了OmniWorld作为训练和评估的强大资源。\n\n**结论：**\n\n作者设想OmniWorld将成为加速通用4D世界模型发展的催化剂，最终促进机器对物理世界的整体理解。",
      "shortSummary": "本文介绍了一个名为OmniWorld的大规模多领域多模态数据集，旨在促进4D世界建模的研究。该数据集由新收集的OmniWorld-Game数据集和多个公共数据集组成，提供了丰富的模态覆盖、更大的规模和更逼真的动态交互。实验表明，OmniWorld能够有效评估和提升现有4D重建和视频生成方法的性能，有望加速通用4D世界模型的发展。",
      "translated_title": "OmniWorld: 用于4D世界建模的多领域和多模态数据集",
      "images": [],
      "contentSource": "完整文章",
      "content": "The field of 4D world modeling - aiming to jointly capture spatial geometry and temporal dynamics - has witnessed remarkable progress in recent years, driven by advances in large-scale generative models and multimodal learning. However, the development of truly general 4D world models remains fundamentally constrained by the availability of high-quality data. Existing datasets and benchmarks often lack the dynamic complexity, multi-domain diversity, and spatial-temporal annotations required to support key tasks such as 4D geometric reconstruction, future prediction, and camera-control video generation. To address this gap, we introduce OmniWorld, a large-scale, multi-domain, multi-modal dataset specifically designed for 4D world modeling. OmniWorld consists of a newly collected OmniWorld-Game dataset and several curated public datasets spanning diverse domains. Compared with existing synthetic datasets, OmniWorld-Game provides richer modality coverage, larger scale, and more realistic dynamic interactions. Based on this dataset, we establish a challenging benchmark that exposes the limitations of current state-of-the-art (SOTA) approaches in modeling complex 4D environments. Moreover, fine-tuning existing SOTA methods on OmniWorld leads to significant performance gains across 4D reconstruction and video generation tasks, strongly validating OmniWorld as a powerful resource for training and evaluation. We envision OmniWorld as a catalyst for accelerating the development of general-purpose 4D world models, ultimately advancing machines' holistic understanding of the physical world."
    },
    {
      "title": "再看一眼，慢思考：增强视觉语言模型中的视觉反思能力 (原标题: Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models)",
      "link": "https://arxiv.org/abs/2509.12132",
      "pubDate": "Mon, 15 Sep 2025 12:57:25 GMT",
      "isoDate": "2025-09-15T12:57:25.000Z",
      "creator": "Pu Jian, Junhong Wu, Wei Sun, Chen Wang, Shuo Ren, Jiajun Zhang",
      "summary": "本文提出了一种名为 **Reflection-V** 的新型视觉推理模型（VRM），旨在解决当前视觉语言模型（VLM）在“慢思考”推理过程中视觉反思能力有限的问题。\n\n### 挑战\n\n*   **视觉反思能力不足**：当前的VRM在进行“慢思考”推理时，检查基于视觉信息的推理过程的能力有限。\n*   **视觉注意力衰减**：定量分析表明，随着生成响应的长度增加，现有VRM对视觉信息的注意力会迅速减弱。\n\n### 解决方案：Reflection-V\n\nReflection-V 通过以下两种机制增强了视觉反思能力：\n\n1.  **视觉中心推理数据构建（冷启动学习）**：\n    *   利用一个在VLM和推理大型语言模型（LLM）之间进行交互的代理，构建以视觉为中心的推理数据。\n    *   这使得模型能够进行视觉反思模式的冷启动学习。\n\n2.  **基于视觉注意力的强化学习奖励设计**：\n    *   在强化学习（RL）过程中，采用一个基于视觉注意力的奖励模型。\n    *   该奖励模型旨在鼓励模型在推理时更多地依赖视觉信息。\n\n### 成果\n\n*   **显著提升**：Reflection-V 在多个视觉推理基准测试中展现出显著的性能提升。\n*   **持续依赖视觉信息**：该模型在视觉推理过程中对视觉信息保持了更强、更一致的依赖，表明其视觉反思能力得到了有效增强。\n\n### 其他信息\n\n*   **会议**：EMNLP2025\n*   **主要研究领域**：计算机视觉与模式识别（cs.CV），计算与语言（cs.CL）",
      "shortSummary": "本文提出 **Reflection-V**，旨在增强视觉语言模型（VLM）的视觉反思能力。研究发现当前VLM在长响应中对视觉信息的注意力会减弱。Reflection-V通过构建视觉中心推理数据进行冷启动学习，并采用基于视觉注意力的强化学习奖励模型，鼓励模型依赖视觉信息。实验证明，Reflection-V在多个视觉推理基准测试中表现显著提升，并能更持续地依赖视觉信息。",
      "translated_title": "再看一眼，慢思考：增强视觉语言模型中的视觉反思能力",
      "images": [],
      "contentSource": "完整文章",
      "content": "Recent advances in text-only \"slow-thinking\" reasoning have prompted efforts to transfer this capability to vision-language models (VLMs), for training visual reasoning models (VRMs). owever, such transfer faces critical challenges: Effective \"slow thinking\" in VRMs requires visual reflection, the ability to check the reasoning process based on visual information. Through quantitative analysis, we observe that current VRMs exhibit limited visual reflection, as their attention to visual information diminishes rapidly with longer generated responses. To address this challenge, we propose a new VRM Reflection-V, which enhances visual reflection based on reasoning data construction for cold-start and reward design for reinforcement learning (RL). Firstly, we construct vision-centered reasoning data by leveraging an agent that interacts between VLMs and reasoning LLMs, enabling cold-start learning of visual reflection patterns. Secondly, a visual attention based reward model is employed during RL to encourage reasoning based on visual information. Therefore, Reflection-V demonstrates significant improvements across multiple visual reasoning benchmarks. Furthermore, Reflection-V maintains a stronger and more consistent reliance on visual information during visual reasoning, indicating effective enhancement in visual reflection capabilities."
    },
    {
      "title": "嵌入中的迷失：视觉语言模型中的信息丢失 (原标题: Lost in Embeddings: Information Loss in Vision-Language Models)",
      "link": "https://arxiv.org/abs/2509.11986",
      "pubDate": "Mon, 15 Sep 2025 10:38:06 GMT",
      "isoDate": "2025-09-15T10:38:06.000Z",
      "creator": "Wenyan Li, Raphael Tang, Chengzu Li, Caiqi Zhang, Ivan Vulić, Anders Søgaard",
      "summary": "## 嵌入中的迷失：视觉语言模型中的信息丢失\n\n本文研究了视觉语言模型 (VLMs) 中，将视觉输入投影到语言模型嵌入空间过程中潜在的信息损失问题。VLMs 通常使用预训练的视觉编码器处理视觉输入，然后通过连接器组件将其投影到语言模型的嵌入空间中。虽然这种方法对于模态融合至关重要，但投影步骤可能导致的信息损失及其对模型能力的直接影响却鲜有研究。\n\n文章提出两种互补的方法来检查和量化这种信息损失：\n\n1. **语义信息保持评估:** 通过分析图像表示在投影前后k近邻关系的变化来评估语义信息的保持情况。\n2. **信息损失直接测量:** 通过从投影后的表示中重建视觉嵌入，在图像块级别定位信息损失。\n\n实验结果表明，连接器会大幅扭曲视觉表示的局部几何结构，投影后k近邻关系差异高达40%-60%，这与检索性能的下降相关。图像块级别的嵌入重建为视觉基础问答任务的模型行为提供了可解释的见解，发现高信息损失区域可靠地预测了模型难以处理的实例。",
      "shortSummary": "本文研究视觉语言模型中将视觉信息投影到语言模型嵌入空间可能导致的信息损失。研究者通过分析k近邻关系变化和重建视觉嵌入两种方法量化信息损失，发现投影过程会显著扭曲视觉表示的局部几何结构，导致检索性能下降，并影响视觉基础问答任务的模型表现。",
      "translated_title": "嵌入中的迷失：视觉语言模型中的信息丢失",
      "images": [],
      "contentSource": "完整文章",
      "content": "Vision--language models (VLMs) often process visual inputs through a pretrained vision encoder, followed by a projection into the language model's embedding space via a connector component. While crucial for modality fusion, the potential information loss induced by this projection step and its direct impact on model capabilities remain understudied. We introduce two complementary approaches to examine and quantify this loss by analyzing the latent representation space. First, we evaluate semantic information preservation by analyzing changes in k-nearest neighbor relationships between image representations, before and after projection. Second, we directly measure information loss by reconstructing visual embeddings from the projected representation, localizing loss at an image patch level. Experiments reveal that connectors substantially distort the local geometry of visual representations, with k-nearest neighbors diverging by 40--60\\% post-projection, correlating with degradation in retrieval performance. The patch-level embedding reconstruction provides interpretable insights for model behavior on visually grounded question-answering tasks, finding that areas of high information loss reliably predict instances where models struggle."
    },
    {
      "title": "EthicsMH：精神健康AI伦理推理的初步基准 (原标题: EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI)",
      "link": "https://arxiv.org/abs/2509.11648",
      "pubDate": "Mon, 15 Sep 2025 03:35:35 GMT",
      "isoDate": "2025-09-15T03:35:35.000Z",
      "creator": "Sai Kartheek Reddy Kasu",
      "summary": "### EthicsMH：精神健康AI伦理推理的初步基准\n\n**引言：AI在精神健康领域的伦理挑战**\n\n随着大型语言模型（LLMs）在精神健康及其他敏感领域的部署，关于伦理推理、公平性和负责任对齐的紧迫问题日益凸显。现有针对道德和临床决策的基准未能充分捕捉精神健康实践中独特的伦理困境，这些困境常涉及保密性、自主性、受益原则和偏见等方面的复杂交叉。\n\n**EthicsMH数据集的提出**\n\n为解决这一空白，研究人员引入了“精神健康伦理推理”（EthicsMH）数据集。这是一个初步的、包含125个情景的数据集，旨在评估AI系统如何在治疗和精神病学背景下处理具有伦理挑战性的情况。\n\n**EthicsMH情景的结构化内容**\n\n每个情景都通过结构化字段进行了丰富，具体包括：\n\n*   **多个决策选项**：提供不同的行动方案供AI选择。\n*   **专家对齐的推理**：包含与专业专家意见一致的推理过程，作为AI决策的参考。\n*   **预期的模型行为**：明确指出在特定伦理情境下，AI系统应如何表现。\n*   **实际世界影响**：评估不同决策可能带来的现实后果。\n*   **多方利益相关者的观点**：考虑患者、家属、治疗师等不同角色的视角和关注点。\n\n**评估范围**\n\n这种结构使得EthicsMH不仅能够评估AI决策的准确性，还能深入评估其解释的质量以及与专业规范的对齐程度。\n\n**开发与未来展望**\n\n尽管EthicsMH目前规模适中，且在开发过程中采用了模型辅助生成，但它成功建立了一个连接AI伦理与精神健康决策的任务框架。通过发布此数据集，研究人员旨在提供一个种子资源，期望能够通过社区和专家贡献进行进一步扩展。最终目标是促进开发能够负责任地处理社会最敏感决策的AI系统，确保AI在精神健康领域的应用是安全、公正和合乎伦理的。",
      "shortSummary": "大型语言模型在精神健康领域的应用面临伦理挑战，现有基准不足。为弥补此空白，研究人员推出了EthicsMH，一个包含125个情景的初步数据集。该数据集旨在评估AI系统在治疗和精神病学背景下的伦理推理能力，涵盖决策选项、专家推理、预期行为和多方观点。EthicsMH旨在连接AI伦理与精神健康决策，提供一个可扩展的资源，以促进开发负责任的AI系统。",
      "translated_title": "EthicsMH：精神健康AI伦理推理的初步基准",
      "images": [],
      "contentSource": "完整文章",
      "content": "The deployment of large language models (LLMs) in mental health and other sensitive domains raises urgent questions about ethical reasoning, fairness, and responsible alignment. Yet, existing benchmarks for moral and clinical decision-making do not adequately capture the unique ethical dilemmas encountered in mental health practice, where confidentiality, autonomy, beneficence, and bias frequently intersect. To address this gap, we introduce Ethical Reasoning in Mental Health (EthicsMH), a pilot dataset of 125 scenarios designed to evaluate how AI systems navigate ethically charged situations in therapeutic and psychiatric contexts. Each scenario is enriched with structured fields, including multiple decision options, expert-aligned reasoning, expected model behavior, real-world impact, and multi-stakeholder viewpoints. This structure enables evaluation not only of decision accuracy but also of explanation quality and alignment with professional norms. Although modest in scale and developed with model-assisted generation, EthicsMH establishes a task framework that bridges AI ethics and mental health decision-making. By releasing this dataset, we aim to provide a seed resource that can be expanded through community and expert contributions, fostering the development of AI systems capable of responsibly handling some of society's most delicate decisions."
    },
    {
      "title": "UI-S1：基于半在线强化学习的GUI自动化改进 (原标题: UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning)",
      "link": "https://arxiv.org/abs/2509.11543",
      "pubDate": "Sun, 14 Sep 2025 23:24:08 GMT",
      "isoDate": "2025-09-14T23:24:08.000Z",
      "creator": "Zhengxi Lu, Jiabo Ye, Fei Tang, Yongliang Shen, Haiyang Xu, Ziwei Zheng, Weiming Lu, Ming Yan, Fei Huang, Jun Xiao, Yueting Zhuang",
      "summary": "## UI-S1：基于半在线强化学习的GUI自动化改进\n\n本文介绍了一种名为UI-S1的新方法，该方法通过半在线强化学习来改进图形用户界面(GUI)自动化。现有的强化学习方法在GUI自动化方面面临着离线强化学习和在线强化学习的困境：离线强化学习虽然训练稳定，但由于缺乏轨迹级别的奖励信号，难以执行多步任务；而在线强化学习虽然能够捕捉到这些信号，但却面临稀疏奖励和高昂的部署成本问题。\n\nUI-S1提出了一种新的半在线强化学习范式，它在离线轨迹上模拟在线强化学习。在每次回滚过程中，该方法保留原始模型在多轮对话中的输出，并使用一个“Patch Module”自适应地恢复回滚轨迹和专家轨迹之间的差异。为了捕捉长期训练信号，UI-S1将贴现的未来回报引入奖励计算，并使用加权的步骤级和情节级优势来优化策略。\n\n此外，UI-S1还引入了一个名为“Semi-Online Performance (SOP)”的指标，该指标更符合真实的在线性能，可以作为现实世界评估的有效代理。实验结果表明，在四个动态基准测试中，UI-S1在7B模型中实现了最先进的性能，与基线模型相比取得了显著的提升（例如，在AndroidWorld上提升了12.0%，在AITW上提升了23.8%）。这表明UI-S1在弥合离线训练效率和在线多轮推理之间的差距方面取得了显著进展。代码已公开发布。",
      "shortSummary": "UI-S1 提出了一种新的半在线强化学习方法，用于改进 GUI 自动化。该方法结合了离线强化学习的稳定性和在线强化学习的反馈能力，在多个基准测试中取得了最先进的性能，显著提升了多步任务执行能力，并降低了部署成本。",
      "translated_title": "UI-S1：基于半在线强化学习的GUI自动化改进",
      "images": [],
      "contentSource": "完整文章",
      "content": "Graphical User Interface (GUI) agents have demonstrated remarkable progress in automating complex user interface interactions through reinforcement learning. However, current approaches face a fundamental dilemma: offline RL enables stable training on pre-collected trajectories, but struggles with multi-step task execution for lack of trajectory-level reward signals; online RL captures these signals through environment interaction, but suffers from sparse rewards and prohibitive deployment costs. To address it, we present Semi-online Reinforcement Learning, a novel paradigm that simulates online RL on offline trajectories. During each rollout process, we preserve the original model output within the multi-turn dialogue, where a Patch Module adaptively recovers the divergence between rollout and expert trajectories. To capture long-term training signals, Semi-online RL introduces discounted future returns into the reward computation and optimizes the policy with weighted step-level and episode-level advantages. We further introduce Semi-Online Performance (SOP), a metric that aligns better with true online performance, serving as a practical and effective proxy for real-world evaluation. Experiments show that ours Semi-online RL achieves SOTA performance among 7B models across four dynamic benchmarks, with significant gains over the base model (e.g., +12.0% on AndroidWorld, +23.8% on AITW), demonstrating significant progress in bridging the gap between offline training efficiency and online multi-turn reasoning. The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1."
    },
    {
      "title": "用于千兆像素病理组织图像分析的掩蔽硬实例挖掘多实例学习框架 (原标题: Multiple Instance Learning Framework with Masked Hard Instance Mining for Gigapixel Histopathology Image Analysis)",
      "link": "https://arxiv.org/abs/2509.11526",
      "pubDate": "Sun, 14 Sep 2025 22:31:33 GMT",
      "isoDate": "2025-09-14T22:31:33.000Z",
      "creator": "Wenhao Tang, Sheng Huang, Heng Fang, Fengtao Zhou, Bo Liu, Qingshan Liu",
      "summary": "## 用于千兆像素病理组织图像分析的掩蔽硬实例挖掘多实例学习框架 (MHIM-MIL)\n\n### 背景与挑战\n\n*   **计算病理学的新机遇**：将病理图像数字化为千兆像素全玻片图像（WSIs）为计算病理学（CPath）带来了新的发展方向。\n*   **现有方法的局限性**：在千兆像素WSIs中，阳性组织通常只占很小一部分。现有的多实例学习（MIL）方法通常侧重于通过注意力机制识别显著实例，但这导致模型偏向于易于分类的实例，而忽略了那些具有挑战性的“硬实例”。\n*   **硬实例的重要性**：最近的研究表明，硬实例对于准确建模判别边界至关重要。\n\n### 提出的解决方案：MHIM-MIL 框架\n\n本文提出了一种新颖的MIL框架——**掩蔽硬实例挖掘多实例学习 (MHIM-MIL)**，旨在解决现有方法忽略硬实例的问题。MHIM-MIL 的核心机制包括：\n\n1.  **Siamese 结构与一致性约束**：MHIM-MIL 采用 Siamese 结构并结合一致性约束来有效地探索和识别硬实例。\n2.  **动量教师模型与隐式挖掘**：\n    *   利用类感知实例概率。\n    *   一个动量教师模型负责掩蔽掉显著的（易于分类的）实例。\n    *   通过这种掩蔽，隐式地挖掘出硬实例，用于训练学生模型。\n3.  **多样化、非冗余的硬实例**：\n    *   采用大规模随机掩蔽策略，以确保获取的硬实例具有多样性且非冗余。\n    *   引入一个全局回收网络，以降低在掩蔽过程中丢失关键特征的风险。\n4.  **稳定优化与持续学习**：\n    *   学生模型通过指数移动平均（EMA）的方式更新教师模型。\n    *   这种更新机制有助于教师模型在后续训练迭代中识别新的硬实例，并稳定整个优化过程。\n\n### 实验结果\n\n*   **广泛评估**：MHIM-MIL 在多项任务上进行了实验验证，包括癌症诊断、亚型分类、生存分析任务以及12个基准测试。\n*   **卓越性能与效率**：实验结果表明，MHIM-MIL 在性能和效率方面均优于最新的方法。\n\n### 代码可用性\n\n*   相关代码已在 `this https URL` 公开。",
      "shortSummary": "针对千兆像素病理图像分析中现有MIL方法忽略关键“硬实例”的问题，本文提出了MHIM-MIL框架。该框架采用Siamese结构和动量教师模型，通过掩蔽显著实例来隐式挖掘并利用硬实例进行训练。为确保多样性并避免特征丢失，MHIM-MIL结合了大规模随机掩蔽和全局回收网络。实验证明，MHIM-MIL在癌症诊断、亚型分类和生存分析等任务上，性能和效率均超越了现有最新方法。",
      "translated_title": "用于千兆像素病理组织图像分析的掩蔽硬实例挖掘多实例学习框架",
      "images": [],
      "contentSource": "完整文章",
      "content": "Digitizing pathological images into gigapixel Whole Slide Images (WSIs) has opened new avenues for Computational Pathology (CPath). As positive tissue comprises only a small fraction of gigapixel WSIs, existing Multiple Instance Learning (MIL) methods typically focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting challenging ones. Recent studies have shown that hard examples are crucial for accurately modeling discriminative boundaries. Applying such an idea at the instance level, we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which utilizes a Siamese structure with a consistency constraint to explore the hard instances. Using a class-aware instance probability, MHIM-MIL employs a momentum teacher to mask salient instances and implicitly mine hard instances for training the student model. To obtain diverse, non-redundant hard instances, we adopt large-scale random masking while utilizing a global recycle network to mitigate the risk of losing key features. Furthermore, the student updates the teacher using an exponential moving average, which identifies new hard instances for subsequent training iterations and stabilizes optimization. Experimental results on cancer diagnosis, subtyping, survival analysis tasks, and 12 benchmarks demonstrate that MHIM-MIL outperforms the latest methods in both performance and efficiency. The code is available at: https://github.com/DearCaat/MHIM-MIL."
    },
    {
      "title": "通过动态奖励权重学习优化多目标对齐 (原标题: Learning to Optimize Multi-Objective Alignment Through Dynamic Reward Weighting)",
      "link": "https://arxiv.org/abs/2509.11452",
      "pubDate": "Sun, 14 Sep 2025 17:56:35 GMT",
      "isoDate": "2025-09-14T17:56:35.000Z",
      "creator": "Yining Lu, Zilong Wang, Shiyang Li, Xin Liu, Changlong Yu, Qingyu Yin, Zhan Shi, Zixuan Zhang, Meng Jiang",
      "summary": "## 通过动态奖励权重学习优化多目标对齐：详细摘要\n\n本文探讨了多目标强化学习中使用固定权重线性奖励标量化方法的局限性，该方法无法有效捕捉非凸帕累托前沿，从而导致次优结果。这种局限性在大型语言模型的在线偏好对齐中尤为关键，因为参数化策略生成的随机轨迹会在参数与目标之间创建高度非线性且非凸的映射，任何单一的静态加权方案都无法找到最佳权衡。\n\n为了解决这个问题，本文引入了**动态奖励权重**方法，该方法在在线强化学习过程中自适应地调整奖励权重。与依赖于固定权重插值的现有方法不同，动态加权在训练过程中持续平衡和优先考虑目标，从而促进有效探索目标空间中的帕累托前沿。\n\n文章提出了两种日益复杂和通用的方法：\n\n1. **超体积引导的权重自适应:**  该方法利用超体积指标来指导奖励权重的调整，从而更有效地探索帕累托前沿。\n2. **基于梯度的权重优化:**  该方法利用梯度信息来优化奖励权重，具有更高的效率和泛化能力。\n\n实验结果表明，这两种方法与常用的在线强化学习算法（包括GRPO、REINFORCE和RLOO）兼容，在多个数学推理数据集上均有效，并适用于不同的模型族，与固定权重线性标量化基线相比，能够在更少的训练步骤中获得帕累托最优解。\n\n总而言之，本文提出了一种新颖的动态奖励权重方法，有效地解决了多目标强化学习中固定权重方法的局限性，为在线多目标对齐提供了一种有效的工具。",
      "shortSummary": "本文提出了一种通过动态调整奖励权重来优化多目标强化学习的方法。该方法克服了传统固定权重线性奖励标量化方法的局限性，能够更有效地探索帕累托最优解。文章提出了两种动态权重调整方法：超体积引导的权重自适应和基于梯度的权重优化，并在多个数据集上验证了其有效性，显著减少了训练步骤。",
      "translated_title": "通过动态奖励权重学习优化多目标对齐",
      "images": [],
      "contentSource": "完整文章",
      "content": "Prior works in multi-objective reinforcement learning typically use linear reward scalarization with fixed weights, which provably fail to capture non-convex Pareto fronts and thus yield suboptimal results. This limitation becomes especially critical in online preference alignment for large language models. Here, stochastic trajectories generated by parameterized policies create highly non-linear and non-convex mappings from parameters to objectives that no single static weighting scheme can find optimal trade-offs. We address this limitation by introducing dynamic reward weighting, which adaptively adjusts reward weights during the online reinforcement learning process. Unlike existing approaches that rely on fixed-weight interpolation, our dynamic weighting continuously balances and prioritizes objectives in training, facilitating effective exploration of Pareto fronts in objective space. We introduce two approaches of increasing sophistication and generalizability: (1) hypervolume-guided weight adaptation and (2) gradient-based weight optimization, offering a versatile toolkit for online multi-objective alignment. Our extensive experiments demonstrate their compatibility with commonly used online reinforcement learning algorithms (including GRPO, REINFORCE, and RLOO), effectiveness across multiple mathematical reasoning datasets, and applicability to different model families, consistently achieving Pareto dominant solutions with fewer training steps than fixed-weight linear scalarization baselines."
    },
    {
      "title": "CognitiveSky：去中心化社交媒体的可扩展情感和叙事分析 (原标题: CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media)",
      "link": "https://arxiv.org/abs/2509.11444",
      "pubDate": "Sun, 14 Sep 2025 17:37:24 GMT",
      "isoDate": "2025-09-14T17:37:24.000Z",
      "creator": "Gaurab Chhetri, Anandi Dutta, Subasish Das",
      "summary": "### CognitiveSky：去中心化社交媒体的可扩展情感和叙事分析框架\n\n本文介绍了 **CognitiveSky**，一个开源且可扩展的框架，专为去中心化社交媒体平台（如 Bluesky）设计，用于进行情感、情绪和叙事分析。\n\n**核心功能与目标：**\n*   **实时分析公共话语：** 旨在应对去中心化社交媒体平台在实时分析公共话语方面带来的新机遇和挑战。\n*   **多维度分析：** 提供对用户生成内容的情感、情绪和叙事进行深入分析的能力。\n\n**工作原理：**\n*   **数据摄取：** 通过 Bluesky 的应用程序编程接口（API）获取数据。\n*   **模型应用：** 利用基于 Transformer 的模型对大规模用户生成内容进行标注。\n*   **输出生成：** 产生结构化且可分析的输出。\n\n**可视化与洞察：**\n*   **动态仪表板：** 分析结果驱动一个动态仪表板，可视化情感、活动和对话主题的演变模式。\n\n**关键特性：**\n*   **开源与可扩展：** 作为一个开源项目，具有良好的可扩展性，能够处理大量数据。\n*   **低运营成本与高可访问性：** 完全基于免费层基础设施构建，实现了低运营成本和高可访问性。\n*   **模块化设计：** 其模块化设计使其能够应用于多个领域。\n\n**应用领域：**\n*   **当前演示：** 在本文中，CognitiveSky 被用于监测心理健康话语。\n*   **潜在应用：** 其应用范围广泛，包括虚假信息检测、危机响应和公民情绪分析等。\n\n**重要意义：**\n*   **连接大语言模型与去中心化网络：** CognitiveSky 弥合了大语言模型与去中心化网络之间的鸿沟。\n*   **透明且可扩展的工具：** 在数字生态系统不断变化的时代，它为计算社会科学提供了一个透明、可扩展的工具。\n\n**背景信息：**\n*   本文是作者的预印本版本，已被 HICSS 59（夏威夷国际系统科学会议，2026 年）接受发表。",
      "shortSummary": "CognitiveSky 是一个开源、可扩展的框架，专为去中心化社交媒体（如 Bluesky）设计，用于情感、情绪和叙事分析。它通过 Bluesky API 摄取数据，利用 Transformer 模型进行标注，并通过动态仪表板可视化用户话语模式。该框架基于免费层基础设施，成本低廉，模块化设计使其适用于心理健康监测、虚假信息检测和危机响应等多种应用，为计算社会科学提供了一个透明且可扩展的工具。",
      "translated_title": "CognitiveSky：去中心化社交媒体的可扩展情感和叙事分析",
      "images": [],
      "contentSource": "完整文章",
      "content": "The emergence of decentralized social media platforms presents new opportunities and challenges for real-time analysis of public discourse. This study introduces CognitiveSky, an open-source and scalable framework designed for sentiment, emotion, and narrative analysis on Bluesky, a federated Twitter or X.com alternative. By ingesting data through Bluesky's Application Programming Interface (API), CognitiveSky applies transformer-based models to annotate large-scale user-generated content and produces structured and analyzable outputs. These summaries drive a dynamic dashboard that visualizes evolving patterns in emotion, activity, and conversation topics. Built entirely on free-tier infrastructure, CognitiveSky achieves both low operational cost and high accessibility. While demonstrated here for monitoring mental health discourse, its modular design enables applications across domains such as disinformation detection, crisis response, and civic sentiment analysis. By bridging large language models with decentralized networks, CognitiveSky offers a transparent, extensible tool for computational social science in an era of shifting digital ecosystems."
    }
  ],
  "lastUpdated": "2025-09-17T09:34:51.893Z"
}
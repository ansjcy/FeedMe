{
  "sourceUrl": "https://www.unite.ai/feed/",
  "title": "Unite.AI",
  "description": "- AI News",
  "link": "https://www.unite.ai/",
  "items": [
    {
      "title": "Evogene 和 Google Cloud 推出生成式分子设计基础模型，开创生命科学 AI 新纪元 (原标题: Evogene and Google Cloud Unveil Foundation Model for Generative Molecule Design, Pioneering a New Era in Life-Science AI)",
      "link": "https://www.unite.ai/evogene-and-google-cloud-unveil-foundation-model-for-generative-molecule-design-pioneering-a-new-era-in-life-science-ai/",
      "pubDate": "Tue, 10 Jun 2025 22:33:46 +0000",
      "isoDate": "2025-06-10T22:33:46.000Z",
      "creator": "Antoine Tardif",
      "summary": "Evogene Ltd. 与 Google Cloud 合作，于2025年6月10日发布了一款开创性的生成式AI基础模型，用于小分子设计。该模型扩展了 Evogene 的 ChemPass AI 平台，旨在革新新化合物的发现方式，尤其是在制药和农业领域。\n\n![AI与分子设计](https://www.unite.ai/wp-content/uploads/2025/06/AI-and-Molecular-Design-512x341.png)\n\n### 传统研发的挑战与AI范式转变\n\n*   **传统方法**：通常采用逐一测试的顺序筛选方式，先验证化合物功效，再测试安全性与稳定性。这种方法耗时、昂贵，且失败率高（约90%的候选药物在上市前失败），同时限制了化学结构的创新。\n*   **生成式AI的优势**：通过AI模型，研究人员可以从一开始就同时优化多个属性（如功效、毒性和稳定性），从而实现多参数同步设计。这有助于在早期阶段降低后期开发风险，减少后期失败率。\n\n### ChemPass AI 的核心技术\n\n*   **基础模型训练**：ChemPass AI 的核心是一个强大的基础模型，它在 Google Cloud 的 Vertex AI 基础设施上，利用GPU超级计算，对约400亿个分子结构（包括已知药物类化合物和多样化的化学骨架）的庞大化学数据集进行了训练。\n*   **架构与机制**：该模型基于Transformer神经网络架构，类似于GPT模型，被称为 ChemPass-GPT。它将分子视为“句子”，通过SMILES字符串（分子结构的文本编码）学习化学“语法”，能够逐字符地“编写”新的分子，生成化学有效且具有药物特性的新SMILES。\n*   **卓越性能**：内部测试显示，ChemPass AI 在生成符合所有设计标准的新分子方面，精度高达90%，远超传统基于GPT模型的约29%的精度。\n*   **多工具集成**：除了序列模型（擅长创造性和新颖性），ChemPass AI 还结合了图神经网络（GNNs）等其他AI工具，用于直接对分子结构进行推理、预测属性，并支持3D虚拟筛选（如DeepDock），确保生成化合物的化学合理性和实际有效性。\n\n### 多目标优化能力\n\n*   **同步优化**：ChemPass AI 的突出特点是其内置的多目标优化能力，能够同时处理多个设计目标，如效力、毒性、稳定性、生物利用度和可合成性。\n*   **实现方式**：通过先进的机器学习技术实现，包括多任务学习和强化学习（RL）。模型可以根据预设的属性要求进行“约束生成”，或者通过奖励机制不断优化其生成策略，以最大化满足多重目标的得分。\n*   **未来发展**：即将推出的 ChemPass AI 2.0 版本将提供更灵活的多参数调整功能，允许用户根据特定治疗领域或作物需求定义标准。\n\n### 超越传统研发方法的飞跃\n\n*   **扩展化学多样性**：AI能够探索数十亿种可能性，深入未知的化学空间，发现前所未有的有效化合物，并从一开始就考虑专利性，避免知识产权拥挤区域。\n*   **并行多特性优化**：AI能并行评估多个参数，预先筛选潜在问题，提高后期临床试验的成功率。\n*   **速度与规模**：AI能在数天内模拟传统方法数年才能完成的工作，快速筛选数百亿化合物，并在单次运行中生成数百个新想法，显著缩短发现周期。\n*   **整合知识**：AI模型在训练中整合了海量的化学和生物知识（如结构-活性关系、毒性警报等），使每次分子设计都受益于人类专家无法掌握的广阔数据。\n\n### Evogene 的AI工具箱与未来展望\n\n*   **AI生态系统**：ChemPass AI 是 Evogene AI 驱动的“技术引擎”三部曲之一，其他包括专注于微生物的 MicroBoost AI 和专注于遗传元素的 GeneRator AI。这体现了 Evogene 作为“AI优先”生命科学公司的战略。\n*   **AI驱动的发现时代**：生成式AI正在将AI的角色从辅助者转变为创造性合作者。它使科学家能够一步到位地设计出满足多重目标（效力、安全性、稳定性等）的全新化合物。这种方法不仅限于药物或农药，未来有望推动材料、食品和可持续发展等领域的突破。",
      "shortSummary": "Evogene 和 Google Cloud 联合推出了生成式AI基础模型 ChemPass AI，用于小分子设计。该模型通过同时优化功效、毒性和稳定性等多个属性，革新了药物和农业领域的研发流程。ChemPass AI 基于Transformer架构，训练于400亿分子数据，能以90%的精度生成符合要求的新颖化合物，显著提升了发现速度和成功率，开创了生命科学AI的新纪元。",
      "translated_title": "Evogene 和 Google Cloud 推出生成式分子设计基础模型，开创生命科学 AI 新纪元",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/AI-and-Molecular-Design-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/AI-and-Molecular-Design-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" fetchpriority=\"high\" sizes=\"(max-width: 512px) 100vw, 512px\" /><p>Evogene Ltd. has unveiled a first-in-class generative AI foundation model for small-molecule design, marking a breakthrough in how new compounds are discovered. Announced on June 10, 2025, in collaboration with Google Cloud, the model expands Evogene’s ChemPass AI platform and tackles a long-standing challenge in both pharmaceuticals and agriculture: finding novel molecules that meet multiple [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/evogene-and-google-cloud-unveil-foundation-model-for-generative-molecule-design-pioneering-a-new-era-in-life-science-ai/\">Evogene and Google Cloud Unveil Foundation Model for Generative Molecule Design, Pioneering a New Era in Life-Science AI</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "Hirundo 融资 800 万美元，利用机器遗忘技术解决 AI 幻觉问题 (原标题: Hirundo Raises $8M to Tackle AI Hallucinations with Machine Unlearning)",
      "link": "https://www.unite.ai/hirundo-raises-8m-to-tackle-ai-hallucinations-with-machine-unlearning/",
      "pubDate": "Tue, 10 Jun 2025 19:07:28 +0000",
      "isoDate": "2025-06-10T19:07:28.000Z",
      "creator": "Antoine Tardif",
      "summary": "## Hirundo 融资 800 万美元，利用机器遗忘技术解决 AI 幻觉问题\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/06/hirundo-512x341.jpg)\n\nHirundo 作为首家专注于机器遗忘技术的初创公司，已成功完成 800 万美元的种子轮融资。本轮融资由 Maverick Ventures Israel 领投，SuperSeed、Alpha Intelligence Capital 等机构参投。此次融资旨在解决人工智能领域最紧迫的挑战，包括 AI 幻觉、偏见和嵌入式数据漏洞。\n\n### 核心创新：机器遗忘技术\n\n与传统的 AI 工具不同，Hirundo 的核心创新是“机器遗忘”（machine unlearning）技术。这项技术允许 AI 模型在训练完成后“遗忘”特定的知识或行为，而无需从头开始重新训练。这使得企业能够精准地从已部署的 AI 模型中移除幻觉、偏见、个人或专有数据以及对抗性漏洞。重新训练大型模型可能耗时数周并花费数百万美元，而 Hirundo 提供了一种更高效的替代方案。\n\nHirundo 将这一过程比作“AI 神经外科”：该公司能够精确识别模型参数中产生不良输出的位置，并进行精准移除，同时保持模型性能。这项突破性技术使组织能够在生产环境中修复模型，并以更高的信心部署 AI。\n\n### AI 幻觉的危害\n\nAI 幻觉指的是模型生成听起来合理甚至真实但实际上是虚假或误导性信息。在企业环境中，基于不正确信息做出的决策可能导致法律风险、操作错误和声誉损害。研究表明，AI 为法律查询生成的“事实”中有 58% 到 82% 包含某种形式的幻觉。尽管有通过护栏或微调来最小化幻觉的努力，但这些方法往往只是掩盖问题，未能消除根本原因。Hirundo 的方法超越了这些，它直接从模型本身移除行为或知识。\n\n### 可扩展的 AI 平台\n\nHirundo 的平台专为灵活性和企业级部署而设计。它能够与生成式和非生成式系统集成，支持广泛的数据类型，包括自然语言、视觉、雷达、激光雷达、表格、语音和时间序列数据。该平台能自动检测训练数据中的错误标记项、异常值和歧义，并允许用户调试特定的错误输出，追溯到有问题的训练数据或学习行为，并立即进行遗忘。所有这些都无需改变现有工作流程。\n\nHirundo 的系统已通过 SOC-2 认证，可通过 SaaS、私有云（VPC）甚至空隙隔离的本地部署运行，使其适用于金融、医疗和国防等敏感环境。\n\n### 已验证的影响与成果\n\n该公司已在流行的大型语言模型（LLM）上展示了显著的性能改进。在对 Llama 和 DeepSeek 进行的测试中，Hirundo 实现了：\n\n*   幻觉减少 55%\n*   偏见减少 70%\n*   成功提示注入攻击减少 85%\n\n这些结果已通过 HaluEval、PurpleLlama 和 Bias Benchmark Q&A 等独立基准测试验证。虽然当前解决方案与 Llama、Mistral 和 Gemma 等开源模型配合良好，但 Hirundo 正在积极扩展对 ChatGPT 和 Claude 等封闭模型的支持，使其技术适用于所有企业级 LLM。\n\n### 经验丰富的创始人团队\n\nHirundo 由三位在学术界和企业 AI 领域拥有深厚背景的专家于 2023 年创立：\n\n*   **Ben Luria（首席执行官）**：罗德学者，牛津大学前访问学者，曾创立金融科技初创公司 Worqly，并联合创立支持高等教育的非营利组织 ScholarsIL。\n*   **Michael Leybovich（首席技术官）**：以色列理工学院前研究生研究员，Ofek324 屡获殊荣的研发官员。\n*   **Oded Shmueli 教授（首席科学家）**：以色列理工学院计算机科学系前系主任，曾在 IBM、惠普、AT&T 等公司担任研究职务。\n\n他们的集体经验涵盖了基础 AI 研究、实际部署和安全数据管理，使他们具备独特的能力来应对当前 AI 行业的可靠性危机。\n\n### 投资者对可信赖 AI 未来的支持\n\n本轮投资者与 Hirundo 建立可信赖、企业级 AI 的愿景高度契合。Maverick Ventures Israel 创始人 Yaron Carni 指出，迫切需要一个能够消除幻觉或有偏见智能的平台，以防止其造成现实世界的危害。SuperSeed 的管理合伙人 Mads Jensen 也表示，AI 转型的力量取决于模型的可靠性，Hirundo 的机器遗忘方法弥补了 AI 开发生命周期中的关键空白。\n\n### 应对 AI 部署中日益增长的挑战\n\n随着 AI 系统越来越多地集成到关键基础设施中，对幻觉、偏见和嵌入式敏感数据的担忧日益突出。机器遗忘技术正成为 AI 行业应对模型可靠性和安全性担忧的关键工具。它能够直接减轻这些风险，在模型训练并投入使用后，有针对性地从模型中移除有问题的行为和数据，而不是依赖重新训练或表面修复。这种方法在寻求可扩展、合规解决方案的高风险应用领域（如金融、医疗和国防）中越来越受到企业和政府机构的青睐。",
      "shortSummary": "Hirundo 成功融资 800 万美元，旨在通过其创新的“机器遗忘”技术解决 AI 幻觉、偏见和数据漏洞问题。该技术允许 AI 模型在训练后高效地“遗忘”特定信息，无需耗时且昂贵的重新训练。Hirundo 的平台已在大型语言模型上验证，显著减少了幻觉和偏见，并支持多种部署环境。公司由经验丰富的专家团队领导，致力于构建可信赖的企业级 AI，以应对 AI 部署中的关键挑战。",
      "translated_title": "Hirundo 融资 800 万美元，利用机器遗忘技术解决 AI 幻觉问题",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/hirundo-512x341.jpg",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/hirundo-512x341.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" sizes=\"(max-width: 512px) 100vw, 512px\" /><p>Hirundo, the first startup dedicated to machine unlearning, has raised $8 million in seed funding to address some of the most pressing challenges in artificial intelligence: hallucinations, bias, and embedded data vulnerabilities. The round was led by Maverick Ventures Israel with participation from SuperSeed, Alpha Intelligence Capital, Tachles VC, AI.FUND, and Plug and Play Tech [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/hirundo-raises-8m-to-tackle-ai-hallucinations-with-machine-unlearning/\">Hirundo Raises $8M to Tackle AI Hallucinations with Machine Unlearning</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "人工智能与国家安全：新战场 (原标题: AI and National Security: The New Battlefield)",
      "link": "https://www.unite.ai/ai-and-national-security-the-new-battlefield/",
      "pubDate": "Tue, 10 Jun 2025 19:00:50 +0000",
      "isoDate": "2025-06-10T19:00:50.000Z",
      "creator": "Dr. Tehseen Zia",
      "summary": "# 人工智能与国家安全：新战场\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/06/ChatGPT-Image-Jun-10-2025-01_34_21-PM-512x341.png)\n\n人工智能（AI）正在深刻改变各国保护自身的方式，成为网络安全、武器开发、边境控制乃至公共话语领域的核心要素。它带来巨大的战略优势，但也伴随着诸多风险。本文探讨了AI如何重塑安全格局、当前的影响以及由此引发的挑战性问题。\n\n## AI在国家安全领域的应用与挑战\n\n### 1. 网络安全：AI对抗AI的战场\n\n*   **攻击方利用AI：** 犯罪分子使用语言模型撰写钓鱼邮件，利用深度伪造视频进行诈骗（例如，2024年一起涉及2500万美元的CFO深度伪造案），利用生成式AI创建软件漏洞或恶意软件。\n*   **防御方利用AI：** 安全团队将网络日志、用户行为和全球威胁报告输入AI工具，以识别“正常”活动并预警可疑事件。AI系统还能在检测到入侵时自动断开受感染计算机，限制损害蔓延。\n\n### 2. 自主武器：物理战场上的AI\n\n*   **军事应用：** 乌克兰使用AI无人机识别燃料卡车或雷达站；美国利用AI协助叙利亚空袭目标识别；以色列军队使用AI目标选择平台分析图像；中国、俄罗斯、土耳其、英国测试“巡飞弹”。这些技术提高了军事行动的精确性，降低了士兵风险。\n*   **伦理与担忧：** 算法选择错误目标时的责任归属；“闪电战”风险（机器反应过快导致外交干预失效）。许多专家呼吁制定国际规则来控制自主武器，但各国担心因此落后。\n\n### 3. 监控与情报：AI的“千里眼”\n\n*   **情报收集：** 情报机构利用AI每小时筛选数百万张图像和信息。\n*   **公民监控：** 在中国等国家，AI追踪公民行为，从闯红灯等小事到在线活动。\n*   **边境监控：** 在美墨边境，带有摄像头和热传感器的太阳能塔利用AI识别移动目标（人或动物），并向巡逻人员发出警报，形成“虚拟墙”。\n*   **挑战：** 人脸识别系统对女性和深色皮肤人群的误识别率高于白人男性；单一误报可能导致无辜者面临额外检查或拘留。政策制定者呼吁算法审计、明确申诉途径和人工复核。\n\n### 4. 信息战：叙事层面的冲突\n\n*   **AI生成虚假信息：** 2024年3月，一段伪造的乌克兰总统投降视频在事实核查人员揭穿前迅速传播；2023年以色列-哈马斯冲突期间，大量AI生成内容旨在左右舆论。\n*   **传播速度与影响：** 虚假信息传播速度快于政府纠正速度，尤其在选举期间，AI生成内容常被用于影响选民。选民难以区分真实与AI生成的图像或视频。\n*   **应对挑战：** 尽管政府和科技公司正开发反AI项目来扫描AI的数字指纹，但攻防竞赛激烈，造假者改进速度与防御者提升过滤能力的速度一样快。\n\n### 5. 决策支持：优化军事与机构运作\n\n*   **数据分析：** 军队和机构收集大量数据（包括无人机视频、维护日志、卫星图像和开源报告），AI通过筛选和突出相关信息提供帮助。\n*   **实际应用：** 北约最近采纳了一个受美国“Maven计划”启发的系统，它连接30个成员国的数据库，为规划者提供统一视图，并预测可能的敌方动向和潜在的补给短缺。美国特种作战司令部利用AI扫描发票并建议重新分配，协助起草年度预算。类似的AI平台还可预测发动机故障、提前安排维修，并为飞行员定制飞行模拟。\n\n### 6. 执法与边境管制：提升效率与安全\n\n*   **身份验证：** 在繁忙机场，生物识别自助服务机确认旅客身份，提高效率。\n*   **模式分析：** 模式分析软件识别暗示人口贩运或毒品走私的旅行记录（例如，2024年一个欧洲伙伴关系利用此类工具破获了一个通过货船贩运移民的团伙）。\n*   **担忧：** 人脸识别有时对某些代表性较低的人群识别失败，可能导致错误；隐私是另一个问题。核心问题在于AI是否应如此密切地监控所有人。\n\n## 结论\n\n人工智能正在多方面改变国家安全，既带来机遇也伴随风险。它能保护国家免受网络威胁，提高军事行动精确性，并改善决策。但它也可能传播谎言、侵犯隐私或导致致命错误。随着AI在安全领域日益普及，我们必须在使用其力量造福人类与控制其危险之间找到平衡。这意味着各国必须合作并制定明确的AI使用规则。归根结底，AI是一种工具，我们如何使用它将重新定义安全的未来。我们必须审慎明智地使用它，使其利大于弊。",
      "shortSummary": "人工智能（AI）正深刻改变国家安全，在网络安全、自主武器、情报监控、信息战、决策支持及执法等领域发挥关键作用。AI能提升防御能力和行动效率，但也带来隐私侵犯、虚假信息传播、误判及伦理责任等风险。未来需国际合作，制定明确规则，平衡AI的利弊，以确保其明智应用，使国家安全受益。",
      "translated_title": "人工智能与国家安全：新战场",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/ChatGPT-Image-Jun-10-2025-01_34_21-PM-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/ChatGPT-Image-Jun-10-2025-01_34_21-PM-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>Artificial intelligence is changing how nations protect themselves. It has become essential for cybersecurity, weapon development, border control, and even public discourse. While it offers significant strategic benefits, it also introduces many risks. This article examines how AI is reshaping security, the current outcomes, and the challenging questions these new technologies raise. Cybersecurity: A Fight [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/ai-and-national-security-the-new-battlefield/\">AI and National Security: The New Battlefield</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "通过有益的通用人工智能弥合发展中国家的教育差距：来自埃塞俄比亚的经验 (原标题: Bridging Educational Gaps in the Developing World through Beneficial AGI: Lessons from Ethiopia)",
      "link": "https://www.unite.ai/bridging-educational-gaps-in-the-developing-world-through-beneficial-agi-lessons-from-ethiopia/",
      "pubDate": "Tue, 10 Jun 2025 17:31:49 +0000",
      "isoDate": "2025-06-10T17:31:49.000Z",
      "creator": "Dr. Ben Goertzel, CEO of the Artificial Superintelligence (ASI) Alliance, and Founder of SingularityNET",
      "summary": "本文探讨了通用人工智能（AGI）在弥合发展中国家教育和经济差距方面的巨大潜力，并以埃塞俄比亚iCog Labs的经验为例进行了深入分析。\n\n### 引言：通用人工智能的普惠潜力\n\n文章强调，随着AGI日益受到全球关注，确保其发展惠及所有人至关重要，特别是那些面临持续教育和经济不平等的服务不足人群。iCog Labs是埃塞俄比亚首家也是最重要的AI公司，其经验揭示了在发展中国家应用AI技术的变革潜力与细微挑战。\n\n### 发展中国家教育面临的核心挑战\n\n服务不足人群在教育领域主要面临两大挑战：\n\n*   **语言障碍**：联合国教科文组织估计，全球40%的学生无法获得以他们完全理解的语言进行的教育。发达国家的科技公司缺乏动力为购买力较低的语言开发完善的技术。\n*   **文化不相关内容**：进口的教育内容往往与学习者的日常生活经验脱节，难以引起共鸣。\n\n### AI解决方案与iCog Labs的实践\n\niCog Labs通过多项创新项目，利用AI技术应对上述挑战：\n\n*   **克服语言障碍**：\n    *   利用生成式AI开发本地语言阅读应用，目前已服务超过85,000名活跃用户。\n    *   推出Leyu平台，这是一个去中心化的数据众包平台，专门收集来自偏远社区的语言资源，用于训练AI模型，将本地语言翻译成互联网上的主流语言。\n*   **通过情境化学习确保相关性**：\n    *   AI能够定制教育材料，将课程内容与当地现实相结合，例如将科学教育与当地农业实践结合，或将数学问题源于社区市场交易。\n    *   **Digitruck项目**：一个由iCog Labs部署的离网移动教育中心，将半挂式卡车改装成便携式教室，配备电脑和电子设备，由当地专家教师授课。该项目让农村地区的年轻学习者通过实践体验和与生活相关的应用（如改善农业实践）接触编程和AI概念。\n    *   **RoboSapiens倡议（2015-2019年）**：通过编程类人机器人踢足球，向埃塞俄比亚大学生介绍AI，这是一种具有文化共鸣且引人入胜的方法。尽管因电子设备进口关税高昂而暂停，但该项目在学生中产生了强大的激励作用。\n\n### AI在发展中国家的认知：值得信赖的盟友\n\n与富裕、数字化饱和社会中普遍存在的对AI的担忧（如终结者式的生存风险或AI导致的失业）不同，互联网接入有限的社区通常将AI视为一个值得信赖的信息盟友。例如，尼日利亚农民积极利用AI支持的呼叫中心获取农业建议和市场洞察，AI在此扮演着辅助和增强生计的角色，而非威胁。\n\n### 支持集体学习与社会结构\n\nAI融入教育必须尊重现有的社会结构。许多服务不足的社区优先考虑集体而非个人主义的学习方式。有益的AI应促进协作，增强社区指导，并与现有的集体决策过程无缝整合。去中心化和参与式设计的AI工具自然符合这种社区驱动的教育模式，从而加强而非破坏社会凝聚力。文章设想将Digitruck项目扩展为更持久的计划，由Digitruck的校友指导AI融入埃塞俄比亚乡村生活的各个方面，并结合社区主导的AI学习平台。\n\n### 风险规避与伦理实施\n\n尽管AI在加速发展中国家积极自我转型方面前景广阔，但仍需应对潜在风险。AI的便捷性可能削弱学生的基础技能或学习动力。负责任地引入AI要求其加强而非取代人类教育者和传统学习基础。AI应被定位为支持性基础设施，促进个性化学习并激发求知欲，而非一个削弱批判性思维和学习动力的答案生成器。人机对齐至关重要，应通过丰富而有意义的协作而非僵硬的限制来实现。\n\n### 去中心化和民主化AI促进全球教育公平\n\n文章指出，当前全球AI技术领域由少数大型公司主导，这导致AI语言技术忽视了大多数非洲语言，且更侧重于发达国家富裕专业人士的需求。作者坚信，去中心化、民主化指导的AI发展对全球教育公平具有关键优势。SingularityNET等平台旨在实现去中心化AI架构，赋能广泛参与和民主化治理，从而使AI发展更能反映多样化的全球需求，而非狭隘的企业或政府利益。\n\n实现AI增强型教育的公平之路并非坦途，它需要有意性、文化敏感性、伦理远见和参与式治理。然而，其潜在回报——消除教育障碍、增强文化相关性、赋能全球社区——使得这一旅程不仅值得，而且势在必行。\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/06/AI-In-Ethiopia-512x341.png)",
      "shortSummary": "本文探讨了通用人工智能（AGI）如何通过埃塞俄比亚iCog Labs的经验，弥合发展中国家的教育差距。文章指出，AI能克服语言障碍（如本地语言应用、数据众包）和文化不相关内容（如情境化学习、移动教室Digitruck）。在发展中国家，AI被视为值得信赖的盟友，支持集体学习。为实现教育公平，文章强调了去中心化、民主化AI发展的重要性，以确保AI惠及全球服务不足的社区。",
      "translated_title": "通过有益的通用人工智能弥合发展中国家的教育差距：来自埃塞俄比亚的经验",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/AI-In-Ethiopia-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/AI-In-Ethiopia-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>As the promise of Artificial General Intelligence (AGI) increasingly captures global imagination, it's critical we ensure advancing AI benefits everyone, not only privileged communities already relatively rich with resources, but particularly underserved populations facing persistent educational as well as economic disparities. Drawing from our experiences working together at iCog Labs in Ethiopia, a company co-founded [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/bridging-educational-gaps-in-the-developing-world-through-beneficial-agi-lessons-from-ethiopia/\">Bridging Educational Gaps in the Developing World through Beneficial AGI: Lessons from Ethiopia</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "人工智能革命是数据革命：为什么存储比以往任何时候都更重要 (原标题: The AI Revolution Is a Data Revolution: Why Storage Matters More Than Ever)",
      "link": "https://www.unite.ai/the-ai-revolution-is-a-data-revolution-why-storage-matters-more-than-ever/",
      "pubDate": "Tue, 10 Jun 2025 17:30:19 +0000",
      "isoDate": "2025-06-10T17:30:19.000Z",
      "creator": "Carlos Sandoval, IBM Worldwide Tape Product Manager, the LTO Program",
      "summary": "## 人工智能革命是数据革命：为什么存储比以往任何时候都更重要\n\n![数据存储](https://www.unite.ai/wp-content/uploads/2025/06/Data-Storage-512x341.webp)\n\n### 数据在人工智能时代的重要性\n\n*   **AI市场增长与数据需求**：全球AI市场预计将从目前的3900多亿美元增长到2030年的8260亿美元以上。这种增长严重依赖于海量数据的可用性，以推动AI技术的发展和应用价值的提升。\n*   **数据存储的爆炸式增长**：2024年全球数据存储量约为7.2泽字节（ZB），预计到2027年将增至15.1泽字节。这凸显了对可靠、可访问存储解决方案的迫切需求。\n*   **AI系统对数据的依赖**：AI系统通过数据来优化算法、增强预测模型和自动化。高质量的数据越多，AI成果的有效性就越高，从而实现更智能的决策和运营效率。\n*   **训练数据集的快速膨胀**：大型语言模型（LLMs）的训练数据集以惊人的速度增长，自2010年以来每年翻三倍。例如，GPT-4的训练数据量是GPT-2的数千倍。\n*   **数据耗尽的风险**：随着AI系统消耗大量现有文本数据，高质量的人类生成材料可能面临耗尽的风险。这可能导致AI开发者依赖AI生成内容进行未来训练，从而引发准确性降低、创造力下降和重复性增加等问题。因此，组织必须优先保留其生成的大部分数据，以备未来AI模型训练之用。\n\n### 数据分析作为竞争优势：没有IA就没有AI\n\n*   **信息档案（IA）的作用**：AI驱动的分析是现代商业策略的基石，但其基础是“信息档案”（IA），即能够随时随地提供数十年数据的基础设施。IA是组织知识的深层储备，通常存储在经济高效、可扩展的存储介质（如磁带）上。\n*   **数据生命周期**：当需要训练AI模型时，大型数据集会从IA中临时提取到高性能系统。训练完成后，数据返回IA进行长期保留。这种访问和保存的循环使得AI的持续发展成为可能。\n*   **长期数据策略的重要性**：高影响力的、数据驱动的决策不仅依赖于最新的AI工具，还取决于能否长期、大规模、经济高效地访问和保留正确的信息。将数据收集视为战略资产而非存储问题，是未来组织成功的关键。\n\n### 成熟技术的新机遇\n\n*   **存储解决方案的新需求**：AI驱动的应用对存储解决方案提出了新要求，包括长期存储海量数据集、确保可访问性、可持续性和安全性。此外，网络攻击的日益增加（预计到2025年全球网络犯罪成本将达10.5万亿美元）使得数据安全成为关键考量。\n*   **磁带存储的复兴**：尽管许多企业可能倾向于寻求新兴技术，但磁带存储作为一种经过验证的可靠技术，正在重新获得关注。它为管理大规模AI和机器学习工作负载提供了强大的组合：\n    *   **可扩展性、灵活性和成本效益**：能够以远低于传统云解决方案的成本存储PB级数据。\n    *   **可持续性**：存储数据时几乎不消耗能源，显著降低碳足迹。\n    *   **安全性**：其离线能力提供了额外的保护层，使其对勒索软件等网络威胁具有天然免疫力。\n    *   **长寿命**：通常可超过30年，确保数据长期保存而无降级风险。\n\n### 结论\n\n人工智能革命本质上是一场数据革命。未能优先考虑数据存储和可访问性的组织，将有落后于日益数据驱动的世界的风险。更多的数据意味着更多的创新和竞争差异化机会。通过采用可扩展、安全的存储解决方案，包括磁带存储的潜力，组织可以确保在AI进步和数据驱动决策方面保持领先地位。",
      "shortSummary": "人工智能的快速发展是一场数据革命，使得数据存储比以往任何时候都更加关键。AI系统需要海量高质量数据进行训练，这导致数据存储需求激增。组织面临着数据耗尽和依赖AI生成内容的风险，因此长期数据保留至关重要。信息档案（IA）作为数据分析的基础，为AI发展提供支持。磁带存储作为一种成熟技术，因其可扩展性、成本效益、可持续性和离线安全性，正成为满足AI时代海量数据存储需求和应对网络安全威胁的理想解决方案。优先考虑数据存储和可访问性是组织在AI时代保持竞争力的关键。",
      "translated_title": "人工智能革命是数据革命：为什么存储比以往任何时候都更重要",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/Data-Storage-512x341.webp",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/Data-Storage-512x341.webp\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>Easy access to data and the ability to utilize it in meaningful ways have always been important, but in the era of AI, machine learning, and data analytics, it has become absolutely essential. The global AI market, currently valued at over $390 billion, is projected to exceed $826 billion by 2030. However, this growth is [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/the-ai-revolution-is-a-data-revolution-why-storage-matters-more-than-ever/\">The AI Revolution Is a Data Revolution: Why Storage Matters More Than Ever</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "API调用代理的理解、构建与优化指南 (原标题: Guide to Understanding, Building, and Optimizing API-Calling Agents)",
      "link": "https://www.unite.ai/guide-to-understanding-building-and-optimizing-api-calling-agents/",
      "pubDate": "Tue, 10 Jun 2025 17:28:49 +0000",
      "isoDate": "2025-06-10T17:28:49.000Z",
      "creator": "Rodrigo Ceballos Lentini, AI Tech Lead, Georgian AI Lab",
      "summary": "API调用代理的理解、构建与优化指南\n\n![API调用代理](https://www.unite.ai/wp-content/uploads/2025/06/API-Calling-Agents-512x341.png)\n\n### 引言：AI代理的崛起\n\n人工智能在技术公司中的作用正在迅速演变，从被动的信息处理转向能够执行任务的主动代理。根据2025年3月的一项全球AI采纳调查，91%的技术高管正在使用或计划使用代理式AI。API调用代理是这一转变的主要例子，它们利用大型语言模型（LLM）通过应用程序编程接口（API）与软件系统交互，将自然语言命令转化为精确的API调用，以检索实时数据、自动化任务或控制其他软件系统。\n\n**API调用代理的应用领域：**\n*   **消费应用：** 如Apple Siri或Amazon Alexa，简化日常任务，如控制智能家居设备和预订。\n*   **企业工作流：** 自动化重复性任务，如从CRM检索数据、生成报告或整合内部系统信息。\n*   **数据检索与分析：** 简化对专有数据集、订阅资源和公共API的访问，以生成洞察。\n\n本文将从工程角度探讨API调用代理的理解、构建和优化，并基于Georgian AI Lab的实践研究。\n\n### 关键定义\n\n*   **API（Application Programming Interface）：** 一套规则和协议，使不同软件应用能够通信和交换信息。\n*   **代理（Agent）：** 一种AI系统，旨在感知环境、做出决策并采取行动以实现特定目标。\n*   **API调用代理（API-Calling Agent）：** 一种专门的AI代理，将自然语言指令转化为精确的API调用。\n*   **代码生成代理（Code Generating Agent）：** 一种AI系统，通过编写、修改和调试代码来辅助软件开发。\n*   **MCP（Model Context Protocol）：** 一种协议，由Anthropic开发，定义了LLM如何连接和利用外部工具和数据源。\n\n### 核心任务：将自然语言转化为API操作\n\nAPI调用代理的基本功能是将用户的自然语言请求解释并转换为一个或多个精确的API调用。此过程通常包括：\n\n1.  **意图识别：** 理解用户的目标，即使表达模糊。\n2.  **工具选择：** 从一组可用选项中识别能够实现意图的适当API端点（或“工具”）。\n3.  **参数提取：** 从用户查询中识别并提取所选API调用所需的参数。\n4.  **执行与响应生成：** 进行API调用，接收响应，然后将这些信息合成连贯的答案或执行后续操作。\n\n例如，对于“嘿Siri，今天天气怎么样？”的请求，代理必须识别需要调用天气API，确定用户当前位置，然后制定API调用来检索天气信息。挑战包括自然语言的模糊性和代理在多步交互中保持上下文的需求。\n\n### 解决方案架构：关键组件与协议\n\n构建有效的API调用代理需要结构化的架构方法。\n\n1.  **为代理定义“工具”：**\n    *   清晰的自然语言描述工具的目的和功能。\n    *   精确的输入参数规范（名称、类型、是否必需、描述）。\n    *   工具返回的输出或数据描述。\n\n2.  **模型上下文协议（MCP）的作用：**\n    *   MCP为LLM更标准化和健壮地使用工具提供了结构化格式。\n    *   促进了不同工具的轻松集成和工具定义在不同代理或模型间的重用。\n    *   最佳实践是使用定义良好的API规范（如OpenAPI），并利用Stainless.ai等工具将其转换为MCP配置。\n\n3.  **代理框架与实现选择：**\n    *   **Pydantic：** 用于定义数据结构和确保工具输入输出的类型安全。\n    *   **LastMile的mcp_agent：** 专门为MCP设计，提供与Anthropic研究实践一致的结构。\n    *   **内部框架：** 越来越多地使用AI代码生成代理（如Cursor或Cline）来帮助编写代理、工具及相关逻辑的样板代码，以创建最小化、自定义的框架。\n\n### 针对可靠性和性能的工程实践\n\n确保代理可靠地进行API调用并表现良好需要专注的工程努力。\n\n1.  **数据集创建与验证：**\n    *   高质量数据集对于训练、测试和优化代理至关重要，应包含代表性的自然语言查询及其对应的期望API调用序列或结果。\n    *   **手动创建：** 精度高但劳动密集。\n    *   **合成生成：** 可扩展数据集创建，但确保合成数据的正确性和现实复杂性非常困难。通常，生成的查询要么过于简单，要么过于复杂，难以衡量细微的代理性能。对合成数据进行仔细验证至关重要。\n\n2.  **提示工程与优化：**\n    *   LLM代理的性能受用于指导其推理和工具选择的提示影响很大。\n    *   有效的提示涉及清晰定义代理任务、提供可用工具描述以及构建提示以鼓励准确的参数提取。\n    *   使用DSPy等框架进行系统优化可以显著提高性能。DSPy允许定义代理组件，并使用少量示例从数据集中找到这些组件的优化提示或配置。\n\n### 构建有效API代理的推荐路径\n\n开发健壮的API调用AI代理是一个迭代的工程学科。基于Georgian AI Lab的研究发现，以下系统化工作流可以显著改善结果：\n\n1.  **从清晰的API定义开始：** 使用结构良好的OpenAPI规范来定义代理将交互的API。\n2.  **标准化工具访问：** 将OpenAPI规范转换为MCP工具，如使用Stainless.ai，为代理理解和使用API创建标准化方式。\n3.  **实现代理：** 选择合适的框架或方法（如Pydantic或LastMile的mcp_agent）。在实现前，可将MCP连接到Claude Desktop或Cline等工具，手动测试通用代理如何使用它，以节省时间。\n4.  **策划高质量评估数据集：** 手动创建或精心验证查询和预期API交互的数据集，这对于可靠的测试和优化至关重要。\n5.  **优化代理提示和逻辑：** 利用DSPy等框架，使用策划的数据集来改进代理的提示和内部逻辑，提高准确性和可靠性。\n\n### 工作流示例：待办事项列表API\n\n1.  **步骤1：清晰的API定义**\n    *   使用OpenAPI定义一个简单的待办事项列表API，包含添加任务（POST /tasks）和获取所有任务（GET /tasks）的端点。\n\n2.  **步骤2：标准化工具访问**\n    *   将OpenAPI规范转换为MCP配置，定义“添加任务”和“获取任务”工具的名称、描述、输入参数和输出描述。\n\n3.  **步骤3：实现代理**\n    *   使用Pydantic进行数据建模，创建与MCP工具对应的函数。然后，使用LLM解释自然语言查询并选择适当的工具和参数。\n\n4.  **步骤4：策划高质量评估数据集**\n    *   创建数据集，包含查询（如“将‘买菜’添加到我的列表”）及其预期的API调用（如`Add Task` with `description` = “买菜”）和预期结果。\n\n5.  **步骤5：优化代理提示和逻辑**\n    *   使用DSPy根据策划的数据集来优化代理的提示，重点关注清晰的指令、工具选择和参数提取。\n\n通过整合这些构建模块——从结构化的API定义和标准化的工具协议到严格的数据实践和系统优化——工程团队可以构建更强大、可靠和可维护的API调用AI代理。",
      "shortSummary": "本文详细介绍了API调用代理的理解、构建与优化。API调用代理利用LLM将自然语言转化为API操作，实现任务自动化。文章阐述了其核心任务（意图识别、工具选择、参数提取、执行），并提出了架构解决方案（工具定义、MCP协议、框架选择）。为确保可靠性和性能，强调了高质量数据集的创建与验证以及提示工程的重要性。最后，提供了一个系统化的工作流，从清晰的API定义到代理的实现和优化，帮助工程团队构建高效、可靠的API调用AI代理。",
      "translated_title": "API调用代理的理解、构建与优化指南",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/API-Calling-Agents-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/API-Calling-Agents-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>The role of Artificial Intelligence in technology companies is rapidly evolving;  AI use cases have evolved from passive information processing to proactive agents capable of executing tasks. According to a March 2025 survey on global AI adoption conducted by Georgian and NewtonX, 91% of technical executives in growth stage and enterprise companies are reportedly using [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/guide-to-understanding-building-and-optimizing-api-calling-agents/\">Guide to Understanding, Building, and Optimizing API-Calling Agents</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "ChatGPT的记忆限制令人沮丧——大脑展示了更好的方法 (原标题: ChatGPT’s Memory Limit Is Frustrating — The Brain Shows a Better Way)",
      "link": "https://www.unite.ai/chatgpts-memory-limit-is-frustrating-the-brain-shows-a-better-way/",
      "pubDate": "Mon, 09 Jun 2025 17:14:39 +0000",
      "isoDate": "2025-06-09T17:14:39.000Z",
      "creator": "Antoine Tardif",
      "summary": "# ChatGPT的记忆限制令人沮丧——大脑展示了更好的方法\n\n## 概述\n对于ChatGPT的重度用户而言，遇到“内存已满”的提示信息是一个常见的痛点，尤其是在进行长期复杂项目时。尽管付费用户可以理解存在存储限制，但当前记忆管理方式的低效性，如只能逐条删除或一次性清空所有记忆，极大地影响了用户体验和AI作为长期助手的潜力。\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/06/AI-Memory-Full-512x341.png)\n\n## ChatGPT记忆限制的痛点\n*   **管理方式繁琐：** 当记忆达到100%时，用户只有两种选择：\n    *   逐条手动删除：每删除一条仅释放约1%空间，意味着总共约100条记忆的上限，耗时且不便。\n    *   一次性清空所有记忆：导致AI失去所有宝贵的上下文信息。\n*   **缺乏中间选项：** 没有批量选择工具，无法高效地修剪存储信息。\n*   **任意的硬性上限：** 100条记忆的上限在现代AI系统规模下显得武断，削弱了ChatGPT成为一个随时间增长的知识型助手的承诺。\n\n## 人脑如何提供更好的记忆管理方式\n文章指出，鉴于ChatGPT背后的计算资源几乎无限，其长期记忆解决方案的原始性令人惊讶。理想情况下，AI的长期记忆应更好地模仿人脑处理信息的方式：\n\n### 1. 记忆巩固与压缩\n*   **人脑机制：** 人脑不会逐字逐句地无限期存储所有事件。新经验最初由海马体编码（短期记忆），然后逐渐巩固和压缩成长期记忆，并转移到大脑皮层进行永久存储。\n*   **“要旨记忆”：** 人脑倾向于过滤掉琐碎细节，保留最有意义的“要旨”（gist）。精确细节（逐字记忆）比一般意义（要旨记忆）消退得更快。这是一种高效的知识存储方式，通过丢弃无关细节来“压缩”信息。\n*   **神经科学发现：** 神经科学家发现，大脑可以通过更快的脑电波机制，在几秒钟内回忆起一连串事件，但编码的是细节较少、高层次的信息，从而实现记忆的“快进”和压缩。\n\n### 2. 记忆优先级与选择性遗忘\n*   **人脑机制：** 并非所有进入短期记忆的信息都会被永久存储。大脑会根据重要性或情感显著性，潜意识地决定哪些值得记住，哪些不值得。\n*   **研究案例：** 洛克菲勒大学对小鼠的研究表明，小鼠最初学习所有关联，但一个月后，只保留了最显著的高奖励记忆，而不太重要的细节则消失了。\n*   **丘脑的作用：** 前丘脑在大脑巩固过程中充当海马体和皮层之间的调节器，指示哪些记忆足够重要，可以长期“保存”。\n*   **遗忘的积极作用：** 遗忘并非记忆失败，而是系统的一个积极特征。通过放弃琐碎或冗余信息，大脑防止记忆存储变得混乱，并确保最有用的知识易于获取。\n\n## 基于人脑原理重塑AI记忆\n人脑处理记忆的方式为ChatGPT及类似AI系统如何管理长期信息提供了清晰的蓝图：\n\n*   **自动整合与总结：** AI应在后台自动整合和总结旧记忆。例如，将十个相关的对话或事实合并成一个简洁的摘要或一组关键结论，从而压缩记忆并保留其本质，同时为新信息腾出空间。\n*   **优先保留记忆：** 摒弃僵硬的记忆上限，AI可以权衡哪些记忆与用户需求最相关或最关键，并优先保留它们，而将不那么重要的信息归档或丢弃。这类似于大脑不断修剪不常用连接并强化常用连接以优化认知效率。\n*   **记忆系统应演进：** AI的长期记忆系统应随时间演进、转化和重组，而不是简单地填满并停止。用户不应被迫手动管理每个记忆槽。\n*   **实现方式：** 这可能涉及上下文摘要、用于知识检索的向量数据库或神经网络中的分层记忆层，这些都是当前活跃的研究领域。\n\n## 结论\nChatGPT当前的记忆限制是一种权宜之计，未能充分利用AI的潜力。通过借鉴人类认知，我们看到有效的长期记忆并非无限存储原始数据，而是智能压缩、整合和选择性遗忘。如果AI能采用类似的策略，自动将过去的互动提炼成持久的洞察，而不是将负担转嫁给用户，那么“记忆已满”的挫败感将被一个随使用而优雅增长、以类人方式学习和记忆的系统所取代。这将不仅解决用户体验痛点，还将为用户和开发者社区解锁更强大、更个性化的AI体验。",
      "shortSummary": "ChatGPT的记忆限制（约100条）及其低效的管理方式（逐条删除或全部清空）给用户带来极大不便。文章提出，AI应借鉴人脑的记忆机制：通过“记忆巩固”将短期记忆转化为长期要旨，实现信息压缩；并通过“优先级”和“选择性遗忘”保留关键信息，丢弃不重要细节。这种智能的、动态的记忆管理方式能让AI更好地成长，提供更流畅、个性化的用户体验，而非简单地达到存储上限。",
      "translated_title": "ChatGPT的记忆限制令人沮丧——大脑展示了更好的方法",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/AI-Memory-Full-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/AI-Memory-Full-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>If you’re a ChatGPT power user, you may have recently encountered the dreaded “Memory is full” screen. This message appears when you hit the limit of ChatGPT’s saved memories, and it can be a significant hurdle during long-term projects. Memory is supposed to be a key feature for complex, ongoing tasks – you want your [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/chatgpts-memory-limit-is-frustrating-the-brain-shows-a-better-way/\">ChatGPT’s Memory Limit Is Frustrating — The Brain Shows a Better Way</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "阻止AI胡编乱造：预防幻觉指南 (原标题: Stopping AI from Spinning Stories: A Guide to Preventing Hallucinations)",
      "link": "https://www.unite.ai/stopping-ai-from-spinning-stories-a-guide-to-preventing-hallucinations/",
      "pubDate": "Mon, 09 Jun 2025 16:52:13 +0000",
      "isoDate": "2025-06-09T16:52:13.000Z",
      "creator": "Dan Balaceanu, Chief Product Officer at DRUID AI",
      "summary": "# 阻止AI胡编乱造：预防幻觉指南\n\n## 引言：AI幻觉的挑战\n\n人工智能（AI）正在彻底改变各行各业的运作方式，提高效率和生产力。然而，随着我们对这项新技术的依赖迅速增加，必须认识到AI并非万无一失。AI的输出不应被盲目接受，因为它和人类一样会犯错。这些错误被称为“AI幻觉”，范围从数学问题错误到提供不准确的政府政策信息。在高度受监管的行业中，幻觉可能导致高昂的罚款、法律问题以及客户不满。现代大型语言模型（LLM）的幻觉发生率估计在1%到30%之间，这意味着每天会产生数百个错误答案。因此，企业在选择和实施AI工具时必须极其谨慎。\n\n## AI幻觉发生的原因：“垃圾进，垃圾出”\n\nAI学习其输入的方式与儿童游戏“传话筒”类似——初始信息在传递过程中会失真。LLM生成的响应质量取决于其所接收的信息。这意味着不正确的上下文可能导致虚假信息的生成和传播。如果AI系统建立在不准确、过时或有偏见的数据上，其输出也将反映这些问题。因此，LLM的质量与其输入数据密切相关，尤其是在缺乏人工干预或监督的情况下。随着更多自主AI解决方案的普及，提供正确的上下文数据以避免幻觉至关重要。我们需要对这些数据进行严格训练，并/或引导LLM仅从提供的上下文而非互联网上的任何信息中提取响应。\n\n## AI幻觉的重要性：为何不容忽视？\n\n对于面向客户的企业而言，准确性是重中之重。如果员工依赖AI来综合客户数据或回答客户查询，他们需要信任这些工具生成的响应是准确的。否则，企业将面临声誉受损和客户忠诚度下降的风险。如果客户通过聊天机器人获得不充分或虚假的答案，或者在员工核实聊天机器人输出时等待，他们可能会转向其他商家。人们不应该担心他们互动的企业是否在提供虚假信息——他们需要迅速可靠的支持。因此，正确处理这些互动至关重要。企业领导者在为员工选择合适的AI工具时必须尽职尽责。AI旨在为员工腾出时间和精力，专注于更高价值的任务；投资一个需要持续人工审查的聊天机器人将完全违背采用AI的初衷。\n\n## 对抗AI幻觉的策略\n\n*   **动态意义理论（DMT）的考量：**\n    *   DMT认为，人与人之间（此处指用户与AI）的理解是相互交换的。然而，语言和主题知识的局限性可能导致对响应的解释出现偏差。\n    *   AI生成的响应可能表面上看似准确，但缺乏真正理解所需的深度或细微差别，因为底层算法尚未完全具备准确解释或生成文本以符合人类期望的能力。\n\n*   **优化数据来源与模型训练：**\n    *   大多数通用LLM仅从互联网上公开可用的内容中提取信息。\n    *   企业级AI应用在由特定行业和业务数据及政策提供信息时表现更佳。\n    *   模型可以通过直接的人工反馈得到改进，特别是那些旨在响应语气和语法的代理式解决方案。\n\n*   **严格测试与验证：**\n    *   AI工具在面向消费者之前应进行严格测试。\n    *   整个流程应使用回合制对话进行测试，LLM扮演特定角色，以更好地预测AI模型在实际对话中的成功率。\n\n*   **强调上下文的重要性：**\n    *   开发者和用户都必须意识到动态意义理论以及输入中使用的语言动态。\n    *   上下文是关键。人类的大部分上下文理解是通过非语言方式实现的，例如肢体语言、社会趋势甚至语气。\n    *   虽然人类也可能在回答问题时产生“幻觉”，但当前AI迭代中，人与人之间的理解无法轻易地被上下文化，因此我们需要对书面输入中提供的上下文更加批判性。\n\n*   **选择合适的AI工具与共同责任：**\n    *   并非所有AI模型都生而平等。随着技术发展以完成日益复杂的任务，企业在考虑实施时，识别那些能够改善而非损害客户互动和体验的工具至关重要。\n    *   解决方案提供商有责任尽其所能最大限度地减少幻觉的发生。潜在买家也有其作用。通过优先选择经过严格训练和测试、并且可以从专有数据（而非互联网上的任何信息）中学习的解决方案，企业可以最大化其AI投资，从而帮助员工和客户取得成功。\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/06/Stopping-AI-Hallucinations-512x341.png)",
      "shortSummary": "AI幻觉指AI生成错误或不准确信息，常见于大型语言模型（1-30%），可能导致商业损失和客户不满。其主要原因在于训练数据质量差、缺乏上下文或人工监督。为对抗幻觉，企业应使用高质量、特定领域的专有数据训练AI，引入人工反馈，并进行严格的发布前测试。理解动态意义理论和强调输入上下文至关重要。选择经过验证的AI工具是确保AI投资成功的关键，这需要解决方案提供商和购买者共同努力。",
      "translated_title": "阻止AI胡编乱造：预防幻觉指南",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/Stopping-AI-Hallucinations-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/Stopping-AI-Hallucinations-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>AI is revolutionizing the way nearly every industry operates. It’s making us more efficient, more productive, and &#8211; when implemented correctly &#8211; better at our jobs overall. But as our reliance on this novel technology increases rapidly, we have to remind ourselves of one simple fact: AI is not infallible. Its outputs should not be [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/stopping-ai-from-spinning-stories-a-guide-to-preventing-hallucinations/\">Stopping AI from Spinning Stories: A Guide to Preventing Hallucinations</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "商业软件与采纳代理式AI的紧迫性 (原标题: Business Software and the Urgency of Adopting Agentic AI)",
      "link": "https://www.unite.ai/business-software-and-the-urgency-of-adopting-agentic-ai/",
      "pubDate": "Mon, 09 Jun 2025 16:50:29 +0000",
      "isoDate": "2025-06-09T16:50:29.000Z",
      "creator": "Tom Dunlop, CEO &#38; Founder at Summize",
      "summary": "## 商业软件与采纳代理式AI的紧迫性\n\n### 软件演进与代理式AI的崛起\n\n软件即服务（SaaS）通过在线订阅模式改变了企业工作方式，随后垂直SaaS增加了行业特定功能。人工智能（AI）和机器人流程自动化（RPA）利用虚拟机器人模仿人类操作并消除重复性任务。如今，企业软件正迈入一个新时代——**代理式AI**。代理式AI由自主代理驱动，它们不仅模仿人类，还能实时分析数据、做出决策、执行任务并自我编排工作流程。它超越了传统的SaaS和RPA，在数字领域充当劳动力，可集成到整个技术栈中并产生可衡量的业务成果。\n\n### 代理式AI的特点\n\n*   **自主性**：无需人类提示，每个代理都可以被分配自己的目标，例如专注于新销售、促进客户服务或实时管理制造变更。\n*   **高级推理**：个体AI代理利用大型语言模型进行高水平推理。\n*   **工作流构建**：与ChatGPT等生成式AI模型不同，代理式AI不仅能重组和输出内容，还能自行抓取数据库并构建工作流以完成给定任务。\n\n### 市场采纳与紧迫性\n\n*   **增长预测**：根据Gartner的数据，2024年只有不到1%的企业应用程序集成了代理式AI，预计到2028年这一数字将达到约三分之一。\n*   **行业共识**：Cloudera对1484名全球IT领导者的调查显示，83%认为AI代理对保持竞争优势至关重要，约60%担心今年不采纳就会落后。此外，96%的受访者计划在未来12个月内扩大部署，其中一半计划在整个组织内进行大规模推广。\n\n### 弥合差距与生产力提升\n\nSalesforce首席执行官马克·贝尼奥夫将代理式AI称为“一种新的劳动力模式、新的生产力模式和新的经济模式”。在劳动力参与率低于疫情前水平且职位空缺多于求职者的情况下，AI的主要目标是消除重复性任务，同时提高员工生产力。数字劳动力应被用于增强劳动力、提高生产力、提升效率并使组织更具竞争力。\n\n例如，销售主管可以使用AI代理与客户群沟通、识别机会、更新记录甚至完成小型销售，从而节省大量人工劳动时间并显著增加销售可能性。\n\n### 挑战与定价模式\n\n代理式AI在发展过程中面临一些挑战，尤其是在定价方面。“按席位”模式可能会转变为“按任务”执行的模式，或者更侧重于基于价值的模式，即AI代理“受雇”完成特定功能并产生有保证的结果。Salesforce的Agentforce平台已将其定价模式改为基于消耗的模式，将成本与结果直接挂钩。\n\n### 责任与问责制\n\n随着代理式AI的普及，软件供应商的选择方式需要改变。传统的评估主要关注功能集，而现在企业必须权衡供应商的可靠性、责任历史以及是否能与公司特定目标保持一致。决策者需要关注问责制，因为他们不再仅仅是购买软件，而是授权数字智能代表他们行事，这可能带来法律和合规问题。企业需要考虑其责任、深入研究风险、注重可审计性并将监管准则放在首位。此外，组织必须明确如果AI代理“失控”，谁应承担责任，并制定相应的遏制或关闭程序。\n\n### 采纳代理式AI的步骤\n\n为了启动代理式AI的采纳进程，企业可以立即采取以下行动：\n\n1.  **重新审视技术栈**：重点关注AI代理可能消除的基于规则的功能，并考虑可能存在的互操作性问题或新的API需求。\n2.  **避免孤立决策**：代理式AI可能影响业务的多个方面，因此应包括来自法律、IT和运营部门的领导者。\n3.  **制定员工政策**：为代理的安全和负责任使用创建员工政策。\n4.  **理解AI代理能力**：了解AI代理的工作能力以及它能消除的复杂性。\n5.  **重新评估成本模型和投资回报**：不再以席位、许可证和订阅成本作为衡量标准，而是关注销量和效率。\n\n### 结论\n\n代理式AI将极大地影响SaaS，但不会完全取代它。我们将看到技术的协作，以增强劳动力为目标。然而，企业将需要从根本上改变与软件的协作方式。代理式AI已经到来，越早理解其能力并付诸实践，就越能巩固未来的地位和成功。\n\n![代理式AI在软件中的应用](https://www.unite.ai/wp-content/uploads/2025/06/Agentic-AI-for-Software-512x341.png)",
      "shortSummary": "代理式AI正在彻底改变商业软件，超越SaaS和RPA，通过自主代理实时分析、决策和执行任务，充当数字劳动力。市场对其采纳需求迫切，预计到2028年将有三分之一的企业应用集成。它能提高生产力、弥补劳动力缺口，但面临定价、责任和合规挑战。企业需重新审视技术栈、制定政策并调整成本模型，以抓住这一变革机遇，确保未来竞争力。",
      "translated_title": "商业软件与采纳代理式AI的紧迫性",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/Agentic-AI-for-Software-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/Agentic-AI-for-Software-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>By delivering tools online via subscription model, Software as a Service (SaaS) changed the way enterprises worked. Still, the capabilities were limiting for some, so vertical SaaS added industry-specific functionality. Then came artificial intelligence (AI) and advancements such as robotic process automation (RPA), which would use virtual bots to replicate the actions of people and [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/business-software-and-the-urgency-of-adopting-agentic-ai/\">Business Software and the Urgency of Adopting Agentic AI</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "受保护的图像反而更容易被AI窃取，而非更难 (原标题: ‘Protected’ Images Are Easier, Not More Difficult, to Steal With AI)",
      "link": "https://www.unite.ai/protected-images-are-easier-not-more-difficult-to-steal-with-ai/",
      "pubDate": "Mon, 09 Jun 2025 13:35:49 +0000",
      "isoDate": "2025-06-09T13:35:49.000Z",
      "creator": "Martin Anderson",
      "summary": "### 受保护的图像反而更容易被AI窃取，而非更难\n\n**引言：AI图像保护的反作用**\n最新研究表明，旨在阻止AI图像编辑的水印工具可能会适得其反。这些保护措施非但未能阻止Stable Diffusion等模型进行修改，反而可能帮助AI更精确地遵循编辑提示，从而使未经授权的图像操作变得更加容易。\n\n**背景：图像保护技术与挑战**\n在计算机视觉领域，存在大量致力于保护受版权图像不被AI模型训练或用于直接图像到图像AI处理的研究。这类系统通常针对Latent Diffusion Models (LDMs)，如Stable Diffusion和Flux，它们利用基于噪声的程序编码和解码图像。\n\n*   **对抗性噪声与版权保护：** 通过向看似正常的图像中插入对抗性噪声，可以使图像检测器错误地识别图像内容，并阻碍图像生成系统利用受版权数据。\n*   **艺术家反弹与“投毒”研究：** 自2023年艺术家对Stable Diffusion广泛使用网络抓取图像（包括受版权图像）表示强烈不满以来，研究界提出了多种“图像投毒”方法。这些方法旨在使图片在不影响普通观看者体验的前提下，隐形地“毒害”AI系统，使其无法被训练或吸纳到生成式AI流程中。\n*   **保护强度与图像质量的权衡：** 在所有情况下，施加的扰动强度、图像受保护的程度以及图像质量受损的程度之间存在直接关联。更强的对抗性扰动通常意味着牺牲部分图像质量以换取安全性。\n*   **流行方法：Mist和Glaze：** 对于寻求保护其艺术风格不被未经授权盗用的艺术家而言，Mist和Glaze等系统尤其受关注。它们不仅能混淆身份和其他信息，还能“说服”AI训练过程看到与实际不同的内容，从而阻止受保护训练数据（例如“保罗·克利风格”）在语义和视觉领域之间形成关联。\n\n**最新研究发现：“乌龙球”效应**\n美国的一项新研究发现，扰动不仅可能无法保护图像，反而可能在扰动旨在免疫的所有AI处理中，提高图像的可利用性。\n\n该论文指出：\n*   在对多种领域（自然场景图像和艺术作品）和编辑任务（图像到图像生成和风格编辑）中各种基于扰动的图像保护方法进行的实验中，研究人员发现此类保护未能完全实现其目标。\n*   在大多数情况下，对受保护图像进行基于扩散的编辑会生成符合指导提示的理想输出图像。\n*   研究结果表明，向图像中添加噪声可能反而会增加它们在生成过程中与给定文本提示的关联，导致意想不到的后果，例如产生更好的编辑结果。\n*   因此，研究人员认为，基于扰动的方法可能无法为对抗基于扩散的编辑提供足够的图像保护解决方案。\n\n在测试中，受保护的图像暴露于两种常见的AI编辑场景：直接的图像到图像生成和风格迁移。这些过程反映了AI模型可能利用受保护内容的常见方式，无论是直接修改图像，还是借用其风格特征用于其他地方。\n\n结果显示，保护的存在通常似乎使模型与提示的对齐更加精确，产生了清晰、准确的输出，而这原本是预期会失败的。作者们实际上建议，这种非常流行的保护方法可能提供了虚假的安全感，任何此类基于扰动的免疫方法都应根据他们自己的方法进行彻底测试。\n\n**实验方法与场景**\n研究人员使用三种精心设计的对抗性扰动保护方法进行了实验：PhotoGuard、Mist和Glaze。\n*   **PhotoGuard** 应用于自然场景图像。\n*   **Mist和Glaze** 应用于艺术作品（即“艺术风格”领域）。\n\n测试涵盖了自然图像和艺术图像，以反映可能的实际应用。每种方法的有效性通过检查AI模型在处理受保护图像时是否仍能生成逼真且与提示相关的编辑来评估；如果生成的图像看起来令人信服并与提示匹配，则认为保护失败。\n\n研究人员使用Stable Diffusion v1.5作为预训练图像生成器进行编辑任务。选择了五个种子（9222、999、123、66和42）以确保可重复性。所有其他生成设置，如指导比例、强度和总步数，均遵循PhotoGuard实验中使用的默认值。\n\n**自然场景图像测试 (PhotoGuard)**\nPhotoGuard在Flickr8k数据集上进行了自然场景图像测试，该数据集包含8000多张图像，每张图像配有多达五个标题。\n*   **提示词生成：** 从每张图像的第一个标题创建了两组修改后的标题，借助Claude Sonnet 3.5。一组包含与原始标题在语境上接近的提示；另一组包含在语境上遥远的提示。\n    *   “接近”提示通过替换名词和形容词为语义相似的词语构建；“遥远”提示通过指示模型创建语境上非常不同的标题生成。\n    *   所有生成的标题都经过手动检查质量和语义相关性。使用Google的Universal Sentence Encoder计算原始标题和修改后标题之间的语义相似度分数。\n*   **图像质量评估：** 每张图像及其受保护版本都使用“接近”和“遥远”提示进行编辑。使用盲/无参考图像空间质量评估器 (BRISQUE) 评估图像质量。生成的图像在BRISQUE上得分为17.88（接近提示为17.82，遥远提示为17.94），而原始图像得分为22.27。这表明编辑后的图像质量与原始图像接近。\n*   **保护效果评估：** 为了判断保护措施对AI编辑的干扰程度，研究人员使用评分系统测量最终图像与给定指令的匹配程度，该系统比较图像内容与文本提示，以评估其对齐程度。\n    *   CLIP-S指标使用一个能理解图像和文本的模型来检查它们的相似性。\n    *   PAC-S++通过添加AI创建的额外样本，使其比较更接近人类估计。\n    *   这些图像-文本对齐 (ITA) 分数表示AI在修改受保护图像时遵循指令的准确性：如果受保护图像仍然导致高度对齐的输出，则意味着保护未能阻止编辑。\n*   **结果比较：** 研究人员比较了AI在编辑受保护图像和未受保护图像时遵循提示的程度。他们首先查看两者之间的差异，称为“实际变化”。然后将差异进行缩放以创建“百分比变化”，以便更容易比较多个测试的结果。这个过程揭示了保护措施是使AI更难还是更容易匹配提示。测试使用不同的随机种子重复了五次，涵盖了对原始标题的小幅和大幅修改。\n\n**艺术作品风格迁移测试 (PhotoGuard, Mist, Glaze)**\n*   **自然照片测试：** 使用Flickr1024数据集，包含一千多张高质量图像。每张图像都使用“将风格更改为[V]”的提示进行编辑，其中[V]代表七种著名艺术风格之一：立体主义、后印象主义、印象主义、超现实主义、巴洛克、野兽派和文艺复兴。\n    *   过程包括将PhotoGuard应用于原始图像，生成受保护版本，然后将受保护和未受保护图像通过相同的风格迁移编辑流程。\n*   **艺术作品测试：** 对WikiArt数据集中的图像进行风格迁移测试，该数据集收集了各种艺术风格。编辑提示遵循与之前相同的格式，指示AI将风格更改为从WikiArt标签中随机选择的、不相关的风格。\n    *   在编辑之前，将Glaze和Mist保护方法应用于图像，使研究人员能够观察每种防御方法如何阻止或扭曲风格迁移结果。\n*   **定量比较：** 研究人员还对图像-文本对齐分数的变化进行了定量比较。\n\n**研究结果总结**\n作者评论道：“结果突显了对抗性扰动在保护方面的显著局限性。对抗性扰动非但没有阻碍对齐，反而常常增强了生成模型的响应能力。”",
      "shortSummary": "新研究表明，旨在保护图像免受AI编辑的“水印”或“扰动”技术可能适得其反。这些保护措施非但未能阻止AI模型（如Stable Diffusion）修改图像，反而可能使其更容易遵循编辑指令，导致更精确的未经授权操作。实验发现，添加噪声可能悖论性地增强图像与文本提示的关联，从而产生更好的编辑结果。这表明当前基于扰动的图像保护方法可能提供虚假的安全感，并可能意外地提高AI利用受保护图像的能力。",
      "translated_title": "受保护的图像反而更容易被AI窃取，而非更难",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/MIT-immunize.jpg",
          "alt": "From the MIT paper 'Raising the Cost of Malicious AI-Powered Image Editing', examples of a source image 'immunized' against manipulation (lower row). Source: https://arxiv.org/pdf/2302.06588",
          "title": "",
          "position": 1
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/protection-success-rate.jpg",
          "alt": "Though the quality of the research PDF does not completely illustrate the problem, greater amounts of adversarial perturbation sacrifice quality for security. Here we see the gamut of quality disturbances in the 2020 'Fawkes' project led by the University of Chicago. Source: https://arxiv.org/pdf/2002.08327",
          "title": "",
          "position": 2
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/style-change-to-cubism.jpg",
          "alt": "Mist and Glaze are two popular injection methods capable of preventing, or at least severely hobbling attempts to use copyrighted styles in AI workflows and training routines. Source: https://arxiv.org/pdf/2506.04394",
          "title": "",
          "position": 3
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/glaze.jpg",
          "alt": "Glaze, one of the frameworks tested by the authors. Glaze protection examples for three artists. The first two columns show the original artworks. The third column shows mimicry results without protection. The fourth column shows style-transferred versions used for cloak optimization, along with the target style name. The fifth and sixth columns show mimicry results with cloaking applied at perturbation levels p = 0.05 and p = 0.1. All results use Stable Diffusion models. https://arxiv.org/pdf/2302.04222",
          "title": "",
          "position": 4
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/graphs.jpg",
          "alt": "From the supplementary material, semantic similarity distributions for the modified captions used in Flickr8k tests. The graph on the left shows the similarity scores for closely modified captions, averaging around 0.6. The graph on the right shows the extensively modified captions, averaging around 0.1, reflecting greater semantic distance from the original captions. Values were calculated using Google’s Universal Sentence Encoder. Source: https://sigport.org/sites/default/files/docs/IncompleteProtection_SM_0.pdf",
          "title": "",
          "position": 5
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/fig-2.jpg",
          "alt": "Image-to-image generation results on natural photographs protected by PhotoGuard. Despite the presence of perturbations, Stable Diffusion v1.5 successfully followed both small and large semantic changes in the editing prompts, producing realistic outputs that matched the new instructions.",
          "title": "",
          "position": 6
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/fig-3.jpg",
          "alt": "Effect of protection on the Flickr8k dataset across five seeds, using both close and distant prompts. Image-text alignment was measured using CLIP-S and PAC-S++ scores.",
          "title": "",
          "position": 7
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/fig-4.jpg",
          "alt": "Original and protected versions of a natural scene image, each edited to apply Cubism, Surrealism, and Fauvism styles.",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "完整文章",
      "content": "<img width=\"535\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/perturbations-MAIN-535x341.jpg\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"A shadowy man steals into an art gallery as the guard sleeps. Krita/Flux-1 Dev + Firefly\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 535px) 100vw, 535px\" /><p>New research suggests that watermarking tools meant to block AI image edits may backfire. Instead of stopping models like Stable Diffusion from making changes, some protections actually help the AI follow editing prompts more closely, making unwanted manipulations even easier. &#160; There is a notable and robust strand in computer vision literature dedicated to protecting [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/protected-images-are-easier-not-more-difficult-to-steal-with-ai/\">‘Protected’ Images Are Easier, Not More Difficult, to Steal With AI</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "为什么Meta最大的AI赌注不在模型上——而在数据上 (原标题: Why Meta’s Biggest AI Bet Isn’t on Models—It’s on Data)",
      "link": "https://www.unite.ai/why-metas-biggest-ai-bet-isnt-on-models-its-on-data/",
      "pubDate": "Mon, 09 Jun 2025 03:17:59 +0000",
      "isoDate": "2025-06-09T03:17:59.000Z",
      "creator": "Alex McFarland",
      "summary": "# Meta的AI战略：从模型转向数据\n\nMeta斥资100亿美元投资Scale AI，这不仅仅是一轮简单的融资，更标志着科技巨头在AI军备竞赛中战略的根本性演变。这项潜在的交易，可能成为Meta最大的外部AI投资，揭示了马克·扎克伯格的公司正在加倍押注一个关键洞察：在ChatGPT时代之后，胜利属于那些控制最高质量数据管道的公司，而非拥有最复杂算法的公司。\n\n## 投资概览与背景\n*   **投资金额**：Meta对Scale AI的潜在投资高达100亿美元。\n*   **Scale AI的增长**：\n    *   营收：从2024年的8.7亿美元增长到2025年的预计20亿美元。\n    *   估值：近期融资轮次中从70亿美元上升至138亿美元。\n*   **战略必要性**：在Llama 4反响平平之后，Meta可能寻求独家数据集以超越OpenAI和微软等竞争对手。文章指出，仅靠架构创新在当今AI世界中已不足够。\n*   **Scale AI的定位**：Scale AI首席执行官Alexandr Wang指出，AI社区已经耗尽了“简单数据”，现在需要转向更复杂的数据，强调“数量重要但质量至关重要”。Scale AI被定位为AI革命的“数据铸造厂”，通过结合自动化和人类专业知识的混合方法，为训练机器学习模型的公司提供数据标注服务。\n\n## 通过数据控制实现战略差异化\nMeta的投资理念基于对竞争动态的深刻理解，超越了传统的模型开发。\n*   **核心策略**：当竞争对手如微软将数十亿美元投入OpenAI等模型创建者时，Meta则押注于控制所有AI系统所需的基础数据基础设施。\n*   **优势**：\n    *   **专有数据集访问**：增强模型训练能力，同时可能限制竞争对手获取相同高质量数据。\n    *   **管道控制**：减少对外部供应商的依赖，并实现更可预测的成本结构。\n    *   **基础设施聚焦**：投资于基础层，而非仅仅在模型架构上竞争。\n*   **行业趋势**：近期发展表明，大型AI模型的进步可能更依赖于高质量训练数据和计算能力，而非架构创新。\n\n## 军事和政府维度\n这项投资也具有超越商业AI应用的重大意义。\n*   **政府合作**：Meta和Scale AI正在深化与美国政府的合作，例如共同开发Meta Llama模型的军事版本“Defense Llama”。\n*   **Scale AI的合同**：Scale AI最近与美国国防部签订合同，开发用于作战的AI代理。\n*   **战略价值**：政府合同提供稳定、长期的收入来源，并将两家公司定位为国家AI能力的关键基础设施提供商。\n\n## 挑战微软-OpenAI范式\nMeta对Scale AI的投资是对当前AI领域由微软-OpenAI主导的合作模式的直接挑战。\n*   **差异化**：微软主要投资于模型开发和部署，而Meta则优先控制所有AI开发的基础层。\n*   **持久优势**：Meta的策略可能比独家模型合作更具持久性，后者面临日益增长的竞争压力和潜在的合作不稳定性。\n*   **行业动态**：有报告指出微软正在开发自己的内部推理模型以与OpenAI竞争，并测试了来自xAI、Meta和DeepSeek的模型以取代Copilot中的ChatGPT，这凸显了大型科技公司AI投资策略中固有的紧张关系。\n\n## AI基础设施的经济效益\n*   **市场需求**：Scale AI的营收增长和估值轨迹表明了对专业AI数据服务的巨大市场需求，数据基础设施代表着持久的竞争护城河。\n*   **规模优势**：Meta的100亿美元投资将为Scale AI提供前所未有的资源，以在全球范围内扩展业务并开发更复杂的数据处理能力。这种规模优势可能产生网络效应，使竞争对手难以匹敌Scale AI的质量和成本效率。\n*   **行业演变**：这项投资预示着AI基础设施向垂直整合的更广泛行业演变。数据质量和模型对齐服务（如通过人类反馈进行强化学习RLHF和模型评估）将变得更加关键。\n\n## 展望：“数据战争”的开启\nMeta对Scale AI的投资被视为“数据战争”的开端，即未来十年AI领导地位将由高质量、专业化数据集的控制权决定。\n*   **战略转变**：这一战略转变承认，尽管当前的AI繁荣始于ChatGPT等突破性模型，但持续的竞争优势将来自控制实现模型持续改进的基础设施。\n*   **未来竞争**：随着行业超越生成式AI的初步兴奋，控制数据管道的公司可能比那些仅仅许可或合作获取模型访问权的公司拥有更持久的优势。\n*   **Meta的赌注**：Meta的100亿美元投资是一项经过深思熟虑的赌注，认为未来AI竞争的胜利将发生在大多数消费者从未见过的、但最终决定哪些AI系统在现实世界中取得成功的数据预处理中心和标注工作流程中。\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/06/20250609_0010_Futuristic-Boardroom-Dynamics_simple_compose_01jx9ajrghe919c0n98ppr8rnw-512x341.png)",
      "shortSummary": "Meta斥资100亿美元投资Scale AI，标志着其AI战略从模型转向数据。此举强调在后ChatGPT时代，高质量数据基础设施是AI领导力的关键。Scale AI提供重要的数据标注服务，对高级AI训练至关重要。这挑战了微软-OpenAI以模型为中心的范式，并包含政府合作。Meta认为，控制数据管道能在未来的“数据战争”中提供更持久的竞争优势。",
      "translated_title": "为什么Meta最大的AI赌注不在模型上——而在数据上",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/20250609_0010_Futuristic-Boardroom-Dynamics_simple_compose_01jx9ajrghe919c0n98ppr8rnw-512x341.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/20250609_0010_Futuristic-Boardroom-Dynamics_simple_compose_01jx9ajrghe919c0n98ppr8rnw-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>Meta's reported $10 billion investment in Scale AI represents far more than a simple funding round—it signals a fundamental strategic evolution in how tech giants view the AI arms race. This potential deal, which could exceed $10 billion and would be Meta's largest external AI investment, reveals Mark Zuckerberg's company doubling down on a critical [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/why-metas-biggest-ai-bet-isnt-on-models-its-on-data/\">Why Meta&#8217;s Biggest AI Bet Isn&#8217;t on Models—It&#8217;s on Data</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "AI责任保险：保护企业免受AI故障影响的下一步 (原标题: AI Liability Insurance: The Next Step in Safeguarding Businesses from AI Failures)",
      "link": "https://www.unite.ai/ai-liability-insurance-the-next-step-in-safeguarding-businesses-from-ai-failures/",
      "pubDate": "Sun, 08 Jun 2025 05:41:15 +0000",
      "isoDate": "2025-06-08T05:41:15.000Z",
      "creator": "Dr. Assad Abbas",
      "summary": "# AI责任保险：保护企业免受AI故障影响的下一步\n\n![AI Liability Insurance](https://www.unite.ai/wp-content/uploads/2025/06/ChatGPT-Image-May-23-2025-09_50_13-AM-512x341.png)\n\n当今企业高度依赖人工智能（AI）来执行关键任务，例如处理客户咨询、识别金融风险、管理供应链和支持医疗决策。尽管AI提高了速度和准确性，但它也带来了传统保险政策无法覆盖的新风险。为了应对这些挑战，AI责任保险应运而生，成为企业管理AI故障带来的财务和法律问题的必要保护。\n\n## AI风险在商业中日益增长\n\n近年来，AI在商业中的应用大幅增长。到2024年末，研究显示，金融、医疗、制造和零售等领域超过70%的公司已在使用AI工具。然而，AI也带来了与旧技术不同的新风险：\n\n*   **AI幻觉（Hallucination）**：AI提供虚假或误导性信息，可能导致基于错误信息的糟糕决策。\n*   **模型漂移（Model Drift）**：AI模型随着数据变化而变得不准确，例如欺诈检测AI可能错过新的欺诈模式。\n*   **数据投毒（Data Poisoning）**：攻击者破坏AI训练数据，导致AI行为异常。\n*   **隐私、偏见和伦理问题**：日益增长的担忧，促使新法律（如欧盟AI法案）的制定。\n\n**真实案例凸显AI风险：**\n\n*   2023年9月，美国消费者金融保护局（CFPB）发布指导意见，要求使用AI的贷款机构明确解释拒绝信贷的原因。\n*   2025年，医疗安全组织ECRI报告警告，AI监管不力可能导致错误诊断和治疗，损害患者健康。\n*   2023年，一名纽约律师因使用ChatGPT生成虚假案例引文而受到法律处罚。\n*   2024年，加拿大航空的AI聊天机器人错误承诺丧亲折扣，导致法律纠纷，法院判决航司赔偿客户。\n*   深度伪造诈骗：英国一家能源公司因AI生成的语音深度伪造而损失24.3万美元。\n\n这些案例表明，AI故障可能导致法律、财务和声誉问题，而传统保险通常无法覆盖这些AI相关风险。\n\n## 什么是AI责任保险及其覆盖范围？\n\nAI责任保险是一种专门的保险，旨在弥补传统保险（如错误与遗漏保险E&O和商业综合责任险CGL）留下的空白。它专注于AI系统设计、使用和管理中产生的风险，通常覆盖：\n\n*   AI系统故障造成的财务损失或损害。\n*   AI输出的虚假或误导性信息（AI幻觉）。\n*   AI模型中未经授权的数据或知识产权使用。\n*   违反新AI法律（如欧盟AI法案）的罚款和处罚，最高可达全球收入的6%。\n*   与AI集成相关的数据泄露或安全问题。\n*   与AI故障相关的诉讼或调查的法律费用。\n\n## 为何需要AI责任保险以及谁提供它？\n\n随着AI的广泛应用，其风险日益增大，且AI系统行为可能不可预测，并面临不断变化的政府法规。因此，管理AI风险需要新的方法。各国政府正在制定更严格的AI安全和公平法律，例如欧盟AI法案。\n\n为满足这些需求，保险公司已开始提供专门的AI责任产品，例如：\n\n*   **Coalition Insurance**：覆盖生成式AI风险，如深度伪造欺诈和安全问题。\n*   **Relm Insurance**：提供PONTAAI等解决方案，覆盖偏见、知识产权侵权和监管问题。\n*   **Munich Re的aiSure™**：保护企业免受AI模型故障和性能下降的影响。\n*   **AXA XL和Chaucer Group**：提供第三方AI风险和生成式AI风险的背书。\n\n## AI责任保险的主要特点和优势\n\nAI责任保险提供多项重要优势，帮助企业管理AI带来的独特风险：\n\n*   **财务保护**：覆盖AI故障相关成本，包括第三方索赔（如偏见、歧视、错误信息）以及被保险公司自身的损失（如业务中断、声誉损害）。\n*   **法律辩护覆盖**：为应对索赔或监管调查提供支持。\n*   **专门设计**：专门覆盖AI相关风险，如幻觉、模型漂移和软件缺陷。\n*   **可定制性**：企业可根据其AI使用和风险状况定制保单。\n*   **广泛的地域限制**：对跨国企业尤为重要。\n*   **促进最佳实践**：保险公司可能要求投保人遵循透明度、定期审计和风险管理计划等最佳实践，从而促进更安全的AI部署并建立信任。\n\n## 谁应该考虑AI责任保险？\n\nAI责任保险对于使用AI技术的企业至关重要。AI风险因行业和AI应用方式而异。以下行业面临较高的AI风险：\n\n*   **医疗保健**：AI错误可能损害患者并导致责任问题。\n*   **金融**：AI错误可能导致不公平决策、损失或监管问题。\n*   **自动驾驶汽车**：AI错误导致的事故需要保险保护。\n*   **营销和内容**：生成式AI可能侵犯版权或传播错误信息。\n*   **网络安全**：AI系统可能因攻击或错误而失效，导致数据泄露。\n\n**需要AI责任保险的对象：**\n\n*   **AI开发者和技术公司**：面临偏见、不正确输出和知识产权纠纷等风险。\n*   **使用AI工具的企业**：如果使用的AI工具出现故障或导致安全问题，需要保护。\n*   **风险经理和领导者**：应评估组织内的AI风险并确保适当的保险覆盖。\n\n## 总结\n\nAI已成为许多企业不可或缺的一部分，但它也带来了传统保险无法很好覆盖的新风险。AI故障（如错误决策、误导性信息和安全威胁）可能导致严重的财务、法律和声誉损害。AI责任保险专门为应对这些挑战提供保护，帮助企业覆盖AI错误、法律索赔和欺诈造成的成本，同时支持遵守新法律。对于医疗保健、金融和网络安全等领域的企业而言，这种保险尤为必要。随着AI使用的增长，定期审查和更新保险对于保持保护至关重要。AI责任保险不再是可选项，而是管理风险和确保企业在AI日益重要的世界中保持安全的必要步骤。",
      "shortSummary": "随着企业对AI的依赖加深，传统保险无法覆盖的AI特有风险（如幻觉、模型漂移、偏见、数据泄露）日益突出。AI责任保险应运而生，旨在弥补这一空白，为企业提供财务保护、法律支持，并应对AI故障、误导性输出、知识产权侵权及监管罚款等风险。真实案例凸显了AI故障的严重后果。因此，AI责任保险对于AI开发者和使用者而言，已成为管理风险、确保合规和保护企业运营的必要保障。",
      "translated_title": "AI责任保险：保护企业免受AI故障影响的下一步",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/06/ChatGPT-Image-May-23-2025-09_50_13-AM-512x341.png",
          "alt": "AI Liability Insurance",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"512\" height=\"341\" src=\"https://www.unite.ai/wp-content/uploads/2025/06/ChatGPT-Image-May-23-2025-09_50_13-AM-512x341.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"AI Liability Insurance\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 512px) 100vw, 512px\" /><p>Businesses today depend heavily on Artificial Intelligence (AI) to run important tasks like handling customer questions, spotting financial risks, managing supply chains, and supporting medical decisions. While AI helps improve speed and accuracy, it also brings risks that old insurance policies do not cover. AI can make wrong choices, give false information, or fail because [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/ai-liability-insurance-the-next-step-in-safeguarding-businesses-from-ai-failures/\">AI Liability Insurance: The Next Step in Safeguarding Businesses from AI Failures</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "建立对AI的信心：培训项目助力弥合知识鸿沟 (原标题: Building Confidence in AI: Training Programs Help Close Knowledge Gaps)",
      "link": "https://www.unite.ai/building-confidence-in-ai-training-programs-help-close-knowledge-gaps/",
      "pubDate": "Fri, 06 Jun 2025 17:18:13 +0000",
      "isoDate": "2025-06-06T17:18:13.000Z",
      "creator": "Amit Mondal, CTO of Panopto",
      "summary": "## 建立对AI的信心：培训项目助力弥合知识鸿沟\n\n### 引言\n人工智能（AI）正以惊人的速度重塑劳动力市场，然而，当前的培训工作未能跟上这一变革。尽管四分之一的高管对AI技术持乐观态度，但过去一年中仅有12%的员工接受了AI相关培训。这种准备不足不仅阻碍了AI的成功和安全应用，也导致员工对AI对其工作的影响感到不确定。为了弥合高管的兴奋与员工的犹豫之间的差距，组织迫切需要培训工具来建立员工对AI的信心，并迎接创新新时代。\n\n### AI将增强而非取代\n建立员工对AI信心的最重要因素之一是帮助他们理解AI将如何融入其角色。尽管存在大量误解，但在大多数情况下，AI并非旨在取代员工。事实上，近期尝试用AI取代人类的公司在实现预期投资回报方面举步维艰。相反，AI的真正价值在于通过处理日常和行政任务来增强员工的技能、生产力和领域竞争力，从而使员工能够专注于更高价值的工作。\n\n然而，同样重要的是，仅仅集成AI并不能自动实现这一点，员工必须了解如何有效使用AI才能充分发挥其潜力。缺乏正确的培训可能导致对数据隐私、偏见和不准确性的担忧，因此掌握这些基础知识至关重要。因此，提升技能（Upskilling）和跨领域技能培训（Cross-skilling）对于跟上变革的步伐必不可少。\n\n### 提升技能（Upskilling）与跨领域技能培训（Cross-skilling）\n提升技能和跨领域技能培训都用于帮助员工扩展技能，是采纳AI的关键工具。尽管两者相似，但理解其区别至关重要：\n\n*   **提升技能（Upskilling）**：\n    *   加强现有技能，侧重于帮助员工在工作中取得进步并承担更高职责。\n    *   例如：培训IT领导者——他们已经拥有坚实的技术基础——以更深入地理解AI。\n\n*   **跨领域技能培训（Cross-skilling）**：\n    *   也称为交叉培训，是发展适用于不同职能的新技能，侧重于培训多名员工完成一项组织任务。\n    *   AI的采用和跨领域技能策略必须同时进行，以确保成功。\n    *   例如：一位技术背景较少的市场营销领导者。随着AI在各部门的日益广泛使用，跨领域技能培训确保每位员工都能根据其特定角色和职责使用该技术。\n\n### AI时代的培训益处\n随着行业、市场和日常商业实践的不断演变，员工的技能和知识仍然是组织创新的基石。员工渴望目标感和影响力，将企业目标与员工抱负相结合是提升敬业度的有效途径。此外，通过AI帮助员工减轻繁重任务，有助于提升整体工作满意度。\n\n在日益激烈的竞争环境中，满足这些需求并留住顶尖人才对于维持生产力和增长至关重要。尽管近期有观点认为拥有AI技能的人将取代工作，但79%的学习与发展专业人士认为，重新培训现有员工比招聘新员工更经济。\n\n### 提升技能与跨领域技能培训的实践\n如果提升技能和跨领域技能培训尚未成为学习与发展计划的一部分，组织可以利用现有资源。以下是一些入门的最佳实践：\n\n1.  **评估当前技能：**\n    *   在不了解员工现有技能和未来所需技能的情况下，很难确定提升技能和跨领域技能培训的优先级。\n    *   鉴于团队已经熟悉其角色和整个组织，调查当前的AI知识水平并识别差距是一个很好的起点。\n\n2.  **设定可实现的目标：**\n    *   在对员工队伍有了基础了解后，下一步是设定提升技能和跨领域技能培训的目标。\n    *   理解这些培训项目背后的“为什么”以及确定员工可以和应该成长的领域至关重要。\n    *   目标应在个人贡献者层面设定，同时也要为更大的团队和整个组织设定目标。\n\n3.  **重新思考学习形式：**\n    *   即使是最强大的培训项目，如果其交付形式无法引起员工共鸣，也无法产生效果。事实上，86%的公司对其现有培训项目不满意。\n    *   雇主们发现，现场或面对面培训项目已不再足够。相反，提供灵活性和更好适应各种学习风格的视频学习，可能是AI等高度复杂主题的最佳途径。\n\n4.  **优先考虑负责任的AI：**\n    *   实施数据隐私、安全和数据治理的最佳实践是确保员工负责任地使用AI的关键一步。\n    *   此外，实施偏见和透明度框架以验证AI输出并建立组织内部对AI有效性的信心至关重要。\n    *   为此，组织应考虑培养“AI倡导者”，教导员工如何有效使用AI，使人类既能从生产力提升中获益，又能具备防范幻觉和偏见的技能。\n\n5.  **监控与推广：**\n    *   为了使提升技能和跨领域技能培训产生影响，员工需要有机会扩展职责。\n    *   组织应建立奖励机制，激励员工寻找创造性方式利用AI提高部门和组织效率，并加速创新。\n\n### 总结\n尽管AI为现代职场带来了巨大的潜力，但员工是决定其成功的关键。无论其角色、部门或专业知识如何，拥有AI基础知识将有益于职业发展和整体业务。通过不仅提升技术前沿员工的技能，还进行跨领域技能培训以创建更大的AI中心文化，组织可以获得更高的敬业度、人才保留和市场竞争优势。\n\n### 关于作者\nAmit Mondal 拥有超过20年构建企业级软件和云解决方案的经验，专注于管理关键业务流程。在加入Panopto之前，Mondal曾在PowerSchool和SumTotal Systems工作十年，负责为K12教育和企业构建一流的学习管理系统。作为这些公司的副总裁，他通过有机创新和整合十余项收购，领导全球开发团队经历了快速变革。他推动了软件开发和交付的规模化和成熟化，并通过合适的人员、工具和流程加速了价值创造，使软件组织在短时间内实现了收入和利润的数倍增长。Mondal拥有印度理工学院坎普尔分校的工程学学士学位、普渡大学的工程学硕士学位以及加州大学伯克利分校哈斯商学院的工商管理硕士学位。\n\n![Amit Mondal](https://www.unite.ai/wp-content/uploads/2025/05/panopto-leadership-amit-mondal-edited-150x150.jpg)\n![Unite.ai Logo](https://www.unite.ai/wp-content/uploads/2021/03/logoUNITE230X30BLACK-1.svg)",
      "shortSummary": "AI正迅速改变职场，但员工培训不足，导致对AI的信心缺失。文章强调，AI旨在增强而非取代人类工作，因此员工需通过培训掌握其有效使用。提升技能（Upskilling）和跨领域技能培训（Cross-skilling）是关键，前者深化现有技能，后者拓展新职能技能。组织应评估技能差距、设定目标、优化培训形式（如视频学习）、强调负责任的AI使用，并激励员工应用AI。通过全面培训，可提升员工敬业度、保留人才，并增强企业竞争力。",
      "translated_title": "建立对AI的信心：培训项目助力弥合知识鸿沟",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/05/panopto-leadership-amit-mondal-edited-150x150.jpg",
          "alt": "mm",
          "title": "",
          "position": 1
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2021/03/logoUNITE230X30BLACK-1.svg",
          "alt": "",
          "title": "",
          "position": 2
        },
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/05/AI-Training-225x150.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "<img width=\"225\" height=\"150\" src=\"https://www.unite.ai/wp-content/uploads/2025/05/AI-Training-225x150.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 225px) 100vw, 225px\" /><p>AI is reshaping the workforce at a breakneck speed, yet training efforts aren’t meeting the moment. Despite a quarter of executives feeling bullish on the technology, only 12% of workers have received AI-related training in the past year. This lack of preparation not only hinders the successful and safe adoption of AI, but also creates [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/building-confidence-in-ai-training-programs-help-close-knowledge-gaps/\">Building Confidence in AI: Training Programs Help Close Knowledge Gaps</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "当你的AI编造事实时：任何领导者都不能忽视的企业风险 (原标题: When Your AI Invents Facts: The Enterprise Risk No Leader Can Ignore)",
      "link": "https://www.unite.ai/when-your-ai-invents-facts-the-enterprise-risk-no-leader-can-ignore/",
      "pubDate": "Fri, 06 Jun 2025 17:16:13 +0000",
      "isoDate": "2025-06-06T17:16:13.000Z",
      "creator": "Joy Dasgupta, CEO of Gyan",
      "summary": "## AI幻觉：企业面临的不可忽视的风险\n\n![AI幻觉风险](https://www.unite.ai/wp-content/uploads/2025/05/AI-Hallucinations-Risk-225x150.png)\n\n### 引言：AI幻觉的定义与普遍性\n\n文章指出，AI幻觉是指生成式AI模型输出的内容听起来、看起来都正确，但实际上却是错误的。这并非偶发性错误，而是系统性问题。企业普遍存在一种误解，认为通过增加防护措施、微调或使用RAG（检索增强生成）等方法，就能在大规模企业应用中有效控制幻觉问题。\n\n### 幻觉率研究与发现\n\n多项研究揭示了AI幻觉的普遍性和高风险性：\n\n*   **斯坦福HAI & RegLab (2024年1月) - 法律领域：** 69%至88%的大型语言模型（LLM）在法律查询中表现出高幻觉率，且常缺乏对自身错误的认知，甚至强化了错误的法律假设。\n*   **JMIR研究 (2024) - 学术引用：** GPT-3.5、GPT-4和Bard生成的学术引用分别有90.6%、86.6%和100%的幻觉率，这些引用通常不相关、不正确或缺乏文献支持。\n*   **英国AI生成内容研究 (2025年2月) - 金融领域：** AI生成的虚假信息增加了银行挤兑的风险，大量银行客户在看到AI生成的虚假内容后考虑转移资金。\n*   **世界经济论坛全球风险报告 (2025) - 全球风险评估：** 由AI放大的错误信息和虚假信息被列为未来两年内的全球首要风险。\n*   **Vectara幻觉排行榜 (2025) - AI模型评估：** 不同LLM的幻觉率差异显著，例如GPT-4.5-Preview为1.2%，Google Gemini-2.0-Pro-Exp为0.8%，Vectara Mockingbird-2-Echo为0.9%。\n*   **Arxiv事实性幻觉研究 (2024) - AI研究：** 引入HaluEval 2.0以系统地研究和检测LLM中的事实不准确性。\n\n**总结：** 幻觉率从0.8%到88%不等，具体取决于模型、领域、用例和上下文，这种巨大的差异应引起所有企业决策者的警惕。\n\n### 现实世界中的后果\n\nAI幻觉已带来严重的现实后果：\n\n*   **G20金融稳定委员会**已将生成式AI标记为虚假信息的载体，可能引发市场危机、政治不稳定、闪电崩盘、假新闻和欺诈。\n*   **摩根律师事务所**发布紧急备忘录，禁止律师提交未经核实的AI生成文件，明确指出伪造判例是可被解雇的严重过失。\n\n### 幻觉的本质：非偶然错误，而是系统性风险\n\n文章强调，AI幻觉并非偶尔的错误答案，而是涉及声誉、法律和运营的系统性风险。生成式AI并非推理引擎，而是一个“统计完成器”或“随机鹦鹉”，它基于训练数据以最可能的方式完成提示。即使听起来真实的部分也只是猜测，从某种意义上说，整个输出都是一种“幻觉”，只是有些幻觉被“精心修饰”过。\n\n### 将AI视为基础设施：透明度、可解释性、可追溯性\n\nAI只有被视为基础设施而非“魔法”时，才能在企业中广泛采用。这意味着AI必须具备透明度、可解释性和可追溯性。如果AI不满足这些要求，则不适合在企业级应用中部署。如果AI参与决策，董事会必须将其纳入风险考量。欧盟的《AI法案》已走在前沿，将司法、医疗和基础设施等高风险领域AI系统视为关键任务系统进行监管，强制要求文档、测试和可解释性。\n\n### 企业安全AI模型的特点\n\n专门构建企业安全AI模型的公司采取了不同的架构方法：\n\n*   它们的语言模型不通过数据进行训练，从而避免了数据中可能存在的偏见、知识产权侵权或猜测倾向等“污染”。\n*   这些模型不“完成用户的想法”，而是根据用户的原始内容、知识库、文档和数据进行推理。\n*   如果答案不存在，这些模型会明确指出。这使得它们可解释、可追溯、确定性，是幻觉不可接受的场景下的理想选择。\n\n### AI问责制5步指南\n\n为确保AI在企业中的安全和负责任使用，文章提出了一个5步指南：\n\n1.  **绘制AI图景：** 识别AI在业务中的具体应用、其影响的决策，以及对决策可追溯性的重视程度。\n2.  **组织对齐：** 根据AI部署的范围，建立严格的角色、委员会、流程和审计实践，其严谨程度应与财务或网络安全风险管理相当。\n3.  **将AI纳入董事会风险：** 如果AI与客户或监管机构交互，其风险应纳入董事会层面的风险报告。AI治理绝非次要问题。\n4.  **将供应商视为共同责任方：** 即使供应商的AI编造内容，企业仍需承担最终后果。应将AI问责原则延伸至供应商，要求提供文档、审计权以及关于可解释性和幻觉率的服务水平协议（SLA）。\n5.  **培养怀疑精神：** 团队应将AI视为初级分析师——有用但不完美。应鼓励并表彰识别出AI幻觉的行为，因为信任需要通过实践赢得。\n\n### 结论：AI的未来方向\n\nAI的未来不在于模型规模的扩大，而在于追求更高的精度、透明度、信任和问责制。",
      "shortSummary": "AI幻觉是企业面临的重大风险，指AI生成的内容看似正确实则错误。研究显示，在法律、金融等高风险领域，AI幻觉率极高，可能导致声誉、法律和运营风险，甚至引发市场危机。文章强调，企业应将AI视为基础设施，要求其透明、可解释、可追溯。为应对此挑战，企业需建立AI问责制，包括全面评估AI应用、将AI风险纳入董事会层面、要求供应商共同承担责任，并培养团队对AI输出的批判性思维。AI的未来在于追求精度、透明度、信任和问责制。",
      "translated_title": "当你的AI编造事实时：任何领导者都不能忽视的企业风险",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/05/AI-Hallucinations-Risk-225x150.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"225\" height=\"150\" src=\"https://www.unite.ai/wp-content/uploads/2025/05/AI-Hallucinations-Risk-225x150.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 225px) 100vw, 225px\" /><p>It sounds right. It looks right. It’s wrong. That’s your AI on hallucination. The issue isn’t just that today’s generative AI models hallucinate. It’s that we feel if we build enough guardrails, fine-tune it, RAG it, and tame it somehow, then we will be able to adopt it at Enterprise scale. Study Domain Hallucination Rate [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/when-your-ai-invents-facts-the-enterprise-risk-no-leader-can-ignore/\">When Your AI Invents Facts: The Enterprise Risk No Leader Can Ignore</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    },
    {
      "title": "人工智能如何拯救新闻媒体 (原标题: How AI Might Save the News Media)",
      "link": "https://www.unite.ai/how-ai-might-save-the-news-media/",
      "pubDate": "Fri, 06 Jun 2025 17:14:24 +0000",
      "isoDate": "2025-06-06T17:14:24.000Z",
      "creator": "Yury Molodtsov, COO &#38; Partner at MA Family",
      "summary": "### 人工智能与新闻媒体：从威胁到拯救\n\n![图片 1](https://www.unite.ai/wp-content/uploads/2025/05/AI-Save-News-Media-225x150.png)\n\n文章探讨了人工智能（AI）与新闻媒体之间复杂且不断演变的关系，指出AI最初被视为新闻业的威胁，但最终可能成为其救星。\n\n#### 1. AI的初期威胁与媒体行业的担忧\n\n*   **取代人类的担忧：** 自OpenAI的ChatGPT于2022年末推出以来，人们普遍担心AI工具将取代记者和其他内容创作者的工作。\n*   **裁员与转型：**\n    *   Politico和Insider的所有者Mathias Döpfner曾表示AI可能取代员工。\n    *   BuzzFeed解雇了整个新闻编辑室，并宣布将重心转向AI。\n    *   Meta和OpenAI等公司吸引记者参与LLM训练，导致了相关裁员。\n*   **早期AI应用的问题：** 媒体高管在快速采用AI时出现了“令人尴尬的事件”，暴露出AI生成内容的准确性问题：\n    *   CNET和Bankrate因发布不准确的AI文章而暂停AI发布。\n    *   G/O Media（Jezebel和Gizmodo所有者）发布的AI生成故事未经编辑审核，包含多处错误。\n    *   微软用户对AI生成的不当民意调查感到震惊。\n*   **结论：** 这些事件表明AI不太可能完全取代记者，反而凸显了人类新闻工作者的价值。\n\n#### 2. AI对高质量内容的需求：新闻媒体的价值凸显\n\n*   **AI训练的关键：** 高质量的训练内容是AI实验室最关键的“商品”。\n*   **历史的重演：** 就像社交媒体重塑了新闻业一样（一些公司因过度依赖而衰落，另一些则因审慎策略而受益），AI也将如此。\n*   **新闻内容的独特性：** 与社交媒体信息不同，新闻机构提供高质量、经过核实、由整个新闻编辑室而非单一创作者策划的信息，因此被AI公司视为更可靠、更具价值的训练数据来源。\n*   **权力回归：** AI有潜力将权力重新带回新闻媒体，因为它们生产的内容对大型语言模型（LLM）的训练至关重要。\n\n#### 3. 媒体与AI公司的合作与博弈\n\n*   **最初的抵制：**\n    *   《纽约时报》起诉OpenAI。\n    *   包括《卫报》、康泰纳仕、福布斯在内的多家媒体公司阻止AI爬虫抓取其网站内容。\n    *   新闻/媒体联盟批评谷歌新推出的AI模式“强行获取内容却不向出版商提供回报”。\n*   **转向合作：** 这种抵制可能是一种谈判策略。AI公司和媒体机构已开始建立伙伴关系：\n    *   OpenAI已与包括《华盛顿邮报》、《纽约客》和《连线》在内的20多家新闻出版商（超过160个媒体机构）合作。\n    *   Perplexity与AdWeek、《独立报》、《洛杉矶时报》和世界历史百科全书签署了协议。\n*   **合作的驱动力：** AI实验室已接近耗尽高质量的公开可用训练数据，正积极寻找新内容。\n*   **多方共赢：** 许可合作对AI公司（开发有用产品）、新闻编辑室（扩大文章分发范围）和消费者（获取经过充分研究的教育信息）都至关重要。\n\n#### 4. “新首页”：进入AI数据集的重要性\n\n*   **消费者搜索习惯的转变：** 消费者已开始利用AI进行搜索，ChatGPT等AI助手在提供更专业、更优质的搜索结果方面正超越传统搜索引擎。\n*   **新的“搜索引擎优化”：** 未来，进入主要LLM的数据集将与出现在谷歌搜索结果首页同等重要。\n*   **新闻媒体的关键地位：** 进入LLM训练数据集的最佳方式，是通过那些生产高质量新闻并已与OpenAI、Anthropic、Perplexity等AI实验室建立直接合作关系的主要新闻媒体出版物。\n*   **巩固地位与未来之路：** 这将进一步巩固新闻媒体的地位，并为它们提供一条真正的未来发展道路。优化内容以纳入训练数据集将成为新的“搜索引擎优化”（SEO）。",
      "shortSummary": "人工智能最初被视为新闻媒体的威胁，导致裁员和AI生成内容的错误。然而，AI大模型对高质量训练内容的需求，凸显了新闻机构经核实信息的独特价值。媒体公司正从抵制转向与AI公司建立许可合作关系，以确保其内容被用于AI训练。未来，进入AI数据集将成为新闻媒体获取受众的关键，高质量新闻内容将成为AI时代的新“搜索引擎优化”，从而为新闻业带来新的发展机遇。",
      "translated_title": "人工智能如何拯救新闻媒体",
      "images": [
        {
          "url": "https://www.unite.ai/wp-content/uploads/2025/05/AI-Save-News-Media-225x150.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "<img width=\"225\" height=\"150\" src=\"https://www.unite.ai/wp-content/uploads/2025/05/AI-Save-News-Media-225x150.png\" class=\"webfeedsFeaturedVisual wp-post-image\" alt=\"\" style=\"display: block; margin-bottom: 5px; clear:both;max-width: 100%;\" link_thumbnail=\"\" decoding=\"sync\" loading=\"eager\" sizes=\"auto, (max-width: 225px) 100vw, 225px\" /><p>That may be tough to see right now. Since the launch of OpenAI’s ChatGPT in late 2022, and a whole host of other AI-powered chatbots and virtual assistants, the focus has revolved around how these tools could take over the jobs of journalists and other content creators. The media industry, already struggling, feels rightfully attacked. [&#8230;]</p>\n<p>The post <a href=\"https://www.unite.ai/how-ai-might-save-the-news-media/\">How AI Might Save the News Media</a> appeared first on <a href=\"https://www.unite.ai\">Unite.AI</a>.</p>\n"
    }
  ],
  "lastUpdated": "2025-06-11T08:34:35.182Z"
}
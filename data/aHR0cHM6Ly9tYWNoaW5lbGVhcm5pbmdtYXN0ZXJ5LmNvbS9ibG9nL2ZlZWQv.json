{
  "sourceUrl": "https://machinelearningmastery.com/blog/feed/",
  "title": "MachineLearningMastery.com",
  "description": "Making developers awesome at machine learning",
  "link": "https://machinelearningmastery.com/blog/",
  "items": [
    {
      "title": "学习率调度器入门指南 (原标题: A Gentle Introduction to Learning Rate Schedulers)",
      "link": "https://machinelearningmastery.com/a-gentle-introduction-to-learning-rate-schedulers/",
      "pubDate": "Fri, 16 May 2025 13:58:14 +0000",
      "isoDate": "2025-05-16T13:58:14.000Z",
      "creator": "Vinod Chugani",
      "summary": "本文介绍了学习率调度器的概念和五种常用的学习率调度器，并通过MNIST数据集的实践案例展示了它们的应用和效果。\n\n*   **学习率基础:** 学习率是机器学习中最重要的超参数之一，控制着模型权重在每次训练步骤中的调整幅度。固定的学习率可能导致训练停滞或无法达到最佳性能。\n*   **学习率调度器:** 学习率调度器是一种算法，可以在训练过程中自动调整模型的学习率。通过在训练的不同阶段使用不同的学习率，可以优化模型的性能、加快收敛速度并提高训练的稳定性。\n*   **五种学习率调度器:**\n    *   **StepLR (Step Decay):** 在固定间隔内按固定因子降低学习率。\n        ![StepLR learning rate decay chart](https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.32.19-1024x609.png)\n    *   **ExponentialLR (Exponential Decay):** 每个epoch将学习率乘以一个衰减因子，平滑地降低学习率。\n        ![ExponentialLR learning rate decay curve](https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.32.47-1024x613.png)\n    *   **CosineAnnealingLR (Cosine Annealing):** 学习率按照余弦曲线变化，从高值平滑地降低到最小值。\n        ![CosineAnnealingLR learning rate schedule graph](https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.33.18-1024x613.png)\n    *   **ReduceLROnPlateau (Adaptive Plateau Reduction):** 监控验证指标，当验证指标停止改善时降低学习率。\n        ![ReduceLROnPlateau learning rate scheduler graph](https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.33.44-1024x598.png)\n    *   **CyclicalLR (Cyclical Learning Rates):** 在最小和最大学习率之间以三角形模式振荡。\n        ![CyclicalLR learning rate pattern visualization](https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.34.12-1024x606.png)\n*   **MNIST实践:** 通过在MNIST数据集上训练一个简单的神经网络，比较了不同调度器的训练性能。\n    *   训练损失曲线显示了不同的行为模式。\n        ![Training loss comparison across learning rate schedulers](https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-20.18.27-1024x607.png)\n    *   ReduceLROnPlateau 取得了最佳性能。\n*   **选择合适的调度器:** 选择合适的调度器取决于问题的特性和训练要求。文章提供了一个实用的决策框架，根据对训练阶段的了解程度、对平滑衰减的需求、以及是否需要逃离局部最小值等因素，来选择合适的调度器。",
      "translated_title": "学习率调度器入门指南",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/ChatGPT-Image-May-15-2025-at-01_26_37-AM-1024x683.png",
          "alt": "Visual summary of five popular learning rate schedulers, including step decay, exponential decay, cosine annealing, plateau reduction, and cyclical oscillation.",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.32.19-1024x609.png",
          "alt": "StepLR learning rate decay chart",
          "title": "",
          "position": 2
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.32.47-1024x613.png",
          "alt": "ExponentialLR learning rate decay curve",
          "title": "",
          "position": 3
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.33.18-1024x613.png",
          "alt": "CosineAnnealingLR learning rate schedule graph",
          "title": "",
          "position": 4
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.33.44-1024x598.png",
          "alt": "ReduceLROnPlateau learning rate scheduler graph",
          "title": "",
          "position": 5
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-19.34.12-1024x606.png",
          "alt": "CyclicalLR learning rate pattern visualization",
          "title": "",
          "position": 6
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/05/Screenshot-2025-05-14-at-20.18.27-1024x607.png",
          "alt": "Training loss comparison across learning rate schedulers",
          "title": "",
          "position": 7
        }
      ],
      "contentSource": "完整文章",
      "content": "Ever wondered why your neural network seems to get stuck during training, or why it starts strong but fails to reach its full potential? The culprit might be your learning rate – arguably one of the most important hyperparameters in machine learning."
    }
  ],
  "lastUpdated": "2025-05-29T01:10:49.212Z"
}
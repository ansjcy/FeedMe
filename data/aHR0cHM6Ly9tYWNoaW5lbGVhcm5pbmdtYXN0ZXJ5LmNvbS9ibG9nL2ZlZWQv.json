{
  "sourceUrl": "https://machinelearningmastery.com/blog/feed/",
  "title": "MachineLearningMastery.com",
  "description": "Making developers awesome at machine learning",
  "link": "https://machinelearningmastery.com/blog/",
  "items": [
    {
      "title": "Training a Model on Multiple GPUs with Data Parallelism",
      "link": "https://machinelearningmastery.com/training-a-model-on-multiple-gpus-with-data-parallelism/",
      "pubDate": "Fri, 26 Dec 2025 06:44:15 +0000",
      "isoDate": "2025-12-26T06:44:15.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Training a Model on Multiple GPUs with Data Parallelism",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/ilse-orsel-hjmV0xG-KPk-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/data_parallelism.png",
          "alt": "",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into two parts; they are: • Data Parallelism • Distributed Data Parallelism If you have multiple GPUs, you can combine them to operate as a single GPU with greater memory capacity."
    },
    {
      "title": "Train a Model Faster with torch.compile and Gradient Accumulation",
      "link": "https://machinelearningmastery.com/train-a-model-faster-with-torch-compile-and-gradient-accumulation/",
      "pubDate": "Thu, 25 Dec 2025 16:44:48 +0000",
      "isoDate": "2025-12-25T16:44:48.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Train a Model Faster with torch.compile and Gradient Accumulation",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/francois-genon-IvlV_Dlt9hg-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into two parts; they are: • Using `torch."
    },
    {
      "title": "Training a Model with Limited Memory using Mixed Precision and Gradient Checkpointing",
      "link": "https://machinelearningmastery.com/training-a-model-with-limited-memory-using-mixed-precision-and-gradient-checkpointing/",
      "pubDate": "Wed, 24 Dec 2025 17:43:03 +0000",
      "isoDate": "2025-12-24T17:43:03.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Training a Model with Limited Memory using Mixed Precision and Gradient Checkpointing",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/meduana-PdnseHuDFZU-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Float_example.svg.png",
          "alt": "",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into three parts; they are: • Floating-point Numbers • Automatic Mixed Precision Training • Gradient Checkpointing Let's get started! The default data type in PyTorch is the IEEE 754 32-bit floating-point format, also known as single precision."
    },
    {
      "title": "Practical Agentic Coding with Google Jules",
      "link": "https://machinelearningmastery.com/practical-agentic-coding-with-google-jules/",
      "pubDate": "Wed, 24 Dec 2025 15:13:48 +0000",
      "isoDate": "2025-12-24T15:13:48.000Z",
      "creator": "Matthew Mayo",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Practical Agentic Coding with Google Jules",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-practical-agentic-coding-with-google-jules.jpeg",
          "alt": "Practical Agentic Coding with Google Jules",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-1-scaled.png",
          "alt": "Authenticate to Try Jules",
          "title": "",
          "position": 2
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-2a.png",
          "alt": "Connect to GitHub to reap the rewards",
          "title": "",
          "position": 3
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-3.png",
          "alt": "Select the target repository and branch",
          "title": "",
          "position": 4
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-4.png",
          "alt": "Select the target repository and branch",
          "title": "",
          "position": 5
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-5.png",
          "alt": "Google Jules toils away while I do something else",
          "title": "",
          "position": 6
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-6.png",
          "alt": "Reviewing the changes that Google Jules implemented",
          "title": "",
          "position": 7
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-mayo-google-jules-7.png",
          "alt": "Inspecting the pull request that Jules creates",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "RSS",
      "content": "If you have an interest in agentic coding, there's a pretty good chance you've heard of <a href=\"https://jules."
    },
    {
      "title": "Evaluating Perplexity on Language Models",
      "link": "https://machinelearningmastery.com/evaluating-perplexity-on-language-models/",
      "pubDate": "Tue, 23 Dec 2025 16:44:35 +0000",
      "isoDate": "2025-12-23T16:44:35.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Evaluating Perplexity on Language Models",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/lucas-davies-3aubsNmGuLE-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into two parts; they are: • What Is Perplexity and How to Compute It • Evaluate the Perplexity of a Language Model with HellaSwag Dataset Perplexity is a measure of how well a language model predicts a sample of text."
    },
    {
      "title": "3 Smart Ways to Encode Categorical Features for Machine Learning",
      "link": "https://machinelearningmastery.com/3-smart-ways-to-encode-categorical-features-for-machine-learning/",
      "pubDate": "Mon, 22 Dec 2025 15:59:29 +0000",
      "isoDate": "2025-12-22T15:59:29.000Z",
      "creator": "Shittu Olumide",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "3 Smart Ways to Encode Categorical Features for Machine Learning",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-3-smart-ways-encode-categorical-features-machine-learning-feature.jpeg",
          "alt": "3 Smart Ways to Encode Categorical Features for Machine Learning",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-3-smart-ways-encode-categorical-features-machine-learning-flowchart.jpeg",
          "alt": "3 Smart Ways to Encode Categorical Features for Machine Learning",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "If you spend any time working with real-world data, you quickly realize that not everything comes in neat, clean numbers."
    },
    {
      "title": "Pretraining a Llama Model on Your Local GPU",
      "link": "https://machinelearningmastery.com/pretraining-a-llama-model-on-your-local-gpu/",
      "pubDate": "Mon, 22 Dec 2025 04:27:38 +0000",
      "isoDate": "2025-12-22T04:27:38.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Pretraining a Llama Model on Your Local GPU",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/hongbin-xIEKIFJzJf0-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into three parts; they are: • Training a Tokenizer with Special Tokens • Preparing the Training Data • Running the Pretraining The model architecture you will use is the same as the one created in the <a href=\"https://machinelearningmastery."
    },
    {
      "title": "Rotary Position Embeddings for Long Context Length",
      "link": "https://machinelearningmastery.com/rotary-position-embeddings-for-long-context-length/",
      "pubDate": "Sat, 20 Dec 2025 15:51:36 +0000",
      "isoDate": "2025-12-20T15:51:36.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Rotary Position Embeddings for Long Context Length",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/nastya-dulhiier-3Ze88tZX-p0-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/rope_scale.png",
          "alt": "",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into two parts; they are: • Simple RoPE • RoPE for Long Context Length Compared to the sinusoidal position embeddings in the original Transformer paper, RoPE mutates the input tensor using a rotation matrix: $$ \\begin{aligned} X_{n,i} &amp;= X_{n,i} \\cos(n\\theta_i) - X_{n,\\frac{d}{2}+i} \\sin(n\\theta_i) \\\\ X_{n,\\frac{d}{2}+i} &amp;= X_{n,i} \\sin(n\\theta_i) + X_{n,\\frac{d}{2}+i} \\cos(n\\theta_i) \\end{aligned} $$ where $X_{n,i}$ is the $i$-th element of the vector at the $n$-th position of the sequence of tensor $X$."
    },
    {
      "title": "How to Fine-Tune a Local Mistral or Llama 3 Model on Your Own Dataset",
      "link": "https://machinelearningmastery.com/how-to-fine-tune-a-local-mistral-or-llama-3-model-on-your-own-dataset/",
      "pubDate": "Fri, 19 Dec 2025 09:00:17 +0000",
      "isoDate": "2025-12-19T09:00:17.000Z",
      "creator": "Shittu Olumide",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "How to Fine-Tune a Local Mistral or Llama 3 Model on Your Own Dataset",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-how-to-fine-tune-a-local-mistral-or-llama-3-model.png",
          "alt": "How to Fine-Tune a Local Mistral/Llama 3 Model on Your Own Dataset",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Change-runtime-type.png",
          "alt": "Change runtime type",
          "title": "",
          "position": 2
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Choose-your-model.png",
          "alt": "Choose your model",
          "title": "",
          "position": 3
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Formatting-Dataset.png",
          "alt": "",
          "title": "",
          "position": 4
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Train-the-Model-Faster-with-Unsloth.png",
          "alt": "Train the Model Faster with Unsloth",
          "title": "",
          "position": 5
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Testing-Fine-Tuned-Model-scaled.png",
          "alt": "Testing Fine-Tuned Model",
          "title": "",
          "position": 6
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Comparing-with-base-model-scaled.png",
          "alt": "Comparing with base model",
          "title": "",
          "position": 7
        }
      ],
      "contentSource": "RSS",
      "content": "Large language models (LLMs) like Mistral 7B and Llama 3 8B have shaken the AI field, but their broad nature limits their application to specialized areas."
    },
    {
      "title": "5 Agentic Coding Tips & Tricks",
      "link": "https://machinelearningmastery.com/5-agentic-coding-tips-tricks/",
      "pubDate": "Thu, 18 Dec 2025 15:40:37 +0000",
      "isoDate": "2025-12-18T15:40:37.000Z",
      "creator": "Nahla Davies",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "5 Agentic Coding Tips & Tricks",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-5-agentic-coding-tips-tricks.png",
          "alt": "5 Agentic Coding Tips & Tricks",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Agentic coding only feels \"smart\" when it ships correct diffs, passes tests, and leaves a paper trail you can trust."
    }
  ],
  "lastUpdated": "2026-01-01T09:33:15.717Z"
}
{
  "sourceUrl": "https://machinelearningmastery.com/blog/feed/",
  "title": "MachineLearningMastery.com",
  "description": "Making developers awesome at machine learning",
  "link": "https://machinelearningmastery.com/blog/",
  "items": [
    {
      "title": "3 Smart Ways to Encode Categorical Features for Machine Learning",
      "link": "https://machinelearningmastery.com/3-smart-ways-to-encode-categorical-features-for-machine-learning/",
      "pubDate": "Mon, 22 Dec 2025 15:59:29 +0000",
      "isoDate": "2025-12-22T15:59:29.000Z",
      "creator": "Shittu Olumide",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "3 Smart Ways to Encode Categorical Features for Machine Learning",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-3-smart-ways-encode-categorical-features-machine-learning-feature.jpeg",
          "alt": "3 Smart Ways to Encode Categorical Features for Machine Learning",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-3-smart-ways-encode-categorical-features-machine-learning-flowchart.jpeg",
          "alt": "3 Smart Ways to Encode Categorical Features for Machine Learning",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "If you spend any time working with real-world data, you quickly realize that not everything comes in neat, clean numbers."
    },
    {
      "title": "Pretraining a Llama Model on Your Local GPU",
      "link": "https://machinelearningmastery.com/pretraining-a-llama-model-on-your-local-gpu/",
      "pubDate": "Mon, 22 Dec 2025 04:27:38 +0000",
      "isoDate": "2025-12-22T04:27:38.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Pretraining a Llama Model on Your Local GPU",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/hongbin-xIEKIFJzJf0-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into three parts; they are: • Training a Tokenizer with Special Tokens • Preparing the Training Data • Running the Pretraining The model architecture you will use is the same as the one created in the <a href=\"https://machinelearningmastery."
    },
    {
      "title": "Rotary Position Embeddings for Long Context Length",
      "link": "https://machinelearningmastery.com/rotary-position-embeddings-for-long-context-length/",
      "pubDate": "Sat, 20 Dec 2025 15:51:36 +0000",
      "isoDate": "2025-12-20T15:51:36.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Rotary Position Embeddings for Long Context Length",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/nastya-dulhiier-3Ze88tZX-p0-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/rope_scale.png",
          "alt": "",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into two parts; they are: • Simple RoPE • RoPE for Long Context Length Compared to the sinusoidal position embeddings in the original Transformer paper, RoPE mutates the input tensor using a rotation matrix: $$ \\begin{aligned} X_{n,i} &amp;= X_{n,i} \\cos(n\\theta_i) - X_{n,\\frac{d}{2}+i} \\sin(n\\theta_i) \\\\ X_{n,\\frac{d}{2}+i} &amp;= X_{n,i} \\sin(n\\theta_i) + X_{n,\\frac{d}{2}+i} \\cos(n\\theta_i) \\end{aligned} $$ where $X_{n,i}$ is the $i$-th element of the vector at the $n$-th position of the sequence of tensor $X$."
    },
    {
      "title": "How to Fine-Tune a Local Mistral or Llama 3 Model on Your Own Dataset",
      "link": "https://machinelearningmastery.com/how-to-fine-tune-a-local-mistral-or-llama-3-model-on-your-own-dataset/",
      "pubDate": "Fri, 19 Dec 2025 09:00:17 +0000",
      "isoDate": "2025-12-19T09:00:17.000Z",
      "creator": "Shittu Olumide",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "How to Fine-Tune a Local Mistral or Llama 3 Model on Your Own Dataset",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-how-to-fine-tune-a-local-mistral-or-llama-3-model.png",
          "alt": "How to Fine-Tune a Local Mistral/Llama 3 Model on Your Own Dataset",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Change-runtime-type.png",
          "alt": "Change runtime type",
          "title": "",
          "position": 2
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Choose-your-model.png",
          "alt": "Choose your model",
          "title": "",
          "position": 3
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Formatting-Dataset.png",
          "alt": "",
          "title": "",
          "position": 4
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Train-the-Model-Faster-with-Unsloth.png",
          "alt": "Train the Model Faster with Unsloth",
          "title": "",
          "position": 5
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Testing-Fine-Tuned-Model-scaled.png",
          "alt": "Testing Fine-Tuned Model",
          "title": "",
          "position": 6
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/Comparing-with-base-model-scaled.png",
          "alt": "Comparing with base model",
          "title": "",
          "position": 7
        }
      ],
      "contentSource": "RSS",
      "content": "Large language models (LLMs) like Mistral 7B and Llama 3 8B have shaken the AI field, but their broad nature limits their application to specialized areas."
    },
    {
      "title": "5 Agentic Coding Tips & Tricks",
      "link": "https://machinelearningmastery.com/5-agentic-coding-tips-tricks/",
      "pubDate": "Thu, 18 Dec 2025 15:40:37 +0000",
      "isoDate": "2025-12-18T15:40:37.000Z",
      "creator": "Nahla Davies",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "5 Agentic Coding Tips & Tricks",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-5-agentic-coding-tips-tricks.png",
          "alt": "5 Agentic Coding Tips & Tricks",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Agentic coding only feels \"smart\" when it ships correct diffs, passes tests, and leaves a paper trail you can trust."
    },
    {
      "title": "The Real Cost of Inaction: How Silos Hurt Productivity for Data Scientists (Sponsored)",
      "link": "https://bit.ly/3Y07mHi",
      "pubDate": "Wed, 17 Dec 2025 16:40:29 +0000",
      "isoDate": "2025-12-17T16:40:29.000Z",
      "creator": "MLM Team",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "The Real Cost of Inaction: How Silos Hurt Productivity for Data Scientists (Sponsored)",
      "images": [],
      "contentSource": "RSS",
      "content": ""
    },
    {
      "title": "Top 5 Vector Databases for High-Performance LLM Applications",
      "link": "https://machinelearningmastery.com/top-5-vector-databases-for-high-performance-llm-applications/",
      "pubDate": "Wed, 17 Dec 2025 15:10:03 +0000",
      "isoDate": "2025-12-17T15:10:03.000Z",
      "creator": "Bala Priya C",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Top 5 Vector Databases for High-Performance LLM Applications",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-bpc-top-5-vector-databases-high-performing-llm-applications.png",
          "alt": "Top 5 Vector Databases for High-Performance LLM Applications",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Building AI applications often requires searching through millions of documents, finding similar items in massive catalogs, or retrieving relevant context for your LLM."
    },
    {
      "title": "The Machine Learning Engineer’s Checklist: Best Practices for Reliable Models",
      "link": "https://machinelearningmastery.com/the-machine-learning-engineers-checklist-best-practices-for-reliable-models/",
      "pubDate": "Tue, 16 Dec 2025 17:55:28 +0000",
      "isoDate": "2025-12-16T17:55:28.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "The Machine Learning Engineer’s Checklist: Best Practices for Reliable Models",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-machine-learning-engineer-checklist.png",
          "alt": "The Machine Learning Engineer’s Checklist: Best Practices for Reliable Models",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Building newly trained machine learning models that work is a relatively straightforward endeavor, thanks to mature frameworks and accessible computing power."
    },
    {
      "title": "Transformer vs LSTM for Time Series: Which Works Better?",
      "link": "https://machinelearningmastery.com/transformer-vs-lstm-for-time-series-which-works-better/",
      "pubDate": "Mon, 15 Dec 2025 11:00:36 +0000",
      "isoDate": "2025-12-15T11:00:36.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Transformer vs LSTM for Time Series: Which Works Better?",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-ipc-lstm-transformer-comparison.jpeg",
          "alt": "Transformer vs LSTM for Time Series: Which Works Better?",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/timeserieschicago.png",
          "alt": "Chicago rides time series",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "From daily weather measurements or traffic sensor readings to stock prices, time series data are present nearly everywhere."
    },
    {
      "title": "How LLMs Choose Their Words: A Practical Walk-Through of Logits, Softmax and Sampling",
      "link": "https://machinelearningmastery.com/how-llms-choose-their-words-a-practical-walk-through-of-logits-softmax-and-sampling/",
      "pubDate": "Sat, 13 Dec 2025 19:25:32 +0000",
      "isoDate": "2025-12-13T19:25:32.000Z",
      "creator": "Yoyo Chan",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "How LLMs Choose Their Words: A Practical Walk-Through of Logits, Softmax and Sampling",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/colton-duke-UExx0KnnkjY-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/effect_temperature.png",
          "alt": "",
          "title": "",
          "position": 2
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/effect_topk.png",
          "alt": "",
          "title": "",
          "position": 3
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/effect_topp.png",
          "alt": "",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into four parts; they are: • How Logits Become Probabilities • Temperature • Top- k Sampling • Top- p Sampling When you ask an LLM a question, it outputs a vector of logits."
    }
  ],
  "lastUpdated": "2025-12-26T09:31:14.589Z"
}
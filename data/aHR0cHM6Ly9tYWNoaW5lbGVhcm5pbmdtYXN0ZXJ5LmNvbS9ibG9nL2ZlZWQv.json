{
  "sourceUrl": "https://machinelearningmastery.com/blog/feed/",
  "title": "MachineLearningMastery.com",
  "description": "Making developers awesome at machine learning",
  "link": "https://machinelearningmastery.com/blog/",
  "items": [
    {
      "title": "7个必知的智能体AI设计模式 (原标题: 7 Must-Know Agentic AI Design Patterns)",
      "link": "https://machinelearningmastery.com/7-must-know-agentic-ai-design-patterns/",
      "pubDate": "Tue, 21 Oct 2025 13:20:55 +0000",
      "isoDate": "2025-10-21T13:20:55.000Z",
      "creator": "Bala Priya C",
      "summary": "# 7个必知的智能体AI设计模式\n\n![7 Must-Know Agentic AI Design Patterns](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-bala-7-must-know-agentic-ai-design-patterns.png)\n\n本文深入探讨了七种经过验证的智能体AI设计模式，旨在指导读者如何为生产工作负载选择和应用这些模式。构建在生产环境中运行的AI智能体，不仅需要强大的模型，更需要清晰的结构来指导它们如何推理、协调、自我纠正和使用工具来完成目标。设计模式提供了这种结构，它们是定义智能体行为的蓝图，有助于将强大的模型转化为可靠的系统。本文介绍的模式借鉴了Google、AWS等团队的最新研究和实践经验。\n\n## 核心设计模式\n\n### 1. ReAct模式：推理与行动\n\n![ReAct Pattern](https://www.kdnuggets.com/wp-content/uploads/react-pattern.png)\n\n*   **描述**：ReAct（Reason and Act）模式将智能体行为组织成明确的推理循环。智能体在推理（分析当前信息、识别差距）、行动（执行工具或查询）和观察（评估结果以确定下一步）之间交替进行，直到任务完成。这种模式通过外部化推理，使每个决策都可见，创建清晰的审计跟踪，防止过早下结论，并通过强制智能体将每一步都基于可观察的结果来减少幻觉。\n*   **适用场景**：需要自适应问题解决的复杂、不可预测任务，例如跨多个来源追踪证据的研究智能体、通过迭代假设测试诊断问题的调试助手、处理非标准请求的客户支持智能体。\n*   **局限性**：以速度换取思考，每个推理循环都需要额外的模型调用，增加延迟和成本。一个工具返回的错误数据可能传播。有效性取决于底层模型的推理能力。\n*   **建议**：可作为复杂、不可预测任务的默认起点，其透明性有助于快速调试和建立信任。\n\n### 2. 反思模式：自我批判的智能体\n\n![Reflection Pattern](https://www.kdnuggets.com/wp-content/uploads/bala-reflection-pattern.png)\n\n*   **描述**：反思模式在智能体输出中添加了一个自我评估层。智能体生成初始响应后，明确切换到批评模式，评估其自身工作，检查准确性、遵守约束，并识别逻辑漏洞或不一致。如果发现问题，智能体将修改输出并重复此过程，直到达到质量阈值。通过强制智能体退后一步进行评估，而不是辩护其第一个答案，减少了确认偏差。\n*   **适用场景**：输出质量远超速度考虑，且错误会带来严重后果的任务，例如需要安全审计或合规性检查的代码生成、发布前需要事实核查的内容创作、错误结论可能导致资本风险的金融分析。\n*   **局限性**：每个反思周期都会增加令牌消耗和延迟。如果没有明确的退出条件，智能体可能会不必要地循环。批评标准必须具体且可衡量，否则会产生不一致的结果。\n*   **建议**：当错误成本超过额外处理时间成本时适用，尤其适用于有明确质量标准的领域，但需要预先投入定义“足够好”的标准。\n\n### 3. 规划模式：先分解再构建\n\n![Planning Pattern](https://www.kdnuggets.com/wp-content/uploads/bala-planning-pattern.png)\n\n*   **描述**：规划智能体在执行前将复杂任务分解为结构化的路线图。它们首先分析需求、识别子任务之间的依赖关系，并按逻辑顺序安排操作。只有在创建详细计划后，智能体才开始实际工作，遵循其构建的路线图。这有助于处理隐藏复杂性的任务，防止在执行过程中发现错误方法。\n*   **适用场景**：涉及显著复杂性或协调性，并受益于明确结构的任务，例如需要特定序列以避免冲突的多系统集成、综合来自不同来源信息的研究项目、具有转换步骤之间依赖关系的数据迁移项目、协调设计、实施和测试的产品开发工作流。\n*   **局限性**：规划开销只适用于真正复杂的工作，简单任务不需要复杂的分解。挑战在于准确评估任务的初始复杂性。\n*   **建议**：用于防止复杂任务中昂贵的错误启动和返工，但对于简单任务而言是纯粹的开销。\n\n### 4. 工具使用模式：超越训练数据\n\n![Tool Use Pattern](https://www.kdnuggets.com/wp-content/uploads/bala-tool-use.png)\n\n*   **描述**：工具使用使智能体能够通过集成外部功能（如调用API、查询数据库、执行代码、抓取网站、与软件系统交互）来执行超出其训练数据的操作。模型根据任务需求协调这些功能，决定调用哪些工具，解释其输出，并链接工具调用以实现仅凭静态知识无法达成的目标。这使得智能体从知识库转变为能够与世界实时交互的活跃系统。\n*   **适用场景**：需要当前信息、外部计算或与系统交互的任务，例如查询订单数据库和库存系统的客户服务智能体、对实时数据集运行统计计算的数据分析智能体、访问超出训练截止日期当前信息的研究助手、在真实环境中执行和测试代码的开发助手。\n*   **局限性**：工具的可靠性成为智能体系统的可靠性。当API返回错误、达到速率限制或超时时，智能体也会继承这些故障。还需要承担每个集成工具的维护负担。\n*   **建议**：对于处理实际任务的生产智能体几乎是不可或缺的。挑战在于如何管理工具的可靠性、选择准确性以及随着工具库增大而增加的复杂性。\n\n### 5. 多智能体协作模式：专家协同工作\n\n![ Multi-Agent Collaboration Pattern](https://www.kdnuggets.com/wp-content/uploads/bala-multiagent-pattern.png)\n\n*   **描述**：多智能体系统将工作分配给专业智能体，而不是构建一个通才。每个智能体都具有专注的专业知识、特定工具和明确定义的系统角色。协调器智能体管理工作分配，将任务路由到适当的专家，并将其输出合成为统一的响应。每个智能体都可以针对其领域进行优化。\n*   **适用场景**：任务真正跨越多个领域，需要不同的专业知识和方法时，例如需要不同技能集（研究→分析→演示）的复杂工作流、受益于专业处理的任务路由应用、由专注智能体更好地解决的多元用例应用。\n*   **局限性**：比单智能体系统更难构建、调试和维护。协调增加了延迟和复杂性。智能体间通信引入新的故障模式。成本随智能体数量增加而倍增。\n*   **建议**：仅当单智能体方法确实无法有效处理多样化、复杂的需求，并且专业化能够带来可衡量的改进时才考虑，否则不建议增加系统复杂性。\n\n### 6. 顺序工作流：可预测的管道\n\n![Sequential Workflow](https://www.kdnuggets.com/wp-content/uploads/bala-seq-pattern.png)\n\n*   **描述**：顺序模式将智能体系统组织成固定顺序的管道。智能体A完成任务并将输出传递给智能体B，智能体B处理后传递给智能体C。每个专家处理预定序列中的一个步骤。编排不需要AI，只需预定义的逻辑来确定流程。这是一种流水线式的智能体系统方法。\n*   **优点**：可预测性、比动态路由系统更低的延迟、比基于协调器的方法更低的成本、可预测的行为简化了调试。\n*   **适用场景**：工作流遵循结构化、可重复模式且处理序列很少改变时，例如具有提取、转换和加载阶段的数据管道、文档处理流程（解析→分析→总结→存储）、内容审核（检测→分类→路由→行动）、订单处理、报告生成。\n*   **局限性**：无法适应工作流中途的变化条件。如果某些输入不需要第三步，它仍然会执行。当工作流需要条件逻辑或动态路由时，顺序模式会导致效率低下或完全失败。\n*   **建议**：适用于一致性和效率比灵活性更重要的生产管道，但对于需要根据中间结果进行调整的任务而言是错误的选择。\n\n### 7. 人在回路模式：高风险任务的安全保障\n\n![Human-in-the-Loop Pattern](https://www.kdnuggets.com/wp-content/uploads/bala-hil-pattern.png)\n\n*   **描述**：人在回路（Human-in-the-Loop）模式认识到某些决策不应完全自动化。在关键检查点，智能体暂停执行，并将信息呈现给人类审查员。人类专家评估工作、提供指导或批准，然后智能体继续。这不是缺乏自动化，而是智能系统设计，承认某些决策需要人类判断、问责或监督。\n*   **适用场景**：决策涉及重大后果、安全问题或需要人类问责的主观判断时，例如超出授权阈值的金融交易、需要细致判断的边缘内容审核、归档或签署前的法律文件批准、AI筛选但人类决定的招聘决策。\n*   **局限性**：增加了架构复杂性，需要暂停工作流、通知人类、管理交接和恢复执行的基础设施。需要明确的升级标准，否则会过度负担人类或自动化需要监督的决策。\n*   **建议**：对于错误可能造成重大损害或问责制需要人类决策的高风险应用是强制性的。它承认完全自动化并非总是目标，机器效率和人类判断的正确平衡往往能带来更好的结果。\n\n## 总结\n\n大多数模式决策归结为三个关键问题：\n\n1.  **工作流是否可预测？** 如果是，顺序模式在成本和速度上占优。如果否，则需要动态编排。\n2.  **质量是否比速度更重要？** 如果是，添加反思或人在回路模式。如果否，优化直接执行。\n3.  **任务是否真正复杂？** 如果是，考虑多智能体或规划模式。如果否，从单个智能体和工具使用开始。\n\n过早地采用复杂模式是代价高昂的错误，应从最简单的有效方案开始。",
      "shortSummary": "本文介绍了7种智能体AI设计模式，旨在构建可靠的生产级AI智能体。这些模式包括ReAct（推理与行动）、反思（自我批判）、规划（任务分解）、工具使用（扩展能力）、多智能体协作（专家协同）、顺序工作流（可预测管道）和人在回路（高风险安全保障）。每种模式都有其适用场景、优缺点和权衡（成本、延迟、可靠性）。选择合适的模式需考虑工作流的可预测性、质量与速度的优先级以及任务的实际复杂性，避免不必要的复杂化，建议从最简单的有效方案开始。",
      "translated_title": "7个必知的智能体AI设计模式",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-bala-7-must-know-agentic-ai-design-patterns.png",
          "alt": "7 Must-Know Agentic AI Design Patterns",
          "title": "",
          "position": 1
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/react-pattern.png",
          "alt": "ReAct Pattern",
          "title": "",
          "position": 2
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-reflection-pattern.png",
          "alt": "Reflection Pattern",
          "title": "",
          "position": 3
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-planning-pattern.png",
          "alt": "Planning Pattern",
          "title": "",
          "position": 4
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-tool-use.png",
          "alt": "Tool Use Pattern",
          "title": "",
          "position": 5
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-multiagent-pattern.png",
          "alt": " Multi-Agent Collaboration Pattern",
          "title": "",
          "position": 6
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-seq-pattern.png",
          "alt": "Sequential Workflow",
          "title": "",
          "position": 7
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-hil-pattern.png",
          "alt": "Human-in-the-Loop Pattern",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "完整文章",
      "content": "Building AI agents that work in production requires more than powerful models."
    },
    {
      "title": "2026年：如何让你的AI工程职业生涯经久不衰 (原标题: Future-Proofing Your AI Engineering Career in 2026)",
      "link": "https://machinelearningmastery.com/future-proofing-your-ai-engineering-career-in-2026/",
      "pubDate": "Mon, 20 Oct 2025 11:00:38 +0000",
      "isoDate": "2025-10-20T11:00:38.000Z",
      "creator": "Nahla Davies",
      "summary": "# 2026年：如何让你的AI工程职业生涯经久不衰\n\n## 引言\n人工智能工程已从一个未来主义的利基领域转变为全球最受欢迎的技术职业之一。然而，行业创新步伐极快，自动化甚至开始影响其创造者。本文旨在探讨如何通过深化核心基础、拥抱系统级自动化以及与开源和不断演变的政策保持一致，来确保AI工程师的职业生涯面向未来。\n\n![2026年：如何让你的AI工程职业生涯经久不衰](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-future-proof-ai-engineering-career-2026.png)\n\n## 核心策略\n\n1.  **掌握他人忽视的基础知识**\n    *   所有新兴AI趋势（如生成式智能体、多模态Transformer、合成数据管道）都建立在相同的基本原理之上。\n    *   优先学习数学基础（线性代数、优化、概率论、信息论），而非急于掌握框架（如PyTorch、TensorFlow）。\n    *   具备推导损失函数、理解收敛行为和推理数据分布的能力，是长期技术韧性的支柱。\n    *   对理论的深入理解能带来更强的适应性和通用性，例如诊断模型训练崩溃或梯度不稳定性。\n\n2.  **驾驭自动化而非对抗**\n    *   自动化工具（AutoML平台、代码生成模型、自动化数据标注）对AI工程师构成直接威胁。\n    *   关键在于管理和扩展自动化，而非与之对抗。\n    *   掌握微调自动化工具或将其集成到更大系统的能力。\n    *   理解人类直觉在哪些方面仍优于机器（例如，提示策略而非简单的提示工程）。\n    *   核心技能是“元工程”：构建基础设施，确保自动化安全、高效、合乎道德地运行。\n\n3.  **培养跨学科的流畅性**\n    *   未来的AI工程更注重系统集成而非孤立的模型性能。\n    *   雇主重视能将技术系统转化为商业、设计和伦理语境的工程师。\n    *   能够与数据隐私律师、用户体验研究员和DevOps工程师有效沟通。\n    *   弥合技术鸿沟，例如优化推理延迟并向非技术团队解释公平性指标。\n    *   从系统层面思考，关注系统如何交互、扩展和演变。\n\n4.  **学会利用开源生态系统**\n    *   开源是AI进步的核心驱动力，战略意义日益增强。\n    *   积极参与、贡献或领导开源项目能迅速建立信誉和知名度。\n    *   通过贡献代码、构建轻量级工具或以新颖方式实验预训练模型来保持创新前沿。\n    *   理解如何评估和组合开源组件（例如，将向量数据库与LLM API结合）。\n\n5.  **理解AI基础设施，而非仅仅模型**\n    *   数据摄取、GPU优化、分布式训练和模型服务等基础设施已成为生产级AI中最具挑战性的部分。\n    *   掌握端到端系统知识，能够管理整个工作流程。\n    *   熟悉云原生MLOps（Python）、容器化（Docker、Kubernetes）和框架（MLflow、Kubeflow）至关重要。\n    *   具备将模型从原型扩展到创收系统的能力。\n    *   未来的AI团队需要融合研究洞察和部署专业知识的混合型人才。\n\n6.  **适应伦理、法律和社会变革**\n    *   AI的未来将受政策影响（如欧盟AI法案、美国数据透明度框架）。\n    *   将合规性知识纳入AI工程师的工具包。\n    *   在模型中嵌入公平性、问责制和可解释性将成为强制要求。\n    *   伦理不仅是避免法律问题，更是改进系统的设计约束，建立信任。\n    *   能够将抽象原则转化为可衡量、可执行的保障措施。\n    *   预测自动化对社会产生的连锁反应，使工作更具防御性和吸引力。\n\n## 结论\n2026年的AI工程师不能仅凭技术技能生存。那些能够将扎实的基础知识与跨学科直觉、系统级理解和伦理远见相结合的人将脱颖而出。工具会变，API会消亡，新架构会主导，但适应能力永不过时。最大的优势不是掌握现有技术，而是为尚未出现的事物做好准备。",
      "shortSummary": "为确保2026年AI工程职业生涯经久不衰，工程师需深化数学与系统基础，通过元工程驾驭自动化，培养跨学科沟通能力，积极利用开源生态系统，并深入理解AI基础设施。同时，适应伦理、法律及社会政策变化至关重要。成功的关键在于持续适应、具备系统级思维，并将技术深度与广阔的背景知识相结合，为未来创新做好准备。",
      "translated_title": "2026年：如何让你的AI工程职业生涯经久不衰",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-future-proof-ai-engineering-career-2026.png",
          "alt": "Future-Proofing Your AI Engineering Career in 2026",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "AI engineering has shifted from a futuristic niche to one of the most in-demand tech careers on the planet."
    },
    {
      "title": "革新MLOps：增强型BigQuery ML UI实现无缝模型创建与管理 (原标题: Revolutionizing MLOps: Enhanced BigQuery ML UI for Seamless Model Creation and Management)",
      "link": "https://machinelearningmastery.com/revolutionizing-mlops-enhanced-bigquery-ml-ui-for-seamless-model-creation-and-management/",
      "pubDate": "Fri, 17 Oct 2025 18:00:44 +0000",
      "isoDate": "2025-10-17T18:00:44.000Z",
      "creator": "Nivedita Kumari",
      "summary": "# 革新MLOps：增强型BigQuery ML UI实现无缝模型创建与管理\n\n本文介绍了增强型BigQuery ML (BQML) 用户界面如何直接在BigQuery控制台中简化端到端的模型创建、管理和预测流程。\n\n## 主要改进与功能\n\n*   **简化模型创建流程**：通过引导式、可保存的SQL流程，极大地简化了模型创建。用户可以直接在模型创建流程中保存SQL查询（需指定区域）。\n*   **可重现的数据准备**：在SQL中准备可重现的训练、评估和预测数据集划分。\n*   **ML.PREDICT预测功能**：利用ML.PREDICT函数运行预测并理解其输出。\n\n## 实际操作示例：使用美国人口普查数据创建逻辑回归模型\n\n本文通过一个具体示例，演示了如何使用增强型BQML UI快速创建一个逻辑回归模型，以预测美国人口普查数据中的收入等级（$<=50K 或 $>50K）。\n\n### 1. 数据探索\n\n*   通过查询`bigquery-public-data.ml_datasets.census_adult_income`数据集，可以查看`age`、`workclass`、`marital_status`、`education_num`、`occupation`、`hours_per_week`、`income_bracket`和`functional_weight`等列。\n*   `income_bracket`列包含“<=50K”或“>50K”两个值。\n*   `functional_weight`列的值与`income_bracket`的值无关。\n\n![Revolutionizing MLOps: Enhanced BigQuery ML UI for Seamless Model Creation and Management](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-nivedita-bigquery-ml-ui.png)\n*图：增强型BigQuery ML UI概览*\n\n### 2. 数据准备\n\n*   为了模型训练，需要准备一个样本数据集，并将其划分为训练、评估和预测集。\n*   通过从`functional_weight`列派生一个新列，将80%的数据用于训练，剩余的20%用于评估和预测。\n*   创建了一个名为`census.input_data`的视图，其中包含一个`dataframe`列，用于标识数据属于“training”、“evaluation”还是“prediction”集。\n\n![Streamlined Model Creation Flow](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-1.png)\n*图：数据探索结果示例*\n\n### 3. 在BigQuery UI中创建ML模型\n\n1.  **启动模型创建**：从BigQuery主屏幕点击“ML Model”开始。\n    ![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-2.png)\n    *图：BigQuery UI中创建ML模型的入口*\n2.  **选择数据集和模型名称**：在“Create new ML model”页面，选择`census`数据集，并将模型命名为`logistic_reg`。\n    ![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-3.png)\n    *图：选择数据集和命名模型*\n3.  **选择创建方法和建模目标**：在“Creation method and Modeling Objective”页面，选择“Train a model in BigQuery”，建模目标为“Classification”，模型类型选择“Logistic Regression”。\n    ![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-4.png)\n    *图：选择建模目标和模型类型*\n4.  **设置训练数据**：选择`census`作为数据集，`input_data`作为表/视图。\n    ![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-5.png)\n    *图：确认训练数据设置*\n5.  **指定输入标签并创建模型**：选择`income_bracket`作为`input_label_cols`，然后点击“Create model”。\n6.  **查看模型创建结果**：模型创建完成后，“Query results”部分将显示“Job information”、“Results”、“Execution details”和“Execution graph”四个标签页。其中，“Execution details”和“Execution graph”提供了关于模型创建作业的详细信息，包括损失和学习率等。\n    ![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-6.png)\n    *图：模型创建后的查询结果界面*\n    ![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-7.png)\n    *图：模型执行详情示例*\n\n### 4. 使用模型进行预测\n\n*   在BigQuery Studio查询编辑器中使用`ML.PREDICT`函数进行预测。\n*   该函数接受训练好的模型（例如`census.logistic_reg`）和`input_data`视图中`dataframe`列值为“prediction”的行作为输入。\n*   查询将生成`income_bracket`的预测结果，包括预测的收入等级、预测概率以及原始输入数据。\n\n![Creating the ML Model in BigQuery UI](https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-8.png)\n*图：使用ML.PREDICT进行预测*\n\n## 总结\n\n这些UI增强功能为BigQuery ML用户提供了更直观、高效的体验，从模型创建到部署和监控，全面简化了MLOps工作流程。鼓励用户探索新的BigQuery ML UI，体验其带来的流畅MLOps工作流，并查阅BQML UI用户指南以了解更多功能。",
      "shortSummary": "增强型BigQuery ML UI革新了MLOps，通过直接在BigQuery控制台中简化端到端的模型创建、管理和预测流程。它提供引导式、可保存的SQL流来创建模型，简化了训练、评估和预测的数据准备，并通过ML.PREDICT实现轻松模型部署。这些改进显著提升了BigQuery ML工作流的效率和用户体验，使MLOps更加无缝和直观。",
      "translated_title": "革新MLOps：增强型BigQuery ML UI实现无缝模型创建与管理",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-nivedita-bigquery-ml-ui.png",
          "alt": "Revolutionizing MLOps: Enhanced BigQuery ML UI for Seamless Model Creation and Management",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-1.png",
          "alt": "Streamlined Model Creation Flow",
          "title": "",
          "position": 2
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-2.png",
          "alt": "Creating the ML Model in BigQuery UI",
          "title": "",
          "position": 3
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-3.png",
          "alt": "Creating the ML Model in BigQuery UI",
          "title": "",
          "position": 4
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-4.png",
          "alt": "Creating the ML Model in BigQuery UI",
          "title": "",
          "position": 5
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-5.png",
          "alt": "Creating the ML Model in BigQuery UI",
          "title": "",
          "position": 6
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-6.png",
          "alt": "Creating the ML Model in BigQuery UI",
          "title": "",
          "position": 7
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/nivedita-bigquery-ml-image-7.png",
          "alt": "Creating the ML Model in BigQuery UI",
          "title": "",
          "position": 8
        }
      ],
      "contentSource": "完整文章",
      "content": "Exciting news for BigQuery ML (BQML) users."
    },
    {
      "title": "机器学习向量数据库完整指南 (原标题: The Complete Guide to Vector Databases for Machine Learning)",
      "link": "https://machinelearningmastery.com/the-complete-guide-to-vector-databases-for-machine-learning/",
      "pubDate": "Fri, 17 Oct 2025 16:34:47 +0000",
      "isoDate": "2025-10-17T16:34:47.000Z",
      "creator": "Bala Priya C",
      "summary": "# 机器学习向量数据库完整指南\n\n![机器学习向量数据库完整指南](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-bala-vector-db-guide.jpeg)\n\n## 引言\n\n向量数据库已成为现代AI应用的核心，尤其是在处理嵌入（embeddings）时，如语义搜索、推荐系统和RAG系统。传统数据库在处理数百万甚至数亿个高维向量（如1024或1536维）时面临性能瓶颈，因为每次查询都需要进行数十亿次浮点运算。向量数据库通过专门的算法避免了暴力距离计算，利用分层图和空间分区等技术，仅检查一小部分候选向量，从而实现近似最近邻（ANN）搜索，将速度提高千倍。\n\n本文旨在解释向量数据库在机器学习应用中的作用、工作原理以及何时需要使用它们，具体涵盖以下主题：\n\n*   传统数据库索引为何不适用于高维空间中的相似性搜索。\n*   驱动向量数据库的关键算法：HNSW、IVF和乘积量化（Product Quantization）。\n*   距离度量及其重要性。\n*   理解召回率与延迟的权衡，以及生产环境中的调优。\n*   向量数据库如何通过分片、压缩和混合索引处理规模化问题。\n*   何时真正需要向量数据库而非更简单的替代方案。\n*   主要选项概述：Pinecone、Weaviate、Chroma、Qdrant、Milvus等。\n\n## 传统数据库为何不适用于相似性搜索\n\n传统数据库擅长精确匹配（如按ID查找用户），依赖于B树索引。然而，机器学习处理的是高维向量（嵌入），它们代表语义含义。查找相似向量需要计算数百或数千维度的距离，暴力计算效率极低。传统索引无法处理这种高维空间中的“邻居”查找。\n\n## 向量数据库的独特之处\n\n向量数据库专为相似性搜索而设计。它们使用专门的数据结构来组织向量，实现近似最近邻（ANN）搜索，以牺牲完美精度换取显著的速度提升。其核心在于索引结构，它使用针对高维几何设计的算法，而非B树，从而避免了暴力距离计算，使实时语义搜索成为可能。\n\n## 向量数据库的核心概念\n\n向量数据库依赖于不同的算法方法，它们在搜索速度、精度和内存使用之间进行权衡。主要有以下三种关键向量索引方法：\n\n### 1. 分层可导航小世界（HNSW）\n\n*   **原理**：构建多层图结构，每层包含向量子集，通过边连接。顶层稀疏，底层包含所有向量。搜索从顶层开始，贪婪地导航到最近邻，然后逐层向下。\n*   **特点**：搜索复杂度为O(log N)，高效扩展到数百万向量。提供出色的召回率和速度，但需要将整个图保存在内存中，适用于延迟敏感型应用。\n\n![分层可导航小世界（HNSW）](https://www.kdnuggets.com/wp-content/uploads/vector-db-hnsw.png)\n\n### 2. 倒排文件索引（IVF）\n\n*   **原理**：使用K-means等聚类算法将向量空间划分为多个区域。索引时，每个向量分配给最近的聚类中心。搜索时，首先识别最相关的聚类，然后只在这些聚类中进行搜索。\n*   **特点**：通过搜索更多聚类提高精度，搜索更少聚类提高速度。比HNSW占用更少内存，因为搜索时只加载相关聚类，适用于内存无法容纳的超大数据集。缺点是在相同速度下召回率较低，但可与乘积量化结合改进。\n\n![IVF 倒排文件索引](https://www.kdnuggets.com/wp-content/uploads/bala-vector-db-ivf-scaled.png)\n\n### 3. 乘积量化（PQ）\n\n*   **原理**：通过将每个向量分割成子向量，然后独立聚类每个子空间来压缩向量，以减少内存使用并加速距离计算。向量被表示为聚类ID序列而非原始浮点数。\n*   **特点**：可将高维向量的内存占用降低数个数量级（例如，1536维float32向量从~6KB压缩到~8字节）。距离计算使用预计算的查找表，速度显著加快。代价是量化带来的精度损失。PQ通常与其他方法结合使用，如先用IVF进行初步过滤，再用PQ高效扫描候选向量。\n\n![乘积量化](https://www.kdnuggets.com/wp-content/uploads/bala-vector-pq-img.png)\n\n## 向量数据库如何处理规模化问题\n\n现代向量数据库结合多种技术来高效处理数十亿个向量：\n\n*   **分片（Sharding）**：将向量分布到多台机器上，每片独立运行ANN搜索，结果通过堆合并，实现索引和搜索的水平扩展。\n*   **过滤（Filtering）**：将元数据过滤与向量搜索集成。解决方案包括独立的元数据索引与向量结果交叉，或根据过滤值复制数据的分区索引。\n*   **混合搜索（Hybrid Search）**：结合向量相似性与传统全文搜索（如BM25），通过加权组合或倒数排名融合合并分数，处理需要语义理解和关键词精度的查询。\n*   **动态更新**：对于HNSW等图基索引，动态更新是挑战。大多数系统通过队列写入并定期重建索引，或使用支持增量更新的专用数据结构。\n\n## 关键相似性度量\n\n向量相似性依赖于量化向量之间距离的度量：\n\n*   **欧几里得距离（Euclidean distance）**：测量直线距离，对向量大小敏感。\n*   **余弦相似度（Cosine similarity）**：测量向量之间的角度，忽略大小，适用于方向编码含义但尺度不重要的嵌入。大多数语义搜索使用余弦相似度。\n*   **点积（Dot product）**：未归一化的余弦相似度。当所有向量都是单位长度时，等同于余弦相似度但计算更快。\n\n选择正确的度量很重要，应与嵌入模型训练时使用的度量一致。\n\n## 理解召回率与延迟的权衡\n\n向量数据库通过近似搜索牺牲完美精度以换取速度。理解这种权衡对生产系统至关重要：\n\n*   **召回率（Recall）**：衡量搜索返回的真实最近邻居的百分比。高召回率需要检查更多候选向量。\n*   **延迟（Latency）**：查询所需的时间。高召回率通常意味着高延迟。\n\n最佳点通常在90-95%的召回率。从95%提高到99%可能会使查询时间增加三倍，而语义搜索质量几乎没有改善。建议对特定用例进行基准测试，通常85%的召回率就能产生与99%无差别的结果，且成本更低。\n\n## 何时需要向量数据库\n\n并非所有使用嵌入的应用都需要专门的向量数据库。以下情况你**不需要**向量数据库：\n\n*   向量数量少于10万个：NumPy的暴力搜索可能足够快。\n*   向量频繁变化：索引开销可能超过搜索节省。\n*   需要完美精度：使用FAISS等优化库进行精确搜索。\n\n以下情况你**需要**向量数据库：\n\n*   拥有数百万向量并需要低延迟搜索。\n*   构建大规模语义搜索、RAG或推荐系统。\n*   需要通过元数据过滤向量同时保持搜索速度。\n*   需要处理分片、复制和更新的基础设施。\n\n许多团队从简单解决方案开始，随着规模扩大再迁移到向量数据库。\n\n## 生产级向量数据库选项\n\n向量数据库市场发展迅速，主要参与者包括：\n\n*   **Pinecone**：全托管云服务，专有算法，适合希望避免运维开销的团队。\n*   **Weaviate**：开源，可部署在任何地方，结合向量搜索和GraphQL模式，模块系统集成嵌入提供商，提供灵活性和控制。\n*   **Chroma**：专注于开发者体验，为AI应用设计，强调简洁性，可嵌入或作为服务器运行，适用于原型开发和中小型部署，底层使用HNSW。\n*   **Qdrant**：用Rust构建，性能高，通过负载索引高效支持过滤搜索，存储与搜索分离，支持磁盘操作，适合高性能需求。\n*   **Milvus**：处理大规模部署，计算与存储分离的解耦架构，支持多种索引类型（IVF、HNSW、DiskANN），配置丰富，操作复杂但扩展性强。\n*   **Postgres with pgvector**：为PostgreSQL添加向量搜索，适用于已使用Postgres的应用，性能适中，提供事务、连接和熟悉工具，支持精确搜索和IVF。\n*   **Elasticsearch and OpenSearch**：通过HNSW索引添加向量搜索，适用于已运行这些服务的用户，混合搜索能力强。\n\n## 超越简单的相似性搜索\n\n向量数据库正在超越简单的相似性搜索，发展出更先进的方法：\n\n*   **混合向量索引**：结合多个嵌入模型，同时搜索句子嵌入和关键词嵌入，捕捉不同方面的相似性。\n*   **多模态搜索**：在同一空间中索引不同模态（文本、图像、音频）的向量，实现跨模态搜索（如用文本查询图像）。\n*   **学习型索引**：使用机器学习优化索引结构以适应特定数据集，通过训练模型预测向量位置，适用于专业工作负载。\n*   **流式更新**：成为一流操作，而非批处理重建，新的索引结构支持增量更新。",
      "shortSummary": "向量数据库是现代AI应用中实现高维向量快速、可扩展相似性搜索的关键。它们通过HNSW、IVF和乘积量化等近似最近邻（ANN）算法，解决了传统数据库在高维嵌入搜索中的性能瓶颈。向量数据库通过分片、过滤和混合搜索处理规模化问题，并允许在召回率和延迟之间进行权衡。当处理数百万向量、需要低延迟搜索或元数据过滤时，向量数据库是必需的。主要选项包括Pinecone、Weaviate、Qdrant等，并且功能正向混合索引、多模态搜索和流式更新发展。",
      "translated_title": "机器学习向量数据库完整指南",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-bala-vector-db-guide.jpeg",
          "alt": "The Complete Guide to Vector Databases for Machine Learning",
          "title": "",
          "position": 1
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/vector-db-hnsw.png",
          "alt": "Hierarchical Navigable Small World (HNSW)",
          "title": "",
          "position": 2
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-vector-db-ivf-scaled.png",
          "alt": "IVF Inverted File Index",
          "title": "",
          "position": 3
        },
        {
          "url": "https://www.kdnuggets.com/wp-content/uploads/bala-vector-pq-img.png",
          "alt": "Product Quantization",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "Vector databases have become essential in most modern AI applications."
    },
    {
      "title": "无需更多GPU即可加速模型训练的3种方法 (原标题: 3 Ways to Speed Up Model Training Without More GPUs)",
      "link": "https://machinelearningmastery.com/3-ways-to-speed-up-model-training-without-more-gpus/",
      "pubDate": "Thu, 16 Oct 2025 17:14:34 +0000",
      "isoDate": "2025-10-16T17:14:34.000Z",
      "creator": "Shittu Olumide",
      "summary": "# 无需更多GPU即可加速模型训练的3种方法\n\n本文介绍了三种无需增加GPU即可显著加速模型训练的有效方法，主要通过优化精度、内存和数据流来实现。\n\n![无需更多GPU即可加速模型训练的3种方法](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-3-ways-speed-model-training-without-gpu.png)\n\n## 引言\n\n训练大型模型通常耗时漫长，人们常本能地寻求更多GPU。然而，预算限制和云服务配额等问题使得额外硬件并非总是可行。好消息是，在不增加任何GPU的情况下，仍有多种方法可以显著加快训练速度。加速训练不仅仅是原始计算能力的问题，更关乎如何高效利用现有资源，减少内存交换、GPU空闲和未优化数据管道造成的浪费。\n\n## 方法一：混合精度与内存优化\n\n混合精度是无需新GPU即可加速训练的最简便方法之一。\n\n### 核心思想\n现代GPU能以比标准32位浮点数快得多的速度处理半精度（FP16）或bfloat16数学运算。通过使用更小的数据类型进行存储和计算，可以减少内存使用和带宽，使更多数据同时驻留在GPU上，从而加快操作完成速度。\n\n*   **主要操作**：使用较低精度（FP16或BF16）。\n*   **关键部分**：如损失缩放和少量累积，保持全精度（FP32）以维持稳定性。\n\n### 工作原理\n正确实施混合精度通常能使训练速度提高1.5至2倍，且对准确性几乎没有影响。PyTorch、TensorFlow和JAX都原生支持，大多数NVIDIA、AMD和Apple GPU也提供硬件加速。\n\n**PyTorch示例（自动混合精度AMP）:**\n使用`torch.cuda.amp.GradScaler`和`autocast()`上下文管理器。`autocast()`自动为操作选择FP16或FP32，而`GradScaler()`通过动态调整损失比例来防止下溢。GPU因处理和计算的字节数减少而执行更快。\n\n### 内存优化技巧\n与混合精度相辅相成，内存优化可以进一步提升效率：\n\n*   **梯度检查点（Gradient checkpointing）**：仅保存关键激活值，在反向传播时重新计算其他值，以计算换取内存。\n*   **激活卸载（Activation offloading）**：将不常用的张量临时移动到CPU内存。\n\n这些功能可通过`torch.utils.checkpoint`或DeepSpeed、Hugging Face Accelerate、bitsandbytes等库自动配置。\n\n### 适用场景与预期收益\n*   模型紧密占用GPU内存，或批次大小较小。\n*   使用较新的GPU（RTX 20系列或更新）。\n*   可容忍训练过程中轻微的数值变化。\n*   **预期收益**：训练速度提高30-100%，内存使用减少高达50%。\n\n## 方法二：梯度累积与有效批次大小技巧\n\n当GPU内存成为瓶颈，导致无法使用大批次训练时，梯度累积提供了一个优雅的解决方案。\n\n### 核心思想\n不一次性处理一个巨大的批次，而是将其拆分为更小的微批次。对每个微批次执行前向和反向传播，累积梯度，并在多次迭代后才更新模型权重。这允许在相同硬件上模拟大批次训练。\n\n### 工作原理\n*   损失值除以累积步数以保持梯度平衡。\n*   梯度在步骤之间存储在内存中，而不是被清除。\n*   在累积`accum_steps`个微批次后，优化器执行一次更新。\n\n这种方法可以将虚拟批次大小扩大四到八倍，提高稳定性并可能加速收敛，同时不超出GPU内存限制。\n\n### 重要性\n*   更大的有效批次减少了梯度更新中的噪声，改善了复杂模型的收敛性。\n*   可与混合精度结合使用以获得额外收益。\n*   当内存而非计算是限制因素时，尤其有效。\n\n### 适用场景\n*   使用大批次时遇到“内存不足”错误。\n*   希望获得大批次的好处，但不改变硬件。\n*   数据加载器或数据增强管道能够跟上每次更新的多个微步骤。\n\n## 方法三：智能卸载与分片训练 (ZeRO)\n\n随着模型规模的增长，GPU内存往往在计算能力之前成为主要瓶颈。智能卸载和分片训练（如ZeRO）旨在通过智能地分割和分配内存使用来解决此问题。\n\n### ZeRO工作原理\n在多GPU设置中，通常每个GPU都保存模型参数、梯度和优化器状态的完整副本，这对于大型模型来说是巨大的浪费。ZeRO（Zero Redundancy Optimizer）通过在设备间分片这些状态来打破这种重复：\n\n*   **ZeRO Stage 1**：分片优化器状态。\n*   **ZeRO Stage 2**：分片优化器状态和梯度。\n*   **ZeRO Stage 3**：分片所有内容，包括模型参数、梯度和优化器状态。\n\n这样，每个GPU仅持有总内存占用量的一小部分，但它们仍协同计算完整的更新。这使得训练模型的大小可以显著超过单个GPU的内存容量。\n\n### 适用场景\n*   训练大型模型（数亿或数十亿参数）。\n*   即使使用混合精度仍出现GPU内存不足。\n*   使用多个GPU或分布式节点。\n\n## 额外优化技巧\n\n除了上述三种主要方法，还有一些小而重要的优化可以带来显著差异：\n\n1.  **优化数据管道**：通过并行化和预取数据来提高GPU利用率。在PyTorch中，可调整`DataLoader`的`num_workers`、`pin_memory=True`和`prefetch_factor`。对于大型数据集，使用WebDataset、TFRecord或Parquet等优化格式。\n2.  **优化前先进行性能分析**：使用PyTorch Profiler、TensorBoard Profiler或NVIDIA Nsight Systems等工具找出训练循环中的实际瓶颈，可能不是GPU计算，而是数据增强、日志记录或损失计算。\n3.  **使用提前停止和课程学习**：提前停止可避免不必要的训练周期；课程学习从简单示例开始，逐步引入复杂示例，帮助模型更快收敛。\n4.  **监控内存和利用率**：定期检查GPU内存使用情况（如`torch.cuda.max_memory_allocated()`、`nvidia-smi`），确保GPU得到充分利用。\n5.  **智能组合技术**：将不同策略结合使用可获得最大收益，例如：\n    *   混合精度 + 梯度累积 = 更快、更稳定的训练。\n    *   ZeRO卸载 + 数据管道优化 = 更大模型且无内存错误。\n    *   提前停止 + 性能分析 = 减少浪费的训练周期。\n\n## 何时选择哪种方法\n\n| 方法                     | 最佳适用场景                               | 如何帮助                                                               | 典型速度增益 | 内存影响       | 复杂性   |\n| :----------------------- | :----------------------------------------- | :--------------------------------------------------------------------- | :----------- | :------------- | :------- |\n| 混合精度与内存优化       | 任何紧密占用GPU内存的模型                  | 使用较低精度和更轻量级张量，减少计算和传输开销                         | 1.5 – 2倍    | 减少30–50%     | 低       |\n| 梯度累积与有效批次大小   | 受GPU内存限制但需要大批次大小的模型        | 通过在小批次上累积梯度来模拟大批次训练                                 | 间接速度增益 | 适度额外内存   | 低 – 中等 |\n| 智能卸载与分片训练 (ZeRO) | 无法适应GPU内存的超大型模型                | 将优化器状态、梯度和参数分片到设备或CPU上                              | 10–30%吞吐量 | 释放大部分GPU内存 | 中等 – 高 |\n\n*   **即时效果**：从混合精度开始，它稳定、简单且内置于主流框架。\n*   **内存限制批次大小**：添加梯度累积，它轻量且易于集成。\n*   **模型仍不适配**：使用ZeRO或卸载来分片内存，在相同硬件上训练更大的模型。\n\n## 总结\n\n训练速度不仅取决于GPU数量，更取决于如何有效利用它们。本文介绍的三种方法是无需升级硬件即可加速训练最实用和广泛采用的方式。每种技术本身都能带来实际收益，但它们的真正优势在于组合使用。混合精度通常与梯度累积自然结合，ZeRO也与两者很好地集成。它们共同可以使有效速度翻倍，提高稳定性，并延长现有硬件设置的寿命。在应用这些方法之前，务必先对训练循环进行性能分析和基准测试。",
      "shortSummary": "本文介绍了无需增加GPU即可加速模型训练的三种核心策略：**混合精度与内存优化**利用FP16/BF16减少计算和内存开销，提升1.5-2倍速度；**梯度累积**通过分批处理模拟大批次训练，解决内存限制并提高稳定性；**智能卸载与分片训练 (ZeRO)**则将模型状态分片至多设备或CPU，支持超大型模型训练。此外，优化数据管道、性能分析、提前停止及技术组合也是提升效率的关键。",
      "translated_title": "无需更多GPU即可加速模型训练的3种方法",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-3-ways-speed-model-training-without-gpu.png",
          "alt": "3 Ways to Speed Up Model Training Without More GPUs",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "In this article, you will learn three proven ways to speed up model training by optimizing precision, memory, and data flow &mdash; without adding any..."
    },
    {
      "title": "文本数据特征工程的7个技巧 (原标题: 7 Feature Engineering Tricks for Text Data)",
      "link": "https://machinelearningmastery.com/7-feature-engineering-tricks-for-text-data/",
      "pubDate": "Thu, 16 Oct 2025 15:24:51 +0000",
      "isoDate": "2025-10-16T15:24:51.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "本文介绍了将原始文本数据转换为机器学习和深度学习模型可处理的数值特征的七个关键特征工程技巧。\n\n![文本数据特征工程的7个技巧](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-ipc-7-feature-engineering-tricks-text-data.png)\n\n### 引言\n\n*   **背景**：越来越多的AI和机器学习系统依赖文本数据，但机器实际处理的是数字而非语言。\n*   **目的**：特征工程是将原始文本数据转化为有用的数值特征，供模型进行推断的关键步骤。\n*   **技巧分类**：\n    *   **经典机器学习**：技巧1至5通常用于决策树等传统模型。\n    *   **深度学习**：技巧6和7对循环神经网络和Transformer等深度学习模型不可或缺，技巧2（词干提取和词形还原）也可能增强其性能。\n\n### 7个特征工程技巧\n\n1.  **移除停用词 (Removing Stopwords)**\n    *   **目的**：减少数据维度，避免“维度诅咒”。\n    *   **方法**：移除文章、介词、助动词等常见且可能增加噪声的词，保留传达主要语义的词。\n    *   **实现**：通常使用NLTK等库。\n\n2.  **词干提取和词形还原 (Stemming and Lemmatization)**\n    *   **目的**：将词语还原为词根形式，合并不同变体（如动词的不同时态），统一特征表示。\n    *   **适用性**：在深度学习模型中较少需要，但在数据有限时可缓解稀疏性，使模型关注核心词义。\n    *   **实现**：NLTK的PorterStemmer是常用工具。\n\n3.  **基于计数的向量：词袋模型 (Count-based Vectors: Bag of Words)**\n    *   **原理**：经典机器学习中将文本转换为数值特征的最简单方法，通过词频编码为向量。\n    *   **优点**：捕获词在文档中的整体存在和相关性。\n    *   **缺点**：无法捕获词序、上下文或语义关系。\n    *   **适用场景**：对不太复杂的文本分类模型简单有效。\n    *   **实现**：scikit-learn的`CountVectorizer`。\n\n4.  **TF-IDF特征提取 (TF-IDF Feature Extraction)**\n    *   **原理**：自然语言处理的基石方法，超越词袋模型，不仅考虑词频，还考虑词在整个数据集中的逆文档频率（即词的独特性和重要性）。\n    *   **结果**：为每个词在每个文本中分配一个0到1之间的TF-IDF重要性权重。\n    *   **实现**：scikit-learn的`TfidfVectorizer`。\n\n5.  **基于句子的N-Gram (Sentence-based N-Grams)**\n    *   **目的**：捕获词之间的交互和短语级语义（如“new”和“york”）。\n    *   **方法**：使用scikit-learn的`CountVectorizer`，通过设置`ngram_range`参数来包含单词（unigrams）和连续词序列（如bigrams）。\n\n6.  **清洗和分词 (Cleaning and Tokenization)**\n    *   **目的**：移除标点、大小写和其他下游模型可能不理解的符号，生成干净、标准化的词单元（tokens）。\n    *   **基本流程**：将文本分割成词、小写化、移除标点符号或特殊字符。\n    *   **实现**：可使用Python的`re`库构建简单的分词器。\n\n7.  **密集特征：词嵌入 (Dense Features: Word Embeddings)**\n    *   **原理**：当前将文本转换为机器可读信息最强大的方法之一，通过将词映射到向量空间来捕获语义。\n    *   **优点**：意义相似的词（如“shogun”和“samurai”）被编码为数值相似的向量。\n    *   **实现**：使用Word2Vec或spaCy等预定义方法和模型。\n    *   **输出**：嵌入向量的维度由所选算法和模型决定。\n\n### 总结\n\n这些技巧对于机器学习和深度学习模型执行文本分类、摘要等自然语言处理任务时，理解和处理原始文本数据至关重要。",
      "shortSummary": "本文介绍了文本数据特征工程的七个核心技巧，旨在将原始文本转化为机器学习和深度学习模型可处理的数值特征。这些技巧包括：移除停用词、词干提取与词形还原、词袋模型、TF-IDF、N-Gram、文本清洗与分词，以及词嵌入。前五种适用于经典机器学习，后两种对深度学习模型至关重要，共同提升文本分类和摘要等NLP任务的性能。",
      "translated_title": "文本数据特征工程的7个技巧",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-ipc-7-feature-engineering-tricks-text-data.png",
          "alt": "7 Feature Engineering Tricks for Text Data",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "An increasing number of AI and machine learning-based systems feed on text data &mdash; language models are a notable example today."
    },
    {
      "title": "10个用于从代码中调用LLM的Python单行代码 (原标题: 10 Python One-Liners for Calling LLMs from Your Code)",
      "link": "https://machinelearningmastery.com/10-python-one-liners-for-calling-llms-from-your-code/",
      "pubDate": "Tue, 14 Oct 2025 11:00:54 +0000",
      "isoDate": "2025-10-14T11:00:54.000Z",
      "creator": "Shittu Olumide",
      "summary": "# 文章概述\n\n本文介绍了10种Python单行代码，用于从您的代码中调用大型语言模型（LLMs），旨在简化LLM的集成，加速原型开发，并减少架构开销。这些单行代码涵盖了托管API和本地模型，并提供了一些实用技巧。\n\n![10 Python One-Liners for Calling LLMs from Your Code](https://machinelearningmastery.com/wp-content/uploads/2025/10/MLM-SHITTU-10-Python-One-Liners-for-Calling-LLMs-from-Your-Code.png)\n\n## 引言\n\n在调用大型语言模型时，并非总是需要复杂的封装、庞大的客户端类或数十行样板代码。有时，一行精心编写的Python代码就能完成所有工作：发送提示，接收响应。这种简洁性可以加快原型开发，或将LLM调用嵌入到脚本或管道中，而无需额外的架构开销。\n\n本文将展示十个调用和与LLM交互的Python单行代码，内容包括：\n*   **托管API**：使用OpenAI、Anthropic、Google Gemini、Mistral和Hugging Face的示例。\n*   **本地模型**：如何从您的机器调用Ollama、LM Studio、vLLM。\n*   **技巧与提示**：流式输出、异步调用、Shell友好模式。\n\n每个代码片段都附有简要解释和官方文档链接，以便您了解其内部工作原理。\n\n## 环境设置\n\n在运行这些单行代码之前，需要进行一些准备工作：\n\n*   **安装所需包（只需一次）**：\n    ```bash\npip install openai anthropic google-generativeai requests httpx\n    ```\n*   **设置API密钥**：确保API密钥作为环境变量设置，切勿硬编码到脚本中。例如：\n    ```bash\nexport OPENAI_API_KEY=\"sk-...\"\nexport ANTHROPIC_API_KEY=\"claude-yourkey\"\nexport GOOGLE_API_KEY=\"your_google_key\"\n    ```\n*   **本地设置**：对于Ollama、LM Studio、vLLM等本地模型，需要确保模型服务器在本地运行并监听正确的端口（例如，Ollama的默认REST API运行在`http://localhost:11434`）。\n*   所有单行代码都假设您使用正确的模型名称，并且该模型可以通过云端或本地访问。\n\n## 托管API单行代码（云模型）\n\n托管API是开始使用大型语言模型最简单的方式。您无需在本地运行模型或担心GPU内存；只需安装客户端库，设置API密钥，然后发送提示。这些API由模型提供商维护，因此它们可靠、安全且经常更新。\n\n以下单行代码展示了如何直接从Python调用一些最流行的托管模型。每个示例都向模型发送一条简单消息并打印生成的响应。\n\n### 1. OpenAI GPT聊天补全\n\nOpenAI的API提供对GPT模型（如GPT-4o和GPT-4o-mini）的访问。SDK处理从身份验证到响应解析的所有事务。\n\n```python\nfrom openai import OpenAI; print(OpenAI().chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\",\"content\":\"Explain vector similarity\"}]).choices[0].message.content)\n```\n*   **作用**：创建一个客户端，向GPT-4o-mini发送消息，并打印模型的回复。\n*   **原理**：`openai` Python包干净地封装了REST API。您只需将`OPENAI_API_KEY`设置为环境变量。\n*   **文档**：[OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat/create)\n\n### 2. Anthropic Claude\n\nAnthropic的Claude模型（Claude 3、Claude 3.5 Sonnet等）以其长上下文窗口和详细推理能力而闻名。其Python SDK遵循与OpenAI类似的聊天消息格式。\n\n```python\nfrom anthropic import Anthropic; print(Anthropic().messages.create(model=\"claude-3-5-sonnet\", messages=[{\"role\":\"user\",\"content\":\"How does chain of thought prompting work?\"}]).content[0].text)\n```\n*   **作用**：初始化Claude客户端，发送消息，并打印第一个响应块的文本。\n*   **原理**：`.messages.create()`方法使用标准消息 schema (角色 + 内容)，返回易于提取的结构化输出。\n*   **文档**：[Anthropic Claude API Reference](https://docs.anthropic.com/claude/reference/messages_post)\n\n### 3. Google Gemini\n\nGoogle的Gemini API（通过`google-generativeai`库）使得以最少的设置调用多模态和文本模型变得简单。主要区别在于Gemini的API将每个提示都视为“内容生成”，无论是文本、代码还是推理。\n\n```python\nimport os, google.generativeai as genai; genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\")); print(genai.GenerativeModel(\"gemini-1.5-flash\").generate_content(\"Describe retrieval-augmented generation\").text)\n```\n*   **作用**：调用Gemini 1.5 Flash模型描述检索增强生成（RAG），并打印返回的文本。\n*   **原理**：`GenerativeModel()`设置模型名称，`generate_content()`处理提示/响应流程。您只需配置`GOOGLE_API_KEY`。\n*   **文档**：[Google Gemini API Quickstart](https://ai.google.dev/gemini-api/docs/quickstart/python)\n\n### 4. Mistral AI (REST请求)\n\nMistral提供了一个简单的聊天补全REST API。您发送一个消息列表，并接收一个结构化的JSON响应。\n\n```python\nimport requests, json; print(requests.post(\"https://api.mistral.ai/v1/chat/completions\", headers={\"Authorization\":\"Bearer YOUR_MISTRAL_API_KEY\"}, json={\"model\":\"mistral-tiny\",\"messages\":[{\"role\":\"user\",\"content\":\"Define fine-tuning\"}]}).json()[\"choices\"][0][\"message\"][\"content\"])\n```\n*   **作用**：向Mistral的API发送聊天请求，并打印助手消息。\n*   **原理**：该端点接受OpenAI风格的消息数组，并返回`choices -> message -> content`。\n*   **文档**：[Mistral API reference](https://docs.mistral.ai/api/)\n\n### 5. Hugging Face推理API\n\n如果您在Hugging Face上托管模型或使用公共模型，您可以通过一个POST请求调用它。文本生成任务以JSON格式返回生成的文本。\n\n```python\nimport requests; print(requests.post(\"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\", headers={\"Authorization\":\"Bearer YOUR_HF_TOKEN\"}, json={\"inputs\":\"Write a haiku about data\"}).json()[0][\"generated_text\"])\n```\n*   **作用**：向Hugging Face上托管的模型发送提示，并打印生成的文本。\n*   **原理**：推理API暴露了特定任务的端点；对于文本生成，它返回一个包含`generated_text`的列表。\n*   **文档**：[Inference API](https://huggingface.co/docs/api-inference/index) 和 [Text Generation task pages](https://huggingface.co/docs/api-inference/detailed_parameters#text-generation-task)\n\n## 本地模型单行代码\n\n在您的机器上运行模型可以提供隐私和控制。您可以避免网络延迟并将数据保留在本地。缺点是设置：您需要运行服务器并拉取模型。以下单行代码假设您已经启动了本地服务。\n\n### 6. Ollama (本地Llama 3或Mistral)\n\nOllama在`localhost:11434`上暴露了一个简单的REST API。使用`/api/generate`进行提示式生成，或使用`/api/chat`进行聊天回合。\n\n```python\nimport requests; print(requests.post(\"http://localhost:11434/api/generate\", json={\"model\":\"llama3\",\"prompt\":\"What is vector search?\"}).text)\n```\n*   **作用**：向您的本地Ollama服务器发送生成请求，并打印原始响应文本。\n*   **原理**：Ollama运行一个带有`/api/generate`和`/api/chat`等端点的本地HTTP服务器。您必须首先运行应用程序并拉取模型。\n*   **文档**：[Ollama API documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)\n\n### 7. LM Studio (OpenAI兼容端点)\n\nLM Studio可以通过OpenAI风格的端点（如`/v1/chat/completions`）提供本地模型服务。从“Developer”选项卡启动服务器，然后像调用任何OpenAI兼容后端一样调用它。\n\n```python\nimport requests; print(requests.post(\"http://localhost:1234/v1/chat/completions\", json={\"model\":\"phi-3\",\"messages\":[{\"role\":\"user\",\"content\":\"Explain embeddings\"}]}).json()[\"choices\"][0][\"message\"][\"content\"])\n```\n*   **作用**：调用本地聊天补全并打印消息内容。\n*   **原理**：LM Studio暴露了OpenAI兼容的路由，并支持增强型API。\n*   **文档**：[LM Studio docs](https://lmstudio.ai/docs/local-server)\n\n### 8. vLLM (自托管LLM服务器)\n\nvLLM提供了一个高性能服务器，具有OpenAI兼容的API。您可以在本地或GPU机器上运行它，然后调用`/v1/chat/completions`。\n\n```python\nimport requests; print(requests.post(\"http://localhost:8000/v1/chat/completions\", json={\"model\":\"mistral\",\"messages\":[{\"role\":\"user\",\"content\":\"Give me three LLM optimization tricks\"}]}).json()[\"choices\"][0][\"message\"][\"content\"])\n```\n*   **作用**：向vLLM服务器发送聊天请求，并打印第一个响应消息。\n*   **原理**：vLLM实现了OpenAI兼容的聊天和补全API，因此一旦服务器运行，任何OpenAI风格的客户端或纯`requests`调用都将起作用。\n*   **文档**：[vLLM documentation](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html)\n\n## 实用技巧与提示\n\n一旦您掌握了向LLM发送请求的基础知识，一些巧妙的技巧可以使您的工作流程更快、更流畅。最后两个示例演示了如何实时流式传输响应以及如何执行异步API调用而不会阻塞程序。\n\n### 9. 从OpenAI流式传输响应\n\n流式传输允许您在模型生成每个token时立即打印它，而不是等待完整的消息。这非常适合交互式应用程序或CLI工具，您希望输出立即出现。\n\n```python\nfrom openai import OpenAI; [print(c.choices[0].delta.content or \"\", end=\"\") for c in OpenAI().chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\",\"content\":\"Stream a poem\"}], stream=True)]\n```\n*   **作用**：向GPT-4o-mini发送提示，并随着token的到来打印它们，模拟“实时打字”效果。\n*   **原理**：OpenAI API中的`stream=True`标志返回部分事件。每个块都包含一个`delta.content`字段，此单行代码在流式传输时打印它。\n*   **文档**：[OpenAI Streaming Guide](https://platform.openai.com/docs/guides/text-generation/streaming)\n\n### 10. 使用httpx进行异步调用\n\n异步调用使您能够在不阻塞应用程序的情况下查询模型，这使得它们非常适合同时发出多个请求或将LLM集成到Web服务器中。\n\n```python\nimport asyncio, httpx; print(asyncio.run(httpx.AsyncClient().post(\"https://api.mistral.ai/v1/chat/completions\", headers={\"Authorization\":\"Bearer TOKEN\"}, json={\"model\":\"mistral-tiny\",\"messages\":[{\"role\":\"user\",\"content\":\"Hello\"}]})).json()[\"choices\"][0][\"message\"][\"content\"])\n```\n*   **作用**：异步向Mistral的API发送聊天请求，完成后打印模型的回复。\n*   **原理**：`httpx`库支持异步I/O，因此网络调用不会阻塞主线程。此模式对于脚本或应用程序中的轻量级并发非常有用。\n*   **文档**：[httpx Async Support](https://www.python-httpx.org/async/)\n\n## 总结\n\n这些单行代码不仅仅是快速演示；它们是构建块。您可以将其中任何一个转换为函数，封装在命令行工具中，或构建到后端服务中。一旦添加了错误处理、缓存或日志记录，同样的代码就可以轻松扩展到生产工作流中。\n\n如果您想进一步探索，请查阅官方文档以获取详细参数，如温度、最大token数和流式传输选项。每个提供商都维护可靠的参考资料：\n*   [OpenAI API Reference](https://platform.openai.com/docs/api-reference)\n*   [Anthropic API Docs](https://docs.anthropic.com/claude/reference)\n*   [Google Gemini Developer Docs](https://ai.google.dev/gemini-api/docs)\n*   [Mistral API Reference](https://docs.mistral.ai/api/)\n*   [Hugging Face Inference API](https://huggingface.co/docs/api-inference/index)\n*   [Ollama API Docs](https://github.com/ollama/ollama/blob/main/docs/api.md)\n*   [LM Studio API Reference](https://lmstudio.ai/docs/local-server)\n*   [vLLM REST API](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html)\n\n真正的启示是，Python使得使用LLM既方便又灵活。无论您是在云端运行GPT-4o还是在本地运行Llama 3，您都可以用几行代码达到生产级别的结果。",
      "shortSummary": "本文介绍了10种Python单行代码，用于快速调用大型语言模型（LLMs）。内容涵盖了OpenAI、Anthropic、Google Gemini、Mistral、Hugging Face等托管API，以及Ollama、LM Studio、vLLM等本地模型。文章还提供了流式传输和异步调用等实用技巧，旨在简化LLM的集成，加速原型开发和脚本编写。使用前需安装所需库并配置API密钥或启动本地服务。",
      "translated_title": "10个用于从代码中调用LLM的Python单行代码",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/MLM-SHITTU-10-Python-One-Liners-for-Calling-LLMs-from-Your-Code.png",
          "alt": "10 Python One-Liners for Calling LLMs from Your Code",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "You don’t always need a heavy wrapper, a big client class, or dozens of lines of boilerplate to call a large language model."
    },
    {
      "title": "处理大型数据集的7个Pandas技巧 (原标题: 7 Pandas Tricks to Handle Large Datasets)",
      "link": "https://machinelearningmastery.com/7-pandas-tricks-to-handle-large-datasets/",
      "pubDate": "Mon, 13 Oct 2025 11:00:08 +0000",
      "isoDate": "2025-10-13T11:00:08.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "# 处理大型数据集的7个Pandas技巧\n\n![处理大型数据集的7个Pandas技巧](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-7-pandas-tricks-handle-large-datasets.png)\n\n## 引言\n\n在Python中处理大型数据集常常面临内存限制和处理流程缓慢的挑战。Pandas库提供了强大的工具和技术来高效管理这些大型、复杂的数据集，包括表格、文本或时间序列数据。本文将介绍7个Pandas技巧，以有效管理大型数据集。\n\n## 7个Pandas技巧\n\n1.  **分块加载数据集 (Chunked Dataset Loading)**\n    *   **方法**：使用`pd.read_csv()`函数的`chunksize`参数，将大型CSV文件分批加载和处理。\n    *   **优点**：防止内存溢出，使数据处理更具可管理性。\n    *   **示例**：通过迭代器处理指定大小的数据块。\n\n2.  **数据类型降级以优化内存效率 (Downcasting Data Types for Memory Efficiency Optimization)**\n    *   **方法**：将数据类型转换为占用更少比特的表示形式，例如使用`astype()`或`pd.to_numeric(downcast=...)`。\n    *   **优点**：显著减少内存使用，尤其适用于数值型（整数、浮点数）和具有少量唯一值的对象/字符串列（转换为`category`类型）。\n    *   **示例**：展示了对整数、浮点数和对象列进行类型降级前后的内存使用对比。\n\n3.  **使用分类数据处理频繁出现的字符串 (Using Categorical Data for Frequently Occurring Strings)**\n    *   **方法**：将重复出现的字符串映射为分类数据类型，本质上是将字符串编码为整数标识符。\n    *   **优点**：提高处理效率，特别是在属性包含有限且重复字符串时。\n    *   **示例**：将星座数据集中的“sign”列转换为`category`类型。\n\n4.  **以高效格式保存数据：Parquet (Saving Data in Efficient Format: Parquet)**\n    *   **方法**：使用Parquet，一种二进制列式数据集格式。\n    *   **优点**：比纯CSV文件读写速度快得多。Parquet还能内部压缩重复字符串，进一步节省内存。需要安装`pyarrow`或`fastparquet`等引擎。\n    *   **示例**：将DataFrame保存为Parquet文件并重新加载。\n\n5.  **GroupBy聚合 (GroupBy Aggregation)**\n    *   **方法**：对分类列进行分组并计算统计量。\n    *   **优点**：在将重复字符串转换为分类列（技巧3）后，`groupby`操作的效率更高。\n    *   **示例**：按星座对数值列（如幸运数字）进行平均值聚合。\n\n6.  **使用`query()`和`eval()`进行高效过滤和计算 (query() and eval() for Efficient Filtering and Computation)**\n    *   **方法**：`query()`函数用于根据条件过滤行，`eval()`函数用于执行计算（通常涉及多个数值特征）。\n    *   **优点**：专为高效处理大型数据集而设计，比传统方法更快。\n    *   **示例**：添加一个合成数值特征，然后使用`query()`过滤行，并使用`eval()`进行列间计算。\n\n7.  **向量化字符串操作进行高效列转换 (Vectorized String Operations for Efficient Column Transformations)**\n    *   **方法**：利用Pandas内置的向量化字符串方法（如`.str.upper()`，`.str.len()`）。\n    *   **优点**：比手动循环更高效、更流畅地处理文本数据。\n    *   **示例**：将星座名称转换为大写，并计算每个名称的长度。\n\n## 总结\n\n本文介绍了7个简单而有效的Pandas技巧，用于更高效地管理大型数据集，涵盖从数据加载到处理和存储的各个环节。尽管出现了专注于高性能计算的新库，但对于许多用户而言，坚持使用Pandas等成熟库可能是一种平衡且更受欢迎的方法。",
      "shortSummary": "",
      "translated_title": "处理大型数据集的7个Pandas技巧",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-7-pandas-tricks-handle-large-datasets.png",
          "alt": "7 Pandas Tricks to Handle Large Datasets",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Large dataset handling in Python is not exempt from challenges like memory constraints and slow processing workflows."
    },
    {
      "title": "使用 PyTorch 从零开始构建 Transformer 模型（10天迷你课程） (原标题: Building Transformer Models from Scratch with PyTorch (10-day Mini-Course))",
      "link": "https://machinelearningmastery.com/building-transformer-models-from-scratch-with-pytorch-10-day-mini-course/",
      "pubDate": "Sun, 12 Oct 2025 03:45:31 +0000",
      "isoDate": "2025-10-12T03:45:31.000Z",
      "creator": "Adrian Tam",
      "summary": "# 使用 PyTorch 从零开始构建 Transformer 模型（10天迷你课程）\n\n大型语言模型（LLMs），如 ChatGPT、Gemini 和 Grok，展示了类人智能，但其工作原理并非遥不可及。本10天迷你课程旨在帮助开发者通过 PyTorch 从零开始构建和训练一个 Transformer 模型，从而深入理解其内部机制，而非将其视为一个“AI黑箱”。\n\n![Transformer模型构建](https://machinelearningmastery.com/wp-content/uploads/2025/10/caleb-jack-jUxMsNZZCJ8-unsplash-scaled.jpg)\n\n## 课程概述\n\n本课程是一个项目制指南，重点关注模型架构，而高级优化技术则不在讨论范围之内。它将引导学习者完成从数据收集到运行训练模型的整个过程。每节课都将详细讲解 Transformer 模型的一个特定组件，包括其作用、设计参数和 PyTorch 实现。\n\n### 课程受众\n\n本课程专为以下开发者设计：\n\n*   **具备 Python 编码经验：** 能够熟练编写 Python 代码并设置开发环境。\n*   **具备机器学习基础知识：** 对机器学习模型有大致了解并能熟练使用。\n*   **熟悉 PyTorch：** 能够阅读和理解 PyTorch 代码，并懂得查阅 PyTorch 文档。\n\n### 迷你课程结构\n\n课程分为10个部分，每节课平均耗时约30分钟。学习者可以按照自己的节奏进行，建议每天一课，以便充分吸收材料。\n\n**课程主题包括：**\n\n1.  获取数据\n2.  训练语言模型的分词器\n3.  位置编码\n4.  分组查询注意力（Grouped Query Attention）\n5.  因果掩码（Causal Mask）\n6.  专家混合模型（Mixture of Expert Models）\n7.  RMS 范数和跳跃连接（Skip Connection）\n8.  完整的 Transformer 模型\n9.  训练模型\n10. 使用模型\n\n## 课程内容节选\n\n### 第一课：获取数据\n\n语言模型通过从大量文本数据中学习来预测词语出现的可能性。因此，构建语言模型的第一步是收集一个能够捕捉语言自然模式的文本语料库。\n\n*   **数据来源：** Project Gutenberg（古腾堡计划）是一个优秀的免费文本数据来源。\n*   **数据下载与预处理：** 文章提供了 Python 代码示例，使用 `requests` 库从古腾堡计划下载多本书籍的文本文件，并使用 `preprocess_gutenberg` 函数移除书籍的页眉页脚，清理文本内容。\n*   **任务：** 运行提供的代码，并思考在构建语言模型时，拥有多样化体裁的书籍为何重要。\n\n### 第二课：训练语言模型的分词器\n\n计算机处理的是数字，因此文本必须转换为数值形式。分词器（tokenizer）负责将输入文本分解成“tokens”，并为这些tokens分配数字，形成模型的词汇表。\n\n*   **分词器作用：** 高效地分割文本并处理未见词。\n*   **常用方法：** 字节对编码（BPE）是现代大型语言模型中流行的分词方法之一。\n*   **PyTorch 实现：** 文章提供了使用 `tokenizers` 库训练 BPE 分词器的 Python 代码示例，包括设置词汇量大小（例如 10,000）、定义特殊 tokens（如 `[pad]` 和 `[eos]`），以及将训练好的分词器保存为 JSON 文件以便后续加载。\n*   **任务：** 尝试使用 WordPiece 算法训练分词器，并解释为何 10,000 的词汇量对于一个好的语言模型来说是不足的。\n\n### 第三课：位置编码\n\n与循环神经网络不同，Transformer 模型同时处理整个序列，因此缺乏对 token 顺序的固有理解。为了捕获这种序列信息，Transformer 模型在输入处理中加入了位置编码。\n\n*   **常用方法：** 旋转位置编码（RoPE）是目前最广泛使用的方法之一。\n*   **RoPE 原理：** 通过对嵌入的 token 向量应用旋转变换来实现。\n*   **PyTorch 实现：** 文章提供了 `RotaryPositionalEncoding` 模块的 PyTorch 代码，该模块预计算正弦和余弦值，并使用 `register_buffer` 存储为非训练参数，然后在 `forward` 函数中应用旋转矩阵来变换输入。\n*   **任务：** 实验提供的代码，并解释用于测试 `RotaryPositionalEncoding` 模块的 4D 输入张量（1, 10, 4, 128）中前三个维度（1, 10, 4）在 Transformer 架构中的含义。\n\n### 第四课：分组查询注意力（Grouped Query Attention）\n\n注意力机制是 Transformer 模型的标志性组件，它在处理 token 序列时建立 token 之间的连接以理解其上下文。分组查询注意力（GQA）是注意力机制的一种变体。\n\n*   **注意力机制：** 基于查询（query）、键（key）和值（value）三个输入序列计算输出序列，这三个序列通过对输入序列进行不同投影得到。\n*   **PyTorch 实现：** 文章提供了 PyTorch 代码示例，展示了如何使用 `nn.Linear` 层进行 q、k、v 的投影，并通过 `view()` 和 `transpose()` 将投影输出重塑为 4D 张量，然后使用 PyTorch 内置的 `F.scaled_dot_product_attention()` 函数进行注意力计算（并启用 GQA）。\n\n（文章内容在此处截断）",
      "shortSummary": "本10天迷你课程旨在指导开发者使用PyTorch从零开始构建和训练Transformer语言模型。课程面向具备Python、机器学习和PyTorch基础的学员，通过实践项目深入理解模型架构。内容涵盖数据获取、分词器训练、位置编码和分组查询注意力等关键组件。目标是帮助学员全面掌握Transformer模型的工作原理，而非将其视为黑箱。课程提供详细代码示例，并建议按日学习，逐步完成模型构建。",
      "translated_title": "使用 PyTorch 从零开始构建 Transformer 模型（10天迷你课程）",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/caleb-jack-jUxMsNZZCJ8-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/09/btfs-400_220.png",
          "alt": "Building Transformer Models From Scratch with PyTorch",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "完整文章",
      "content": "Before we begin, let's make sure you're in the right place."
    },
    {
      "title": "机器学习从业者的智能体AI系统指南 (原标题: The Machine Learning Practitioner’s Guide to Agentic AI Systems)",
      "link": "https://machinelearningmastery.com/the-machine-learning-practitioners-guide-to-agentic-ai-systems/",
      "pubDate": "Fri, 10 Oct 2025 11:00:13 +0000",
      "isoDate": "2025-10-10T11:00:13.000Z",
      "creator": "Vinod Chugani",
      "summary": "本文为机器学习从业者提供了从传统机器学习工作流过渡到设计、构建和部署生产级智能体AI系统的全面指南。\n\n**1. 智能体AI系统简介**\n*   **范式转变**：智能体AI代表了自深度学习以来机器学习领域最重要的转变。它不再是构建响应提示的被动工具，而是设计能够独立规划、推理和行动以实现复杂目标的自主系统。\n*   **基础技能**：这一演进自然地建立在从业者现有的基础之上，包括提示工程、大型语言模型（LLMs）应用和检索增强生成（RAG）系统。\n*   **指南目标**：本文旨在提供一个循序渐进的方法，帮助从业者学习核心概念、探索有效框架、利用最佳学习资源，并构建解决实际问题的生产级智能体。\n\n**2. 智能体AI的基础概念**\n*   **定义**：智能体AI是指通过规划、推理、工具使用和记忆，独立追求目标的自主系统，而不仅仅是响应提示。\n*   **核心区别**：与传统LLM的被动响应（你问，它答）不同，智能体系统能够主动分解复杂任务、做出决策、使用工具、从反馈中学习并适应其方法，无需持续的人工指导。\n*   **学习资源**：建议从吴恩达教授的免费课程“Agentic AI”开始。\n\n**3. 核心架构模式**\n理解这些模式是构建有效智能体的关键：\n*   **ReAct (Reasoning and Acting)**：\n    *   **工作原理**：智能体在推理（做什么）、采取行动（使用工具）和观察结果之间交替进行，直到任务完成。\n    *   **适用场景**：实现简单，适用于直接的任务。\n    *   **局限性**：每一步都需要调用LLM，可能成本较高。\n*   **Plan-and-Execute (规划与执行)**：\n    *   **工作原理**：智能体首先制定一个完整的、多步骤的计划，然后执行每个步骤（通常使用更小、更便宜的模型），并根据需要调整计划。\n    *   **优势**：对于复杂工作流，通常比ReAct更快、更经济，是2025年生产系统的首选。\n*   **Reflexion (反思)**：\n    *   **工作原理**：通过语言反馈实现自我改进。智能体明确地批判自己的响应，维护过去尝试的记忆，并根据失败经验改进方法。\n    *   **适用场景**：特别适用于研究密集型和高风险应用，其中正确性比速度更重要。\n*   **选择指南**：简单客服查询选择ReAct；复杂多步工作流如数据分析管道选择Plan-and-Execute；需要高准确性的研究智能体选择Reflexion。\n*   **学习资源**：DeepLearning.AI上关于AutoGen的“AI Agentic Design Patterns”课程。\n\n**4. 框架选择与深入学习**\n2025年有三个主要的框架：\n*   **LangGraph**：\n    *   **定位**：生产系统的标准框架。\n    *   **特点**：通过基于图的工作流提供细粒度控制，内置状态管理，通过LangGraph Studio和LangSmith提供出色的可观察性。\n    *   **适用场景**：需要复杂、有状态工作流和详细监控的专业部署。\n    *   **学习曲线**：较陡峭，但对于专业部署而言物有所值。\n*   **CrewAI**：\n    *   **定位**：最快入门多智能体系统。\n    *   **特点**：基于角色的设计使其直观易用。定义具有特定角色和职责的智能体，分配任务，并让它们协作。\n    *   **适用场景**：内容创作、研究管道以及任何可以按“团队角色”思考的场景。\n*   **AutoGen (微软)**：\n    *   **定位**：擅长对话式多智能体模式。\n    *   **特点**：适用于复杂的智能体协作和企业微软环境。2025年3月更新引入了统一SDK、Agent-to-Agent协议和无缝Azure AI Foundry集成。\n*   **建议**：大多数从业者可以从CrewAI开始进行快速原型开发，然后在需要生产级控制时学习LangGraph。\n\n**5. 构建实用项目以展示技能**\n理论知识需要通过实践项目来巩固和展示：\n*   **入门级项目**：构建一个研究智能体，接收问题，搜索多个来源，综合信息，并提供带引用的答案。这有助于学习工具集成（网络搜索）、内存管理和响应生成。\n*   **进阶项目**：创建一个多智能体内容创作系统，定义研究员、撰稿人、编辑、事实核查员等角色，并协调它们生成高质量文章。这展示了智能体协调和任务委派的能力。\n*   **高级项目**：构建一个自主数据分析智能体，连接到数据库，根据自然语言查询探索数据，生成洞察，创建可视化，并标记异常，无需逐步人工指导。这展示了RAG技术、工具使用和规划能力。\n*   **实践资源**：微软的“AI Agents for Beginners”（GitHub上的12节结构化课程）和“500 AI Agent Projects”代码库。\n\n**6. 学习记忆系统和高级模式**\n专家级智能体开发者需要掌握：\n*   **记忆系统**：\n    *   **短期记忆**：处理当前交互（会话状态），可使用Redis或LangGraph内置的检查点。\n    *   **长期记忆**：更复杂，包括用于语义检索的向量存储、用于结构化事实和时间跟踪的知识图谱，以及防止记忆膨胀的摘要策略。\n    *   **2025年最佳实践**：混合方法，结合向量搜索、知识图谱和衰减策略。\n    *   **生产级方案**：LangGraph的LangMem模块和Redis Agent Memory Server。\n*   **高级模式**：\n    *   **智能体RAG**：智能体决定何时检索信息并生成有针对性的查询。\n    *   **多智能体编排**：“傀儡师”模式，由训练有素的编排器动态指导专业智能体。\n    *   **人机协作工作流**：在保持常规任务自主性的同时，将重要决策升级给人类。\n    *   **模型上下文协议 (MCP)**：2025年广泛采用，正在改变智能体连接性，掌握MCP可确保技能的未来适用性。\n*   **深度学习资源**：DeepLearning.AI上关于LlamaIndex的“Building Agentic RAG”和关于DSPy的“Building Memory-Enabled Agents”。\n\n**7. 将所学付诸实践**\n掌握这些技能将带来广泛的职业机会，包括AI工程师、机器学习工程师（侧重智能体）、AI架构师、MLOps工程师和新兴的智能体编排师等。\n\n**市场前景**：智能体AI领域正在迅速发展，市场规模预计将从2025年的50-70亿美元增长到2030-2034年的500-2000亿美元。金融服务、医疗保健、零售和专业服务等行业的组织正在积极部署智能体系统。现在掌握这些技能的从业者将站在这一快速发展领域的最前沿。\n\n![The Machine Learning Practitioner’s Guide to Agentic AI Systems](https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-chugani-machine-learning-practitioners-guide-agentic-ai-systems-feature-png-1024x683.png)",
      "shortSummary": "本文是机器学习从业者向智能体AI系统转型的指南。智能体AI代表了从被动工具到自主系统的重大转变，它能独立规划、推理和行动。文章涵盖了智能体AI的基础概念、ReAct、Plan-and-Execute、Reflexion等核心架构模式，以及LangGraph、CrewAI、AutoGen等主流框架。同时强调了通过实践项目、学习记忆系统和高级模式的重要性。掌握这些技能将为从业者在快速增长的智能体AI市场中带来丰富的职业机会。",
      "translated_title": "机器学习从业者的智能体AI系统指南",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/10/mlm-chugani-machine-learning-practitioners-guide-agentic-ai-systems-feature-png-1024x683.png",
          "alt": "The Machine Learning Practitioner’s Guide to Agentic AI Systems",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Agentic artificial intelligence (AI) represents the most significant shift in machine learning since deep learning transformed the field."
    }
  ],
  "lastUpdated": "2025-10-22T09:44:32.314Z"
}
{
  "sourceUrl": "https://machinelearningmastery.com/blog/feed/",
  "title": "MachineLearningMastery.com",
  "description": "Making developers awesome at machine learning",
  "link": "https://machinelearningmastery.com/blog/",
  "items": [
    {
      "title": "Prompt Engineering for Time Series Analysis",
      "link": "https://machinelearningmastery.com/prompt-engineering-for-time-series-analysis/",
      "pubDate": "Thu, 04 Dec 2025 17:02:33 +0000",
      "isoDate": "2025-12-04T17:02:33.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Prompt Engineering for Time Series Analysis",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-ipc-prompt-engineering-time-series-analysis-1.jpeg",
          "alt": "Prompt Engineering for Time Series Analysis",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Strange as it may sound, large language models (LLMs) can be leveraged for data analysis tasks, including specific scenarios such as time series analysis."
    },
    {
      "title": "The Complete Guide to Using Pydantic for Validating LLM Outputs",
      "link": "https://machinelearningmastery.com/the-complete-guide-to-using-pydantic-for-validating-llm-outputs/",
      "pubDate": "Wed, 03 Dec 2025 16:59:32 +0000",
      "isoDate": "2025-12-03T16:59:32.000Z",
      "creator": "Bala Priya C",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "The Complete Guide to Using Pydantic for Validating LLM Outputs",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-complete-guide-pydantic-featured-image.jpeg",
          "alt": "The Complete Guide to Using Pydantic for Validating LLM Outputs",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Large language models generate text, not structured data."
    },
    {
      "title": "The Roadmap for Mastering Agentic AI in 2026",
      "link": "https://machinelearningmastery.com/the-roadmap-for-mastering-agentic-ai-in-2026/",
      "pubDate": "Tue, 02 Dec 2025 11:48:31 +0000",
      "isoDate": "2025-12-02T11:48:31.000Z",
      "creator": "Kanwal Mehreen",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "The Roadmap for Mastering Agentic AI in 2026",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-roadmap-mastering-agentic-ai.jpeg",
          "alt": "The Roadmap for Mastering Machine Learning in 2026",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Agentic AI is changing how we interact with machines."
    },
    {
      "title": "Prompt Compression for LLM Generation Optimization and Cost Reduction",
      "link": "https://machinelearningmastery.com/prompt-compression-for-llm-generation-optimization-and-cost-reduction/",
      "pubDate": "Mon, 01 Dec 2025 14:08:17 +0000",
      "isoDate": "2025-12-01T14:08:17.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Prompt Compression for LLM Generation Optimization and Cost Reduction",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/12/mlm-5-techniques-reduce-tokens.jpeg",
          "alt": "Prompt Compression for LLM Generation Optimization and Cost Reduction",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Large language models (LLMs) are mainly trained to generate text responses to user queries or prompts, with complex reasoning under the hood that not only involves language generation by predicting each next token in the output sequence, but also entails a deep understanding of the linguistic patterns surrounding the user input text."
    },
    {
      "title": "How to Speed-Up Training of Language Models",
      "link": "https://machinelearningmastery.com/how-to-speed-up-training-of-language-models/",
      "pubDate": "Sun, 30 Nov 2025 14:49:19 +0000",
      "isoDate": "2025-11-30T14:49:19.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "How to Speed-Up Training of Language Models",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/11/emma-fabbri-2TmsyZXMNTE-unsplash-scaled.jpg",
          "alt": "",
          "title": "",
          "position": 1
        },
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/11/learning-rate-schedules.png",
          "alt": "",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into four parts; they are: • Optimizers for Training Language Models • Learning Rate Schedulers • Sequence Length Scheduling • Other Techniques to Help Training Deep Learning Models Adam has been the most popular optimizer for training deep learning models."
    },
    {
      "title": "Fine-Tuning a BERT Model",
      "link": "https://machinelearningmastery.com/fine-tuning-a-bert-model/",
      "pubDate": "Fri, 28 Nov 2025 20:18:20 +0000",
      "isoDate": "2025-11-28T20:18:20.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Fine-Tuning a BERT Model",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/11/BERT-fine-tuning.png",
          "alt": "",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "This article is divided into two parts; they are: • Fine-tuning a BERT Model for GLUE Tasks • Fine-tuning a BERT Model for SQuAD Tasks GLUE is a benchmark for evaluating natural language understanding (NLU) tasks."
    },
    {
      "title": "The Journey of a Token: What Really Happens Inside a Transformer",
      "link": "https://machinelearningmastery.com/the-journey-of-a-token-what-really-happens-inside-a-transformer/",
      "pubDate": "Wed, 26 Nov 2025 14:24:54 +0000",
      "isoDate": "2025-11-26T14:24:54.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "The Journey of a Token: What Really Happens Inside a Transformer",
      "images": [
        {
          "url": "https://machinelearningmastery.com/wp-content/uploads/2025/11/journeytoken.jpg",
          "alt": "The Journey of a Token: What Really Happens Inside a Transformer",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Large language models (LLMs) are based on the transformer architecture, a complex deep neural network whose input is a sequence of token embeddings."
    },
    {
      "title": "Pretrain a BERT Model from Scratch",
      "link": "https://machinelearningmastery.com/pretrain-a-bert-model-from-scratch/",
      "pubDate": "Wed, 26 Nov 2025 05:30:06 +0000",
      "isoDate": "2025-11-26T05:30:06.000Z",
      "creator": "Adrian Tam",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Pretrain a BERT Model from Scratch",
      "images": [],
      "contentSource": "RSS",
      "content": "This article is divided into three parts; they are: • Creating a BERT Model the Easy Way • Creating a BERT Model from Scratch with PyTorch • Pre-training the BERT Model If your goal is to create a BERT model so that you can train it on your own data, using the Hugging Face `transformers` library is the easiest way to get started."
    },
    {
      "title": "K-Means Cluster Evaluation with Silhouette Analysis",
      "link": "https://machinelearningmastery.com/k-means-cluster-evaluation-with-silhouette-analysis/",
      "pubDate": "Tue, 25 Nov 2025 11:00:05 +0000",
      "isoDate": "2025-11-25T11:00:05.000Z",
      "creator": "Iván Palomares Carrascosa",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "K-Means Cluster Evaluation with Silhouette Analysis",
      "images": [],
      "contentSource": "RSS",
      "content": "Clustering models in machine learning must be assessed by how well they separate data into meaningful groups with distinctive characteristics."
    },
    {
      "title": "The Complete Guide to Docker for Machine Learning Engineers",
      "link": "https://machinelearningmastery.com/the-complete-guide-to-docker-for-machine-learning-engineers/",
      "pubDate": "Mon, 24 Nov 2025 11:00:13 +0000",
      "isoDate": "2025-11-24T11:00:13.000Z",
      "creator": "Bala Priya C",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "The Complete Guide to Docker for Machine Learning Engineers",
      "images": [],
      "contentSource": "RSS",
      "content": "Machine learning models often behave differently across environments."
    }
  ],
  "lastUpdated": "2025-12-06T09:27:15.022Z"
}
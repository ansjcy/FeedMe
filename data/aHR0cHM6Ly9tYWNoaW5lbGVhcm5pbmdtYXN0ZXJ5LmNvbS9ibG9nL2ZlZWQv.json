{
  "sourceUrl": "https://machinelearningmastery.com/blog/feed/",
  "title": "MachineLearningMastery.com",
  "description": "Making developers awesome at machine learning",
  "link": "https://machinelearningmastery.com/blog/",
  "items": [
    {
      "title": "学习率调度器入门 (原标题: A Gentle Introduction to Learning Rate Schedulers)",
      "link": "https://machinelearningmastery.com/a-gentle-introduction-to-learning-rate-schedulers/",
      "pubDate": "Fri, 16 May 2025 13:58:14 +0000",
      "isoDate": "2025-05-16T13:58:14.000Z",
      "content": "Ever wondered why your neural network seems to get stuck during training, or why it starts strong but fails to reach its full potential? The culprit might be your learning rate – arguably one of the most important hyperparameters in machine learning.",
      "contentSnippet": "Ever wondered why your neural network seems to get stuck during training, or why it starts strong but fails to reach its full potential? The culprit might be your learning rate – arguably one of the most important hyperparameters in machine learning.",
      "creator": "Vinod Chugani",
      "encodedSnippet": "Ever wondered why your neural network seems to get stuck during training, or why it starts strong but fails to reach its full potential? The culprit might be your learning rate – arguably one of the most important hyperparameters in machine learning.\nundefined",
      "summary": "本文介绍了学习率在机器学习中的重要性，以及神经网络训练过程中可能遇到的问题，例如训练停滞或无法充分发挥潜力，这些问题可能与学习率设置不当有关。\n\n*   学习率是机器学习中最重要的超参数之一。",
      "translated_title": "学习率调度器入门",
      "contentSource": "RSS"
    },
    {
      "title": "领域特定LLM的自定义微调 (原标题: Custom Fine-Tuning for Domain-Specific LLMs)",
      "link": "https://machinelearningmastery.com/custom-fine-tuning-for-domain-specific-llms/",
      "pubDate": "Wed, 14 May 2025 12:00:23 +0000",
      "isoDate": "2025-05-14T12:00:23.000Z",
      "content": "Fine-tuning a large language model (LLM) is the process of taking a pre-trained model &mdash; usually a vast one like GPT or Llama models, with millions to billions of weights &mdash; and continuing to train it, exposing it to new data so that the model weights (or typically parts of them) get updated.",
      "contentSnippet": "Fine-tuning a large language model (LLM) is the process of taking a pre-trained model — usually a vast one like GPT or Llama models, with millions to billions of weights — and continuing to train it, exposing it to new data so that the model weights (or typically parts of them) get updated.",
      "creator": "Iván Palomares Carrascosa",
      "encodedSnippet": "Fine-tuning a large language model (LLM) is the process of taking a pre-trained model &mdash; usually a vast one like GPT or Llama models, with millions to billions of weights &mdash; and continuing to train it, exposing it to new data so that the model weights (or typically parts of them) get updated.\nundefined",
      "summary": "本文介绍了对大型语言模型（LLM）进行微调的概念。微调是指在预训练模型（如GPT或Llama模型）的基础上，通过向其提供新的数据来继续训练，从而更新模型的权重（或部分权重）。",
      "translated_title": "领域特定LLM的自定义微调",
      "contentSource": "RSS"
    }
  ],
  "lastUpdated": "2025-05-28T21:13:54.325Z",
  "processingStats": {
    "totalItems": 2,
    "newItems": 0,
    "existingItems": 2,
    "lastProcessed": "2025-05-28T21:13:54.325Z"
  }
}
{
  "sourceUrl": "https://rsshub.rssforever.com/google/research",
  "title": "Google Research Blog",
  "description": "Google Research Blog - Powered by RSSHub",
  "link": "https://research.google/blog",
  "items": [
    {
      "title": "使用用户级差分隐私微调大型语言模型 (原标题: Fine-tuning LLMs with user-level differential privacy)",
      "link": "https://research.google/blog/fine-tuning-llms-with-user-level-differential-privacy/",
      "pubDate": "Thu, 22 May 2025 16:00:00 GMT",
      "isoDate": "2025-05-22T16:00:00.000Z",
      "creator": "Google",
      "summary": "本文探讨了如何使用用户级差分隐私（DP）来微调大型语言模型（LLM），以保护用户数据的隐私。\n\n*   **背景：** 现代机器学习模型通常需要在特定领域的数据上进行微调，但这些数据往往是隐私敏感的。用户级DP是一种更强的隐私保护形式，可以保证攻击者无法了解用户的任何信息，例如用户数据是否包含在训练数据集中。\n*   **方法：** 研究人员优化了两种DP-SGD的变体，即示例级别采样（ELS）和用户级别采样（ULS），以实现用户级DP。这些方法通过限制每个用户对模型的影响来实现隐私保护。\n*   **优化：** 针对ELS，研究人员提出了新的隐私保证，并开发了一种启发式方法来设置贡献界限，而无需进行多次训练。对于ULS，也开发了一种启发式方法来设置贡献界限。\n*   **结果：** 实验表明，经过优化后，使用用户级DP微调LLM是可行且优于仅使用预训练模型的。在大多数情况下，ULS算法表现更好。优化后的方法使得模型训练者能够在保护用户隐私的同时，对敏感数据集进行模型微调。\n\n文章中包含以下图片：\n\n*   ![UserLvlDP-1-Overview](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-1-Overview.width-1250.png)\n*   ![UserLvlDP-2a-Visualization](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-2a-Visualization.width-800.gif)\n*   ![UserLvlDP-3a-Example](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-3a-Example.width-1250.png)\n*   ![UserLvlDP-4a-ELSvULS](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-4a-ELSvULS.width-800.gif)\n*   ![UserLvlDP-5-ContributionBound](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-5-ContributionBound.width-1250.png)\n*   ![UserLvlDP-6a-ELSvULS](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-6a-ELSvULS.width-1250.png)\n*   ![UserLvlDP-6b-ELSvULS](https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-6b-ELSvULS.width-1250.png)",
      "translated_title": "使用用户级差分隐私微调大型语言模型",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-1-Overview.width-1250.png",
          "alt": "UserLvlDP-1-Overview",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-2a-Visualization.width-800.gif",
          "alt": "UserLvlDP-2a-Visualization",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-3a-Example.width-1250.png",
          "alt": "UserLvlDP-3a-Example",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-4a-ELSvULS.width-800.gif",
          "alt": "UserLvlDP-4a-ELSvULS",
          "title": "",
          "position": 4
        },
        {
          "url": "https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-5-ContributionBound.width-1250.png",
          "alt": "UserLvlDP-5-ContributionBound",
          "title": "",
          "position": 5
        }
      ],
      "contentSource": "RSS",
      "content": "<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n\n\n    <p data-block-key=\"ifmk7\">The machine learning community has consistently found that while modern machine learning (ML) models are powerful, they <a href=\"https://arxiv.org/pdf/2103.08493\" target=\"_blank\" rel=\"noopener noreferrer\">often need to be fine-tuned on domain-specific data</a> to maximize performance. This can be problematic or even impossible, as informative data is often privacy-sensitive. Differential privacy (DP) allows us to train ML models while rigorously guaranteeing that the learned model respects the privacy of its training data, by injecting noise into the training process.</p><p data-block-key=\"eauhh\">Most work on DP focuses on the privacy of individual examples (i.e., <a href=\"https://desfontain.es/blog/differential-privacy-in-more-detail.html\" target=\"_blank\" rel=\"noopener noreferrer\">example-level DP</a>). This has drawbacks. If a particular user has many examples training the model, attackers may be able to learn something about that user even if they can’t learn about their individual examples.</p><p data-block-key=\"8jgo8\"><a href=\"https://arxiv.org/abs/1710.06963\" target=\"_blank\" rel=\"noopener noreferrer\">User-level DP</a> is a stronger form of privacy that guarantees that an attacker who uses a model can’t learn things about the user, like whether or not the user’s data is included in the training dataset. User-level DP better reflects how data is actually owned in today’s society. It’s used frequently in <a href=\"https://research.google/blog/federated-learning-collaborative-machine-learning-without-centralized-training-data/\">federated learning</a> to train models across distributed devices like cell phones. Those devices often have many examples, all owned by a single user, and require more stringent privacy guarantees.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --medium\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- Determine the appropriate width based on image_width -->\n    \n        \n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-1-Overview.width-1250.png\" alt=\"UserLvlDP-1-Overview\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-1-Overview.width-1250.png\" alt=\"UserLvlDP-1-Overview\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n      <div class=\"glue-grid__col glue-grid__col--span-4-sm  glue-grid__col--span-12-md caption --center\">\n        <p data-block-key=\"37bs3\"><i>User-level DP makes it so you can’t tell if</i> <b><i>all</i></b><i> of someone’s data was included in training or not, rather than just one piece of their data.</i></p>\n      </div>\n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n\n\n    <p data-block-key=\"ifmk7\">Learning with user-level DP is strictly harder than example-level DP, and requires adding significantly more noise. This is a problem that gets worse as the model gets larger!</p><p data-block-key=\"2tkl7\">In “<a href=\"https://arxiv.org/abs/2407.07737\" target=\"_blank\" rel=\"noopener noreferrer\">Learning with User-Level Differential Privacy Under Fixed Compute Budgets</a>”, we set out to scale user-level DP to large language models (LLMs) trained in the datacenter. Datacenter training is much more flexible than federated learning. In federated learning, one can only perform queries on users and not on individual examples, and it is not possible to choose which users are available to query. In datacenter training, one can query both individual examples and whole users, and it is possible to choose which ones to query every round. Our central question is, how can we use this increased flexibility to achieve better training results?</p><p data-block-key=\"630i4\">Rather than training the full LLM with DP, we focus on LLM DP fine-tuning as DP requires more computation, which might be unaffordable for full LLM training, and fine-tuning is more likely to require private domain-specific data. We determine which algorithms worked best and how to use the flexibility of datacenter training to further optimize them. This optimization is important for LLMs as even small reductions in noise can result in significant quality gains. We also show that even with the added flexibility in the datacenter, our proposed training strategy looks more like an algorithm for federated learning.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n    <div class=\"component-intro \">\n        \n            \n                <h2 class=\"\">Training models with user-level privacy</h2>\n            \n        \n        \n    </div>\n\n\n\n    <p data-block-key=\"ifmk7\"><a href=\"https://en.wikipedia.org/wiki/Stochastic_gradient_descent\" target=\"_blank\" rel=\"noopener noreferrer\">Stochastic gradient descent</a> (SGD) is a common model training algorithm that randomly divides training data into small batches, computes model updates, called “gradients”, for each example in the batch, and applies them to the model. To train with DP, we modify this slightly by adding random noise to the gradients, essentially combining DP with SGD in a process referred to as DP-SGD. The noise makes it so the model gets imperfect information about the examples during training, which is good for privacy! But since we are giving the model imperfect information, its ability to learn from the examples is necessarily weaker than if we gave it perfect information. However, DP is a prerequisite for using private data, and imperfect information about the private data is better than no information at all.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --full\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- For GIFs, use a default width -->\n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-2a-Visualization.width-800.gif\" alt=\"UserLvlDP-2a-Visualization\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-2a-Visualization.width-800.gif\" alt=\"UserLvlDP-2a-Visualization\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n      <div class=\"glue-grid__col glue-grid__col--span-4-sm  glue-grid__col--span-12-md caption --center\">\n        <p data-block-key=\"37bs3\"><i>Visualizing the steps in (DP-)SGD.</i></p>\n      </div>\n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n\n\n    <p data-block-key=\"ifmk7\">DP-SGD is great for achieving example-level DP because it directly limits how much each example affects the model. It’s been <a href=\"https://research.google/blog/bridging-the-gap-in-differentially-private-model-training/\">extensively</a> <a href=\"https://research.google/blog/differential-privacy-accounting-by-connecting-the-dots/\">studied</a> at Google, including use cases such as <a href=\"https://research.google/blog/private-ads-prediction-with-dp-sgd/\">ads modelling</a> and <a href=\"https://research.google/blog/protecting-users-with-differentially-private-synthetic-training-data/\">synthetic data generation</a>.</p><p data-block-key=\"did4l\">How do we change DP-SGD if we want user-level DP? We need to make sure to limit the effect each user has on the model.</p><p data-block-key=\"7c1mm\">There are two ways to achieve this. For both, we first pre-process the dataset so that each user only contributes a bounded number of examples to the training dataset. Then we either:</p><ol><li data-block-key=\"dp1dq\">Apply DP-SGD as-is. By adding more noise than before, we can turn our example-level DP guarantee into user-level DP (this is the hard part!).</li><li data-block-key=\"d00is\">Instead of sampling random examples in DP-SGD to form batches, sample random users, and then take all examples from the sampled users to form the batch.</li></ol><p data-block-key=\"eskpp\">The big difference between these methods is in the data we sample. The first samples random examples, so we call it “Example-Level Sampling” (ELS). The second samples random users, so we call it “User-Level Sampling” (ULS). ULS looks a lot like federated learning in the datacenter (and is actually used in real federated learning settings, but without random sampling). Note that because of the random sampling step, both algorithms are not feasible in federated learning because devices are not necessarily available for every round of training!</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --medium\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- Determine the appropriate width based on image_width -->\n    \n        \n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-3a-Example.width-1250.png\" alt=\"UserLvlDP-3a-Example\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-3a-Example.width-1250.png\" alt=\"UserLvlDP-3a-Example\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n      <div class=\"glue-grid__col glue-grid__col--span-4-sm  glue-grid__col--span-12-md caption --center\">\n        <p data-block-key=\"37bs3\"><i>An example dataset before and after we bound the contribution of each user to at most 3.</i></p>\n      </div>\n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --medium\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- For GIFs, use a default width -->\n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-4a-ELSvULS.width-800.gif\" alt=\"UserLvlDP-4a-ELSvULS\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-4a-ELSvULS.width-800.gif\" alt=\"UserLvlDP-4a-ELSvULS\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n      <div class=\"glue-grid__col glue-grid__col--span-4-sm  glue-grid__col--span-12-md caption --center\">\n        <p data-block-key=\"37bs3\"><i>A visual comparison of how ELS and ULS form batches.</i></p>\n      </div>\n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n\n\n    <p data-block-key=\"ifmk7\">Both ELS and ULS have a key parameter to optimize: the bound on the number of examples each user can contribute to the dataset, which we call the “contribution bound”, that we use in pre-processing. As we will discuss later, this parameter needs to be carefully chosen to optimize performance.</p><p data-block-key=\"f4umd\">Which of these algorithms works better, especially at scale? It’s not obvious, and it isn’t something that we found an answer to in the literature. That’s what we set out to find.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n    <div class=\"component-intro \">\n        \n            \n                <h2 class=\"\">Making these algorithms work for LLMs</h2>\n            \n        \n        \n    </div>\n\n\n\n    <p data-block-key=\"ifmk7\">If we run these algorithms “out-of-the-box” for LLMs, things go badly. So, we came up with optimizations to the algorithms that fix the key issues with running them “out-of-the-box”.</p><p data-block-key=\"5g4e3\">For ELS, we had to go from example-level DP guarantees to user-level DP guarantees. We found that <a href=\"https://privacytools.seas.harvard.edu/sites/g/files/omnuum6656/files/privacytools/files/manuscript_2016.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">previous work</a> was adding orders of magnitude more noise than was actually necessary. We were able to prove that we can add significantly less noise, making the model much better while retaining the same privacy guarantees.</p><p data-block-key=\"7hcld\">For both ELS and ULS, we had to figure out how to optimize the contribution bound. A “default” choice is to choose a contribution bound that every user already satisfies; that is, we don’t do any pre-processing. However, some users may contribute a large amount of data, and we will need to add large amounts of noise to provide privacy to these users. Setting a smaller contribution bound reduces the amount of noise we need to add, but the cost is having to discard a lot of data. Because LLM training runs are expensive, we can’t afford to try training a bunch of models with different contribution bounds and pick the best one — we need an effective strategy to pick the contribution bound <i>before</i> we start training.</p><p data-block-key=\"a8hkp\">After lengthy experimentation at scale, for ELS we found that setting the contribution bound to be the median number of examples held by each user was an effective strategy. For ULS, we give a prediction for the total noise added as a function of the contribution bound, and found that choosing the contribution bound minimizing this prediction was an effective strategy.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n    <div class=\"component-intro \">\n        \n            \n                <h2 class=\"\">Results</h2>\n            \n        \n        \n    </div>\n\n\n\n    <p data-block-key=\"ifmk7\">We first compared the amount of noise we proved was necessary for ELS to the noise <a href=\"https://salil.seas.harvard.edu/sites/g/files/omnuum4266/files/salil/files/the_complexity_of_differential_privacy.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">past work</a> suggested was necessary. The noise levels we determined by our analyses reflected an exponential reduction in the noise needed:</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --full\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- Determine the appropriate width based on image_width -->\n    \n        \n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-5-ContributionBound.width-1250.png\" alt=\"UserLvlDP-5-ContributionBound\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-5-ContributionBound.width-1250.png\" alt=\"UserLvlDP-5-ContributionBound\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n      <div class=\"glue-grid__col glue-grid__col--span-4-sm  glue-grid__col--span-12-md caption --center\">\n        <p data-block-key=\"37bs3\"><i>Black-box calculations suggest that privacy guarantees (ε) decay exponentially in the contribution bound. Our new bound shows the privacy guarantee only decays near-linearly in the contribution bound!</i></p>\n      </div>\n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n\n\n    <p data-block-key=\"ifmk7\">We next compared ELS and ULS, both using our optimizations, on language model fine-tuning tasks, where each algorithm saw the same total number of examples per round of training. We fine-tuned a 350 million parameter transformer model on the <a href=\"https://arxiv.org/abs/2307.09619\" target=\"_blank\" rel=\"noopener noreferrer\">StackOverflow and CC-News datasets</a>, two standard research datasets for studying user-level DP.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --full\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- Determine the appropriate width based on image_width -->\n    \n        \n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-6a-ELSvULS.width-1250.png\" alt=\"UserLvlDP-6a-ELSvULS\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-6a-ELSvULS.width-1250.png\" alt=\"UserLvlDP-6a-ELSvULS\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  \n\n\n\n\n\n  <div class=\"\n      dynamic_media\n      glue-grid__col\n      glue-grid__col--span-4-sm\n      glue-grid__col--span-12-md\n      glue-grid__col--span-12-lg\n      --\n      \n        --flex\n        --center\n      \n    \" data-gt-id=\"dynamic_media\" data-gt-component-name=\"\">\n  \n\n\n\n    <div class=\"glue-grid\n      \n        --remove-gap\n        --full\n      \">\n      \n          <div class=\"\n            dynamic_media__item\n            glue-grid__col\n            glue-grid__col--span-4-sm\n            \n                glue-grid__col--span-12-md\n            \n            \n                glue-grid__col--span-12-lg\n            \n          \">\n            <div class=\"\">\n              \n\n\n    \n        \n\n\n\n\n\n    <!-- Determine the appropriate width based on image_width -->\n    \n        \n    \n\n\n<!-- For mobile images, use a default width -->\n\n\n<picture class=\"media__image media__image\">\n    \n    \n        <source media=\"(min-width: 768px)\" srcset=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-6b-ELSvULS.width-1250.png\" alt=\"UserLvlDP-6b-ELSvULS\">\n    \n    <img src=\"https://storage.googleapis.com/gweb-research2023-media/images/UserLvlDP-6b-ELSvULS.width-1250.png\" alt=\"UserLvlDP-6b-ELSvULS\" loading=\"lazy\" referrerpolicy=\"no-referrer\">\n    \n</picture>\n    \n\n\n            </div>\n          </div>\n      \n      \n      <div class=\"glue-grid__col glue-grid__col--span-4-sm  glue-grid__col--span-12-md caption --center\">\n        <p data-block-key=\"37bs3\"><i>Comparing ELS, ULS, and no fine-tuning on CCNews and StackOverflow.</i></p>\n      </div>\n      \n    </div>\n  </div>\n\n\n\n\n\n\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n\n\n    <p data-block-key=\"ifmk7\">We found that in most cases, ULS is the better algorithm. The exception (at least for CC-News) was in cases where we wanted more privacy or don’t use much compute. Notably, in part thanks to our optimizations, both methods performed better than the pre-trained model, despite the strict privacy requirement.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                    \n    \n\n\n<section class=\"component-as-block --no-padding-top --theme-light --dbl-padding\">\n    <div class=\"glue-page\">\n        \n  <div class=\"rich-text --theme-light --mode-standalone\" data-gt-id=\"rich_text\" data-gt-component-name=\"\">\n    \n\n\n    <div class=\"component-intro \">\n        \n            \n                <h2 class=\"\">Conclusion</h2>\n            \n        \n        \n    </div>\n\n\n\n    <p data-block-key=\"ifmk7\">In this work, we optimized the performance of ELS and ULS, two variants of DP-SGD that achieve user-level DP and are enabled by training in the datacenter. We optimized ELS by giving new privacy guarantees for it and by developing an heuristic for setting the contribution bound without needing to do multiple training runs. We similarly optimized ULS by developing an heuristic for setting the contribution bound, again without needing to do training runs. Our optimizations provide well-justified choices for important parameters that previously were chosen in an <i>ad hoc</i> manner.</p><p data-block-key=\"cgs4i\">Despite user-level DP being a strict privacy definition and the challenges of training large models with DP, our experiments demonstrated that fine-tuning LLMs with user-level DP is both feasible and advantageous over sticking to pre-trained models thanks to our optimizations. Our work thus enables model trainers to fine-tune their models to sensitive datasets while still providing strong protections to their users.</p>\n</div>\n\n    </div>\n</section>\n\n                    \n                "
    }
  ],
  "lastUpdated": "2025-05-29T00:13:24.446Z"
}
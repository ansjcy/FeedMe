{
  "sourceUrl": "https://github.blog/feed/",
  "title": "The GitHub Blog",
  "description": "Updates, ideas, and inspiration from GitHub to help developers build and design software.",
  "link": "https://github.blog/",
  "items": [
    {
      "title": "GitHub 内部：我们如何加强 SAML 实现 (原标题: Inside GitHub: How we hardened our SAML implementation)",
      "link": "https://github.blog/security/web-application-security/inside-github-how-we-hardened-our-saml-implementation/",
      "pubDate": "Tue, 27 May 2025 16:00:00 +0000",
      "isoDate": "2025-05-27T16:00:00.000Z",
      "content": "<p>Maintaining and developing complex and risky code is never easy. See how we addressed the challenges of securing our SAML implementation with this behind-the-scenes look at building trust in our systems.</p>\n<p>The post <a href=\"https://github.blog/security/web-application-security/inside-github-how-we-hardened-our-saml-implementation/\">Inside GitHub: How we hardened our SAML implementation</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>\n",
      "contentSnippet": "Maintaining and developing complex and risky code is never easy. See how we addressed the challenges of securing our SAML implementation with this behind-the-scenes look at building trust in our systems.\nThe post Inside GitHub: How we hardened our SAML implementation appeared first on The GitHub Blog.",
      "creator": "Greg Ose",
      "encodedSnippet": "<p>Maintaining and developing complex and risky code is never easy. See how we addressed the challenges of securing our SAML implementation with this behind-the-scenes look at building trust in our systems.</p>\n<p>The post <a href=\"https://github.blog/security/web-application-security/inside-github-how-we-hardened-our-saml-implementation/\">Inside GitHub: How we hardened our SAML implementation</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>\n\nFor over a decade, GitHub has offered enterprise authentication using SAML (Security Assertion Markup Language), starting with our 2.0.0 release of GitHub Enterprise Server in November 2014. SAML single sign-on (SSO) allows enterprises to integrate their existing identity providers with a broad range of GitHub products, extend conditional access policies, and bring enterprise organization management to GitHub.\nTo ship this feature, we had to build and maintain support for the SAML 2.0 specification, which defines how to perform authentication and establish trust between an identity provider and our products, the service provider. This involves generating SAML metadata for identity providers, generating SAML authentication requests as part of the service provider–initiated SSO flow, and most importantly, processing and validating SAML responses from an identity provider in order to authenticate users.\nThese code paths are critical from a security perspective. Here’s why: \nAny bug in how authentication is established and validated between the service and identity providers can lead to a bypass of authentication or impersonation of other users. \nThese areas of the codebase involve XML parsing and cryptography, and are dependent on complex specifications, such as the XML Signature, XML Encryption, and XML Schema standards. \nThe attack surface of SAML code is very broad, so the data that is validated for authentication and passed through users’ (and potential attackers’) browsers could be manipulated. \nThis combination of security criticality, complexity, and attack surface puts the implementation of SAML at a higher level of risk than most of the code we build and maintain.\nBackground\nWhen we launched SAML support in 2014, there were few libraries available for implementing it. After experimenting initially with ruby-saml, we decided to create our own implementation to better suit our needs. \nOver the years since, we have continually invested in hardening these authentication flows, including working with security researchers both internally and through our Security Bug Bounty to identify and fix vulnerabilities impacting our implementation. \nHowever, for each vulnerability addressed, there remained lingering concerns given the breadth and complexity of root causes we identified. This is why we decided to take a step back and rethink how we could move forward in a more sustainable and holistic manner to secure our implementation.\nSo, how do you build trust in a technology as complex and risky as SAML? \nLast year, this is exactly the question our engineering team set out to answer. We took a hard look at our homegrown implementation and decided it was time for change. We spent time evaluating the previous bounties we’d faced and brainstormed new ideas on how to improve our SAML strategy. During this process, we identified several promising changes we could make to regain our confidence in SAML. \nIn this article, we’ll describe the four key steps we took to get there:\nRethinking our library: Evaluating the ruby-saml library and auditing its implementation\nValidating the new library with A/B testing: Building a system where we could safely evaluate and observe changes to our SAML processing logic\nSchema validations and minimizing our attack surface: Reducing the complexity of input processing by tightening schema validation\nLimiting our vulnerability impact: Using multiple parsers to decrease risk\nRethinking our library\nWhen we reviewed our internal implementation, we recognized the advantages of transitioning to a library with strong community support that we could contribute to alongside a broader set of developers. \nAfter reviewing a number of ruby SAML libraries, we decided to focus again on utilizing the ruby-saml library maintained by Sixto Martín for a few reasons: \nThis library is used by a number of critical SaaS products, including broad adoption through its usage in omniauth-saml.\nRecent bugs and vulnerabilities were being reported and fixed in the library, showing active maintenance and security response. \nThese vulnerabilities and fixes were distributed through the GitHub Advisory Database and CVEs, and had updates pushed through Dependabot, which integrates well with our existing vulnerability management processes. \nThis support and automation is something we wouldn’t be able to benefit from with our own internal implementation.\nBut moving away from our internal implementation wasn’t a simple decision. We had grown familiar with it, and had invested significant time and effort into identifying and addressing vulnerabilities. We didn’t want to have to retread the same vulnerabilities and issues we had with our own code. \nWith that concern, we set out to see what work across our security and engineering teams we could do to gain more confidence in this new library before making a potential switch.\nIn collaboration with our bug bounty team and researchers, our product security team, and the GitHub Security Lab, we laid out a gauntlet of validation and testing activities. We spun up a number of security auditing activities, worked with our VIP bug bounty researchers (aka Hacktocats) who had expertise in this area (thanks @ahacker1) and researchers on the GitHub Security Lab team (thanks @p-) to perform in-depth code analysis and application security testing. \nThis work resulted in the identification of critical vulnerabilities in the ruby-saml library and highlighted areas for overall hardening that could be applied to the library to remove the possibility of classes of vulnerabilities in the code.\nBut is security testing and auditing enough to confidently move to this new library? Even with this focus on testing, assessment, and vulnerability remediation, we knew from experience that we couldn’t just rely on this point-in-time analysis. \nThe underlying code paths are just too complex to hang our hat on any amount of time-bound code review. With that decision, we shifted our focus toward engineering efforts to validate the new library, identify edge cases, and limit the attack surface of our SAML code.\nValidating the new library with A/B testing\nGitHub.com processes around one million SAML payloads per business day, making it the most widely used form of external authentication that we support. Because this code is the front door for so many enterprise customers, any changes require a high degree of scrutiny and testing. \nIn order to preserve the stability of our SAML processing code while evaluating ruby-saml, we needed an abstraction that would give us the safety margins to experiment and iterate quickly. \nThere are several solutions for this type of problem, but at GitHub, we use a tool we have open sourced called Scientist. At its core, Scientist is a library that allows you to execute an experiment and compare two pieces of code: a control and a candidate. The result of the comparison is recorded so that you can monitor and debug differences between the two sources. \nThe beauty of Scientist is it always honors the result of the control, and isolates failures in your candidate, freeing you to truly experiment with your code in a safe way. This is useful for tasks like query performance optimization—or in our case, gaining confidence in and validating a new library.\nApplying Scientist to SAML\nGitHub supports configuring SAML against both organizations and enterprises. Each of these configurations is handled by a separate controller that implements support for SAML metadata, initiation of SAML authentication requests, and SAML response validation. \nFor the sake of building confidence, our primary focus was the code responsible for handling SAML response validation, also known as the Assertion Consumer Service (ACS) URL. This is the endpoint that does the heavy lifting to process the SAML response coming from the identity provider, represented in the SAML sequence diagram below as “Validate SAML Response.” Most importantly, this is where most vulnerabilities occur.\n\n\n\n\nIn order to gain confidence in ruby-saml, we needed to validate that we could get the library to handle our existing traffic correctly. \nTo accomplish this, we applied Scientist experiments to the controller code responsible for consuming the SAML response and worked on the following three critical capabilities:\nGranular rollout gating: Scientist provides a percent-based control for enabling traffic on an experiment. Given the nature of this code path, we wanted an additional layer of feature flagging to ensure that we could send our own test accounts through the path before actual customer traffic\nObservability: GitHub has custom instrumentation for experiments, which sends metrics to Datadog. We leaned heavily on this for monitoring our progress, but also added supplemental logging to generate more granular validation data to help debug differences between libraries.\nIdempotency: There are pieces of state that are tracked during a SAML flow, such as tokens for CSRF, and we needed to ensure that our experiment did not modify them. Any changes must be clear of these code paths to prevent overwriting state.\nWhen all was said and done, our experiment looked something like the following:\n# gate the experiment by business, allowing us to run test account traffic through first\nif business.feature_enabled?(:run_consume_experiment)\n  # auth_result is the result of `e.use` below\n  auth_result = science \"consume_experiment\" do |e|\n\n    # ensure that we isolate the raw response ahead of time, and scope the experiment to\n    # just the validation portion of response processing\n    e.use { consume_control_validation(raw_saml_response) }\n    e.try { consume_candidate_validation(raw_saml_response) }\n\n    # compare results and perform logging\n    e.compare { |control, candidate| compare_and_log_results(control, candidate) }\n  end\nend\n\n# deal with auth_result below...\nSo, how did our experiments help us build confidence in ruby-saml? \nFor starters, we used them to identify configuration differences between implementations. This guided our integration with the library, ensuring it could handle traffic in a way that was behaviorally consistent. \nAs an example, in September 2024 we noticed in our logs that approximately 3% of mismatches were caused by SAML issuer validation discrepancies. Searching the logs, we found that ruby-saml validated the issuer against an empty string. This helped us identify that some SAML configurations had an issuer set to an empty string, rather than null in the database. \nGiven that GitHub has not historically required an issuer for all SAML configurations, if the value is blank or unset, we skip issuer validation in our implementation. To handle this legacy invariant, we shipped a change that prevented configuring ruby-saml with blank or null issuer values, allowing the validation to be skipped in the library. \nThe impact of this change can be seen in graph below:\n\n\n\n\nOnce we set ruby-saml up correctly, our experiments allowed us to run all of our traffic through the library to observe how it would perform over an extended period of time. This was critical for building confidence that we had covered all edge cases. Most importantly, by identifying edge cases where the implementations handled certain inputs differently, we could investigate if any of these had security-relevant consequences. \nBy reviewing these exceptions, we were able to proactively identify incorrect behavior in either the new or old implementation. We also noticed during testing that ruby-saml rejected responses with multiple SAML assertions, while ours was more lenient. \nWhile not completely wrong, we realized our implementation was trying to do too much. The information gained during this testing allowed us to safely augment our candidate code with new ideas and identify further areas of hardening like our next topic.\nSchema validations and minimizing our attack surface\nBefore looking into stricter input validation, we first have to dive into what makes up the inputs we need to validate. Through our review of industry vulnerabilities, our implementation, and related research, we identified two critical factors that make parsing and validating this input particularly challenging: \nThe relationship between enveloped XML signatures and the document structure\nThe SAML schema flexibility\nEnveloped XML Signatures\nA key component of SAML is the XML signatures specification, which provides a way to sign and verify the integrity of SAML data. There are multiple ways to use XML signatures to sign data, but SAML relies primarily on enveloped XML signatures, where the signature itself is embedded within the element it covers. \nHere’s an example of a <Response> element with an enveloped XML signature:\n<Response ID=\"1234>\n   <Signature xmlns=\"http://www.w3.org/2000/09/xmldsig#\">\n      <SignedInfo>\n         <CanonicalizationMethod Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"></CanonicalizationMethod>\n         <SignatureMethod Algorithm=\"http://www.w3.org/2001/04/xmldsig-more#rsa-sha256\"></SignatureMethod>\n         <Reference URI=\"#1234\">\n            <Transforms>\n               <Transform Algorithm=\"http://www.w3.org/2000/09/xmldsig#enveloped-signature\"></Transform>\n               <Transform Algorithm=\"http://www.w3.org/2001/10/xml-exc-c14n#\"></Transform>\n            </Transforms>\n            <DigestMethod Algorithm=\"http://www.w3.org/2001/04/xmlenc#sha256\"></DigestMethod>\n            <DigestValue>...</DigestValue>\n         </Reference>\n      </SignedInfo>\n      <SignatureValue>...</SignatureValue>\n      <KeyInfo>\n         <X509Data>\n            <X509Certificate>...</X509Certificate>\n         </X509Data>\n      </KeyInfo>\n   </Signature>\n</Response>\nIn order to verify this signature, we performed some version of the following high-level process:\nFind the signature: Locate the <Signature> element in the <Response> element.\nExtract values: Get the <SignatureValue> and <SignedInfo> from the <Signature>.\nExtract reference and digest: From <SignedInfo>, extract the <Reference> (a pointer to the signed part of the document—note the URI attribute and the associated ID attribute on <Response>) and <DigestValue> (a hashed version of <Response>, minus the <Signature>).\nVerify the digest: Apply the transformation instructions in the signature to the <Response> element and compare the results to the <DigestValue>.\nValidate integrity: If the digest is valid, hash and encode <SignedInfo> using another algorithm, then use the configured public key (exchanged during SAML set up) to verify it against the <SignatureValue>.\nIf we get through this list of steps and the signature is valid, we assume that the <Response> element has not been tampered with. The interesting part about this is that to process the signature that legitimizes the <Response> element’s contents, we had to parse the <Response> element’s contents! \nPut another way, the integrity of the SAML data is tied to its document structure, but that same document structure plays a critical role in how it is validated. Herein lies the crux of many SAML validation vulnerabilities.\nThis troubling relationship between structure and integrity can be exploited, and has been many times. One of the more common classes of vulnerability is the XML signature wrapping attack, which involves tricking the library into trusting the wrong data. \nSAML libraries typically deal with this by querying the document and rejecting unexpected or ambiguous input shapes. This strategy isn’t ideal because it still requires trusting the document before verifying its authenticity, so any small blunders can be targeted.\nLax SAML schema definitions\nSAML responses must be valid against the SAML 2.0 XML schema definition (XSD). XSD files are used to define the structure of XML, creating a contract between the sender and receiver about the sequence of elements, data types, and attributes. \nThis is exactly what we would look for in creating a clear set of inputs that we can easily limit parsing and validation around! Unfortunately, the SAML schema is quite flexible in what it allows, providing many opportunities for a document structure that would never appear in typical SAML responses.\nFor example, take a look at the SAML response below and notice the <StatusDetail> element. <StatusDetail> is one example in the spec that allows arbitrary data of any type and namespace to be added to the document. Consequently, including the elements <Foo>, <Bar>, and <Baz> into <StatusDetail> below would be completely valid given the SAML 2.0 schema. \n<Response xmlns=\"urn:oasis:names:tc:SAML:2.0:protocol\" Version=\"2.0\" ID=\"_\" IssueInstant=\"1970-01-01T00:00:00.000Z\">\n  <Status>\n    <StatusCode Value=\"urn:oasis:names:tc:SAML:2.0:status:Success\"/>\n    <StatusDetail>\n      <Foo>\n        <Bar>\n          <Baz />\n        </Bar>\n      </Foo>\n    </StatusDetail>\n  </Status>\n  <Assertion xmlns=\"urn:oasis:names:tc:SAML:2.0:assertion\" Version=\"2.0\" ID=\"TEST\" IssueInstant=\"1970-01-01T00:00:00.000Z\">\n    <Issuer>issuer</Issuer>\n    <Signature xmlns=\"http://www.w3.org/2000/09/xmldsig#\">\n\tOmitted for Brevity...\n    </Signature>\n    <Subject>\n      <NameID>\n        user@example.net\n      </NameID>\n    </Subject>\n  </Assertion>\n</Response>\nKnowing that the signature verification process is sensitive to the document structure, this is problematic. These schema possibilities leave gaps that your code must check. \nConsider an implementation that does not correctly associate signatures with signed data, only validating the first signature it finds because it assumes that the signature should always be in the <Response> element (which encompasses the <Assertion> element), or in the <Assertion> element directly. This is where the signatures are located in the schema, after all. \nTo exploit this, replace the contents of our previous example with a piece of correctly signed SAML data from the identity provider (remember that the schema allows any type of data in <StatusDetail>). Since the library only cares about the first signature it finds, it never verifies the <Assertion> signature in the example below, allowing an attacker to modify its contents to gain system access.\n<Response xmlns=\"urn:oasis:names:tc:SAML:2.0:protocol\" Version=\"2.0\" ID=\"_\" IssueInstant=\"1970-01-01T00:00:00.000Z\">\n  <Status>\n    <StatusCode Value=\"urn:oasis:names:tc:SAML:2.0:status:Success\"/>\n    <StatusDetail>\n    \t<Response Version=\"2.0\" ID=\"TEST\" IssueInstant=\"1970-01-01T00:00:00.000Z\">\n        <Signature xmlns=\"http://www.w3.org/2000/09/xmldsig#\">\n\t   Omitted for Brevity...\n        </Signature>\n      </Response>\n    </StatusDetail>\n  </Status>\n  <Assertion xmlns=\"urn:oasis:names:tc:SAML:2.0:assertion\" Version=\"2.0\" ID=\"TEST\" IssueInstant=\"1970-01-01T00:00:00.000Z\">\n    <Issuer>issuer</Issuer>\n    <Signature xmlns=\"http://www.w3.org/2000/09/xmldsig#\">\n\tOmitted for Brevity...\n    </Signature>\n    <Subject>\n      <NameID>\n        attacker-controller@example.net\n      </NameID>\n    </Subject>\n  </Assertion>\n</Response>\nThere are so many different permutations of vulnerabilities like this that depend on the loose SAML schema, including many that we have protected against in our internal implementation.\nLimiting the attack surface\nWhile we can’t change how SAML works or the schema that defines it, what if we change the schema we validate it against? By making a stricter schema, we could enforce exactly the structure we expect to process, thereby reducing the likelihood of signature processing mistakes. Doing this would allow us to rule out bad data shapes before ever querying the document.\nBut in order to build a stricter schema, we first needed to confirm that the full SAML 2.0 schema wasn’t necessary. Our process began with bootstrapping: we gathered SAML responses from test accounts provided by our most widely integrated identity providers. \nStarting small, we focused on Entra and Okta, which together accounted for nearly 85% of our SSO traffic volume. Using these responses, we crafted an initial schema based on real-world usage.\nNext, we used Scientist to validate the schemas against our vast amount of production traffic. We first A/B tested with the very restrictive “bootstrapped” schema and gradually added back in the parts of the schema that we saw in anonymized traffic. \nThis allowed us to define a minimal schema that only contained the structures we saw in real-world requests. The same tooling we used for A/B testing allowed us to craft a minimal schema by iterating on the failures we saw across millions of requests.\nHow did the “strict” schema turn out based on our real-world validation from identity providers? Below are some of the key takeaways and schema restrictions we now enforce:\nEnsure Signature elements are only where you expect them \nWe expect at most two elements to be signed: the Response, and the Assertion, but we know the schema is more lenient. For example, we don’t expect the SubjectConfirmationData or Advice elements to contain a signature, yet the following is a valid structure:\n<samlp:Response ID=\"response-id\" xmlns:samlp=\"urn:oasis:names:tc:SAML:2.0:protocol\">\n  <saml:Assertion ID=\"signed-assertion-id\">\n    <ds:Signature>\n      <ds:SignedInfo>\n        <ds:Reference URI=\"#signed-assertion-id\" />\n        ...\n      </ds:SignedInfo>\n    </ds:Signature>\n    <saml:Subject>\n      <saml:NameID>legitimate-user@example.com</saml:NameID>\n      <saml:SubjectConfirmation>\n        <saml:SubjectConfirmationData>\n          <ds:Signature>...</ds:Signature>\n        </saml:SubjectConfirmationData>\n      </saml:SubjectConfirmation>\n    </saml:Subject>\n  </saml:Assertion>\nThese are ambiguous situations that we can prevent. By removing <any> type elements, we can prevent additional signatures from being added to the document, and reduce the risk of attacks targeting flaws in signature selection logic.\nIt’s safe to enforce a single assertion in your response \nThe SAML spec allows for an unbounded number of assertions:\n<choice minOccurs=\"0\" maxOccurs=\"unbounded\">\n  <element ref=\"saml:Assertion\"/>\n  <element ref=\"saml:EncryptedAssertion\"/>\n</choice>\nWe expect exactly one assertion, and most SAML libraries account for this invariant by querying and rejecting documents with multiple assertions. By removing the minOccurs and maxOccurs attributes from the schema’s assertion choice, we can reject responses containing multiple assertions ahead of time. \nThis matters because multiple assertions in the document lead to structures that are vulnerable to XML signature wrapping attacks. Enforcing a single assertion removes structural ambiguity around the most important part of the document. \nRemove additional elements and attributes that are unused in practice by your implementation \nThis is probably the least specific piece of advice, but important: Removing what you don’t support from the existing schema will reduce the risk of your application code handling that input incorrectly. For example, if you don’t support EncryptedAssertions, you should probably omit those definitions from your schema all together to prevent your code from touching data it doesn’t expect.\nIt is safe to reject document type definitions (DTDs) \nWhile not strictly XSD related, we felt this was an important callout. DTDs are an older and more limited alternative to XSDs that add an unnecessary attack vector. Given that SAML 2.0 relies on schema definition files for validation, DTDs are both outdated and unnecessary, so we felt it best to disallow them altogether. In the wild, we never saw DTDs being used by identity providers.\nThe goal of a stricter SAML schema is to simplify working with SAML signatures and documents by removing ambiguity. By enforcing precise rules about where signatures should appear and their relationship to the data, validation becomes more straightforward and reliable. \nWhile stricter schemas don’t eliminate all risks—since signature processing also depends on implementation—they significantly reduce the attack surface, enhancing overall security and minimizing the complex parsing we need to reason about for validation.\nLimiting our vulnerability impact\nAt this point, we had made significant progress in addressing the risks associated with integrating ruby-saml and had restricted our critical inputs to a much smaller portion of the SAML schema. \nBy implementing safeguards, validating critical code paths, and taking a deliberate approach to testing, we mitigated many of the uncertainties inherent in adopting a new library and of SAML in general. \nHowever, one fundamental truth remained: implementation vulnerabilities are inevitable, and we wanted to see what additional hardening we could apply to limit their impact.\nConsidering a compromise\nMigrating to ruby-saml fully would mean embracing a more modern, actively maintained codebase that addresses known vulnerabilities. It would also position us for better long-term maintainability with broad community support: one of the primary motivators for this initiative. \nHowever, replacing a core component like a SAML library isn’t without trade-offs. The risk of new vulnerabilities that weren’t surfaced during our work would always exist. With this in mind, we considered an alternative path: Instead of relying entirely on one library, why not use both?\nWe took this idea and ran with it by implementing a dual-parsing strategy and running both libraries independently and in parallel, requiring them to agree on validation before accepting a result. It might sound redundant and inefficient, but here’s why it worked to harden our implementation:\nDefense in depth: The two libraries parse SAML differently. Exploiting both would require two independent vulnerabilities that work in unison—a much taller order than compromising just one.\nBuilt-in feedback: When they disagree, we are notified. This gives us the opportunity to identify and investigate potential security critical edge cases. We can then feed stricter validation logic from one library back into the other.\nNo pressure to rush: Our original library is battle-tested and hardened. Using both together allows us to leverage its reliability while adopting the benefits of ruby-saml. We can always revisit this decision as we learn more about this strategy and its performance over time.\nWith this approach, we recognize that keeping something that works—when paired with something new—can be more powerful than replacing it outright. Of course, there are still risks involved. But by having two parsers, we increase our exposure of implementation vulnerabilities in our XML parsing code: things like memory corruption or XML external entity vulnerabilities. We also increase the burden of having to maintain two libraries. \nDespite this, we decided that this risk and time investment is worth the increased resilience to the complex validation logic that is the core to the historical and critical vulnerabilities we’ve seen. \nLearn from our blueprint\nWhile our original goal was to “just” move to a new SAML library, we ended up taking the opportunity to reduce the risk profile of our entire SAML implementation. \nBy investing in upfront code review, security testing, and A/B testing and validation, we’ve gained confidence in the implementation of this new library. We then decreased the complexity of these code paths by restricting our allowed schema to one that is minimized using real world data. Finally, we’ve limited the impact of a single vulnerability found in either library by combining the strengths of both ruby-saml and our internal implementation.\nAs this code continues to parse almost a million SAML responses per day, our robust logging and exception handling will provide us with the observability needed to adjust our strategy or identify new hardening opportunities. \nThis experience should provide any team with a great blueprint on how to approach other complex or dangerous parts of a codebase they may be tasked with maintaining or hardening—and a reminder that incremental, data-driven experiments and compromises can sometimes lead to unexpected outcomes.\nRead more about GitHub Security Lab’s research into SAML vulnerabilities and how GitHub can help you secure your code.\n\nThe post Inside GitHub: How we hardened our SAML implementation appeared first on The GitHub Blog.",
      "summary": "以下是关于 GitHub 如何加强其 SAML 实现的摘要：\n\n*   **背景：** GitHub 从 2014 年开始提供基于 SAML 的企业身份验证，但 SAML 代码的复杂性和攻击面使其风险较高。\n*   **目标：** 重新评估并改进 SAML 实现，以提高安全性。\n*   **关键步骤：**\n    1.  **重新思考库：** 评估并迁移到 ruby-saml 库，该库具有强大的社区支持和积极的维护。\n    2.  **使用 A/B 测试验证新库：** 使用 Scientist 工具进行 A/B 测试，以安全地评估和观察 SAML 处理逻辑的更改。\n        *   GitHub 使用 Scientist 库来比较新旧代码，并隔离新代码中的故障。\n        *   通过实验，识别配置差异，确保行为一致。\n        *   下图展示了通过 A/B 测试发现并解决 SAML issuer 验证差异的例子：\n\n        \n    3.  **模式验证并最小化攻击面：** 通过收紧模式验证来降低输入处理的复杂性。\n        *   SAML 依赖于 XML 签名来验证数据完整性，但 XML 签名和文档结构之间的关系可能导致漏洞。\n        *   SAML 响应必须符合 SAML 2.0 XML 模式定义 (XSD)，但 SAML 模式定义较为宽松。\n    4.  **限制漏洞影响：** 使用多个解析器来降低风险。\n\n总而言之，GitHub 通过迁移到社区支持的库、进行 A/B 测试、加强模式验证和使用多个解析器来提高 SAML 实现的安全性。",
      "translated_title": "GitHub 内部：我们如何加强 SAML 实现",
      "contentSource": "RSS"
    },
    {
      "title": "GitHub 初学者教程：使用 GitHub Copilot 进行测试驱动开发 (TDD) (原标题: GitHub for Beginners: Test-driven development (TDD) with GitHub Copilot)",
      "link": "https://github.blog/ai-and-ml/github-copilot/github-for-beginners-test-driven-development-tdd-with-github-copilot/",
      "pubDate": "Mon, 26 May 2025 13:00:00 +0000",
      "isoDate": "2025-05-26T13:00:00.000Z",
      "content": "<p>See how to use GitHub Copilot to engage in some test-driven development.</p>\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/github-for-beginners-test-driven-development-tdd-with-github-copilot/\">GitHub for Beginners: Test-driven development (TDD) with GitHub Copilot</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>\n",
      "contentSnippet": "See how to use GitHub Copilot to engage in some test-driven development.\nThe post GitHub for Beginners: Test-driven development (TDD) with GitHub Copilot appeared first on The GitHub Blog.",
      "creator": "Kedasha Kerr",
      "encodedSnippet": "<p>See how to use GitHub Copilot to engage in some test-driven development.</p>\n<p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/github-for-beginners-test-driven-development-tdd-with-github-copilot/\">GitHub for Beginners: Test-driven development (TDD) with GitHub Copilot</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>\n\nWelcome to the next episode in our GitHub for Beginners series, where we’re diving into the world of GitHub Copilot. We’re now on our seventh episode, and we’ve covered quite a lot of ground. You can check out all our previous episodes on our blog or as videos.\nToday we’re going to dive into the world of testing, a much needed but historically tedious part of the development process. This is especially true as our codebase becomes larger and more complex. Fortunately, we can use GitHub Copilot to help automate some of this process.\nAfter all, one of the most basic questions we have when writing code is: “Does it work?”\n\n\n\n\n\n\n\nFor the demos in this series, we’re using GitHub Copilot in Visual Studio Code.\nCopilot is available in other IDEs, but the available functionality may vary depending on your environment.\nTesting 101\nBefore we jump into how to use GitHub Copilot to write some tests, we should talk about testing, why it’s important, and different ways to test your code. Be aware that test testing is a very deep topic, and we’ll only be touching the surface here. Covering the nuances of testing would be an entire course in and of itself.\nSo why is testing important? In short, it’s how you make sure that your code does what you expect.\n\n\n\n\nTesting can take many different forms, such as:\nAcceptance tests: Tests that ensure your app meets a set of defined functionality.\nIntegration tests: Tests that verify your app can talk across various systems such as databases and APIs.\nUnit tests: Tests focused on breaking the code into small, isolated pieces called units. These make sure the individual units do exactly what you’d expect them to do.\nWriting unit tests\nAs we just covered, unit tests work by breaking down your code into smaller chunks that are easier to test. Making sure each individual piece is doing what it’s supposed to do increases confidence that the entire app will work when you put all the pieces together.\nOne of the great things about unit tests is that you can automate the process. Once you’ve created a large battery of tests, you can literally run thousands of tests with a single command. This gives you a good indicator regarding the health of your application. By regularly running these tests, you’ll also discover if any changes to your code broke something you might not have been expecting.\nSo how do you use GitHub Copilot to create some unit tests?\nOpen up your code and highlight a section that you want to test. For example, you might highlight a specific function.\nOpen up Copilot Chat. You might notice that Copilot suggests using the /tests slash command to write tests.\nSend Copilot the following prompt:\n/tests add unit tests for my code\nIf Copilot asks if you want to configure a test framework, select Dismiss.\n\n\n\n\n\nReview the plan and code suggestions to make sure you understand what changes Copilot is going to make.\nClick the Add to new file button at the top of the code suggestion to create the tests.\nSave the new file.\nRun the tests by running the following command in your terminal:\npython -m pytest\nCongratulations! You just added some unit tests to your code! If you’d like to see a demo of this in action, make sure to watch the video!\nTest-driven development\nNow that you’ve seen how to write some unit tests, let’s talk a little bit about test-driven development (TDD). What exactly is TDD? It’s a process where you use the tests to drive how you develop your code. When using TDD, you write your tests first, and then create the implementation afterward.\nThe process takes a little bit of adjusting how you think about development, but it does come with several advantages. It gives you the opportunity to see how your code will behave and ensure the tests you’re writing are testing what you expect them to test. \nA concept that can be helpful for wrapping your brain around this is called “red, green, refactor.” In this process, you create the tests first, and they fail. They might not even build! This is the red stage.\n\n\n\n\nThen you write just enough code to get your tests to pass. For example, if you’re writing a test that makes sure an error is thrown if a number is less than 0, you write just enough code to throw that error on that condition. When you return to the test, it now passes. You’ve actively made a change to the codebase to implement the desired functionality. This is the green stage. \nFinally, you implement any refactoring to make the code look good. Now that it works, you can focus on making it pretty. The entire time you are working on this, you keep running the unit tests to make sure your changes don’t break anything. As you probably guessed, this is the refactor stage.\nGitHub Copilot can help you with TDD. It’s one of the hidden little tricks that Copilot is able to do—you can tell it code will exist and generate tests based on that information. For example, if you were working on an email validation app, you could send the following prompt to Copilot Chat:\nI'm going to be adding a new validator function for usernames. Usernames must be between 3 and 16 characters, start with a letter or an underscore, not use multiple underscores to start, and after the first character chan have letters, numbers, and underscores. Just create the new test functions.\nThis prompt provides the criteria that you’re expecting and gives it to Copilot. Copilot will then use this prompt to generate unit tests to test that functionality. If you ran these tests, they would fail, because you’ve only created the tests. Red stage.\n\n\n\n\nNow, to move on to the green stage, you could send Copilot the following prompt:\nCreate the implementation\nCopilot will now generate the code to make sure these tests pass. Now when you add this code to your validators and rerun the tests, they pass. Green stage.\n\n\n\n\nThanks to Copilot’s help, we’ve gone through some TDD and have code that works.\nBest practices\nRemember that unit tests are code. In order to make them more palatable to others, you should follow follow several of the same coding standards you’d use for production code:\nAdd documentation to your tests\nKeep your tests organized\nCreate utilities to write your tests faster\nUpdate your tests as you make changes to your code\nWe don’t have time to cover every aspect of TDD or unit testing, but there are plenty of resources available. Here are some to get you started:\nAccelerate TDD with AI\nHow to generate unit tests with GitHub Copilot\nGenerating unit tests with GitHub Copilot\nWriting tests with GitHub Copilot\nYour next steps\nTesting is an essential part of development. Having tools like GitHub Copilot that make tests less tedious to write improves your code and gives you more time to focus on the parts of coding you enjoy.\nDon’t forget that you can use GitHub Copilot for free! If you have any questions, pop them in the GitHub Community thread, and we’ll be sure to respond. Join us for the next part in this series, which will be our final episode of the season. \nHappy coding!\nNeed some help testing your code and keeping it all running smoothly? Give GitHub Copilot a try!\n\nThe post GitHub for Beginners: Test-driven development (TDD) with GitHub Copilot appeared first on The GitHub Blog.",
      "summary": "本文是 GitHub 初学者系列教程的第七集，主要介绍如何使用 GitHub Copilot 辅助进行测试驱动开发 (TDD)。\n\n*   **测试的重要性：** 确保代码按预期工作。\n\n    ![A slide explaining 'Why are tests important? Ensures code is working as expected.'](https://github.blog/wp-content/uploads/2025/05/01-testing-important.png?resize=1657%2C927)\n\n*   **测试类型：**\n    *   验收测试：确保应用程序满足一组定义的功能。\n    *   集成测试：验证应用程序是否可以跨各种系统（如数据库和 API）进行通信。\n    *   单元测试：将代码分解为小的、隔离的单元，确保每个单元按预期工作。\n\n*   **使用 GitHub Copilot 编写单元测试：**\n    1.  在代码中选择要测试的部分（例如，特定函数）。\n    2.  打开 Copilot Chat。\n    3.  发送提示：`/tests add unit tests for my code`\n    4.  查看 Copilot 的计划和代码建议。\n    5.  将测试添加到新文件并保存。\n    6.  运行测试：`python -m pytest`\n\n*   **测试驱动开发 (TDD)：** 先编写测试，然后编写实现代码。\n\n*   **红、绿、重构 (Red, Green, Refactor) 流程：**\n    1.  编写测试（红色阶段：测试失败）。\n    2.  编写最少量的代码使测试通过（绿色阶段：测试通过）。\n\n        ![A slide explaining Red, Green, Refactor steps: 1. Write tests first 2. Tests fail because there's no code (red!) 3. Write just enough code to allow tests to pass 4. Rerun the test to see it pass (green!) 5. Refactor and clean up code](https://github.blog/wp-content/uploads/2025/05/red_green_refactor.png?resize=1657%2C927)\n    3.  重构代码（重构阶段：改进代码）。\n\n*   **GitHub Copilot 在 TDD 中的应用：** 可以根据预期的代码行为生成测试。\n\n*   **单元测试的最佳实践：**\n    *   添加文档。\n    *   保持测试的组织性。\n    *   创建实用程序以更快地编写测试。\n    *   在更改代码时更新测试。\n\n*   **总结：** GitHub Copilot 可以简化测试编写过程，提高代码质量，并节省开发时间。\n\n*   **作者：**\n\n    ![Kedasha Kerr](https://avatars.githubusercontent.com/u/47188731?v=4&s=200) Kedasha Kerr\n\n*   **更多资源：**\n\n    ![Docs](https://github.blog/wp-content/uploads/2024/07/Icon-Circle.svg) Docs\n\n    ![GitHub](https://github.blog/wp-content/uploads/2024/07/Icon_95220f.svg) GitHub\n\n    ![Customer stories](https://github.blog/wp-content/uploads/2024/07/Icon_da43dc.svg) Customer stories\n\n    ![Enterprise content](https://github.blog/wp-content/uploads/2022/05/careers.svg) Enterprise content",
      "translated_title": "GitHub 初学者教程：使用 GitHub Copilot 进行测试驱动开发 (TDD)",
      "images": [
        {
          "url": "https://github.blog/wp-content/uploads/2025/05/01-testing-important.png?resize=1657%2C927",
          "alt": "A slide explaining 'Why are tests important? Ensures code is working as expected.'",
          "title": "",
          "position": 1
        },
        {
          "url": "https://github.blog/wp-content/uploads/2025/05/red_green_refactor.png?resize=1657%2C927",
          "alt": "A slide explaining Red, Green, Refactor steps:\n\n1. Write tests first\n2. Tests fail because there's no code (red!)\n3. Write just enough code to allow tests to pass\n4. Rerun the test to see it pass (green!)\n5. Refactor and clean up code",
          "title": "",
          "position": 2
        },
        {
          "url": "https://avatars.githubusercontent.com/u/47188731?v=4&s=200",
          "alt": "Kedasha Kerr",
          "title": "",
          "position": 3
        },
        {
          "url": "https://github.blog/wp-content/uploads/2024/07/Icon-Circle.svg",
          "alt": "Docs",
          "title": "",
          "position": 4
        },
        {
          "url": "https://github.blog/wp-content/uploads/2024/07/Icon_95220f.svg",
          "alt": "GitHub",
          "title": "",
          "position": 5
        },
        {
          "url": "https://github.blog/wp-content/uploads/2024/07/Icon_da43dc.svg",
          "alt": "Customer stories",
          "title": "",
          "position": 6
        },
        {
          "url": "https://github.blog/wp-content/uploads/2022/05/careers.svg",
          "alt": "Enterprise content",
          "title": "",
          "position": 7
        }
      ],
      "contentSource": "完整文章"
    }
  ],
  "lastUpdated": "2025-05-28T21:13:55.172Z",
  "processingStats": {
    "totalItems": 2,
    "newItems": 0,
    "existingItems": 2,
    "lastProcessed": "2025-05-28T21:13:55.172Z"
  }
}
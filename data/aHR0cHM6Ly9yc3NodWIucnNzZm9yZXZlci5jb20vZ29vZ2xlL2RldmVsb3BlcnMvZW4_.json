{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "Gemini Code Assist 的新功能 (原标题: What's new in Gemini Code Assist)",
      "link": "https://developers.googleblog.com/en/new-in-gemini-code-assist/",
      "pubDate": "Wed, 20 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-20T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini Code Assist 的新功能：Agent 模式、IDE 改进和 CLI 更新\n\nGoogle 于 2025 年 8 月 21 日宣布了 Gemini Code Assist 的多项重要更新，旨在通过强大的智能代理功能、集成开发环境（IDE）的优化以及命令行界面（CLI）的增强，彻底改变开发者的工作方式。\n\n## 1. Agent 模式全面可用\n\nGemini Code Assist 的 Agent 模式现已在 VS Code 和 IntelliJ 中全面推出，为开发者提供了智能协作式方法来处理复杂的、多步骤的任务。\n\n*   **核心功能**：\n    *   **智能任务处理**：例如，重构购物车模型的视图和控制器以显示折扣代码，Agent 模式会提出详细的计划供开发者审查和批准，确保完全控制。它结合了 AI 的力量和开发者的专业知识，提高效率并生成更好的代码。\n*   **VS Code 中的 Agent 模式**：\n    *   此前在 Insiders 频道推出，现在已进入预览阶段并向所有人开放。\n    *   它是一个由 Gemini CLI 提供支持的全新聊天体验，通过以下方式提升生产力：\n        *   支持多文件编辑。\n        *   提供完整的项目上下文。\n        *   内置工具和与生态系统工具（使用 MCP）的集成。\n        *   集成“人在回路”（Human in the Loop, HiTL）机制。\n    *   **增强功能**：\n        *   直接使用集成的 Gemini 内联差异（Inline diff）编辑代码，直观高亮修改。\n        *   聊天中内联差异提高了代码编辑的清晰度。\n        *   聊天历史中 Agent 模式的持久性，提供一致体验。\n        *   简化直观的用户友好配额更新。\n        *   实时显示 shell 命令输出。\n        *   支持批量工具调用审批和编辑。\n        *   更快的 UI 性能和渲染。\n        *   Agent 模式的切换状态在 IDE 重启后保持不变。\n    *   ![VS Code prompts](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_9I8wDqd.original.png)\n    *   ![Gemini Code Assist Agent Mode in VS Code](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_CT8FmrZ.original.png)\n*   **IntelliJ 中的 Agent 模式**：\n    *   现已在稳定版中可用。\n    *   允许开发者在完全控制每次更改的情况下完成复杂的、多步骤的任务。\n    *   代理在进行任何修改前会提出计划供审查，开发者可以编辑、请求更改、批准或拒绝建议。\n    *   支持启用自动批准模式，让代理代为操作，完成后可审查和回滚更改。\n\n## 2. IDE 改进\n\nGemini Code Assist 在 IDE 体验方面进行了多项改进，以提升开发者的生产力。\n\n*   **聊天交互控制**：\n    *   新增功能，可停止正在进行的聊天响应，立即终止不必要冗长或错误的响应。\n    *   **IntelliJ**：引入了“思考令牌”（thinking tokens），让开发者在 Gemini 提供响应前，更深入地了解其思考过程。\n    *   ![IntelliJ tokens](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_n0A7ZgJ.original.png)\n*   **代码补全**：\n    *   **VS Code**：代码补全建议的性能得到显著提升，帮助开发者更快、更高效地编写代码。\n*   **预览功能普遍可用**：\n    *   许多之前推出的预览功能现已普遍可用，确保日常工作流的稳定性和可靠性，包括：\n        *   回滚到检查点。\n        *   将选定的代码片段添加到上下文。\n        *   使用选定的终端输出提示 Gemini Code Assist。\n        *   在工作区中指定文件名。\n        *   将文件从 Gemini Code Assist 的使用中排除。\n\n## 3. Gemini CLI 更新\n\n自 6 月底推出以来，Gemini CLI 社区活跃，贡献了 2800 多个拉取请求，提交了约 3400 个问题，并获得了超过 70,000 颗星。最近的更新主要集中在安全性、隐私和持续改进上。\n\n*   **Gemini CLI GitHub Actions**：\n    *   现已推出（测试版，广泛可用），是一个免费、强大的 AI 编码助手，可作为仓库的自主代理处理常规编码任务，也可作为按需协作工具。\n    *   由新问题或拉取请求等事件触发，在后台异步工作，利用项目完整上下文自动处理任务。\n    *   **三大核心用例**：智能问题分类、加速拉取请求审查、按需协作。\n*   **更深度的 VS Code 集成**：\n    *   Gemini CLI 现在能感知开发者打开的文件，并访问选定的文本，从而提供更有针对性和上下文相关的建议。\n    *   通过原生的编辑器内差异功能，开发者可以并排查看建议的更改，并在接受前进行编辑。\n    *   需使用 Gemini CLI 0.1.20 或更高版本，并进行一次性设置。\n*   **其他改进**：\n    *   提升了 Gemini CLI 的可靠性和一致性。\n    *   推出了自定义斜杠命令（Custom Slash Commands），允许定义可重用提示，简化与 Gemini CLI 的交互。\n*   **公共路线图**：已发布 Gemini CLI v1 的公共路线图，以保持透明度。\n\n这些更新旨在提供更好的编码体验，并提高开发者的生产力。开发者可以免费试用 Gemini Code Assist，并在发布说明中了解更多详细信息。",
      "shortSummary": "Gemini Code Assist 发布重大更新，包括 Agent 模式的全面可用，现已支持 VS Code 和 IntelliJ，提供智能多步骤任务处理和代码协作。IDE 方面，改进了聊天控制、VS Code 代码补全性能，并使多项预览功能普遍可用。Gemini CLI 也迎来更新，推出了 GitHub Actions，并深化了与 VS Code 的集成，提供上下文感知建议和编辑器内差异功能，旨在全面提升开发者效率和工作流。",
      "translated_title": "Gemini Code Assist 的新功能",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_9I8wDqd.original.png",
          "alt": "VS Code prompts",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_CT8FmrZ.original.png",
          "alt": "Gemini Code Assist Agent Mode in VS Code",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_n0A7ZgJ.original.png",
          "alt": "IntelliJ tokens",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "完整文章",
      "content": "Gemini Code Assist's Agent Mode, now available in VS Code (Preview) and IntelliJ (Stable), streamlines complex coding tasks by proposing detailed plans for user review and approval. This intelligent, collaborative approach, enhanced with features like inline diffs and persistent chat history, aims to boost developer productivity and efficiency."
    },
    {
      "title": "Gemini API 的 URL 上下文工具现已全面推出 (原标题: URL context tool for Gemini API now generally available)",
      "link": "https://developers.googleblog.com/en/url-context-tool-for-gemini-api-now-generally-available/",
      "pubDate": "Sun, 17 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-17T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini API 的 URL 上下文工具现已全面推出\n\n**发布日期：** 2025年8月18日\n\nGoogle 宣布 Gemini API 的 URL 上下文工具现已全面推出，并新增多项功能，可供大规模生产使用。该工具旨在帮助开发者通过提供 URL 来为 Gemini 模型提供额外的上下文信息，从而避免手动上传内容，进而构建更强大、更具上下文感知能力的生成式 AI 应用。\n\n## 核心功能与优势\n\n*   **增强模型上下文理解：** 默认情况下，Gemini 模型拥有静态知识库且无法直接访问互联网。虽然通过 Google Search 进行接地（Grounding）可以实现广泛的实时信息发现，但 URL 上下文工具更进一步，允许模型摄取并理解特定网页的完整内容，而不仅仅是搜索摘要。\n*   **强大的组合：** 结合 Google Search 的发现能力和 URL 上下文工具的深度分析能力，为执行复杂的、多步骤的任务奠定了基础。\n\n## 扩展的内容支持\n\n此次发布显著扩展了 URL 上下文工具支持的上下文内容类型，使其适用于更广泛的应用场景：\n\n*   **PDF 支持：** 现在可以直接提供 PDF 链接。Gemini 不仅能从中提取文本，还能理解表格和整体结构，使报告、论文和手册等内容完全可用于模型接地。\n*   **图像支持：** 工具现在可以处理和分析 PNG、JPEG、BMP 和 WebP 等格式的图像。这利用了 Gemini 的多模态能力来理解视觉信息，为图表、示意图等的分析开辟了新途径。\n*   **网络和数据文件：** 继续稳健支持标准网页（HTML）、结构化数据（JSON、XML、CSV）以及文本文件（纯文本、RTF、CSS、JavaScript）。\n\n## 生产规模就绪\n\nURL 上下文工具已为大规模生产使用做好准备，并更新了限制和定价策略：\n\n*   **可扩展性：** 速率限制现在基于所选的 Gemini 模型，允许更大的规模。\n*   **成本透明：** 费用根据添加到上下文的输入令牌数量收取，按照模型的标准费率计算，确保成本清晰可预测。\n\n## 开启新的用例\n\nURL 上下文工具为开发者开启了广泛的智能体工作流，包括但不限于：\n\n*   **个性化客户互动：** 使用客户的网页信息来接地 AI 聊天代理，使其能提供准确且相关的咨询答案。\n*   **文档比较：** 分析多个报告、文章或 PDF，以识别差异并追踪趋势。\n*   **内容合成与创建：** 结合来自多个源 URL 的信息，生成准确的摘要、博客文章或报告。\n*   **代码与文档分析：** 指向 GitHub 仓库或技术文档，以解释代码、生成设置说明或回答技术问题。\n\n## URL 上下文工具的实际应用\n\n目前已有开发者利用 URL 上下文工具构建了令人惊叹的应用：\n\n*   **Gemini CLI：** 这是一个开源的 AI 代理，允许直接在终端中访问 Gemini。其 `web-fetch` 命令利用 URL 上下文工具，使开发者能够快速轻松地与网页内容交互，例如总结网页、提取关键信息或将其翻译成其他语言。\n\n    ![Gemini CLI 中的 Web fetch 工具](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/web-fetch-tool-gemini-cli.original.png)\n\n*   **Gladly.ai：** 作为一家客户服务平台，Gladly 利用 URL 上下文工具创建高度个性化的客户体验。通过提供客户网站的链接，基于 Gladly AI 平台构建的代理可以访问并理解最新的产品信息、促销活动和支持文章，从而为客户咨询提供更准确和相关的答案。\n\n## 立即开始\n\n开发者可以通过提供的 Python 代码示例开始使用 URL 上下文工具，并可查阅 URL 上下文文档、体验迷你演示应用，或在 Google AI Studio 的“工具”下找到 URL 上下文的开关进行尝试。",
      "shortSummary": "Gemini API 的 URL 上下文工具现已全面推出，使开发者能通过URL而非手动上传来为Gemini模型提供上下文。此工具扩展了对PDF、图片及多种网络和数据文件的支持，增强了模型的上下文感知能力。它已为生产规模应用做好准备，可用于个性化客户互动、文档比较、内容合成和代码分析等多种高级AI应用，结合Google搜索实现深度分析和复杂任务。",
      "translated_title": "Gemini API 的 URL 上下文工具现已全面推出",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/web-fetch-tool-gemini-cli.original.png",
          "alt": "Web fetch tool in Gemini CLI",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "The Gemini API's URL Context tool is now generally available, allowing developers to ground prompts using web content instead of manual uploads. This release expands support to PDFs and images."
    },
    {
      "title": "宣布 Imagen 4 Fast 以及 Imagen 4 系列在 Gemini API 中的普遍可用性 (原标题: Announcing Imagen 4 Fast and the general availability of the Imagen 4 family in the Gemini API)",
      "link": "https://developers.googleblog.com/en/announcing-imagen-4-fast-and-imagen-4-family-generally-available-in-the-gemini-api/",
      "pubDate": "Thu, 14 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-14T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Imagen 4 系列在 Gemini API 中普遍可用\n\nGoogle 近日宣布，其最先进的文本到图像模型 Imagen 4 现已在 Gemini API 和 Google AI Studio 中普遍可用。此次发布标志着文本到图像生成质量的重大飞跃，尤其在文本渲染方面相比之前的模型有了显著改进。\n\n### Imagen 4 系列模型\n\n为了满足不同的创意需求，Imagen 4 系列提供了多种模型，让用户可以在质量、速度和成本之间取得平衡：\n\n*   **Imagen 4 Fast**：\n    *   **特点**：专为速度而设计，是快速图像生成和高吞吐量任务的理想选择。\n    *   **成本**：每张输出图像仅需 0.02 美元，价格亲民。\n*   **Imagen 4**：\n    *   **特点**：旗舰模型，适用于各种高质量图像生成任务，在文本渲染等领域有显著提升。\n*   **Imagen 4 Ultra**：\n    *   **特点**：当创意愿景需要最高水平的细节和严格遵循提示时，Imagen 4 Ultra 能提供高度一致的结果。\n\n### 更高分辨率带来更多细节\n\n为了进一步拓展创意边界，Imagen 4 和 Imagen 4 Ultra 现在支持生成高达 2K 分辨率的图像。这使得创建细节惊人、清晰锐利的视觉效果成为可能，非常适合营销素材或复杂的艺术作品。\n\n### Imagen 4 Fast 实际应用示例\n\n以下是一些使用 Imagen 4 Fast 创建的图像示例，展示了该模型在各种风格和内容上的多功能性：\n\n*   **风景/自然图像**：\n    *   **描述**：黎明时分的壮丽山脉景观，前景是清澈的湖泊，倒映着白雪皑皑的山峰。\n    *   **图片**：\n        ![Imagen 4 Fast demo - landscape](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Imagen-4-fast-demo-landscape.original.png)\n\n*   **四格漫画**：\n    *   **描述**：一个复古风格的四格漫画。第一格显示一只友好的猫坐在 Chromebook 旁边，屏幕上是 https://ai.dev 网站，配文：“Imagen 4 现已普遍可用！” 第二格显示一只狗说：“我们还推出了 Imagen 4 FAST，它以每张图像仅 0.02 美元的价格提供低延迟图像！” 第三格显示猫说：“2K 图像升级也可用！” 第四格显示猫和狗击掌，配文：“立即在 AI Studio 中尝试 Imagen 4！”\n    *   **图片**：\n        ![Imagen 4 Fast demo - four panel comic strip](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-four-panel-comic-strip.original.png)\n\n*   **复古科幻电影海报**：\n    *   **描述**：一张复古科幻电影海报，采用喷绘艺术风格。海报上有一艘细节丰富的宇宙飞船，向右飞过一个充满恒星的深空中的充满活力的星云。飞船的两个引擎发出明亮的蓝色发光轨迹。海报顶部的标题是“SUPER GALACTICA: THE LAST NEBULA”，采用粗体、斜面、金属铬字体，带有阴影。下方副标题“STARFALLS REVENGE”以更简洁、干净的白色字体书写。整个图像具有复古、风化的外观，带有破旧的米白色边框。最底部以小字体写着：“此海报由 AI 创建，此免责声明亦然 :)”。\n    *   **图片**：\n        ![Imagen 4 Fast demo - retro sci-fi movie poster](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-retro-sci-fi-movie-poster.original.png)\n\n### 负责任的 AI\n\n作为对负责任 AI 承诺的一部分，所有由 Imagen 4 系列生成的图像都使用 SynthID 进行了不可察觉的水印处理。Google 鼓励用户查阅官方文档和操作指南，开始使用 Imagen 4 进行创作。",
      "shortSummary": "Google 宣布其先进的文本到图像模型 Imagen 4 及其新推出的 Imagen 4 Fast 已在 Gemini API 和 Google AI Studio 中普遍可用。Imagen 4 系列在图像质量，特别是文本渲染方面有显著提升。Imagen 4 Fast 专为速度和成本效益设计，每张图像仅需 0.02 美元。Imagen 4 和 Imagen 4 Ultra 支持高达 2K 分辨率。所有 Imagen 4 生成的图像都使用 SynthID 进行水印处理，以确保负责任的 AI 应用。",
      "translated_title": "宣布 Imagen 4 Fast 以及 Imagen 4 系列在 Gemini API 中的普遍可用性",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Imagen-4-fast-demo-landscape.original.png",
          "alt": "Imagen 4 Fast demo - landscape",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-four-panel-comic-strip.original.png",
          "alt": "Imagen 4 Fast demo - four panel comic strip",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-retro-sci-fi-movie-poster.original.png",
          "alt": "Imagen 4 Fast demo - retro sci-fi movie poster",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "完整文章",
      "content": "Google announces the general availability of Imagen 4, its advanced text-to-image model, in the Gemini API and Google AI Studio, featuring significant improvements in text rendering. The new Imagen 4 Fast model, designed for speed and rapid image generation, is now available alongside Imagen 4 and Imagen 4 Ultra, with Imagen 4 and Imagen 4 Ultra also supporting up to 2K resolution image generation."
    },
    {
      "title": "介绍 Gemma 3 270M：超高效AI的紧凑型模型 (原标题: Introducing Gemma 3 270M: The compact model for hyper-efficient AI)",
      "link": "https://developers.googleblog.com/en/introducing-gemma-3-270m/",
      "pubDate": "Wed, 13 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-13T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 介绍 Gemma 3 270M：超高效AI的紧凑型模型\n\n**发布日期：** 2025年8月14日\n\nGemma系列开放模型近期发展迅速，继Gemma 3、Gemma 3 QAT和移动优先的Gemma 3n之后，谷歌推出了Gemma 3 270M。这款模型是Gemma 3工具包中的一个高度专业化新成员，旨在为开发者提供构建AI的实用工具，并已助力Gemma系列下载量突破2亿。\n\n### Gemma 3 270M 概览\n\nGemma 3 270M是一个拥有2.7亿参数的紧凑型模型，从头开始设计，专注于任务特定的微调，并内置了强大的指令遵循和文本结构化能力。它在IFEval基准测试中表现出色，为同等规模的模型设立了新的性能标准，使复杂的AI能力在设备端和研究应用中更易于访问。\n\n![Gemma 3 270M](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3-270M_Chart01_RD3-V01.original.jpg)\n\n### 核心能力\n\n1.  **紧凑而强大的架构：**\n    *   总参数：2.7亿（1.7亿嵌入参数，1亿用于Transformer块）。\n    *   大词汇量：25.6万个词元，能够处理特定和罕见的词元，是特定领域和语言微调的强大基础模型。\n\n2.  **极致的能源效率：**\n    *   功耗极低。在Pixel 9 Pro SoC上的内部测试显示，INT4量化模型进行25次对话仅消耗0.75%的电池电量，是Gemma系列中最节能的模型。\n\n3.  **指令遵循能力：**\n    *   发布了经过指令微调的模型和预训练检查点。\n    *   虽然不适用于复杂的对话场景，但它能很好地遵循通用指令。\n\n4.  **生产就绪的量化：**\n    *   提供量化感知训练（QAT）检查点，支持以INT4精度运行模型，性能下降极小，这对于部署在资源受限设备上至关重要。\n\n### “物尽其用”的理念\n\nGemma 3 270M体现了“物尽其用”的工程哲学。它是一个高质量的基础模型，开箱即用就能很好地遵循指令，其真正的力量通过微调得以释放。经过专业化处理后，它能以卓越的准确性、速度和成本效益执行文本分类和数据提取等任务。通过使用紧凑而强大的模型，可以构建精简、快速且运营成本显著降低的生产系统。\n\n### 实际应用案例\n\n*   **Adaptive ML与SK Telecom的合作：** Adaptive ML通过微调Gemma 3 4B模型来应对多语言内容审核的挑战。结果显示，专业化的Gemma模型在特定任务上超越了许多大型专有模型的性能。\n*   **创意应用：** Gemma 3 270M被用于驱动一个基于Transformers.js的睡前故事生成器网络应用。其小巧的尺寸和高性能使其非常适合离线、基于网络的创意任务。\n\n### 何时选择 Gemma 3 270M\n\nGemma 3 270M继承了Gemma 3系列的先进架构和强大的预训练基础，为自定义应用提供了坚实的基础。它是以下场景的理想选择：\n\n*   **高吞吐量、明确定义的任务：** 适用于情感分析、实体提取、查询路由、非结构化到结构化文本处理、创意写作和合规性检查等功能。\n*   **对毫秒和微分成本敏感：** 大幅降低或消除生产中的推理成本，并为用户提供更快的响应。微调后的270M模型可以在轻量级、廉价的基础设施上或直接在设备上运行。\n*   **需要快速迭代和部署：** Gemma 3 270M的小尺寸允许快速进行微调实验，帮助您在数小时而非数天内找到适合您用例的完美配置。\n*   **需要确保用户隐私：** 由于模型可以完全在设备上运行，您可以构建处理敏感信息的应用程序，而无需将数据发送到云端。\n*   **需要一系列专业化任务模型：** 可以在不超出预算的情况下，构建和部署多个自定义模型，每个模型都经过专业训练以执行不同的任务。\n\n### 开始微调\n\nGemma 3 270M与Gemma 3系列其他模型采用相同架构，并提供快速入门的指南和工具。您可以在Gemma文档中找到使用Gemma 3 270M进行完整微调的指南。\n\n*   **下载模型：** 可从Hugging Face、Ollama、Kaggle、LM Studio或Docker获取预训练和指令微调模型。\n*   **试用模型：** 可在Vertex AI或使用llama.cpp、Gemma.cpp、LiteRT、Keras和MLX等流行推理工具进行试用。\n*   **开始微调：** 使用Hugging Face、UnSloth和JAX等您喜欢的工具。\n*   **部署解决方案：** 微调完成后，您可以将专业化模型部署到任何地方，从本地环境到Google Cloud Run。\n\nGemmaverse的理念是创新无大小。通过Gemma 3 270M，谷歌赋能开发者构建更智能、更快、更高效的AI解决方案。",
      "shortSummary": "Gemma 3 270M是谷歌推出的一款紧凑型、2.7亿参数的AI模型，专为任务特定微调设计。它具备强大的指令遵循能力和极高的能源效率，可在设备端运行，大幅降低推理成本并保护用户隐私。该模型非常适合需要高效率、快速迭代和专业化AI解决方案的场景，使先进AI更易于部署和访问，推动创新。",
      "translated_title": "介绍 Gemma 3 270M：超高效AI的紧凑型模型",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3-270M_Chart01_RD3-V01.original.jpg",
          "alt": "Gemma 3 270M",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Google's new Gemma 3 270M is a compact, 270-million parameter model offering energy efficiency, production-ready quantization, and strong instruction-following, making it a powerful solution for task-specific fine-tuning in on-device and research settings."
    },
    {
      "title": "Gemini CLI + VS Code：原生差异比较和上下文感知工作流 (原标题: Gemini CLI + VS Code: Native diffing and context-aware workflows)",
      "link": "https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/",
      "pubDate": "Tue, 12 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini CLI + VS Code：原生差异比较和上下文感知工作流\n\nGemini CLI 的最新更新为 VS Code 带来了更深层次的集成，旨在提升开发者的命令行应用体验。此次更新将智能功能直接引入 VS Code 集成终端，通过理解上下文并提供即时建议，彻底改变了开发者与项目互动的方式。\n\n## 新特性：更深层次的集成\n\n此次更新从根本上改变了 Gemini CLI 与编辑器的交互方式，使开发工作流更加流畅高效。\n\n*   **工作区与选择上下文感知**\n    当 VS Code IDE 连接到 Gemini CLI 时，CLI 可以直接访问您的工作区。它能够感知您打开的文件并访问选定的文本。这使得 CLI 能够提供有针对性且与上下文相关的建议，因为它能准确理解您当前正在处理的内容。\n\n*   **原生编辑器内差异比较 (Native In-editor Diffing)**\n    Gemini CLI 的建议现在可以直接在 VS Code 内部触发全屏差异比较视图。这提供了全面的并排更改审查。至关重要的是，您可以在接受更改之前直接在此差异视图中修改代码，从而获得完全的控制和灵活性。\n\n## 如何开始\n\n准备好体验了吗？设置过程非常简单。\n\n1.  **先决条件**\n    *   Gemini CLI 版本 0.1.20 或更高。\n    *   在 VS Code 的集成终端中运行 CLI。\n\n2.  **一次性设置**\n    在您的集成终端中运行 `/ide install` 命令，以安装必要的配套扩展。\n\n3.  **切换集成状态**\n    完成一次性设置后，您可以轻松管理集成：\n    *   激活：运行 `/ide enable`\n    *   停用：运行 `/ide disable`\n\n立即启用 IDE 集成，体验使用 Gemini CLI 和 VS Code 构建项目的新方式。",
      "shortSummary": "Gemini CLI 最新更新深度集成 VS Code，提供智能、上下文感知的开发体验。核心功能包括：CLI 直接访问工作区和选定文本，实现精准建议；以及原生编辑器内全屏差异比较，允许直接修改代码。用户需满足版本要求并在VS Code终端运行`/ide install`进行一次性设置，随后可轻松启用或禁用集成，大幅提升开发效率和控制力。",
      "translated_title": "Gemini CLI + VS Code：原生差异比较和上下文感知工作流",
      "images": [],
      "contentSource": "完整文章",
      "content": "The latest Gemini CLI update provides a deep IDE integration within VS Code for intelligent, context-aware suggestions, and native in-editor diffing, allowing developers to review and modify proposed changes directly within the diff view for a more efficient workflow."
    },
    {
      "title": "认识Jules最犀利的批评者和最有价值的盟友 (原标题: Meet Jules’ sharpest critic and most valuable ally)",
      "link": "https://developers.googleblog.com/en/meet-jules-sharpest-critic-and-most-valuable-ally/",
      "pubDate": "Mon, 11 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-11T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Jules AI 编码代理的新“批评者”功能\n\n## 介绍\nJules 是一款 AI 编码代理，能够构建、重构和搭建代码，让开发者专注于其他任务。然而，这种便利性有时会导致细微的错误、遗漏的边缘情况和未经测试的假设。为了解决这些问题，Jules 引入了一项新功能——“批评者”（critic），它能在代码提交给用户之前对其进行审查和批判。\n\n## 批评者的角色与“批评者增强生成”\n“批评者”功能简单而强大：当 Jules 构建代码时，批评者会对其提出质疑。每一个提议的更改在完成之前都会经过对抗性审查。可以把批评者看作 Jules 的同行评审员，它深入了解代码质量原则，并敢于指出潜在的问题，例如重复发明了有风险的轮子。\n\n这项功能直接集成到代码生成过程中，被称为“批评者增强生成”（critic-augmented generation）。在当前版本中，它是一个一次性过程，在单个通道中评估最终输出。未来的里程碑目标是使其成为一个真正的多步骤代理，能够使用工具调用，或在子任务之后、规划之前触发。目前，它一次性审查完整的生成内容。这将借鉴多步骤研究，其中批评者使用外部工具（如代码解释器或搜索引擎）验证输出，并从结果中学习。\n\n## 批评者的具体作用\n批评者不直接修复代码，而是标记出问题，然后将其反馈给 Jules 进行改进。例如：\n*   一个通过所有测试但引入了微妙逻辑错误的补丁：批评者会指出“输出符合预期情况，但在未见输入上失败。”\n*   一个能编译但默默丢弃了所需字段的更改：批评者会指出“函数签名已更新，但未处理所有参数。”\n*   一个能工作但使用了低效方法的代码：批评者会指出“算法产生正确结果，但具有不必要的 O(n²) 复杂度。”\n\n由于此过程发生在补丁生成之后和提交之前（如果仍有问题，可能会多次进行），Jules 可以实时重新规划。我们的目标是减少低质量的拉取请求（PRs），提高测试覆盖率，增强安全性。\n\n## 与传统工具的区别\n批评者功能与传统的代码检查工具（如 Linter）和测试不同：\n*   **Linter**：遵循浅层、固定的规则。\n*   **测试**：验证特定的断言。\n*   **批评者**：理解代码背后的意图和上下文。它更接近于一种无参考评估方法，在不需要黄金标准实现的情况下判断代码的正确性和健壮性。\n\n它还借鉴了“LLM-as-a-judge”（大语言模型作为评判者）的研究，即一个模型评估另一个模型的工作质量和正确性。这种自动化评判与生成过程紧密集成时特别有用，能将审查转化为实时的反馈循环。\n\n## 工作流程\n批评者功能的工作流程如下：\n1.  用户提示 Jules 开始一项任务。\n2.  批评者功能在单个通道中审查候选补丁及其描述，并做出总体判断。\n3.  Jules 根据反馈进行响应，在完成之前进行改进。之后，批评者可以再次审查更新后的补丁，并继续标记任何它认为必要的问题，直到不再存在问题。\n4.  用户收到已经过内部审查的代码。\n\n这借鉴了“行动者-批评者”（actor-critic）强化学习（RL）的原理，其中“行动者”生成，“批评者”评估。在 RL 中，这个循环根据学习信号更新行动者和批评者。在我们的“LLM-as-critic”设置中，模式类似：提出，然后评估。然而，反馈不是更新学习参数，而是影响当前状态和下一步行动。同样的原则也支撑着“LLM-as-a-judge”的研究，其中批评者的评估在不重新训练的情况下指导质量。\n\n## 重要性\n在快速迭代的世界中，批评者将审查过程提前，并融入到生成行为本身。这意味着用户审查的代码已经过内部的质询、完善和压力测试。当然，用户在使用前仍应仔细审查生成的代码。\n\n优秀的开发者不仅编写代码，他们还会质疑代码。现在，Jules 也能做到。",
      "shortSummary": "Jules AI编码代理推出一项“批评者”功能，在用户看到代码前对其进行审查。该功能作为Jules的同行评审员，能识别并标记AI生成代码中的细微错误、低效或逻辑问题。Jules会根据批评者的反馈实时重构代码，以提高质量、测试覆盖率和安全性。它不同于传统Linter或测试，能理解代码意图和上下文，借鉴了“LLM作为评判者”的理念。最终，用户将获得经过内部审查、更高质量的代码。",
      "translated_title": "认识Jules最犀利的批评者和最有价值的盟友",
      "images": [],
      "contentSource": "完整文章",
      "content": "Jules' critic functionality addresses potential issues like subtle bugs and missed edge cases in AI-generated code by acting as a peer reviewer within the generation process. This \"critic-augmented generation\" means proposed code changes undergo adversarial review, allowing Jules to improve its output and ultimately deliver higher-quality, pre-reviewed code."
    },
    {
      "title": "使用JAX在TPU上免费训练GPT2模型 (原标题: Train a GPT2 model with JAX on TPU for free)",
      "link": "https://developers.googleblog.com/en/train-gpt2-model-with-jax-on-tpu/",
      "pubDate": "Mon, 11 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-11T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 使用JAX在TPU上免费训练GPT2模型\n\n本文旨在指导读者如何使用JAX从零开始构建和预训练一个GPT-2模型，并利用Google的TPU资源（可在Colab或Kaggle上免费使用）。文章基于Cloud Next 2025的一次研讨会内容，假设读者对机器学习概念有基本了解，并为JAX新手提供了入门指南。\n\n### JAX生态系统概述\n\nJAX生态系统采用模块化方法，其核心提供强大的数值处理能力，并在此基础上构建了丰富的库以满足不同应用需求：\n*   **Flax**：用于构建神经网络（本文使用其新接口NNX）。\n*   **Orbax**：用于检查点和模型持久化。\n*   **Optax**：用于优化算法。\n\nJAX的内置函数转换（如自动求导、向量化和JIT编译）、卓越的性能以及易用的API使其成为训练大型语言模型（LLM）的理想选择。\n\n### 构建GPT-2模型\n\n文章参考了OpenAI发布的GPT-2模型代码和权重，以及社区项目如nanoGPT。\n\n**GPT-2模型架构图：**\n![GPT-2模型架构图](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_N4168XT.original.png)\n\n本文使用NNX来构建GPT-2模型，重点关注其核心组件——Transformer Block。Transformer Block能够捕捉序列中的长距离依赖并建立丰富的上下文理解。一个GPT-2 Transformer Block包含：\n*   2个LayerNorm层\n*   1个多头注意力（Multi-Head Attention, MHA）层\n*   2个Dropout层\n*   2个线性投影层\n*   2个残差连接\n\n文章提供了`TransformerBlock`类的`__init__`和`__call__`函数的Python代码示例，展示了如何定义和组装这些层。JAX的一大优势是其通过SPMD（单程序多数据）自动并行运行代码的能力，这对于在多个TPU核心上运行代码至关重要。\n\n为了使用TPU，读者需要在Colab或Kaggle中选择TPU运行时，或使用Cloud TPU VM。免费的Colab和Kaggle通常提供8个独立TPU核心的TPU v2或v3。\n\n**TPU v3板图：**\n![TPU v3板图](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_PYQXoSD.original.png)\n\n### 训练GPT-2模型\n\n为了高效训练GPT-2模型，文章利用SPMD和JAX的数据并行性。关键步骤包括：\n\n1.  **定义硬件网格（Mesh）**：使用`jax.make_mesh((8, 1), ('batch', 'model'))`定义一个8个核心的2D加速器网格，包含'batch'和'model'轴，用于数据和模型参数的分区。\n2.  **模型参数分区**：在`TransformerBlock`的`__init__`函数中，通过`nnx.with_partitioning`指示JAX如何沿'model'轴分片模型参数（例如，LayerNorm的尺度/偏差张量和MHA/线性层的核张量）。这为未来的模型张量并行化奠定了基础。\n3.  **损失函数与训练步骤**：\n    *   `loss_fn`：计算交叉熵损失。\n    *   `train_step`：计算损失梯度并通过优化器更新权重。\n    *   这两个计算密集型函数都使用`@nnx.jit`装饰器进行JIT编译，以实现最佳性能。\n4.  **优化器配置**：使用Optax库中的AdamW优化器，并结合余弦衰减学习率调度。\n5.  **训练循环**：\n    *   在训练循环中，通过`jax.device_put`函数将输入数据沿'batch'轴分区，实现数据并行。\n    *   JAX会自动插入通信集合操作（如AllReduce），并尽可能重叠计算与通信。\n\n**GPT-2 124M模型测试运行图：**\n![GPT-2 124M模型测试运行图](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_yIkuQBk.original.png)\n\n训练过程可以通过Weights and Biases进行监控。在Kaggle TPU v3上训练GPT-2 124M模型大约需要7小时，而在Trillium上则可缩短至约1.5小时（Trillium具有更大的HBM，允许更大的批次大小）。最终损失与nanoGPT的基线结果大致一致。\n\n**nanoGPT基线比较表：**\n![nanoGPT基线比较表](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/nanoGPT-baseline-comparison-table_FgWDn7b.original.png)\n\n此外，还可以通过`tpu-info`命令或Weights and Biases仪表板监控TPU利用率。\n\n**‘tpu-info’命令输出图：**\n![‘tpu-info’命令输出图](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_MzgrJxz.original.png)\n\n模型训练完成后，可以使用Orbax的`PyTreeCheckpointer`保存模型状态。\n\n### 后续步骤\n\n完整的代码笔记本包含了数据加载、超参数和指标等更多细节。虽然GPT-2在今天看来是一个小型模型，但本文所学知识为读者进一步探索大型语言模型训练和扩展奠定了基础。读者可以参考“How to scale your model”指南，或使用MaxText训练前沿LLM，亦可参考JAX LLM示例或Stanford Marin模型从头构建最新模型。",
      "shortSummary": "本文指导读者如何使用JAX在免费TPU（Colab/Kaggle）上从零开始构建和预训练GPT-2模型。文章介绍了JAX生态系统及其核心库（Flax、Orbax、Optax），并详细展示了如何使用NNX构建GPT-2的Transformer Block。通过JAX的SPMD和数据并行性，文章解释了如何在多TPU核心上高效训练模型，包括参数分区、优化器配置和训练循环。最终模型性能与nanoGPT相当，并提供了进一步扩展大型语言模型的方向。",
      "translated_title": "使用JAX在TPU上免费训练GPT2模型",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_N4168XT.original.png",
          "alt": "architecture diagram for the GPT2 model",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_PYQXoSD.original.png",
          "alt": "TPU v3 board",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_yIkuQBk.original.png",
          "alt": "test run for the GPT2 124M model",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/nanoGPT-baseline-comparison-table_FgWDn7b.original.png",
          "alt": "nanoGPT baseline comparison table",
          "title": "",
          "position": 4
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_MzgrJxz.original.png",
          "alt": "‘tpu-info’ command",
          "title": "",
          "position": 5
        }
      ],
      "contentSource": "完整文章",
      "content": "Build and train a GPT2 model from scratch using JAX on Google TPUs, with a complete Python notebook for free-tier Colab or Kaggle. Learn how to define a hardware mesh, partition model parameters and input data for data parallelism, and optimize the model training process."
    },
    {
      "title": "Google 开发者计划正在演进 (原标题: The Google Developer Program is evolving)",
      "link": "https://developers.googleblog.com/en/google-developer-program-join-connect-code/",
      "pubDate": "Thu, 31 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-31T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Google 开发者计划正在演进\n\nGoogle 于2025年8月1日宣布了Google开发者计划的最新进展，旨在通过强大的AI工具和资源，帮助开发者更快、更智能地进行构建。此次更新引入了多项增强功能，以更深入地融入开发者工作流程，并连接他们所需的专业知识。\n\n## 访问 Google AI 工具的更大灵活性\n\n为了让高级资源更易于访问，Google 推出了 Google 开发者计划月度订阅计划，费用为每月 24.99 美元*。该计划提供所有 AI 增强型高级福利，包括：\n*   用于 Vertex AI 和 Google AI Studio 的 Google Cloud 积分。\n*   Gemini Code Assist Standard。\n*   30 个 Firebase Studio 工作区，用于将全栈应用程序投入生产。\n*   以及更多其他福利。\n\n开发者可以通过新的福利仪表板轻松激活所有福利。\n\n![Google Developer Program pricing](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-pricing.original.png)\n![Google Developer Program benefits](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-benefits.original.png)\n\n*注：Google 开发者计划月度订阅计划目前仅在美国可用，未来几周将推广到其他国家。\n\n## 统一的协作中心：Google 开发者计划论坛\n\nGoogle 还推出了新的 Google 开发者计划论坛，网址为 `discuss.google.dev`。这个新平台将开发者的 Google 开发者计划资料、社区和兴趣整合在一起，使得提问、分享知识、与同行联系、寻求错误帮助以及分享发现变得更加容易。\n\n现有的 Google Cloud、Workspace Developer、AppSheet 和 Looker 社区及其所有历史内容和讨论已迁移到这个新的中心论坛。\n\n![Google Developer Program forums](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-forums.original.png)\n\n## 加速您的 AI 之旅：加入 Google Cloud & NVIDIA 社区\n\n在 Google I/O 大会上，Google 宣布了新的 Google Cloud & NVIDIA 社区，专为有兴趣在 Google Cloud 上利用 NVIDIA 尖端技术的实践者而建。社区成员可以获得独家学习路径，例如亲身体验 GKE 和 NVIDIA NIM 进行 AI 推理任务。此外，在完成学习路径后，限时可获得 Google Cloud 积分。\n\n未来几周将推出新的学习路径。\n\n![Accelerate your AI journey: Join the Google Cloud & NVIDIA community](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-cloud-nvidia-community-google-developer-.original.png)\n\n## 立即开始\n\n无论开发者是寻求更灵活的工具访问方式，渴望与社区建立更紧密的联系，还是希望通过 AI 提升生产力，Google 开发者计划都能提供相应支持。访问 `developers.google.com/program` 了解更多信息并探索您的 Google 开发者计划福利。",
      "shortSummary": "Google 开发者计划于2025年8月1日宣布重大演进，旨在通过AI工具赋能开发者。核心更新包括：推出每月24.99美元的月度计划（美国），提供Google Cloud积分、Gemini Code Assist等高级AI福利；上线统一的Google开发者计划论坛（discuss.google.dev），整合现有社区；以及成立Google Cloud & NVIDIA社区，提供AI学习路径和积分。这些举措旨在提供更灵活的工具访问、更强的社区连接和AI驱动的生产力提升。",
      "translated_title": "Google 开发者计划正在演进",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-pricing.original.png",
          "alt": "Google Developer Program pricing",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-benefits.original.png",
          "alt": "Google Developer Program benefits",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-forums.original.png",
          "alt": "Google Developer Program forums",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-cloud-nvidia-community-google-developer-.original.png",
          "alt": "Accelerate your AI journey: Join the Google Cloud & NVIDIA community",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "The Google Developer Program is rolling out major updates to make its tools and community more accessible and powerful. These enhancements include a new flexible monthly subscription tier, a centralized GDP Forum for collaboration, and increased Gemini CLI access for all members."
    },
    {
      "title": "Veo 3 Fast 和新的图像到视频功能 (原标题: Veo 3 Fast and new image-to-video capabilities)",
      "link": "https://developers.googleblog.com/en/veo-3-fast-image-to-video-capabilities-now-available-gemini-api/",
      "pubDate": "Wed, 30 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-30T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Veo 3 Fast 和新的图像到视频功能发布\n\n### 发布概览\n\n*   **日期：** 2025年7月31日\n*   **核心内容：** 在Veo 3发布后，谷歌现推出Veo 3 Fast模型，并为Veo 3和Veo 3 Fast引入了图像到视频（image-to-video）功能。\n*   **可用性：** 这两款模型及其图像到视频功能均已通过Gemini API提供付费预览。\n\n### Veo 3 Fast：更快、更高效的模型\n\nVeo 3 Fast是Veo 3的优化版本，旨在提高速度和降低成本，使开发者能够更快地迭代，同时高效地生成高质量输出。\n\n*   **主要特点：**\n    *   比Veo 3更快、更具成本效益。\n    *   支持文本到视频（text-to-video）和图像到视频（image-to-video）两种模式。\n    *   在优化速度和业务用例的同时，保持高质量视频输出（含音频）。\n*   **理想应用场景：**\n    *   **程序化广告：** 为自动生成广告创意的后端服务提供支持。\n    *   **快速原型设计：** 快速进行不同创意概念的A/B测试。\n    *   **规模化内容创作：** 构建需要快速生产社交媒体内容的应用程序。\n*   **定价：** 0.40美元/秒（含音频）。\n\n### 新的图像到视频功能\n\n开发者现在可以使用Veo 3和Veo 3 Fast，通过输入图像生成高质量的视频内容（含音频）。这项新功能能够将静态图像转换为动态视频片段，同时保持内容的一致性。\n\n*   **操作方式：**\n    *   只需提供一张图像和文本提示，即可引导模型实现所需的动作、叙事和音频。\n*   **定价：** 图像到视频的输出定价与文本到视频的输出相同（Veo 3为0.75美元/秒，含音频）。\n*   **主要优势：**\n    *   **高质量视频生成：** 从单张图像创建流畅、电影级的视频，保持风格一致性和细节，并包含音频。\n    *   **精确提示：** 结合图像输入和描述性文本提示，精确指导视频内容的动作、风格和演变。\n    *   **无缝API集成：** 通过直观的Gemini API访问此强大新功能，易于集成到现有工作流程和应用程序中。\n\n### 实际应用案例：OpusClip\n\nOpusClip利用Veo 3的图像到视频功能，增强客户的视频编辑体验并生成B-roll视频。Veo 3能够将静态图像作为第一帧，通过生成流畅、电影般的运动使其生动起来，帮助创作者以最小的努力获得引人入胜的视频内容。\n\n### 展望与行动\n\n谷歌对开发者将利用Veo 3、Veo 3 Fast和通过Gemini API提供的图像到视频功能创造出什么感到非常兴奋。鼓励开发者查阅Gemini API视频生成文档或Veo食谱，立即开始构建。",
      "shortSummary": "谷歌推出了Veo 3 Fast模型，该模型针对速度和成本进行了优化，并为Veo 3和Veo 3 Fast引入了新的图像到视频功能。Veo 3 Fast更快速、经济，适用于程序化广告、快速原型设计和规模化内容创作。图像到视频功能允许用户将静态图像转换为高质量、连贯的动态视频，并可通过文本提示进行精确控制。这两项功能均已通过Gemini API提供付费预览。",
      "translated_title": "Veo 3 Fast 和新的图像到视频功能",
      "images": [],
      "contentSource": "完整文章",
      "content": "Google introduces Veo 3 Fast, an optimized model for speed and price, along with new image-to-video capabilities for both Veo 3 and Veo 3 Fast, enabling developers to efficiently create high-quality video content from text or still images, with varying pricing based on the model and audio inclusion, now available in the Gemini API."
    },
    {
      "title": "介绍 LangExtract：一个由 Gemini 驱动的信息提取库 (原标题: Introducing LangExtract: A Gemini powered information extraction library)",
      "link": "https://developers.googleblog.com/en/introducing-langextract-a-gemini-powered-information-extraction-library/",
      "pubDate": "Tue, 29 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-29T16:00:00.000Z",
      "creator": "Google",
      "summary": "LangExtract 简介\n\n在当今数据丰富的世界中，有价值的洞察常常隐藏在非结构化文本中，例如详细的临床笔记、冗长的法律文件、客户反馈和新闻报道。手动筛选或构建定制代码来处理这些数据既耗时又容易出错，而简单地使用现代大型语言模型（LLMs）可能会引入错误。为了解决这一挑战，LangExtract 应运而生。\n\nLangExtract 概述\n\nLangExtract 是一个新推出的开源 Python 库，旨在帮助开发者以编程方式提取所需的确切信息，同时确保输出结构化并可靠地追溯到其来源。它为各种 LLM（如 Gemini 模型）提供了一个轻量级接口，用于根据自定义指令将大量非结构化文本处理成结构化信息，确保灵活性和可追溯性。\n\n核心功能与优势\n\nLangExtract 提供了一系列独特的功能，使其在信息提取方面非常有用：\n\n*   **精确源定位**：每个提取的实体都被映射回其在源文本中的精确字符偏移量。这提供了可追溯性，通过在原始文本中视觉高亮显示每次提取，使得评估和验证提取的信息变得更加容易。\n*   **可靠的结构化输出**：用户可以使用 LangExtract 的数据表示定义所需的输出，并提供“少量示例”（few-shot examples）。LangExtract 利用这些示例来强制执行模式，并利用 Gemini 等支持模型中的“受控生成”（Controlled Generation）功能，确保输出始终保持结构化。\n*   **优化长上下文信息提取**：从大型文档中检索信息可能很复杂。LangExtract 通过采用分块策略、并行处理和对更小、更集中的上下文进行多次提取，来处理这一问题，从而提高多事实检索场景中的召回率。\n*   **交互式可视化**：LangExtract 可以在几分钟内将原始文本转换为交互式、自包含的 HTML 可视化，方便用户在上下文中审查提取的实体，并支持探索数千个注释。\n*   **灵活支持 LLM 后端**：用户可以使用他们偏好的模型，无论是基于云的 LLM（如 Google 的 Gemini 系列）还是开源的设备端模型。\n*   **跨领域灵活性**：只需几个精心选择的示例，即可为任何领域定义信息提取任务，无需对 LLM 进行微调。LangExtract 可以“学习”用户所需的输出，并将其应用于大量新的文本输入。\n*   **利用 LLM 世界知识**：除了提取有根据的实体外，LangExtract 还可以利用模型的“世界知识”来补充提取的信息。这些信息可以是明确的（即源自源文本）或推断的（即源自模型的固有世界知识）。此类补充知识的准确性和相关性，特别是推断出的知识，很大程度上受所选 LLM 能力和引导提取的提示示例的精确性影响。\n\n快速入门示例 (莎士比亚)\n\nLangExtract 提供了一个简单的流程来从文本中提取信息：\n\n1.  **安装库**：通过 `pip install langextract` 命令进行安装。\n2.  **定义提取任务**：提供清晰的提示和高质量的“少量示例”来指导模型。\n3.  **运行提取**：使用 `lx.extract()` 函数对输入文本执行提取。\n4.  **保存与可视化**：将结果保存到 JSONL 文件，然后生成交互式 HTML 文件以查看注释。这种可视化功能非常适合演示或评估提取质量。\n\n专业领域应用\n\nLangExtract 的核心思想最初应用于医疗信息提取，并能有效处理临床文本，例如识别药物、剂量及其属性，并映射它们之间的关系。这一能力是促成该库研究的核心部分。\n\n为了展示 LangExtract 在专业领域的强大功能，开发团队还在 Hugging Face 上开发了一个名为 RadExtract 的交互式结构化放射学报告演示。该演示展示了 LangExtract 如何处理自由文本的放射学报告，并自动将其关键发现转换为结构化格式，同时突出重要发现。这种方法在放射学中非常重要，因为结构化报告可以增强清晰度、确保完整性并改善研究和临床护理的数据互操作性。\n\n**免责声明**：上述药物提取示例和结构化报告演示仅用于说明 LangExtract 的基本功能。它们不代表已完成或批准的产品，不用于诊断或建议任何疾病或状况的治疗，也不应用于医疗建议。\n\n资源与下一步\n\nLangExtract 团队期待看到开发者如何利用 LangExtract 从文本中解锁洞察。用户可以深入研究文档，探索 GitHub 存储库中的示例，并立即开始转换非结构化数据。",
      "shortSummary": "LangExtract 是一个由 Gemini 驱动的新型开源 Python 库，旨在帮助开发者从非结构化文本中高效提取结构化信息。它利用大型语言模型（如 Gemini）和少量示例，确保输出的精确性、可追溯性和结构化。该库能优化长上下文信息提取，灵活支持多种 LLM 后端，并适用于不同领域。LangExtract 还提供交互式可视化功能，简化了从文本中获取洞察的过程，尤其适用于医疗、金融等专业领域。",
      "translated_title": "介绍 LangExtract：一个由 Gemini 驱动的信息提取库",
      "images": [],
      "contentSource": "完整文章",
      "content": "LangExtract is a new open-source Python library powered by Gemini models for extracting structured information from unstructured text, offering precise source grounding, reliable structured outputs using controlled generation, optimized long-context extraction, interactive visualization, and flexible LLM backend support."
    }
  ],
  "lastUpdated": "2025-08-24T10:27:17.285Z"
}
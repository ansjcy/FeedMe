{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "Unlocking Peak Performance on Qualcomm NPU with LiteRT",
      "link": "https://developers.googleblog.com/en/unlocking-peak-performance-on-qualcomm-npu-with-litert/",
      "pubDate": "Sun, 23 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Unlocking Peak Performance on Qualcomm NPU with LiteRT",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/GPU_NPU_pipeline.original.png",
          "alt": "GPU_NPU_pipeline",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/LiteRT_NPU_and_GPU_latency_relative_to_CPU_1.original.png",
          "alt": "LiteRT NPU and GPU latency relative to CPU (1)",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/FastVLM_table_new.original.png",
          "alt": "FastVLM_table_new",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "RSS",
      "content": "LiteRT's new Qualcomm AI Engine Direct (QNN) Accelerator unlocks dedicated NPU power for on-device GenAI on Android. It offers a unified mobile deployment workflow, SOTA performance (up to 100x speedup over CPU), and full model delegation. This enables smooth, real-time AI experiences, with FastVLM-0.5B achieving over 11,000 tokens/sec prefill on Snapdragon 8 Elite Gen 5 NPU."
    },
    {
      "title": "Build with Google Antigravity, our new agentic development platform",
      "link": "https://developers.googleblog.com/en/build-with-google-antigravity-our-new-agentic-development-platform/",
      "pubDate": "Wed, 19 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-19T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Build with Google Antigravity, our new agentic development platform",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/AGYBlogHero.original.png",
          "alt": "AGYBlogHero",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/editor-open-agent-manager.original.png",
          "alt": "editor-open-agent-manager",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/settings-review-policy-manual.original.png",
          "alt": "settings-review-policy-manual",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "RSS",
      "content": "Introducing Google Antigravity, a new agentic development platform for orchestrating code. It combines an AI-powered Editor View with a Manager Surface to deploy agents that autonomously plan, execute, and verify complex tasks across your editor, terminal, and browser. Agents communicate progress via Artifacts (screenshots, recordings) for easy verification. Available now in public preview."
    },
    {
      "title": "Building AI Agents with Google Gemini 3 and Open Source Frameworks",
      "link": "https://developers.googleblog.com/en/building-ai-agents-with-google-gemini-3-and-open-source-frameworks/",
      "pubDate": "Tue, 18 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-18T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Building AI Agents with Google Gemini 3 and Open Source Frameworks",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/langchain.original.png",
          "alt": "langchain",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ai-sdk.original.png",
          "alt": "ai-sdk",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_vCYoxzo.original.png",
          "alt": "LlamaIndex",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/pydantic-ai.original.png",
          "alt": "pydantic-ai",
          "title": "",
          "position": 4
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/n8n.original.png",
          "alt": "n8n",
          "title": "",
          "position": 5
        }
      ],
      "contentSource": "RSS",
      "content": "Gemini 3 Pro Preview is introduced as a powerful, agentic model for complex, (semi)-autonomous workflows. New agentic features include `thinking_level` for reasoning control, Stateful Tool Use via Thought Signatures, and `media_resolution` for multimodal fidelity. It has Day 0 support for open-source frameworks like LangChain, AI SDK, LlamaIndex, Pydantic AI, and n8n. Best practices include simplifying prompts and keeping temperature at 1.0."
    },
    {
      "title": "Building production AI on Google Cloud TPUs with JAX",
      "link": "https://developers.googleblog.com/en/building-production-ai-on-google-cloud-tpus-with-jax/",
      "pubDate": "Tue, 18 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-18T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Building production AI on Google Cloud TPUs with JAX",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/JAX_logo.original.jpg",
          "alt": "JAX logo",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/JAX_ecosystem.original.jpg",
          "alt": "JAX_ecosystem",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "The JAX AI Stack is a modular, industrial-grade, end-to-end machine learning platform built on the core JAX library, co-designed with Cloud TPUs. It features key components like JAX, Flax, Optax, and Orbax for foundational model development, plus an extended ecosystem for the full ML lifecycle and production. This integration provides a powerful, scalable foundation for AI development, delivering significant performance advantages."
    },
    {
      "title": "Building with Gemini 3 in Jules",
      "link": "https://developers.googleblog.com/en/jules-gemini-3/",
      "pubDate": "Tue, 18 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-18T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Building with Gemini 3 in Jules",
      "images": [],
      "contentSource": "RSS",
      "content": "Jules, an always-on, multi-step software development agent, now features Gemini 3, offering clearer reasoning and better reliability. Recent improvements include parallel CLI runs, a stable API, and safer Git handling. Upcoming features include directory attachment without GitHub and automatic PR creation. Jules aims to reduce software writing overhead so developers can focus on building."
    },
    {
      "title": "5 things to try with Gemini 3 Pro in Gemini CLI",
      "link": "https://developers.googleblog.com/en/5-things-to-try-with-gemini-3-pro-in-gemini-cli/",
      "pubDate": "Mon, 17 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-17T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "5 things to try with Gemini 3 Pro in Gemini CLI",
      "images": [],
      "contentSource": "RSS",
      "content": "Gemini 3 Pro is now integrated into Gemini CLI, unlocking state-of-the-art reasoning, agentic coding, and advanced tool use for enhanced developer productivity. It's available now for Google AI Ultra and paid Gemini API key subscribers (upgrade CLI to 0.16.x). Features include generating 3D apps and code from visual sketches, running complex shell commands, creating documentation, and debugging live Cloud Run services."
    },
    {
      "title": "推出 Code Wiki：加速你的代码理解 (原标题: Introducing Code Wiki: Accelerating your code understanding)",
      "link": "https://developers.googleblog.com/en/introducing-code-wiki-accelerating-your-code-understanding/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Code Wiki：加速你的代码理解\n\nGoogle Cloud 的产品管理总监 Fergus Hurley、高级工程经理 Pedro Rodriguez 和产品经理 Rafael Marques 共同宣布推出 Code Wiki。该平台旨在解决软件开发中阅读现有代码这一最大且最昂贵的瓶颈，通过为代码仓库维护一个持续更新、结构化的维基来显著提高开发人员的生产力。\n\n## 理解代码的新方式\n\nCode Wiki 的核心使命是组织并解锁复杂源代码中蕴藏的关键知识，使文档保持“鲜活”和实用。它通过以下关键特性实现这一目标：\n\n*   **自动化且始终最新**：Code Wiki 扫描整个代码库，并在每次代码更改后自动重新生成文档，确保文档与代码的演进保持同步。\n*   **智能且上下文感知**：整个、始终最新的维基作为集成聊天（由 Gemini 提供支持）的知识库。用户可以与一个深入了解整个仓库的特定模型进行对话，而非通用模型，从而获得高度相关的答案。\n*   **集成且可操作**：维基的每个部分和聊天回答都直接超链接到相关的代码文件和定义，将代码的阅读和探索无缝整合到一个工作流程中。\n\n## Code Wiki 网站（公开预览版）\n\nCode Wiki 网站现已推出公开预览版，这是基于新系统构建的首个产品。它能够摄取公共仓库，并为每个仓库生成、托管并维护全面且交互式的文档。通过 Code Wiki 网站，用户可以：\n\n*   **交互式导航**：从高层概念解释直接跳转到引用的具体代码文件、类和函数，实现高效的代码探索。\n*   **Gemini 驱动的聊天代理**：当遇到复杂模块时，用户可以向使用最新维基作为上下文的 Gemini 聊天代理提问，即时获得关于仓库的特定问题的答案，弥合学习代码与实际探索代码之间的鸿沟。\n*   **自动生成图表**：当文本不足以解释复杂关系时，Code Wiki 会自动生成始终最新的架构图、类图和序列图，帮助用户可视化与代码当前状态完全匹配的复杂关系。\n\n![Gemini CLI Code Wiki v2](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_CLI_Code_Wiki_v2.original.png)\n\n这种由 AI 驱动、自动化、智能且集成的方法是解决代码理解瓶颈的关键。它能让新贡献者在第一天就提交他们的第一个代码，并让资深开发人员在几分钟而非几天内理解新的库，从而显著提升团队效率。\n\n## 即将推出：Code Wiki Gemini CLI 扩展\n\n尽管开源生态系统拥有大量仓库，但私有仓库往往是最难有效文档化的。尤其是在原始代码作者可能已不在公司的情况下，理解遗留代码是一个巨大的障碍。Code Wiki 团队认为这项技术将彻底改变这些内部环境，确保每个人都能深入理解他们正在处理的代码。\n\n团队正在为 Code Wiki 构建一个 Gemini CLI 扩展，以便团队可以在本地安全地运行相同的系统，处理内部仓库。用户可以加入 Gemini CLI 扩展的等候名单，以获取最新信息。\n\n## 开发的未来\n\nCode Wiki 旨在让开发人员将时间花在构建上，而不是解密代码。手动、过时的文档和无休止的代码阅读时代已经结束。开发的未来在于即时理解，Code Wiki 正是这一愿景的体现。",
      "shortSummary": "Google Cloud 推出 Code Wiki，旨在解决代码理解难题。该平台通过为代码仓库自动生成并维护持续更新、智能且集成的维基文档，结合 Gemini 驱动的上下文感知聊天和自动图表，加速代码理解。Code Wiki 网站已上线公开预览，未来还将推出 Gemini CLI 扩展以支持内部仓库。这使得新开发者能快速上手，资深开发者能迅速理解新库，将开发重心从代码解密转向构建，开启即时理解的开发新时代。",
      "translated_title": "推出 Code Wiki：加速你的代码理解",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_CLI_Code_Wiki_v2.original.png",
          "alt": "Gemini CLI Code Wiki v2",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Code Wiki is a new platform that tackles the bottleneck of reading existing code by providing an automated, continuously updated, structured wiki for code repositories. It features hyper-linked documentation, a Gemini-powered chat agent that understands your repo, and automated diagrams. A public preview is available for open-source projects, and a Gemini CLI extension is coming soon for secure use on private repos."
    },
    {
      "title": "让终端美观，一次一个像素 (原标题: Making the terminal beautiful one pixel at a time)",
      "link": "https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini CLI用户体验重大升级：打造更美观、稳定的终端\n\nGoogle于2025年11月13日宣布对Gemini CLI的用户体验进行重大升级，旨在使其终端交互更加强大、直观和视觉稳定。此次升级彻底改造了Gemini CLI的渲染基础，消除了终端应用常见的视觉干扰，将图形界面级别的精致度直接带入终端。用户将不再遇到屏幕闪烁、输入提示跳动或在长输出流中迷失位置的问题，Gemini CLI变得更加流畅。\n\n## 关键增强功能\n\n新的渲染基础带来了多项即时改进，旨在提升用户体验：\n\n*   **鼠标导航**：\n    *   用户现在可以直接在输入提示符内使用鼠标点击进行导航，无需再频繁使用方向键。\n*   **持久化标题行**：\n    *   引入了工具确认和操作的持久化标题行，确保用户在复杂交互中也能始终了解当前操作的上下文。\n    *   ![持久化标题](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Sticky_header.original.png)\n*   **无闪烁体验**：\n    *   新设计几乎消除了屏幕闪烁。使用VSCode、iTerm、Ghostty等现代终端的用户将告别闪烁屏幕，享受流畅的终端体验。\n*   **健壮的渲染**：\n    *   以前，调整终端窗口大小有时会导致视觉故障或伪影。现在，这些渲染伪影已成为历史，无论如何调整窗口大小，都能提供清晰、精致的显示。\n*   **稳定的输入提示符**：\n    *   输入字段现在牢固地固定在终端底部，提供一致、可预测的体验，告别跳动的提示框。\n    *   ![锚定提示符](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/anchored-prompt.original.png)\n*   **历史记录保留**：\n    *   尽管为了无缝体验使用了备用屏幕缓冲区，但在退出Gemini CLI后，完整的聊天历史记录仍可在标准终端中访问。\n\n## 如何开始使用新UI\n\n这些新的UI改进已在Gemini CLI v0.15.0及更高版本中默认启用。\n要升级到最新版本的Gemini CLI，请使用以下命令：\n`npm install -g @google/gemini-cli@latest`\n\n## 后续计划\n\n这仅仅是健壮的新TUI渲染基础所能实现功能的开始。团队正在积极开发进一步的改进，包括：\n\n*   滚动条的点击拖动功能（目前可通过鼠标滚轮或Shift+上/下键滚动）。\n*   提供更无缝的复制粘贴解决方案（目前，用户可通过按Ctrl-S暂时退出鼠标模式来使用标准复制/粘贴方法选择文本）。\n\n鼓励用户立即尝试新的无缝UI，并在GitHub上提供反馈。",
      "shortSummary": "Gemini CLI发布v0.15.0版本，带来用户体验重大升级，旨在使终端交互更稳定、直观。核心改进包括：消除屏幕闪烁、鼠标导航、持久化标题行、稳定的输入提示符以及健壮的窗口大小调整渲染。这些功能默认启用，用户可通过升级CLI体验更流畅的终端操作。未来还将支持拖动滚动条和更无缝的复制粘贴，并鼓励用户提供反馈。",
      "translated_title": "让终端美观，一次一个像素",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Sticky_header.original.png",
          "alt": "Sticky header",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/anchored-prompt.original.png",
          "alt": "anchored-prompt",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "完整文章",
      "content": "Google has launched the redesigned **Android AI Sample Catalog**, a dedicated, open-source application to inspire and educate Android developers on building AI-powered apps. It showcases examples using both on-device (Gemini Nano via ML Kit GenAI API) and Cloud models (via Firebase AI Logic SDK), including image generation with Imagen, on-device summarization, and a \"Chat with Nano Banana\" chatbot. The code is easy to copy and paste to help developers quickly start their own projects."
    },
    {
      "title": "介绍 Metrax：JAX 中高性能、高效且稳健的模型评估指标 (原标题: Introducing Metrax: performant, efficient, and robust model evaluation metrics in JAX)",
      "link": "https://developers.googleblog.com/en/introducing-metrax-performant-efficient-and-robust-model-evaluation-metrics-in-jax/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 介绍 Metrax：JAX 中高性能、高效且稳健的模型评估指标\n\nMetrax 是一个专为 JAX 设计的高性能库，旨在提供高效且稳健的模型评估指标。它的诞生是为了解决 Google 团队在从 TensorFlow 迁移到 JAX 时，由于 JAX 缺乏内置指标库而不得不手动重新实现各种评估指标的问题，尤其是在大规模分布式计算环境中，这变得尤为复杂。\n\n## Metrax 的核心优势与特性\n\n*   **全面的指标覆盖**：Metrax 提供了用于评估各种机器学习模型（分类、回归、推荐、视觉、音频和语言）的预定义指标。\n*   **分布式环境兼容性**：它确保了在分布式和规模化训练环境中的兼容性和一致性，让开发者能专注于模型评估结果，而非重复实现指标定义。\n*   **“At K”指标的并行计算**：\n    *   Metrax 能够并行计算多个 K 值的“at K”指标，例如 PrecisionAtK、RecallAtK 和 NDCGAtK。\n    *   这意味着用户可以在模型的一次前向传播中，同时获取 K=1、K=8 和 K=20 等多个 K 值下的精度，从而更快、更全面地评估模型性能。\n*   **稳健性和可靠性**：作为一个经过充分测试的指标库，Metrax 有助于社区编写更少出错的代码和进行更可靠的模型评估。\n*   **性能优化**：Metrax 利用 JAX 的核心优势，如 `vmap` 和 `jit`，以高性能方式执行多项操作，包括“at K”操作。\n*   **丰富的指标类型**：除了准确率、精确率和召回率等经典指标外，Metrax 还包含一套强大的自然语言处理（NLP）相关指标（如 Perplexity、BLEU、ROUGE），以及视觉模型指标（如 IoU、SNR、SSIM）。\n\n## Metrax 的使用示例\n\nMetrax 的使用方式简洁明了，支持直接计算和批处理合并。\n\n1.  **直接计算指标**：\n    通过 `metrax.Precision.from_model_output` 方法传入预测值、标签和阈值，然后调用 `compute()` 即可获得结果。\n    ```python\n    import metrax\n    # 直接计算指标状态。\n    metric_state = metrax.Precision.from_model_output(\n        predictions=predictions,\n        labels=labels,\n        threshold=0.5\n    )\n    # 调用 compute() 即可获得结果。\n    result = metric_state.compute()\n    ```\n\n2.  **迭代合并批次指标**：\n    在批处理评估中，可以使用 `merge()` 函数迭代地将每个批次的指标信息合并到总的指标状态中，最后调用 `compute()` 获取最终值。\n    ```python\n    # 迭代合并精确率指标\n    for labels_b, predictions_b, weights_b in zip(labels_batched, predictions_batched, sample_weights_batched):\n        batch_metric_state = metrax.Precision.from_model_output(\n            predictions=predictions_b,\n            labels=labels_b\n        )\n        metric_state = metric_state.merge(batch_metric_state)\n    result = metric_state.compute()\n    ```\n\n## 生态系统整合与贡献\n\n*   **JAX AI Stack 的一部分**：Metrax 很好地融入了 JAX AI Stack，这是一个旨在协同工作以满足 AI 工具需求的工具套件。\n*   **广泛应用**：目前，Metrax 已被 Google 内部一些最大的软件栈使用，包括 Google 搜索、YouTube 和 Google 自己的训练后库 Tunix。\n*   **社区贡献**：Metrax 在 GitHub 上开源（github.com/google/metrax），并欢迎社区贡献。许多现有指标都是由社区贡献者添加的。\n*   **更多资源**：用户可以在 `jaxstack.ai` 找到更多与 Metrax 良好集成的 JAX 生态系统库和关于构建机器学习模型的内容。",
      "shortSummary": "Metrax 是一个为 JAX 设计的高性能模型评估指标库，旨在解决 JAX 缺乏内置指标库的问题。它提供了一系列预定义、高效且稳健的机器学习模型评估指标，支持并行计算多个“at K”指标，并利用 JAX 的性能优势。Metrax 整合了 JAX AI Stack，已被 Google 内部团队广泛使用，并在 GitHub 上开源，欢迎社区贡献。",
      "translated_title": "介绍 Metrax：JAX 中高性能、高效且稳健的模型评估指标",
      "images": [],
      "contentSource": "完整文章",
      "content": "Metrax is a high-performance JAX-based metrics library developed by Google. It standardizes model evaluation by offering robust, efficient metrics for classification, NLP, and vision, eliminating manual re-implementation after migrating from TensorFlow. Key strengths include parallel computation of \"at K\" metrics (e.g., PrecisionAtK) for multiple K values and strong integration with the JAX AI Stack, leveraging JAX's performance features. It is open-source on GitHub."
    },
    {
      "title": "Google Colab 即将登陆 VS Code (原标题: Google Colab is Coming to VS Code)",
      "link": "https://developers.googleblog.com/en/google-colab-is-coming-to-vs-code/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Google Colab VS Code 扩展发布\n\nGoogle Colab 团队于2025年11月13日宣布推出全新的 Google Colab Visual Studio Code 扩展。此举旨在将全球最受欢迎的代码编辑器 VS Code 的强大功能与数百万 AI/ML 开发者、学生和研究人员首选的 Colab 平台结合起来。\n\n## 发布背景与动机\n\n*   **VS Code 的普及**：VS Code 以其速度、轻量级和高度适应性，成为全球广受欢迎的代码编辑器。\n*   **Colab 的成功**：Colab 已成为 AI/ML 领域编写和执行代码、协作以及无缝访问 GPU 和 TPU 等强大计算资源的平台。\n*   **弥合差距的需求**：此前，VS Code 和 Colab 的使用场景相对独立。社区强烈希望将强大的 VS Code 开发环境与基于网络的 Colab 笔记本结合，以支持更复杂的项目开发和工作流。Colab 的目标是满足用户需求，而许多用户都在 VS Code 中工作。\n\n## 融合两者的优势\n\n新的 Colab VS Code 扩展旨在结合两个平台的优点：\n\n*   **对于 VS Code 用户**：\n    *   可以在熟悉的 VS Code 编辑器中继续工作。\n    *   将本地笔记本连接到高性能的 Colab 运行时，包括提供高级 GPU 和 TPU 的 Colab Pro 运行时。\n*   **对于 Colab 用户**：\n    *   支持 Colab 用户现有的工作流，例如处理作为大型项目或 Git 仓库一部分的笔记本。\n    *   为需要更强大 IDE 功能和更高可扩展性的 Colab 用户提供了解决方案。\n    *   弥合了简单易用的 Colab 运行时与功能丰富的 VS Code 编辑器之间的鸿沟。\n\n## 如何开始使用 Colab 扩展\n\n只需几个简单的步骤即可开始使用：\n\n1.  **安装 Colab 扩展**：\n    *   在 VS Code 中，打开左侧活动栏的“扩展”视图（或按 `Ctrl|Cmd + Shift + X`）。\n    *   在市场中搜索“Google Colab”。\n    *   点击官方 Colab 扩展的“安装”按钮。\n    *   如果提示，安装所需的依赖项——Jupyter 扩展。\n2.  **连接到 Colab 运行时**：\n    *   在本地工作区中创建或打开任何 `.ipynb` 笔记本文件。\n    *   运行一个单元格（这将引导您选择内核）或点击右上角的“选择内核”按钮。\n    *   点击“Colab”，然后选择所需的运行时，使用您的 Google 账户登录即可。\n    *   您的本地笔记本现在将由 Colab 运行时提供支持。\n\n该扩展也已发布到 Open VSX，支持 VS Code 的衍生版本。\n\n## 未来展望\n\n此次发布是 Google Colab 将其最佳功能带给用户的起点。团队计划未来将更多 Colab 功能引入 VS Code。\n\n鼓励用户立即从 VS Code Marketplace 下载扩展，试用并提供反馈。",
      "shortSummary": "Google Colab 已推出适用于 Visual Studio Code 的官方扩展。此举将 VS Code 的强大编辑功能与 Colab 的高性能 AI/ML 计算资源（包括 GPU 和 TPU）相结合。用户现在可以在熟悉的 VS Code 环境中，将本地 Jupyter 笔记本连接到 Colab 运行时，从而简化开发流程，并支持更复杂的项目和协作。该扩展旨在满足开发者在 VS Code 中使用 Colab 的需求，并计划未来带来更多功能。",
      "translated_title": "Google Colab 即将登陆 VS Code",
      "images": [],
      "contentSource": "完整文章",
      "content": "Google Colab has launched an official VS Code extension, bridging the gap between the popular code editor and the AI/ML platform. The extension combines VS Code's powerful development environment with Colab's seamless access to high-powered runtimes (GPUs/TPUs), allowing users to connect local notebooks to Colab. This aims to meet developers where they are and brings the best of both worlds."
    }
  ],
  "lastUpdated": "2025-11-25T10:34:42.544Z"
}
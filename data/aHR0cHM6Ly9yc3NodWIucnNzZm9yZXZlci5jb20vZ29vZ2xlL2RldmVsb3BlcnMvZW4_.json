{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "Building agents with the ADK and the new Interactions API",
      "link": "https://developers.googleblog.com/en/building-agents-with-the-adk-and-the-new-interactions-api/",
      "pubDate": "Wed, 10 Dec 2025 16:00:00 GMT",
      "isoDate": "2025-12-10T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Building agents with the ADK and the new Interactions API",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gfd-blog-banner-interactions-api-adk-a2a.original.jpg",
          "alt": "gfd-blog-banner-interactions-api-adk-a2a",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "The new Gemini Interactions API enables stateful, multi-turn AI agent workflows, providing a single interface for raw models and the Gemini Deep Research Agent. It can be integrated with existing ADK systems as a superior inference engine with simplified state management, or used as a transparent remote A2A agent via InteractionsApiTransport, allowing seamless expansion of multi-agent systems with minimal refactoring."
    },
    {
      "title": "Pick up exactly where you left off with Session Management in Gemini CLI",
      "link": "https://developers.googleblog.com/en/pick-up-exactly-where-you-left-off-with-session-management-in-gemini-cli/",
      "pubDate": "Tue, 09 Dec 2025 16:00:00 GMT",
      "isoDate": "2025-12-09T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Pick up exactly where you left off with Session Management in Gemini CLI",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_CLI_-_Session_Browser.original.png",
          "alt": "Gemini CLI - Session Browser",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Gemini CLI's new automatic **Session Management** (v0.20.0+) saves your conversation history, tool outputs, and reasoning, providing project-specific context. Resume easily using the **Interactive Session Browser** (`/resume`) or command-line flags (`--resume`). This feature ensures you never lose your work state, capturing prompts, tool execution details, and usage stats. Customize history with cleanup policies in `settings.json`."
    },
    {
      "title": "Don't Trust, Verify: Building End-to-End Confidential Applications on Google Cloud",
      "link": "https://developers.googleblog.com/en/dont-trust-verify-building-end-to-end-confidential-applications-on-google-cloud/",
      "pubDate": "Mon, 08 Dec 2025 16:00:00 GMT",
      "isoDate": "2025-12-08T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Don't Trust, Verify: Building End-to-End Confidential Applications on Google Cloud",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/oak_session_diagram.original.jpg",
          "alt": "oak session diagram",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "Google Cloud enables end-to-end confidential applications, protecting sensitive data 'in-use' with hardware isolation. The solution combines Confidential Space (TEE/attestation), Oak Functions (private sandbox), and Oak Session (attested end-to-end encryption for scale). This framework anchors user trust in open-source components, proving confidentiality for sensitive workloads like proprietary GenAI models, even when running behind untrusted load balancers."
    },
    {
      "title": "MediaTek NPU and LiteRT: Powering the next generation of on-device AI",
      "link": "https://developers.googleblog.com/en/mediatek-npu-and-litert-powering-the-next-generation-of-on-device-ai/",
      "pubDate": "Sun, 07 Dec 2025 16:00:00 GMT",
      "isoDate": "2025-12-07T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "MediaTek NPU and LiteRT: Powering the next generation of on-device AI",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma_3_270_AOT_JIT.original.png",
          "alt": "Gemma 3 270 AOT_JIT",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Perf_data_12-04.original.png",
          "alt": "Perf_data_12-04",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "RSS",
      "content": "LiteRT and MediaTek are announcing the new LiteRT NeuroPilot Accelerator. This is a ground-up successor for the TFLite NeuroPilot delegate, bringing seamless deployment experience, state-of-the-art LLM support, and advanced performance to millions of devices worldwide."
    },
    {
      "title": "Architecting efficient context-aware multi-agent framework for production",
      "link": "https://developers.googleblog.com/en/architecting-efficient-context-aware-multi-agent-framework-for-production/",
      "pubDate": "Wed, 03 Dec 2025 16:00:00 GMT",
      "isoDate": "2025-12-03T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Architecting efficient context-aware multi-agent framework for production",
      "images": [],
      "contentSource": "RSS",
      "content": "ADK introduces **Context Engineering** to scale AI agents beyond large context windows. It treats context as a compiled view over a tiered, stateful system (**Session, Memory, Artifacts**). This architecture uses explicit processors for transformation, enables efficient compaction and caching, and allows for strict, scoped context handoffs in multi-agent workflows to ensure reliability and cost-effectiveness in production."
    },
    {
      "title": "Announcing the Data Commons Gemini CLI extension",
      "link": "https://developers.googleblog.com/en/announcing-the-data-commons-gemini-cli-extension/",
      "pubDate": "Mon, 01 Dec 2025 16:00:00 GMT",
      "isoDate": "2025-12-01T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Announcing the Data Commons Gemini CLI extension",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/GDP-answer.original.png",
          "alt": "GDP-answer",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "RSS",
      "content": "The new Data Commons extension for the Gemini CLI makes accessing public data easier. It allows users to ask complex, natural-language questions to query Data Commons' public datasets, grounding LLM responses in authoritative sources to reduce AI hallucinations. Data Commons is an organized library of public data from sources like the UN and World Bank. The extension enables instant data analysis, exploration, and integration with other data-related extensions."
    },
    {
      "title": "New Gemini API updates for Gemini 3",
      "link": "https://developers.googleblog.com/en/new-gemini-api-updates-for-gemini-3/",
      "pubDate": "Mon, 24 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-24T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "New Gemini API updates for Gemini 3",
      "images": [],
      "contentSource": "RSS",
      "content": "Gemini 3 is available via API with updates for developers: new `thinking_level` for depth control, `media_resolution` for multimodal processing, and enforced `Thought Signatures` for agentic workflows, especially with function calling and image generation. It also introduces combining Google Search/URL Grounding with Structured Outputs and new usage-based pricing for Grounding. Best practices, like using default temperature, are advised for optimal results."
    },
    {
      "title": "Unlocking Peak Performance on Qualcomm NPU with LiteRT",
      "link": "https://developers.googleblog.com/en/unlocking-peak-performance-on-qualcomm-npu-with-litert/",
      "pubDate": "Sun, 23 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Unlocking Peak Performance on Qualcomm NPU with LiteRT",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/GPU_NPU_pipeline.original.png",
          "alt": "GPU_NPU_pipeline",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/LiteRT_NPU_and_GPU_latency_relative_to_CPU_1.original.png",
          "alt": "LiteRT NPU and GPU latency relative to CPU (1)",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/FastVLM_table_new.original.png",
          "alt": "FastVLM_table_new",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "RSS",
      "content": "LiteRT's new Qualcomm AI Engine Direct (QNN) Accelerator unlocks dedicated NPU power for on-device GenAI on Android. It offers a unified mobile deployment workflow, SOTA performance (up to 100x speedup over CPU), and full model delegation. This enables smooth, real-time AI experiences, with FastVLM-0.5B achieving over 11,000 tokens/sec prefill on Snapdragon 8 Elite Gen 5 NPU."
    },
    {
      "title": "Build with Google Antigravity, our new agentic development platform",
      "link": "https://developers.googleblog.com/en/build-with-google-antigravity-our-new-agentic-development-platform/",
      "pubDate": "Wed, 19 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-19T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Build with Google Antigravity, our new agentic development platform",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/AGYBlogHero.original.png",
          "alt": "AGYBlogHero",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/editor-open-agent-manager.original.png",
          "alt": "editor-open-agent-manager",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/settings-review-policy-manual.original.png",
          "alt": "settings-review-policy-manual",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "RSS",
      "content": "Introducing Google Antigravity, a new agentic development platform for orchestrating code. It combines an AI-powered Editor View with a Manager Surface to deploy agents that autonomously plan, execute, and verify complex tasks across your editor, terminal, and browser. Agents communicate progress via Artifacts (screenshots, recordings) for easy verification. Available now in public preview."
    },
    {
      "title": "Building AI Agents with Google Gemini 3 and Open Source Frameworks",
      "link": "https://developers.googleblog.com/en/building-ai-agents-with-google-gemini-3-and-open-source-frameworks/",
      "pubDate": "Tue, 18 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-18T16:00:00.000Z",
      "creator": "Google",
      "summary": "无法生成摘要（API请求失败）。",
      "shortSummary": "",
      "translated_title": "Building AI Agents with Google Gemini 3 and Open Source Frameworks",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/langchain.original.png",
          "alt": "langchain",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ai-sdk.original.png",
          "alt": "ai-sdk",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_vCYoxzo.original.png",
          "alt": "LlamaIndex",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/pydantic-ai.original.png",
          "alt": "pydantic-ai",
          "title": "",
          "position": 4
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/n8n.original.png",
          "alt": "n8n",
          "title": "",
          "position": 5
        }
      ],
      "contentSource": "RSS",
      "content": "Gemini 3 Pro Preview is introduced as a powerful, agentic model for complex, (semi)-autonomous workflows. New agentic features include `thinking_level` for reasoning control, Stateful Tool Use via Thought Signatures, and `media_resolution` for multimodal fidelity. It has Day 0 support for open-source frameworks like LangChain, AI SDK, LlamaIndex, Pydantic AI, and n8n. Best practices include simplifying prompts and keeping temperature at 1.0."
    }
  ],
  "lastUpdated": "2025-12-13T10:29:14.365Z"
}
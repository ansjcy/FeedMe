{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "Google 开发者计划正在演进 (原标题: The Google Developer Program is evolving)",
      "link": "https://developers.googleblog.com/en/google-developer-program-join-connect-code/",
      "pubDate": "Thu, 31 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-31T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Google 开发者计划正在演进\n\nGoogle 于2025年8月1日宣布了Google开发者计划的最新进展，旨在通过强大的AI工具和资源，帮助开发者更快、更智能地进行构建。此次更新引入了多项增强功能，以更深入地融入开发者工作流程，并连接他们所需的专业知识。\n\n## 访问 Google AI 工具的更大灵活性\n\n为了让高级资源更易于访问，Google 推出了 Google 开发者计划月度订阅计划，费用为每月 24.99 美元*。该计划提供所有 AI 增强型高级福利，包括：\n*   用于 Vertex AI 和 Google AI Studio 的 Google Cloud 积分。\n*   Gemini Code Assist Standard。\n*   30 个 Firebase Studio 工作区，用于将全栈应用程序投入生产。\n*   以及更多其他福利。\n\n开发者可以通过新的福利仪表板轻松激活所有福利。\n\n![Google Developer Program pricing](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-pricing.original.png)\n![Google Developer Program benefits](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-benefits.original.png)\n\n*注：Google 开发者计划月度订阅计划目前仅在美国可用，未来几周将推广到其他国家。\n\n## 统一的协作中心：Google 开发者计划论坛\n\nGoogle 还推出了新的 Google 开发者计划论坛，网址为 `discuss.google.dev`。这个新平台将开发者的 Google 开发者计划资料、社区和兴趣整合在一起，使得提问、分享知识、与同行联系、寻求错误帮助以及分享发现变得更加容易。\n\n现有的 Google Cloud、Workspace Developer、AppSheet 和 Looker 社区及其所有历史内容和讨论已迁移到这个新的中心论坛。\n\n![Google Developer Program forums](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-forums.original.png)\n\n## 加速您的 AI 之旅：加入 Google Cloud & NVIDIA 社区\n\n在 Google I/O 大会上，Google 宣布了新的 Google Cloud & NVIDIA 社区，专为有兴趣在 Google Cloud 上利用 NVIDIA 尖端技术的实践者而建。社区成员可以获得独家学习路径，例如亲身体验 GKE 和 NVIDIA NIM 进行 AI 推理任务。此外，在完成学习路径后，限时可获得 Google Cloud 积分。\n\n未来几周将推出新的学习路径。\n\n![Accelerate your AI journey: Join the Google Cloud & NVIDIA community](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-cloud-nvidia-community-google-developer-.original.png)\n\n## 立即开始\n\n无论开发者是寻求更灵活的工具访问方式，渴望与社区建立更紧密的联系，还是希望通过 AI 提升生产力，Google 开发者计划都能提供相应支持。访问 `developers.google.com/program` 了解更多信息并探索您的 Google 开发者计划福利。",
      "shortSummary": "Google 开发者计划于2025年8月1日宣布重大演进，旨在通过AI工具赋能开发者。核心更新包括：推出每月24.99美元的月度计划（美国），提供Google Cloud积分、Gemini Code Assist等高级AI福利；上线统一的Google开发者计划论坛（discuss.google.dev），整合现有社区；以及成立Google Cloud & NVIDIA社区，提供AI学习路径和积分。这些举措旨在提供更灵活的工具访问、更强的社区连接和AI驱动的生产力提升。",
      "translated_title": "Google 开发者计划正在演进",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-pricing.original.png",
          "alt": "Google Developer Program pricing",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-benefits.original.png",
          "alt": "Google Developer Program benefits",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-forums.original.png",
          "alt": "Google Developer Program forums",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-cloud-nvidia-community-google-developer-.original.png",
          "alt": "Accelerate your AI journey: Join the Google Cloud & NVIDIA community",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "The Google Developer Program is rolling out major updates to make its tools and community more accessible and powerful. These enhancements include a new flexible monthly subscription tier, a centralized GDP Forum for collaboration, and increased Gemini CLI access for all members."
    },
    {
      "title": "Veo 3 Fast 和新的图像到视频功能 (原标题: Veo 3 Fast and new image-to-video capabilities)",
      "link": "https://developers.googleblog.com/en/veo-3-fast-image-to-video-capabilities-now-available-gemini-api/",
      "pubDate": "Wed, 30 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-30T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Veo 3 Fast 和新的图像到视频功能发布\n\n### 发布概览\n\n*   **日期：** 2025年7月31日\n*   **核心内容：** 在Veo 3发布后，谷歌现推出Veo 3 Fast模型，并为Veo 3和Veo 3 Fast引入了图像到视频（image-to-video）功能。\n*   **可用性：** 这两款模型及其图像到视频功能均已通过Gemini API提供付费预览。\n\n### Veo 3 Fast：更快、更高效的模型\n\nVeo 3 Fast是Veo 3的优化版本，旨在提高速度和降低成本，使开发者能够更快地迭代，同时高效地生成高质量输出。\n\n*   **主要特点：**\n    *   比Veo 3更快、更具成本效益。\n    *   支持文本到视频（text-to-video）和图像到视频（image-to-video）两种模式。\n    *   在优化速度和业务用例的同时，保持高质量视频输出（含音频）。\n*   **理想应用场景：**\n    *   **程序化广告：** 为自动生成广告创意的后端服务提供支持。\n    *   **快速原型设计：** 快速进行不同创意概念的A/B测试。\n    *   **规模化内容创作：** 构建需要快速生产社交媒体内容的应用程序。\n*   **定价：** 0.40美元/秒（含音频）。\n\n### 新的图像到视频功能\n\n开发者现在可以使用Veo 3和Veo 3 Fast，通过输入图像生成高质量的视频内容（含音频）。这项新功能能够将静态图像转换为动态视频片段，同时保持内容的一致性。\n\n*   **操作方式：**\n    *   只需提供一张图像和文本提示，即可引导模型实现所需的动作、叙事和音频。\n*   **定价：** 图像到视频的输出定价与文本到视频的输出相同（Veo 3为0.75美元/秒，含音频）。\n*   **主要优势：**\n    *   **高质量视频生成：** 从单张图像创建流畅、电影级的视频，保持风格一致性和细节，并包含音频。\n    *   **精确提示：** 结合图像输入和描述性文本提示，精确指导视频内容的动作、风格和演变。\n    *   **无缝API集成：** 通过直观的Gemini API访问此强大新功能，易于集成到现有工作流程和应用程序中。\n\n### 实际应用案例：OpusClip\n\nOpusClip利用Veo 3的图像到视频功能，增强客户的视频编辑体验并生成B-roll视频。Veo 3能够将静态图像作为第一帧，通过生成流畅、电影般的运动使其生动起来，帮助创作者以最小的努力获得引人入胜的视频内容。\n\n### 展望与行动\n\n谷歌对开发者将利用Veo 3、Veo 3 Fast和通过Gemini API提供的图像到视频功能创造出什么感到非常兴奋。鼓励开发者查阅Gemini API视频生成文档或Veo食谱，立即开始构建。",
      "shortSummary": "谷歌推出了Veo 3 Fast模型，该模型针对速度和成本进行了优化，并为Veo 3和Veo 3 Fast引入了新的图像到视频功能。Veo 3 Fast更快速、经济，适用于程序化广告、快速原型设计和规模化内容创作。图像到视频功能允许用户将静态图像转换为高质量、连贯的动态视频，并可通过文本提示进行精确控制。这两项功能均已通过Gemini API提供付费预览。",
      "translated_title": "Veo 3 Fast 和新的图像到视频功能",
      "images": [],
      "contentSource": "完整文章",
      "content": "Google introduces Veo 3 Fast, an optimized model for speed and price, along with new image-to-video capabilities for both Veo 3 and Veo 3 Fast, enabling developers to efficiently create high-quality video content from text or still images, with varying pricing based on the model and audio inclusion, now available in the Gemini API."
    },
    {
      "title": "介绍 LangExtract：一个由 Gemini 驱动的信息提取库 (原标题: Introducing LangExtract: A Gemini powered information extraction library)",
      "link": "https://developers.googleblog.com/en/introducing-langextract-a-gemini-powered-information-extraction-library/",
      "pubDate": "Tue, 29 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-29T16:00:00.000Z",
      "creator": "Google",
      "summary": "LangExtract 简介\n\n在当今数据丰富的世界中，有价值的洞察常常隐藏在非结构化文本中，例如详细的临床笔记、冗长的法律文件、客户反馈和新闻报道。手动筛选或构建定制代码来处理这些数据既耗时又容易出错，而简单地使用现代大型语言模型（LLMs）可能会引入错误。为了解决这一挑战，LangExtract 应运而生。\n\nLangExtract 概述\n\nLangExtract 是一个新推出的开源 Python 库，旨在帮助开发者以编程方式提取所需的确切信息，同时确保输出结构化并可靠地追溯到其来源。它为各种 LLM（如 Gemini 模型）提供了一个轻量级接口，用于根据自定义指令将大量非结构化文本处理成结构化信息，确保灵活性和可追溯性。\n\n核心功能与优势\n\nLangExtract 提供了一系列独特的功能，使其在信息提取方面非常有用：\n\n*   **精确源定位**：每个提取的实体都被映射回其在源文本中的精确字符偏移量。这提供了可追溯性，通过在原始文本中视觉高亮显示每次提取，使得评估和验证提取的信息变得更加容易。\n*   **可靠的结构化输出**：用户可以使用 LangExtract 的数据表示定义所需的输出，并提供“少量示例”（few-shot examples）。LangExtract 利用这些示例来强制执行模式，并利用 Gemini 等支持模型中的“受控生成”（Controlled Generation）功能，确保输出始终保持结构化。\n*   **优化长上下文信息提取**：从大型文档中检索信息可能很复杂。LangExtract 通过采用分块策略、并行处理和对更小、更集中的上下文进行多次提取，来处理这一问题，从而提高多事实检索场景中的召回率。\n*   **交互式可视化**：LangExtract 可以在几分钟内将原始文本转换为交互式、自包含的 HTML 可视化，方便用户在上下文中审查提取的实体，并支持探索数千个注释。\n*   **灵活支持 LLM 后端**：用户可以使用他们偏好的模型，无论是基于云的 LLM（如 Google 的 Gemini 系列）还是开源的设备端模型。\n*   **跨领域灵活性**：只需几个精心选择的示例，即可为任何领域定义信息提取任务，无需对 LLM 进行微调。LangExtract 可以“学习”用户所需的输出，并将其应用于大量新的文本输入。\n*   **利用 LLM 世界知识**：除了提取有根据的实体外，LangExtract 还可以利用模型的“世界知识”来补充提取的信息。这些信息可以是明确的（即源自源文本）或推断的（即源自模型的固有世界知识）。此类补充知识的准确性和相关性，特别是推断出的知识，很大程度上受所选 LLM 能力和引导提取的提示示例的精确性影响。\n\n快速入门示例 (莎士比亚)\n\nLangExtract 提供了一个简单的流程来从文本中提取信息：\n\n1.  **安装库**：通过 `pip install langextract` 命令进行安装。\n2.  **定义提取任务**：提供清晰的提示和高质量的“少量示例”来指导模型。\n3.  **运行提取**：使用 `lx.extract()` 函数对输入文本执行提取。\n4.  **保存与可视化**：将结果保存到 JSONL 文件，然后生成交互式 HTML 文件以查看注释。这种可视化功能非常适合演示或评估提取质量。\n\n专业领域应用\n\nLangExtract 的核心思想最初应用于医疗信息提取，并能有效处理临床文本，例如识别药物、剂量及其属性，并映射它们之间的关系。这一能力是促成该库研究的核心部分。\n\n为了展示 LangExtract 在专业领域的强大功能，开发团队还在 Hugging Face 上开发了一个名为 RadExtract 的交互式结构化放射学报告演示。该演示展示了 LangExtract 如何处理自由文本的放射学报告，并自动将其关键发现转换为结构化格式，同时突出重要发现。这种方法在放射学中非常重要，因为结构化报告可以增强清晰度、确保完整性并改善研究和临床护理的数据互操作性。\n\n**免责声明**：上述药物提取示例和结构化报告演示仅用于说明 LangExtract 的基本功能。它们不代表已完成或批准的产品，不用于诊断或建议任何疾病或状况的治疗，也不应用于医疗建议。\n\n资源与下一步\n\nLangExtract 团队期待看到开发者如何利用 LangExtract 从文本中解锁洞察。用户可以深入研究文档，探索 GitHub 存储库中的示例，并立即开始转换非结构化数据。",
      "shortSummary": "LangExtract 是一个由 Gemini 驱动的新型开源 Python 库，旨在帮助开发者从非结构化文本中高效提取结构化信息。它利用大型语言模型（如 Gemini）和少量示例，确保输出的精确性、可追溯性和结构化。该库能优化长上下文信息提取，灵活支持多种 LLM 后端，并适用于不同领域。LangExtract 还提供交互式可视化功能，简化了从文本中获取洞察的过程，尤其适用于医疗、金融等专业领域。",
      "translated_title": "介绍 LangExtract：一个由 Gemini 驱动的信息提取库",
      "images": [],
      "contentSource": "完整文章",
      "content": "LangExtract is a new open-source Python library powered by Gemini models for extracting structured information from unstructured text, offering precise source grounding, reliable structured outputs using controlled generation, optimized long-context extraction, interactive visualization, and flexible LLM backend support."
    },
    {
      "title": "Gemini Embedding：赋能RAG和上下文工程 (原标题: Gemini Embedding: Powering RAG and context engineering)",
      "link": "https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/",
      "pubDate": "Tue, 29 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-29T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini Embedding：赋能RAG和上下文工程\n\n自Gemini Embedding文本模型全面上市以来，开发者们迅速采纳它来构建先进的AI应用。除了传统的分类、语义搜索和检索增强生成（RAG）等用例，许多人现在正利用“上下文工程”技术为AI代理提供完整的操作上下文。嵌入技术在此过程中至关重要，因为它能高效识别并将文档、对话历史和工具定义等关键信息直接整合到模型的“工作记忆”中。\n\n以下示例展示了各行各业的组织如何利用Gemini Embedding模型来驱动复杂的系统：\n\n## Gemini Embedding 的实际应用\n\n### 1. 赋能全球内容智能——Box\n\n*   **公司：** Box，一个智能内容管理平台。\n*   **应用：** 整合Gemini Embedding以实现关键用例：从复杂文档中回答问题并提取洞察。\n*   **性能提升：** 在评估中，`gemini-embedding-001`在超过81%的时间内找到了正确答案，召回率比其他嵌入模型提高了3.6%。\n*   **核心优势：** 模型内置的多语言支持对全球用户而言是一项有前景的进步，使Box AI能够从不同语言和区域的内容中解锁洞察。\n*   **图片：** ![Box AI - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Box-AI-Gemini-Embedding.original.png)\n\n### 2. 提高金融数据分析的准确性——re:cap\n\n*   **公司：** re:cap，一家金融科技公司。\n*   **应用：** 使用嵌入技术对大量B2B银行交易进行分类。\n*   **性能提升：** 通过与之前的Google模型（`text-embedding-004`和`text-embedding-005`）在21,500笔交易数据集上进行基准测试，`gemini-embedding-001`的F1分数分别提高了1.9%和1.45%。F1分数平衡了模型的精确度和召回率，对分类任务至关重要。\n*   **核心优势：** Gemini Embedding等强大模型直接带来了显著的性能提升，帮助re:cap为其客户提供更敏锐的流动性洞察。\n*   **图片：** ![re:cap - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/re-cap.original.png)\n\n### 3. 实现法律发现中的语义精度——Everlaw\n\n*   **公司：** Everlaw，一个为法律专业人士提供可验证RAG以分析大量发现文档的平台。\n*   **应用：** 需要在数百万份专业文本中实现精确的语义匹配。\n*   **性能提升：** 内部基准测试显示，`gemini-embedding-001`表现最佳，在从140万份包含行业特定和复杂法律术语的文档中发现相关答案方面达到了87%的准确率，超过了Voyage（84%）和OpenAI（73%）模型。\n*   **核心优势：** Gemini Embedding的Matryoshka特性使Everlaw能够使用紧凑的表示，将基本信息集中在更少的维度中，从而最大限度地减少性能损失，降低存储成本，并提高检索和搜索效率。\n*   **图片：** ![Everlaw - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/everlaw.original.png)\n\n### 4. 提升开发者代码库搜索能力——Roo Code\n\n*   **公司：** Roo Code，一个开源AI编码助手。\n*   **应用：** 使用Gemini Embedding模型为其代码库索引和语义搜索提供支持。开发者需要一种能理解意图而非仅仅语法的搜索。\n*   **性能提升：** 通过将`gemini-embedding-001`与Tree-sitter结合进行逻辑代码分割，Roo Code即使对于不精确的查询也能提供高度相关的结果。初步测试发现，Gemini Embedding显著改进了其LLM驱动的代码搜索。\n*   **核心优势：** 使代码搜索更灵活、准确，并与开发者工作流程更一致。\n*   **图片：** ![ROO Code - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ROOCode.original.png)\n\n### 5. 提供个性化心理健康支持——Mindlid\n\n*   **公司：** Mindlid，一个AI健康伴侣。\n*   **应用：** 利用`gemini-embedding-001`理解对话历史，从而提供实时适应用户的上下文感知和有意义的洞察。\n*   **性能提升：** 实现了持续的亚秒级延迟（中位数：420毫秒）和可衡量的82%前3召回率，比OpenAI的`text-embedding-3-small`召回率提升了4%。\n*   **核心优势：** 提高了AI支持的相关性和速度，提供最相关的信息。\n*   **图片：** ![Mindlid - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Mindlid.original.png)\n\n### 6. 增强AI助手的上下文和效率——Interaction Co. (Poke)\n\n*   **公司：** Interaction Co.，正在构建Poke，一个AI电子邮件助手。\n*   **应用：** Poke使用Gemini Embedding执行两个关键功能：检索用户“记忆”和识别相关电子邮件以增强上下文。\n*   **性能提升：** 整合`gemini-embedding-001`后，Poke的语言模型以更快的速度和更高的精度检索数据。他们报告称，与Voyage-2相比，嵌入100封电子邮件的平均时间减少了90.4%，仅需21.45秒。\n*   **核心优势：** 大幅提升了电子邮件自动化中数据检索的速度和精度。\n*   **图片：** ![Poke - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Poke.original.png)\n\n## 未来智能代理的基础\n\n随着AI系统变得更加自主，它们的有效性将取决于我们提供给它们的上下文质量。像`gemini-embedding-001`这样的高性能嵌入模型是构建下一代能够推理、检索信息并代表我们行动的智能代理的基础。\n\n**注意：** 性能指标由开发者提供，未经Google独立证实。",
      "shortSummary": "Gemini Embedding模型已广泛应用于RAG和上下文工程等高级AI应用，通过高效整合关键信息，显著提升了AI系统的性能。文章展示了其在多个行业的成功案例：Box提升全球内容智能，re:cap提高金融数据分析准确性，Everlaw实现法律发现语义精度，Roo Code优化代码搜索，Mindlid提供个性化心理健康支持，以及Poke增强AI邮件助手效率。Gemini Embedding是构建未来智能代理的关键基础。",
      "translated_title": "Gemini Embedding：赋能RAG和上下文工程",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Box-AI-Gemini-Embedding.original.png",
          "alt": "Box AI - Gemini Embedding",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/re-cap.original.png",
          "alt": "re:cap - Gemini Embedding",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/everlaw.original.png",
          "alt": "Everlaw - Gemini Embedding",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ROOCode.original.png",
          "alt": "ROO Code - Gemini Embedding",
          "title": "",
          "position": 4
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Mindlid.original.png",
          "alt": "Mindlid - Gemini Embedding",
          "title": "",
          "position": 5
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Poke.original.png",
          "alt": "Poke - Gemini Embedding",
          "title": "",
          "position": 6
        }
      ],
      "contentSource": "完整文章",
      "content": "The Gemini Embedding model enhances AI applications, particularly through context engineering, which is being successfully adopted by various organizations across industries to power context-aware systems, leading to significant improvements in performance, accuracy, and efficiency."
    },
    {
      "title": "机器人专家与 JAX 的旅程：在最优控制和仿真中寻找效率 (原标题: A roboticist's journey with JAX: Finding efficiency in optimal control and simulation)",
      "link": "https://developers.googleblog.com/en/a-roboticists-journey-with-jax/",
      "pubDate": "Mon, 28 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-28T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 机器人专家与 JAX 的旅程：在最优控制和仿真中寻找效率\n\nJAX 正在被越来越多的开发者用于广泛的计算任务，其作用已超越最初对大规模 AI 的关注。尽管它仍然是开发大型语言模型 (LLMs) 和基础模型的流行框架，但 JAX 也在各种科学领域获得发展势头，尤其是在机器人学中，它在仿真、控制以及学习方法集成方面展现出强大的能力。\n\n最近，西北大学机器人学博士生兼研究员 Max Muchen Sun 的经历清晰地展示了 JAX 如何解决机器人研究中的关键挑战，特别是在复杂控制算法的计算效率以及模型驱动和学习驱动方法无缝结合方面。\n\n## Max 的 JAX 之旅：效率与集成\n\nMax 对 JAX 的兴趣始于对计算效率的追求。在导师 Ian Abraham 的引导下，他开始接触 JAX。他们当时正在研究遍历控制 (ergodic control)，这是一种用于覆盖问题的控制框架，其计算复杂性远高于标准控制公式。为了实现实时遍历控制，Max 最初使用标准 NumPy 并利用了向量化和广播特性。\n\n### JAX 的核心优势\n\n1.  **`vmap` 的强大功能**：\n    *   `vmap` 是 Max 第一个关注的 JAX 特性。\n    *   它结合并进一步泛化了标准 NumPy 的向量化和广播机制，通过函数转换和组合抽象，使得并行化推理和实现变得更加容易。\n2.  **`scan` 的效率提升**：\n    *   `scan` 最初不太直观，但最终成为模拟动态系统轨迹的有效工具。\n    *   在轨迹优化中，系统动力学的正向仿真是一个核心操作，需要重复执行并经常成为计算瓶颈。\n    *   使用 `scan`，轨迹仿真速度比基于标准 NumPy 的实现快两个数量级。这种易用性和显著的速度优势使 Max 完全投入到 JAX 生态系统中。\n\n### 模型驱动与学习驱动方法的融合\n\nMax 博士研究的核心重点是将模型驱动控制与学习驱动表示相结合，用于自主探索和多智能体协作。他认为模型驱动方法并非独立的解决方案，而是提高学习效率和鲁棒性的结构。JAX 的可组合性使其成为融合模型驱动和学习驱动流程的理想选择。\n\n#### 项目案例：\n\n*   **机器人探索 (RSS 论文)**：\n    *   Max 将生成模型中的流匹配 (flow matching) 与模型驱动的最优控制相结合，用于机器人探索。\n    *   通过基于 LQR 的更新，利用流梯度将状态空间流映射到控制，类似于动态系统上的反向传播。\n    *   最初，流匹配模块在 PyTorch 中构建，LQR 使用 C++，但集成缓慢。\n    *   切换到 JAX 后，他使用 `vmap` 和 `grad` 重新实现了流匹配部分，并利用了 JAX 工具如 OTT (Optimal Transport Toolbox)。唯一缺少的是一个 JAX 原生 LQR 管道。\n*   **多智能体协作 (ICRA 论文)**：\n    *   Max 将模型驱动的博弈论控制流程集成到生成轨迹模型中，以从演示中学习多智能体协作。\n    *   他没有将博弈论控制作为完整的解决方案（通常计算成本高昂且需要手动指定损失），而是将博弈论计算作为结构化层嵌入到条件变分自编码器 (CVAE) 中。这在不牺牲性能的情况下提高了数据效率。\n    *   两个组件都在 JAX 中实现：CVAE 使用 Flax，控制层从头开始构建。JAX 使其无缝衔接：`grad` 可以直接通过平衡点进行微分。他还构建了一个基于 JAX 的 iLQGames 求解器用于生成合成数据。\n\n### LQRax 的诞生\n\n在这些项目之后，Max 意识到他正在大量重用用于动态系统计算（尤其是基于 LQR 的计算）的 JAX 代码。由于他以非标准方式使用 LQR 来集成学习驱动和模型驱动控制，他将其打包成一个独立的 JAX 原生求解器——**LQRax**。\n\n*   **LQRax 的特性**：支持 GPU 加速、`vmap`、`scan` 和 `grad`，实现了向量化和可微分的 LQR。\n*   **应用示例**：Max 在 LQRax 中包含了遍历控制和博弈论控制的示例，以强调模型驱动方法如何补充学习。\n\n### JAX 的使用环境与未来展望\n\nMax 在 CPU 和 GPU 上都使用 JAX，其方式与机器学习社区有所不同。例如，在流匹配项目中，LQR 在 CPU 上运行更快，而流匹配梯度在 GPU 上更快。他没有使用 TPU，因为通常所有计算都在本地进行。几年前，他尝试在 Nvidia Jetson 上安装 JAX，当时很困难。他很高兴 JAX 现在支持这些嵌入式平台，这对于机器人学至关重要。他正在使用 Jetson 在四足机器人上测试人群导航算法，并计划很快将 JAX 集成到该项目中。\n\n展望未来，Max 将继续使用 JAX，原因与他最初开始使用时相同：\n\n1.  **计算效率**：尤其是基于 GPU 的并行化，在机器人学中变得越来越重要。除了训练，它还支持新的模型驱动控制可能性，如大规模并行仿真和实时参数更新，类似于具身主动学习。\n2.  **模型集成**：JAX 使将模型驱动结构直观地集成到学习流程中成为可能，无论是用于动力学、损失塑形还是可微分求解器。这种灵活性让他对进一步推动研究充满热情。\n\n## JAX 机器人生态系统\n\nMax 的经验展示了 JAX 为机器人社区提供的几个关键优势。`vmap` 实现的并行操作显著加速，以及 `scan` 实现的轨迹仿真加速，对于实时控制和复杂规划至关重要。此外，JAX 的函数式范式和自动微分能力使其非常适合将经典的模型驱动技术与现代学习驱动组件相结合。\n\nMax 的 LQRax 包是 JAX 原生机器人工具活跃生态系统的重要补充。在仿真领域，JAX 通过 Brax 和新的 MuJoCo XLA (MJX) 等大规模并行引擎提供了强大的基础，MJX 将流行的标准 MuJoCo 物理引擎直接引入 JAX。社区中也出现了专业工具，例如用于控制驱动多体动力学的 JaxSim 库。\n\n在轨迹优化领域，LQRax 作为 Trajax 等先驱之后的一个受欢迎的现代库，为研究人员构建下一代控制系统提供了支持。它完美地体现了 JAX 精神，提供了一个强大、可组合的工具，弥合了模型驱动控制和深度学习之间的鸿沟。",
      "shortSummary": "JAX正日益成为机器人学领域的重要工具，Max Muchen Sun的经验证明了其在最优控制和仿真中的高效性。JAX的`vmap`和`scan`功能显著提升了计算效率，加速了并行操作和轨迹仿真。它还使得模型驱动与学习驱动方法无缝集成成为可能，Max开发的`LQRax`库便是例证。JAX在CPU、GPU及嵌入式平台上的支持，使其成为构建下一代智能机器人系统的理想选择，推动了实时控制和复杂规划的发展。",
      "translated_title": "机器人专家与 JAX 的旅程：在最优控制和仿真中寻找效率",
      "images": [],
      "contentSource": "完整文章",
      "content": "Max's journey introduces LQRax, a JAX-native LQR solver, which exemplifies the growing JAX robotics ecosystem that includes tools like Brax, MJX, and JaxSim, highlighting the benefits of JAX for computational efficiency in optimal control and simulation, and for seamlessly integrating model-based and learning-based approaches."
    },
    {
      "title": "代理式体验：MCP 是您 AI 未来的正确工具吗？ (原标题: The agentic experience: Is MCP the right tool for your AI future?)",
      "link": "https://developers.googleblog.com/en/the-agentic-experience-is-mcp-the-right-tool-for-your-ai-future/",
      "pubDate": "Wed, 23 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 企业AI集成与Apigee的角色\n\n随着企业竞相将人工智能（AI）投入运营，挑战不仅在于构建和部署大型语言模型（LLM），还在于如何将其无缝集成到现有API生态系统中，同时保持企业级的安全性、治理和合规性。Apigee致力于在此旅程中引领企业，通过增强生成式AI代理的安全性、可扩展性和治理能力，从而简化其与应用程序的集成。\n\n### 模型上下文协议（MCP）的兴起与局限\n\n模型上下文协议（MCP）已成为集成离散API作为工具的事实标准方法。然而，MCP正在迅速演变，并且尚未完全满足企业对身份验证（AuthN）、授权（AuthZ）和可观测性（Observability）的需求。将API转化为代理式工具的旅程，远不止一个单一协议所能涵盖。\n\n### Apigee如何赋能企业级AI\n\nApigee作为Google Cloud的原生API管理平台，能够将您现有的企业API带入AI领域。Apigee承诺将继续引导企业在不断变化的AI格局中进行代理式转型，并确保为所有AI工作负载提供一流的企业级功能。\n\n#### 使MCP具备企业级能力\n\n在网络中利用MCP服务需要特定的安全约束。例如，您可能希望为MCP服务器本身添加身份验证，并根据消费应用程序授权对特定工具的访问。此外，您可能需要提供一流的可观测性信息，以跟踪哪些工具正在被谁使用。最后，您需要确保MCP服务器所提供的下游API也具备最低限度的安全保障。\n\nApigee提供了一个MCP服务器的开源示例，它精确地提供了这种类型的API安全性，并且所有这些功能现在都可用于您的MCP服务并得到支持。\n\n#### 通过Apigee API产品实现安全与治理\n\n此示例展示了如何利用Apigee的API产品对工具进行身份验证和授权控制。此外，最终位于MCP服务器背后的API（在此案例中部署到Cloud Run）本身也托管在Apigee上，因此它们获得了与Apigee上托管的其他任何API相同的安全性、分发和可观测性功能。这弥合了托管API与探索性AI交互之间的鸿沟，利用Apigee丰富的功能集来保护、扩展和治理您的AI旅程。此演示展示了如何立即启动并运行MCP服务器，同时提供所需的必要企业级控制。即使MCP标准发生变化，此设置也易于适应，因为它最终只是像其他任何后端一样通过Apigee提供服务。\n\n如下图所示，Apigee将API产品引入这些代理和MCP工具，并将其转化为AI产品。这些AI产品拥有自己的消费者和开发者，就像其他任何API一样。\n\n![API产品到AI产品](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_2ySlzKi.original.png)\n\n#### 参考架构与资源\n\nApigee的GitHub仓库提供了快速入门指南、示例工件和文档，将帮助您构建和部署Apigee中的参考MCP服务架构，并理解通过利用API产品将API暴露为AI代理工具的步骤。\n\n### 未来展望\n\nAI集成之旅将随着时间推移而不断调整和变化：MCP正在演变，例如从最初无身份验证到使用OAuth进行授权和资源服务的转变。Google Apigee致力于与这种演变同步发展。\n\n了解更多关于如何使用Apigee操作生成式AI应用程序，并查阅Apigee的AI策略文档。",
      "shortSummary": "Apigee帮助企业将AI代理（如LLMs）安全、可扩展地集成到现有API生态系统中。尽管模型上下文协议（MCP）是工具集成方法，但其缺乏企业级安全功能。Apigee提供了一个开源MCP服务器示例，利用其API管理平台为MCP服务提供认证、授权和可观测性，确保企业级安全与治理，并支持API产品化，从而简化AI集成并适应未来变化。",
      "translated_title": "代理式体验：MCP 是您 AI 未来的正确工具吗？",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_2ySlzKi.original.png",
          "alt": "API product to AI product",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Apigee helps enterprises integrate large language models (LLMs) into existing API ecosystems securely and scalably, addressing challenges like authentication and authorization not fully covered by the evolving Model Context Protocol (MCP), and offering an open-source MCP server example that demonstrates how to implement enterprise-ready API security for AI agents."
    },
    {
      "title": "介绍 Opal：描述、创建和分享你的 AI 迷你应用 (原标题: Introducing Opal: describe, create, and share your AI mini-apps)",
      "link": "https://developers.googleblog.com/en/introducing-opal/",
      "pubDate": "Wed, 23 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 介绍 Opal：描述、创建和分享你的 AI 迷你应用\n\n**发布日期：** 2025年7月24日\n\nGoogle Labs 宣布推出 **Opal**，这是一款全新的实验性工具，旨在简化 AI 模型、提示和工具的整合，从而轻松构建和分享功能强大的 AI 应用。\n\n### Opal 是什么？\n\nOpal 是一个来自 Google Labs 的创新实验性工具，它允许用户通过简单的自然语言和可视化编辑，构建并分享强大的 AI 迷你应用。这些迷你应用能够将提示、AI 模型调用和各种工具串联起来，形成完整的工作流程。\n\n### 主要用途\n\nOpal 旨在加速 AI 想法和工作流程的实现，其主要用途包括：\n\n*   加速 AI 概念和工作流程的原型开发。\n*   通过功能性应用展示概念验证（PoC）。\n*   构建自定义 AI 应用以显著提高工作效率。\n\n### 可用性\n\nOpal 目前已在美国地区以**公开测试版**形式推出。Google Labs 强调，通过与社区的合作，能够更好地构建和完善这款新产品。\n\n### 核心功能（无需代码）\n\n尽管 Opal 仍处于实验阶段，但它已具备强大的功能，旨在将用户的想法变为现实，且无需编写代码：\n\n1.  **创建工作流程：**\n    *   Opal 简化并可视化了软件开发中“工作流程”的概念，即用户完成特定目标所采取的步骤序列。\n    *   它通过将提示、AI 模型调用和其他工具串联起来，帮助用户构建强大的多步骤应用。\n    *   用户只需描述逻辑，Opal 即可自动构建相应的可视化工作流程。\n\n2.  **进行编辑：**\n    *   Opal 将用户的指令转化为可视化工作流程，提供精细的控制，而无需用户接触任何代码。\n    *   用户可以通过对话式自然语言命令、可视化编辑器或两者结合的方式，构建和修改他们的 AI 迷你应用。\n    *   无论是调整某个步骤的提示、添加新功能还是调用工具，都可以通过可视化编辑器或直接描述变更来实现。\n\n3.  **分享应用：**\n    *   一旦应用构建完成并准备就绪，用户可以将其作为独立应用分享给他人。\n    *   其他用户可以使用自己的 Google 账户立即使用这些分享的应用。\n\n### 开始使用 Opal\n\n为了帮助用户快速上手，Opal 提供了一个**演示画廊**，其中包含各种入门模板。用户可以直接使用这些预构建的 AI 应用，也可以根据自身具体需求进行修改和定制。\n\n![Opal 模板画廊](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Just_Gallery.original.png)\n\n### 愿景\n\nOpal 引入了一种全新的 AI 创作方式。它旨在赋能创作者、创新者和实践者，通过将简单的提示转化为强大的迷你应用，从而构建他们所设想的工具。",
      "shortSummary": "Opal 是 Google Labs 推出的一款实验性工具，旨在帮助用户通过自然语言和可视化编辑，无需代码即可描述、创建和分享 AI 迷你应用。它能将提示、AI 模型和工具串联成工作流程，加速 AI 想法原型开发，并构建自定义应用以提升生产力。Opal 目前在美国提供公开测试版，并提供模板画廊以方便用户快速上手。",
      "translated_title": "介绍 Opal：描述、创建和分享你的 AI 迷你应用",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Just_Gallery.original.png",
          "alt": "Gallery of Opal templates",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Opal is a new experimental tool from Google Labs that helps you compose prompts into dynamic, multi-step mini-apps using natural language, removing the need for code, allowing users to build and deploy shareable AI apps with powerful features and seamless integration with existing Google tools."
    },
    {
      "title": "AI人物播客第五季上线：认识塑造未来的人工智能建设者 (原标题: People of AI podcast Season 5 is here: Meet the builders shaping the future)",
      "link": "https://developers.googleblog.com/en/people-of-ai-podcast-season-5/",
      "pubDate": "Wed, 23 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "## AI人物播客第五季：聚焦AI建设者\n\nGoogle的“AI人物播客”（People of AI podcast）第五季已于2025年7月24日回归，本季将深入探讨不断变化的AI世界，并带来一个全新的视角：聚焦AI的“建设者”（Builders）。这些建设者包括开发者、初创公司、创始人以及所有积极塑造AI未来的人。\n\n### 聚焦“建设者”的原因\n\nAI领域正在迅速发展，对“可能”的定义、开发者角色以及日常工作方式都在快速演变。几年前还在研究论文中的概念，如今已迅速成为数百万用户日常使用的产品和应用的核心部分。生成式AI已触手可及，并嵌入到用户喜爱的工具中，以科幻般的方式激发着人们的想象力。因此，本季播客将重点转向这些正在构建AI的“建设者”。\n\n### 首集亮点：探索AI前沿\n\n首集节目邀请到Google DeepMind研究副总裁Clement Farabet。节目深入探讨了AI的演变，从卷积神经网络（CNNs）到Transformer模型，再到大型语言模型（LLMs）的强大能力，以及这些进步如何为智能体系统（agentic systems）铺平道路。Clement Farabet以工程师、企业家和自称“疯狂科学家”的独特视角，分享了构建能够真正学习、行动、在现实世界中提供帮助并负责任的AI智能体的激动人心的可能性和关键挑战。\n\n### 第五季新变化\n\n除了新的焦点，本季播客主持人Ashley Oldacre将与资深播客主持人Christina Warren搭档，为对话带来深刻的技术见解和全新视角。他们将带领听众深入了解那些正在改变一切的初创公司、研究人员和行业领袖的幕后故事，揭示建设者们正在努力解决的问题以及AI如何融入解决方案。\n\n### 本季部分嘉宾预告\n\n本季将邀请多位行业专家和创新者，包括：\n\n*   **AI开发与教育：** 听取资深开发者Muhammad Farooq和Jerome Hardaway关于未来开发和AI教育的见解。\n*   **AI电影创作：** 了解导演Eliza McNitt和Google DeepMind的Veo团队（Ben Wiley, Kory Mathewson）如何创作出首部AI制作电影《ANCESTRA》的幕后创意过程。\n*   **AI助手未来：** 与Bibo Xu（Project Astra）和Jérôme Monceaux（Enchanted Tools）讨论AI助手的未来发展。\n*   **AI跨领域应用：** 探索创新者Max Child和James Wilsterman（Volley）、Andrew Carr（Cartwheel）以及Dr. Dhruv Joshi（Cloudphysician）如何将AI融入游戏、动画和医疗保健领域。\n\n### 播客目标\n\n“AI人物播客”第五季是了解推动AI革命的真实世界创新者的绝佳机会。他们的故事将激励听众进行创造性思考，克服挑战，并为负责任且有影响力的AI未来做出贡献。\n\n### 订阅与关注\n\n请在goo.gle/PAI订阅“AI人物播客”，并在LinkedIn和X上关注Google AI Developers，获取最新动态和幕后内容。",
      "shortSummary": "Google的“AI人物播客”第五季已上线，本季将聚焦AI的“建设者”，即塑造AI未来的开发者、初创公司和创始人。节目将深入探讨AI的快速演变，包括生成式AI和智能体系统，并邀请Google DeepMind的Clement Farabet等行业领袖分享见解。新主持人Christina Warren加入，共同揭示AI创新者如何解决现实问题，并探讨AI在各领域的应用，旨在激励听众为负责任的AI未来贡献力量。",
      "translated_title": "AI人物播客第五季上线：认识塑造未来的人工智能建设者",
      "images": [],
      "contentSource": "完整文章",
      "content": "Co-hosted by Ashley Oldacre and Christina Warren, People of AI podcast's Season 5 will focus on the builders in the space of AI, highlighting the unique journeys, challenges, and triumphs of these innovators."
    },
    {
      "title": "在 Firebase Studio 中为流行框架释放新的 AI 能力 (原标题: Unleashing new AI capabilities for popular frameworks in Firebase Studio)",
      "link": "https://developers.googleblog.com/en/new-ai-capabilities-for-popular-frameworks-in-firebase-studio/",
      "pubDate": "Tue, 22 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-22T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Firebase Studio 推出新 AI 功能，赋能流行框架\n\nFirebase Studio 是一个基于云的 AI 工作空间，旨在帮助开发者构建和发布下一代 AI 驱动的应用程序。继之前推出多功能代理模式、模型上下文协议（MCP）基础支持以及与 Gemini CLI 集成之后，Google 在 I/O Connect India 大会上公布了多项新更新，旨在结合 Gemini 的强大功能与这些新特性，帮助开发者利用其喜爱的框架和语言，将想法快速转化为应用程序。\n\n这些新更新包括：\n\n*   **AI 优化模板加速代理开发**\n*   **与 Firebase 后端服务无缝集成**\n*   **通过分叉工作区更好地控制不断演进的代码库**\n\n选择在印度发布这些公告具有特殊意义，因为印度拥有全球最大的应用程序开发者社区之一。例如，Google Android 开发者专家 Pankaj Rai 利用 Firebase Studio 构建了学生指导平台 Mentor Sarthi，并将其个人造型应用 GlamMEAi 推广到网络平台，而无需学习网络开发。\n\n### 详细功能介绍：\n\n1.  **引入 AI 优化模板，助力极速构建**\n    *   Firebase Studio 更新了 Flutter、Angular、React、Next.js 和通用 Web 的工作区模板，新增了利用 Gemini 的 AI 功能，帮助开发者构建和部署美观、强大的应用程序。\n    *   使用 AI 优化模板创建项目时，工作区将默认进入自主代理模式，并采用重新设计过的布局，帮助开发者快速进入工作流。\n    *   开发者可以获得 Gemini 的协助，独立规划和执行任务，无需等待分步批准。同时，仍可根据任务需求切换到“询问”和“代理”模式，无论是生成整个应用程序、优化功能、运行测试、生成文档还是添加新功能。\n    *   每个模板中都添加了 `airules.md` 文件，为 Gemini 提供专门的指令，以指导代码生成并为每种特定类型的应用程序创建文档。这使得 Gemini 能更好地了解相关的编码标准、错误处理方法、依赖项和开发最佳实践。\n    *   未来几周，Firebase Studio 将更新 Go、Node.js、.NET 等更多流行框架和语言的模板。\n\n2.  **与 Firebase 服务无缝集成**\n    *   从即日起，开发者只需向 Gemini 发出提示，即可将 Firebase 后端服务集成到应用程序中。\n    *   如果使用 App Prototyping Agent 进行“氛围编码”或使用 AI 优化模板，只需告诉 Gemini 应用程序需要实现什么功能，它就会推荐相应的 Firebase 服务。\n    *   Gemini 将自动导入所需的库或包，更新代码以集成所需服务，并指导完成任何额外的设置或配置步骤，从而节省开发者的时间和点击次数。\n    *   所有这些功能均可免费开始使用。\n\n3.  **分叉工作区，赋能实验与协作**\n    *   现在，开发者可以分叉工作区，创建一份完全相同的副本，包括保留原始工作区中的所有代理聊天历史记录。\n    *   这提供了一个可靠的备份，可以随时恢复，让开发者能够自信地构建新功能和尝试新事物，而无需担心犯下不可逆转的错误。\n    *   分叉工作区还可用于调试和故障排除，而不会影响主开发工作区，并通过与他人共享“进行中”的工作区来使协作更加顺畅。\n\n4.  **增强提示功能并增加项目上传大小**\n    *   Firebase Studio 持续改进 AI 辅助开发体验，提供更大的控制和灵活性。\n    *   新增的“增强提示”功能允许开发者在 Firebase Studio 内与 Gemini 协作并完善其提示和应用程序想法。\n    *   项目上传大小已显著增加到 100MB，使得开发者可以将更大、更复杂的现有项目导入 Firebase Studio。\n\nFirebase Studio 致力于使 AI 辅助开发更加直观、快速和愉悦，无论开发者拥有数十年的编码经验还是完全没有经验，都能将他们最雄心勃勃的应用程序想法变为现实。",
      "shortSummary": "Firebase Studio 推出重大更新，旨在通过 AI 赋能应用开发。新功能包括：AI 优化模板，加速 Flutter、React 等框架的开发；与 Firebase 后端服务无缝集成，Gemini 可自动推荐并导入服务；支持分叉工作区，便于实验、备份和协作；以及增强提示功能和将项目上传大小提升至 100MB。这些更新旨在让 AI 辅助开发更直观、高效，帮助全球开发者将创意变为现实。",
      "translated_title": "在 Firebase Studio 中为流行框架释放新的 AI 能力",
      "images": [],
      "contentSource": "完整文章",
      "content": "New AI capabilities for popular frameworks in Firebase Studio include AI-optimized templates, streamlined integration with Firebase backend services, and the ability to fork workspaces for experimentation and collaboration, making AI-assisted app development more intuitive and faster for developers worldwide."
    },
    {
      "title": "Gemini 2.5 Flash-Lite 现已稳定版发布并普遍可用 (原标题: Gemini 2.5 Flash-Lite is now stable and generally available)",
      "link": "https://developers.googleblog.com/en/gemini-25-flash-lite-is-now-stable-and-generally-available/",
      "pubDate": "Mon, 21 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-21T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Gemini 2.5 Flash-Lite 稳定版发布\n\n2025年7月22日，谷歌正式发布了 Gemini 2.5 Flash-Lite 的稳定版本。作为 Gemini 2.5 模型家族中速度最快、成本最低（输入每百万代币0.10美元，输出每百万代币0.40美元）的模型，它的推出旨在推动“每美元智能”的边界，并提供可选的原生推理能力，以应对更严苛的用例。该模型与此前的 2.5 Pro 和 2.5 Flash 一起，完善了可用于大规模生产的 Gemini 2.5 模型系列。\n\n### 核心优势\n\nGemini 2.5 Flash-Lite 在性能和成本之间取得了平衡，同时不牺牲质量，尤其适用于对延迟敏感的任务，如翻译和分类。其突出特点包括：\n\n*   **一流的速度**：在广泛的提示样本上，Gemini 2.5 Flash-Lite 的延迟均低于 2.0 Flash-Lite 和 2.0 Flash。\n*   **成本效益**：它是目前成本最低的 2.5 模型，定价为每百万输入代币0.10美元，每百万输出代币0.40美元，使得处理大量请求变得经济实惠。此外，音频输入价格相比预览版降低了40%。\n*   **智能且小巧**：在编码、数学、科学、推理和多模态理解等广泛基准测试中，其整体质量均高于 2.0 Flash-Lite。\n*   **功能全面**：使用 2.5 Flash-Lite 进行开发，可获得100万代币的上下文窗口、可控的思考预算，并支持原生工具，如 Google 搜索接地（Grounding）、代码执行和 URL 上下文。\n\n### 模型能力对比\n\n![Gemini 2.5 Flash-Lite、2.5 Flash 和 2.5 Pro 的能力对比表](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_ga_family_1-1__dark.original.png)\n\n### Gemini 2.5 Flash-Lite 的实际应用\n\n自 2.5 Flash-Lite 发布以来，已有一些成功的部署案例：\n\n*   **Satlyt**：正在构建一个去中心化的空间计算平台，用于实时总结在轨遥测数据、自主任务管理和卫星间通信解析。2.5 Flash-Lite 的速度使其关键的在轨诊断延迟降低了45%，功耗比基线模型降低了30%。\n*   **HeyGen**：利用 AI 创建视频内容头像。他们使用 Gemini 2.5 Flash-Lite 自动化视频规划、分析和优化内容，并将视频翻译成180多种语言，为用户提供全球化的个性化体验。\n*   **DocsHound**：将产品演示转化为文档。通过 Gemini 2.5 Flash-Lite 处理长视频并以低延迟提取数千张截图，将素材快速转化为全面的文档和 AI 代理训练数据，远快于传统方法。\n*   **Evertune**：帮助品牌了解其在 AI 模型中的表现。Gemini 2.5 Flash-Lite 大幅加快了他们的分析和报告生成速度，使其能够快速扫描和合成大量模型输出，为客户提供动态、及时的洞察。\n\n### 如何开始使用\n\n您可以通过在代码中指定“gemini-2.5-flash-lite”来开始使用该模型。如果您正在使用预览版本，可以直接切换到“gemini-2.5-flash-lite”，它们是相同的底层模型。预览别名计划于8月25日移除。现在即可在 Google AI Studio 和 Vertex AI 中试用 Gemini 2.5 Flash-Lite 的稳定版本。",
      "shortSummary": "Gemini 2.5 Flash-Lite 稳定版已于2025年7月22日发布，是 Gemini 2.5 模型家族中速度最快、成本最低的模型（输入每百万代币0.10美元，输出0.40美元）。它在性能、成本和质量之间取得平衡，尤其适用于延迟敏感任务。该模型提供100万代币上下文窗口和原生工具支持，并在编码、推理等多方面表现出色。Satlyt、HeyGen、DocsHound 和 Evertune 等公司已成功将其应用于各自领域，显著提升了效率。用户可在 Google AI Studio 和 Vertex AI 中使用。",
      "translated_title": "Gemini 2.5 Flash-Lite 现已稳定版发布并普遍可用",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_ga_family_1-1__dark.original.png",
          "alt": "Comparative table showing capabilities of Gemini 2.5 Flash-Lite, 2.5 Flash, and 2.5 Pro",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Gemini 2.5 Flash-Lite, previously in preview, is now stable and generally available. This cost-efficient model is ~1.5x faster than 2.0 Flash-Lite and 2.0 Flash, offers high quality, and includes 2.5 family features like a 1 million-token context window and multimodality."
    }
  ],
  "lastUpdated": "2025-08-09T10:29:53.342Z"
}
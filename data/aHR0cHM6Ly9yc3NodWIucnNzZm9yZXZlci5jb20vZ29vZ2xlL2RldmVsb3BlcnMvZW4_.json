{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "推出 Code Wiki：加速你的代码理解 (原标题: Introducing Code Wiki: Accelerating your code understanding)",
      "link": "https://developers.googleblog.com/en/introducing-code-wiki-accelerating-your-code-understanding/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Code Wiki：加速你的代码理解\n\nGoogle Cloud 的产品管理总监 Fergus Hurley、高级工程经理 Pedro Rodriguez 和产品经理 Rafael Marques 共同宣布推出 Code Wiki。该平台旨在解决软件开发中阅读现有代码这一最大且最昂贵的瓶颈，通过为代码仓库维护一个持续更新、结构化的维基来显著提高开发人员的生产力。\n\n## 理解代码的新方式\n\nCode Wiki 的核心使命是组织并解锁复杂源代码中蕴藏的关键知识，使文档保持“鲜活”和实用。它通过以下关键特性实现这一目标：\n\n*   **自动化且始终最新**：Code Wiki 扫描整个代码库，并在每次代码更改后自动重新生成文档，确保文档与代码的演进保持同步。\n*   **智能且上下文感知**：整个、始终最新的维基作为集成聊天（由 Gemini 提供支持）的知识库。用户可以与一个深入了解整个仓库的特定模型进行对话，而非通用模型，从而获得高度相关的答案。\n*   **集成且可操作**：维基的每个部分和聊天回答都直接超链接到相关的代码文件和定义，将代码的阅读和探索无缝整合到一个工作流程中。\n\n## Code Wiki 网站（公开预览版）\n\nCode Wiki 网站现已推出公开预览版，这是基于新系统构建的首个产品。它能够摄取公共仓库，并为每个仓库生成、托管并维护全面且交互式的文档。通过 Code Wiki 网站，用户可以：\n\n*   **交互式导航**：从高层概念解释直接跳转到引用的具体代码文件、类和函数，实现高效的代码探索。\n*   **Gemini 驱动的聊天代理**：当遇到复杂模块时，用户可以向使用最新维基作为上下文的 Gemini 聊天代理提问，即时获得关于仓库的特定问题的答案，弥合学习代码与实际探索代码之间的鸿沟。\n*   **自动生成图表**：当文本不足以解释复杂关系时，Code Wiki 会自动生成始终最新的架构图、类图和序列图，帮助用户可视化与代码当前状态完全匹配的复杂关系。\n\n![Gemini CLI Code Wiki v2](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_CLI_Code_Wiki_v2.original.png)\n\n这种由 AI 驱动、自动化、智能且集成的方法是解决代码理解瓶颈的关键。它能让新贡献者在第一天就提交他们的第一个代码，并让资深开发人员在几分钟而非几天内理解新的库，从而显著提升团队效率。\n\n## 即将推出：Code Wiki Gemini CLI 扩展\n\n尽管开源生态系统拥有大量仓库，但私有仓库往往是最难有效文档化的。尤其是在原始代码作者可能已不在公司的情况下，理解遗留代码是一个巨大的障碍。Code Wiki 团队认为这项技术将彻底改变这些内部环境，确保每个人都能深入理解他们正在处理的代码。\n\n团队正在为 Code Wiki 构建一个 Gemini CLI 扩展，以便团队可以在本地安全地运行相同的系统，处理内部仓库。用户可以加入 Gemini CLI 扩展的等候名单，以获取最新信息。\n\n## 开发的未来\n\nCode Wiki 旨在让开发人员将时间花在构建上，而不是解密代码。手动、过时的文档和无休止的代码阅读时代已经结束。开发的未来在于即时理解，Code Wiki 正是这一愿景的体现。",
      "shortSummary": "Google Cloud 推出 Code Wiki，旨在解决代码理解难题。该平台通过为代码仓库自动生成并维护持续更新、智能且集成的维基文档，结合 Gemini 驱动的上下文感知聊天和自动图表，加速代码理解。Code Wiki 网站已上线公开预览，未来还将推出 Gemini CLI 扩展以支持内部仓库。这使得新开发者能快速上手，资深开发者能迅速理解新库，将开发重心从代码解密转向构建，开启即时理解的开发新时代。",
      "translated_title": "推出 Code Wiki：加速你的代码理解",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini_CLI_Code_Wiki_v2.original.png",
          "alt": "Gemini CLI Code Wiki v2",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Code Wiki is a new platform that tackles the bottleneck of reading existing code by providing an automated, continuously updated, structured wiki for code repositories. It features hyper-linked documentation, a Gemini-powered chat agent that understands your repo, and automated diagrams. A public preview is available for open-source projects, and a Gemini CLI extension is coming soon for secure use on private repos."
    },
    {
      "title": "让终端美观，一次一个像素 (原标题: Making the terminal beautiful one pixel at a time)",
      "link": "https://developers.googleblog.com/en/making-the-terminal-beautiful-one-pixel-at-a-time/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini CLI用户体验重大升级：打造更美观、稳定的终端\n\nGoogle于2025年11月13日宣布对Gemini CLI的用户体验进行重大升级，旨在使其终端交互更加强大、直观和视觉稳定。此次升级彻底改造了Gemini CLI的渲染基础，消除了终端应用常见的视觉干扰，将图形界面级别的精致度直接带入终端。用户将不再遇到屏幕闪烁、输入提示跳动或在长输出流中迷失位置的问题，Gemini CLI变得更加流畅。\n\n## 关键增强功能\n\n新的渲染基础带来了多项即时改进，旨在提升用户体验：\n\n*   **鼠标导航**：\n    *   用户现在可以直接在输入提示符内使用鼠标点击进行导航，无需再频繁使用方向键。\n*   **持久化标题行**：\n    *   引入了工具确认和操作的持久化标题行，确保用户在复杂交互中也能始终了解当前操作的上下文。\n    *   ![持久化标题](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Sticky_header.original.png)\n*   **无闪烁体验**：\n    *   新设计几乎消除了屏幕闪烁。使用VSCode、iTerm、Ghostty等现代终端的用户将告别闪烁屏幕，享受流畅的终端体验。\n*   **健壮的渲染**：\n    *   以前，调整终端窗口大小有时会导致视觉故障或伪影。现在，这些渲染伪影已成为历史，无论如何调整窗口大小，都能提供清晰、精致的显示。\n*   **稳定的输入提示符**：\n    *   输入字段现在牢固地固定在终端底部，提供一致、可预测的体验，告别跳动的提示框。\n    *   ![锚定提示符](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/anchored-prompt.original.png)\n*   **历史记录保留**：\n    *   尽管为了无缝体验使用了备用屏幕缓冲区，但在退出Gemini CLI后，完整的聊天历史记录仍可在标准终端中访问。\n\n## 如何开始使用新UI\n\n这些新的UI改进已在Gemini CLI v0.15.0及更高版本中默认启用。\n要升级到最新版本的Gemini CLI，请使用以下命令：\n`npm install -g @google/gemini-cli@latest`\n\n## 后续计划\n\n这仅仅是健壮的新TUI渲染基础所能实现功能的开始。团队正在积极开发进一步的改进，包括：\n\n*   滚动条的点击拖动功能（目前可通过鼠标滚轮或Shift+上/下键滚动）。\n*   提供更无缝的复制粘贴解决方案（目前，用户可通过按Ctrl-S暂时退出鼠标模式来使用标准复制/粘贴方法选择文本）。\n\n鼓励用户立即尝试新的无缝UI，并在GitHub上提供反馈。",
      "shortSummary": "Gemini CLI发布v0.15.0版本，带来用户体验重大升级，旨在使终端交互更稳定、直观。核心改进包括：消除屏幕闪烁、鼠标导航、持久化标题行、稳定的输入提示符以及健壮的窗口大小调整渲染。这些功能默认启用，用户可通过升级CLI体验更流畅的终端操作。未来还将支持拖动滚动条和更无缝的复制粘贴，并鼓励用户提供反馈。",
      "translated_title": "让终端美观，一次一个像素",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Sticky_header.original.png",
          "alt": "Sticky header",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/anchored-prompt.original.png",
          "alt": "anchored-prompt",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "完整文章",
      "content": "Google has launched the redesigned **Android AI Sample Catalog**, a dedicated, open-source application to inspire and educate Android developers on building AI-powered apps. It showcases examples using both on-device (Gemini Nano via ML Kit GenAI API) and Cloud models (via Firebase AI Logic SDK), including image generation with Imagen, on-device summarization, and a \"Chat with Nano Banana\" chatbot. The code is easy to copy and paste to help developers quickly start their own projects."
    },
    {
      "title": "介绍 Metrax：JAX 中高性能、高效且稳健的模型评估指标 (原标题: Introducing Metrax: performant, efficient, and robust model evaluation metrics in JAX)",
      "link": "https://developers.googleblog.com/en/introducing-metrax-performant-efficient-and-robust-model-evaluation-metrics-in-jax/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 介绍 Metrax：JAX 中高性能、高效且稳健的模型评估指标\n\nMetrax 是一个专为 JAX 设计的高性能库，旨在提供高效且稳健的模型评估指标。它的诞生是为了解决 Google 团队在从 TensorFlow 迁移到 JAX 时，由于 JAX 缺乏内置指标库而不得不手动重新实现各种评估指标的问题，尤其是在大规模分布式计算环境中，这变得尤为复杂。\n\n## Metrax 的核心优势与特性\n\n*   **全面的指标覆盖**：Metrax 提供了用于评估各种机器学习模型（分类、回归、推荐、视觉、音频和语言）的预定义指标。\n*   **分布式环境兼容性**：它确保了在分布式和规模化训练环境中的兼容性和一致性，让开发者能专注于模型评估结果，而非重复实现指标定义。\n*   **“At K”指标的并行计算**：\n    *   Metrax 能够并行计算多个 K 值的“at K”指标，例如 PrecisionAtK、RecallAtK 和 NDCGAtK。\n    *   这意味着用户可以在模型的一次前向传播中，同时获取 K=1、K=8 和 K=20 等多个 K 值下的精度，从而更快、更全面地评估模型性能。\n*   **稳健性和可靠性**：作为一个经过充分测试的指标库，Metrax 有助于社区编写更少出错的代码和进行更可靠的模型评估。\n*   **性能优化**：Metrax 利用 JAX 的核心优势，如 `vmap` 和 `jit`，以高性能方式执行多项操作，包括“at K”操作。\n*   **丰富的指标类型**：除了准确率、精确率和召回率等经典指标外，Metrax 还包含一套强大的自然语言处理（NLP）相关指标（如 Perplexity、BLEU、ROUGE），以及视觉模型指标（如 IoU、SNR、SSIM）。\n\n## Metrax 的使用示例\n\nMetrax 的使用方式简洁明了，支持直接计算和批处理合并。\n\n1.  **直接计算指标**：\n    通过 `metrax.Precision.from_model_output` 方法传入预测值、标签和阈值，然后调用 `compute()` 即可获得结果。\n    ```python\n    import metrax\n    # 直接计算指标状态。\n    metric_state = metrax.Precision.from_model_output(\n        predictions=predictions,\n        labels=labels,\n        threshold=0.5\n    )\n    # 调用 compute() 即可获得结果。\n    result = metric_state.compute()\n    ```\n\n2.  **迭代合并批次指标**：\n    在批处理评估中，可以使用 `merge()` 函数迭代地将每个批次的指标信息合并到总的指标状态中，最后调用 `compute()` 获取最终值。\n    ```python\n    # 迭代合并精确率指标\n    for labels_b, predictions_b, weights_b in zip(labels_batched, predictions_batched, sample_weights_batched):\n        batch_metric_state = metrax.Precision.from_model_output(\n            predictions=predictions_b,\n            labels=labels_b\n        )\n        metric_state = metric_state.merge(batch_metric_state)\n    result = metric_state.compute()\n    ```\n\n## 生态系统整合与贡献\n\n*   **JAX AI Stack 的一部分**：Metrax 很好地融入了 JAX AI Stack，这是一个旨在协同工作以满足 AI 工具需求的工具套件。\n*   **广泛应用**：目前，Metrax 已被 Google 内部一些最大的软件栈使用，包括 Google 搜索、YouTube 和 Google 自己的训练后库 Tunix。\n*   **社区贡献**：Metrax 在 GitHub 上开源（github.com/google/metrax），并欢迎社区贡献。许多现有指标都是由社区贡献者添加的。\n*   **更多资源**：用户可以在 `jaxstack.ai` 找到更多与 Metrax 良好集成的 JAX 生态系统库和关于构建机器学习模型的内容。",
      "shortSummary": "Metrax 是一个为 JAX 设计的高性能模型评估指标库，旨在解决 JAX 缺乏内置指标库的问题。它提供了一系列预定义、高效且稳健的机器学习模型评估指标，支持并行计算多个“at K”指标，并利用 JAX 的性能优势。Metrax 整合了 JAX AI Stack，已被 Google 内部团队广泛使用，并在 GitHub 上开源，欢迎社区贡献。",
      "translated_title": "介绍 Metrax：JAX 中高性能、高效且稳健的模型评估指标",
      "images": [],
      "contentSource": "完整文章",
      "content": "Metrax is a high-performance JAX-based metrics library developed by Google. It standardizes model evaluation by offering robust, efficient metrics for classification, NLP, and vision, eliminating manual re-implementation after migrating from TensorFlow. Key strengths include parallel computation of \"at K\" metrics (e.g., PrecisionAtK) for multiple K values and strong integration with the JAX AI Stack, leveraging JAX's performance features. It is open-source on GitHub."
    },
    {
      "title": "Google Colab 即将登陆 VS Code (原标题: Google Colab is Coming to VS Code)",
      "link": "https://developers.googleblog.com/en/google-colab-is-coming-to-vs-code/",
      "pubDate": "Wed, 12 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Google Colab VS Code 扩展发布\n\nGoogle Colab 团队于2025年11月13日宣布推出全新的 Google Colab Visual Studio Code 扩展。此举旨在将全球最受欢迎的代码编辑器 VS Code 的强大功能与数百万 AI/ML 开发者、学生和研究人员首选的 Colab 平台结合起来。\n\n## 发布背景与动机\n\n*   **VS Code 的普及**：VS Code 以其速度、轻量级和高度适应性，成为全球广受欢迎的代码编辑器。\n*   **Colab 的成功**：Colab 已成为 AI/ML 领域编写和执行代码、协作以及无缝访问 GPU 和 TPU 等强大计算资源的平台。\n*   **弥合差距的需求**：此前，VS Code 和 Colab 的使用场景相对独立。社区强烈希望将强大的 VS Code 开发环境与基于网络的 Colab 笔记本结合，以支持更复杂的项目开发和工作流。Colab 的目标是满足用户需求，而许多用户都在 VS Code 中工作。\n\n## 融合两者的优势\n\n新的 Colab VS Code 扩展旨在结合两个平台的优点：\n\n*   **对于 VS Code 用户**：\n    *   可以在熟悉的 VS Code 编辑器中继续工作。\n    *   将本地笔记本连接到高性能的 Colab 运行时，包括提供高级 GPU 和 TPU 的 Colab Pro 运行时。\n*   **对于 Colab 用户**：\n    *   支持 Colab 用户现有的工作流，例如处理作为大型项目或 Git 仓库一部分的笔记本。\n    *   为需要更强大 IDE 功能和更高可扩展性的 Colab 用户提供了解决方案。\n    *   弥合了简单易用的 Colab 运行时与功能丰富的 VS Code 编辑器之间的鸿沟。\n\n## 如何开始使用 Colab 扩展\n\n只需几个简单的步骤即可开始使用：\n\n1.  **安装 Colab 扩展**：\n    *   在 VS Code 中，打开左侧活动栏的“扩展”视图（或按 `Ctrl|Cmd + Shift + X`）。\n    *   在市场中搜索“Google Colab”。\n    *   点击官方 Colab 扩展的“安装”按钮。\n    *   如果提示，安装所需的依赖项——Jupyter 扩展。\n2.  **连接到 Colab 运行时**：\n    *   在本地工作区中创建或打开任何 `.ipynb` 笔记本文件。\n    *   运行一个单元格（这将引导您选择内核）或点击右上角的“选择内核”按钮。\n    *   点击“Colab”，然后选择所需的运行时，使用您的 Google 账户登录即可。\n    *   您的本地笔记本现在将由 Colab 运行时提供支持。\n\n该扩展也已发布到 Open VSX，支持 VS Code 的衍生版本。\n\n## 未来展望\n\n此次发布是 Google Colab 将其最佳功能带给用户的起点。团队计划未来将更多 Colab 功能引入 VS Code。\n\n鼓励用户立即从 VS Code Marketplace 下载扩展，试用并提供反馈。",
      "shortSummary": "Google Colab 已推出适用于 Visual Studio Code 的官方扩展。此举将 VS Code 的强大编辑功能与 Colab 的高性能 AI/ML 计算资源（包括 GPU 和 TPU）相结合。用户现在可以在熟悉的 VS Code 环境中，将本地 Jupyter 笔记本连接到 Colab 运行时，从而简化开发流程，并支持更复杂的项目和协作。该扩展旨在满足开发者在 VS Code 中使用 Colab 的需求，并计划未来带来更多功能。",
      "translated_title": "Google Colab 即将登陆 VS Code",
      "images": [],
      "contentSource": "完整文章",
      "content": "Google Colab has launched an official VS Code extension, bridging the gap between the popular code editor and the AI/ML platform. The extension combines VS Code's powerful development environment with Colab's seamless access to high-powered runtimes (GPUs/TPUs), allowing users to connect local notebooks to Colab. This aims to meet developers where they are and brings the best of both worlds."
    },
    {
      "title": "宣布ADK评估中的用户模拟功能 (原标题: Announcing User Simulation in ADK Evaluation)",
      "link": "https://developers.googleblog.com/en/announcing-user-simulation-in-adk-evaluation/",
      "pubDate": "Thu, 06 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-06T16:00:00.000Z",
      "creator": "Google",
      "summary": "### ADK评估中用户模拟功能的发布\n\n2025年11月7日，Agent的本质是对话式的。用户可能需要提出后续问题、完善之前的请求并根据需要提供额外信息。然而，为Agent手动编写多轮对话测试脚本是一个脆弱且耗时的过程，容易因Agent行为的微小变化而失效，使测试维护变得令人沮丧。\n\n为了解决这个问题，Agent开发工具包（ADK）中推出了一项新功能：**用户模拟（User Simulation）**。这项功能旨在帮助开发者摆脱测试僵化的实现路径，转而评估Agent实际达成用户意图的能力。\n\n#### 什么是用户模拟器？\n\n用户模拟器本质上是一个由大型语言模型（LLM）驱动的用户提示生成器。它直接集成到ADK评估框架中，允许在本地运行。开发者只需提供一个高层次的目标，模拟器就会动态生成对话的用户端，以追求该目标。它不是一个独立的服务，而是ADK内部的一个本地工具，支持快速、迭代的“内循环”工作流程。\n\n#### 工作原理\n\n1.  **定义对话场景（Conversation Scenario）**\n    *   不再需要僵化的逐轮脚本，而是提供一个`ConversationScenario`。\n    *   这是一个简单的JSON对象，包含两个关键部分：\n        *   `starting_prompt`：一个固定的初始提示，用于开始对话。\n        *   `conversation_plan`：一个自然语言指南，告诉模拟器其目标。\n    *   **示例：**\n        ```json\n        {\n          \"scenarios\": [\n            {\n              \"starting_prompt\": \"What can you do for me?",
      "shortSummary": "ADK（Agent开发工具包）推出“用户模拟”新功能，旨在解决手动编写多轮对话测试脚本的耗时和脆弱性问题。该功能是一个由LLM驱动的用户提示生成器，允许开发者通过定义高层次的“对话场景”和“评估配置”来动态模拟用户交互，从而评估Agent达成用户意图的能力。它能显著减少测试创建时间，构建更具弹性的测试，并创建可靠的回归测试套件，是构建可靠AI Agent的关键一步。",
      "translated_title": "宣布ADK评估中的用户模拟功能",
      "images": [],
      "contentSource": "完整文章",
      "content": "The new **User Simulation** feature in the Agent Development Kit (ADK) replaces rigid, brittle manual test scripts with dynamic, LLM-powered conversation generation. Developers define a high-level `conversation_plan`, and the simulator handles the multi-turn interaction to achieve the goal. This dramatically reduces test creation time, builds more resilient tests, and creates a reliable regression suite for AI agents."
    },
    {
      "title": "宣布推出Go语言版Agent开发工具包：用你喜爱的语言构建强大的AI智能体 (原标题: Announcing the Agent Development Kit for Go: Build Powerful AI Agents with Your Favorite Languages)",
      "link": "https://developers.googleblog.com/en/announcing-the-agent-development-kit-for-go-build-powerful-ai-agents-with-your-favorite-languages/",
      "pubDate": "Thu, 06 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-06T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 宣布推出Go语言版Agent开发工具包（ADK）\n\nGoogle于2025年11月7日宣布，将Go语言加入Agent开发工具包（ADK）支持语言家族，旨在让开发者能够使用Go语言构建强大且复杂的AI智能体。ADK是一个开源、代码优先的工具包，专为需要对AI智能体进行精细控制的开发者设计，它将大型语言模型（LLM）编排、智能体行为和工具使用的复杂性直接融入代码中。\n\n## ADK的核心优势\nADK通过将复杂逻辑直接编码，为开发者带来以下关键优势：\n*   **强大的调试能力：** 能够像对待所有服务一样严谨地定义和调试智能体逻辑。\n*   **可靠的版本控制：** 轻松跟踪更改并自信地部署应用。\n*   **部署自由：** 应用程序可以部署到任何地方，无论是本地笔记本电脑还是云端。\n\n## Go语言版ADK的特点\n对于Go语言开发者而言，ADK for Go提供了一种地道且高性能的方式来构建智能体，充分利用Go语言的并发性和强类型特性，创建健壮且可扩展的智能体应用。此外，ADK Go通过MCP Toolbox for Databases开箱即用地支持30多种数据库，使数据集成变得无缝且简单。\n\n## ADK的通用关键特性\nGo语言版ADK与Python和Java版ADK共享相同的核心设计原则和特性，确保一致的开发体验：\n*   **丰富的工具生态系统：** 通过预构建工具、自定义函数、OpenAPI规范以及与Google生态系统的紧密集成来增强智能体功能。\n*   **代码优先开发：** 直接在首选语言中定义智能体逻辑、工具和编排，实现极致的灵活性、可测试性和版本控制。\n*   **模块化多智能体系统：** 通过将多个专业智能体组合成灵活的层次结构，设计可扩展的应用程序。\n*   **开发UI：** 内置的开发用户界面可加速工作流程，允许开发者测试、评估、调试和展示其智能体。\n\n## Go语言版ADK对Agent2Agent (A2A) 协议的支持\nADK Go现在包含对Agent2Agent (A2A) 协议的支持，这使得开发者能够构建强大的多智能体系统，其中智能体可以协作解决复杂问题。通过A2A协议，主智能体可以无缝地编排和委托任务给专业的子智能体（无论是本地服务还是远程部署），确保安全且不透明的交互，而无需暴露内部内存或专有逻辑。Google已将A2A Go SDK贡献给A2A项目仓库。\n\n## 立即开始\n准备好利用Go语言的速度和ADK的控制力了吗？您的下一个颠覆性智能体只需一个命令即可实现。\n\n*   **ADK for Go 获取命令：** `go get google.golang.org/adk`\n*   **源代码：** [https://github.com/google/adk-go](https://github.com/google/adk-go)\n*   **示例：** [https://github.com/google/adk-samples](https://github.com/google/adk-samples)\n*   **文档：** [https://google.github.io/adk-docs/](https://google.github.io/adk-docs/)\n\n加入社区，提问、分享项目并与其他开发者联系：\n*   **Reddit：** `r/agentdevelopmentkit`\n*   **报告Bug：** [https://github.com/google/adk-go/issues](https://github.com/google/adk-go/issues)",
      "shortSummary": "Google宣布推出Go语言版Agent开发工具包（ADK），这是一个开源、代码优先的工具包，旨在帮助Go开发者构建强大且可扩展的AI智能体。ADK将LLM编排、智能体行为和工具使用直接融入代码，提供强大的调试、版本控制和部署自由。它支持丰富的工具生态系统、模块化多智能体系统，并集成了Agent2Agent (A2A) 协议，允许智能体协作。开发者可利用Go的并发性和强类型特性，高效构建AI应用。",
      "translated_title": "宣布推出Go语言版Agent开发工具包：用你喜爱的语言构建强大的AI智能体",
      "images": [],
      "contentSource": "完整文章",
      "content": "The Agent Development Kit (ADK), an open-source, code-first toolkit for building powerful and sophisticated AI agents, now supports Go. ADK moves LLM orchestration and agent behavior directly into your code, giving you robust debugging, versioning, and deployment freedom. ADK for Go is idiomatic and performant, leveraging Go's strengths, and includes support for over 30+ databases and the Agent-to-Agent (A2A) protocol for collaborative multi-agent systems. Start building today!"
    },
    {
      "title": "Agent Garden - 学习、发现和构建的示例 (原标题: Agent Garden - Samples for learning, discovering and building)",
      "link": "https://developers.googleblog.com/en/agent-garden-samples-for-learning-discovering-and-building/",
      "pubDate": "Mon, 03 Nov 2025 16:00:00 GMT",
      "isoDate": "2025-11-03T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Agent Garden 简介\n\nAgent Garden 现已向所有用户开放，不再仅限于 Google Cloud 用户。它旨在解决创建复杂 AI 代理（特别是多代理系统）所面临的主要挑战，这些挑战通常涉及大量研究、精确协调和巨大的开发投入以整合各种工具和框架。\n\n**Agent Garden 帮助开发者解决以下挑战：**\n*   开发能够应对复杂业务挑战的 AI 代理。\n*   创建将生成式 AI 与确定性逻辑相结合的复杂多代理工作流。\n*   将代理无缝部署并集成到现有系统和数据源中。\n\n## 核心功能与优势\n\nAgent Garden 提供了一个不断增长的精选代理示例、解决方案和工具库，旨在利用 Agent Development Kit (ADK) 加速强大 AI 代理的开发和部署。它提供独特的学习体验和资源，以启动代理开发之旅。\n\n**Agent Garden 的能力包括：**\n*   **丰富的示例集合**：提供针对各种用例量身定制的强大功能集合。这些代码示例使用 ADK 开发，并与 BigQuery 和 Vertex AI Search 等云服务进行了广泛集成。\n*   **详细的示例信息**：每个代理示例都包含详细的概述、适用的用例、架构洞察及其功能描述。开发者还可以直接在 GitHub 上访问示例代码进行深入审查。\n\n## 简化部署与定制\n\nAgent Garden 简化了代理的部署和定制过程，使开发者能够更高效地工作。\n\n*   **一键部署**：通过 Agent Starter Pack（一个帮助无缝部署到生产环境的开源启动包），开发者现在只需点击一下即可将示例代理部署到其项目中的 Agent Engine，并通过 Agent Engine Playground UI 进行测试和实验。\n*   **代理定制**：Agent Garden 通过 Firebase Studio 提供选项，允许开发者打开和定制代理，以满足其特定的需求和用例。\n\n这种探索、学习、部署和定制的开发者旅程旨在使 ADK 代理开发对您的用例而言无缝衔接。\n\n## 成功案例\n\n早期测试者已经成功利用 Agent Garden 提供的创新示例，展示了成功的采用和切实的商业价值。雷诺集团（Renault Group）在 Google Cloud Next’2025 上分享了他们的成功经验，详细介绍了如何将一个复杂的数据科学家代理集成到其电动汽车 (EV) 充电器平台中。这一集成显著增强了他们的运营和用户体验，赋予业务团队直接利用其数据的自主权。\n\n## 常见问题与资源\n\n**常见问题解答：**\n*   **代理是否可以直接部署到生产环境？** adk-samples 和 Agent Starter Pack 都是开源软件，受适用源代码中规定的条款约束。\n*   **部署的代理是否可以访问和共享？** 代理部署在 Agent Engine 中，并受 Agent Engine 访问管理选项的约束。\n*   **如何删除部署的代理？** 代理部署在 Agent Engine 中，可以在 Agent Engine 内部删除。\n*   **在哪里可以找到更多示例？** Agent Garden 将提供高影响力用例的精选示例，更多示例可在 ADK samples、ADK community repo 和 ADK docs 中找到。\n*   **如何与社区保持互动？** 请积极参与 ADK 社区。\n\n**相关资源：**\n*   Agent Garden\n*   Agent Starter Pack\n*   Agent Development Kit (ADK Docs, ADK samples, ADK Python community)",
      "shortSummary": "Agent Garden 现已向所有用户开放，旨在简化 AI 代理（特别是多代理系统）的开发和部署。它提供精选的代理示例、解决方案和工具，结合 Agent Development Kit (ADK)，帮助开发者应对复杂业务挑战，实现生成式 AI 与确定性逻辑的融合。通过一键部署和 Firebase Studio 定制，开发者可以轻松学习、部署和个性化代理，加速 AI 解决方案的落地，如雷诺集团的成功案例所示。",
      "translated_title": "Agent Garden - 学习、发现和构建的示例",
      "images": [],
      "contentSource": "完整文章",
      "content": "Agent Garden is now available to all users to simplify AI agent creation and deployment using the Agent Development Kit (ADK). It provides curated agent samples, one-click deployment via Agent Starter Pack, and customization through Firebase Studio. It helps developers with complex business challenges and multi-agent workflows, with Renault Group cited as an early success story."
    },
    {
      "title": "超越请求-响应：构建实时双向流式多智能体系统 (原标题: Beyond Request-Response: Architecting Real-time Bidirectional Streaming Multi-agent System)",
      "link": "https://developers.googleblog.com/en/beyond-request-response-architecting-real-time-bidirectional-streaming-multi-agent-system/",
      "pubDate": "Wed, 29 Oct 2025 16:00:00 GMT",
      "isoDate": "2025-10-29T16:00:00.000Z",
      "creator": "Google",
      "summary": "本文探讨了传统请求-响应模型在构建复杂AI智能体时的局限性，并提出了实时双向流式架构作为多智能体系统的下一步发展方向。文章详细分析了这种“无回合”模型引入的主要工程挑战，并介绍了Agent开发工具包（ADK）如何通过流原生优先的方法来解决这些问题。\n\n### 请求-响应模型智能体的架构局限性\n\n传统的请求-响应通信模式在AI智能体开发中存在以下关键局限性，阻碍了真正交互式和智能体验的实现：\n\n*   **感知延迟**：智能体必须等待用户完整输入后才能开始处理，导致不自然的、基于回合的延迟，破坏了对话的流畅性。\n*   **脱节的工具集成**：在请求-响应模型中，调用工具通常会中断交互流程，导致用户体验碎片化。\n*   **笨拙的多模态处理**：处理音频和视频等同步数据流需要复杂且脆弱的逻辑来拼接独立输入，难以实现统一体验。\n\n### 实时双向流式智能体范式的愿景\n\n通过从基于回合的事务转向持久的、双向的流，可以解锁新一类智能体能力，使其更像协作伙伴而非简单工具：\n\n*   **真正的并发性和可中断性**：智能体可以在用户仍在输入时处理信息并采取行动，实现非阻塞交互和自然中断（“插话”）功能。\n*   **通过流式工具提供主动协助**：工具不再局限于单一请求-响应周期，可以作为持久的后台进程，随时间向用户或智能体流式传输信息。\n*   **统一的多模态处理**：流式架构通过原生处理连续、并行的流作为单一、统一的上下文来解决多模态问题，实现实时的环境和情境感知。\n\n### 实时双向流式多智能体系统的工程挑战\n\n构建一个健壮的实时双向多智能体应用并非易事，开发者必须解决一系列新的复杂工程问题：\n\n*   **无回合世界中的上下文管理**：在连续流中，需要设计新的机制来将流分割成逻辑事件，用于调试、分析和恢复对话。在没有明确“回合结束”信号的情况下，如何存储和传输连续的上下文流是一个挑战。\n*   **并发性和性能问题**：流式智能体是高度并发的系统，必须以低延迟处理多个异步I/O流。在多智能体系统中，这种固有的并发性变得指数级复杂。\n*   **开发者体验和可扩展性**：流式系统的底层复杂性必须通过简单、强大的抽象来隐藏。框架需要提供直观的开发者体验，例如定义可随时间产生多个结果的工具，并提供钩子和回调以注入自定义逻辑。\n\n### 双向流式范式：ADK的架构深度解析\n\nADK（Agent Development Kit）通过其开源架构，旨在实现“实时”智能体范式，该架构基于以下核心设计：\n\n![ADK架构图](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/unnamed.original_CLUn4eI.png)\n\n1.  **异步实时I/O管理**：\n    *   ADK引入了`LiveRequestQueue`，一个基于`asyncio`的队列，允许客户端应用程序无缝地将各种数据类型（文本、音频/视频blob）排队。智能体的异步运行器（`run_live`）从该队列中消费，实现近实时的数据处理，并以事件形式流式响应。\n\n2.  **多智能体的有状态、可转移会话**：\n    *   ADK会话在实时交互中持续存在，不仅包含历史记录，还包括工具调用、工具响应和各种系统信号。\n    *   通过信号（如中断、明确的“完成”信号或智能体转移）来划分连续流为离散事件。\n    *   将大型媒体blob存储在对象存储中，并在事务性数据库中引用它们。\n    *   从音频/视频流生成文本转录，作为单独的、带时间戳的事件捕获。\n    *   这种有状态的会话在智能体交接时（例如，从分流智能体到专家智能体）被完整传输，确保无缝衔接。\n\n3.  **事件驱动回调实现实时定制**：\n    *   ADK实现了回调机制，如`before_tool_callback`和`after_tool_callback`，允许开发者在工具执行前后注入自定义逻辑，实现动态控制（如日志记录、内容审核或信息注入）。\n\n4.  **流原生工具**：\n    *   ADK支持“流式工具”，这些工具被定义为异步生成器（`AsyncGenerator`）。它们可以接受标准输入并随时间产生多个结果，可选地接受`LiveRequestQueue`直接处理用户输入流，并在长时间运行任务在后台执行时向用户/模型提供中间更新。\n\n### 前进之路：挑战与未来研究\n\n该架构是深入探索和研究的起点。未来的工作将专注于提高性能（启动和智能体转移时间），并提供更丰富的回调类型（如`before-model-callback`和`after-model-callback`），以实现对智能体生命周期更深层次的控制。",
      "shortSummary": "传统请求-响应模型因延迟、工具集成脱节和多模态处理笨拙而限制了AI智能体。本文提出实时双向流式架构，以实现真正的并发性、可中断性、主动协助和统一多模态处理。该模型面临上下文管理、并发性能和开发者体验等工程挑战。Agent开发工具包（ADK）通过异步I/O管理、有状态可转移会话、事件驱动回调和流原生工具来解决这些问题，为构建更具交互性的多智能体系统铺平道路。",
      "translated_title": "超越请求-响应：构建实时双向流式多智能体系统",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/unnamed.original_CLUn4eI.png",
          "alt": "unnamed",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "The blog post argues the request-response model fails for advanced multi-agent AI. It advocates for a real-time bidirectional streaming architecture, implemented by the Agent Development Kit (ADK). This streaming model enables true concurrency, natural interruptibility, and unified multimodal processing. ADK's core features are real-time I/O management, stateful sessions for agent handoffs, and streaming-native tools."
    },
    {
      "title": "介绍 Gemini CLI 的 Jules 扩展 (原标题: Introducing the Jules extension for Gemini CLI)",
      "link": "https://developers.googleblog.com/en/introducing-the-jules-extension-for-gemini-cli/",
      "pubDate": "Tue, 28 Oct 2025 16:00:00 GMT",
      "isoDate": "2025-10-28T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 介绍 Gemini CLI 的 Jules 扩展\n\n本文宣布推出 Jules 扩展，为 Gemini CLI 带来了一个自主的助手，旨在异步处理编码任务，从而为开发者提供强大的新工作流程。\n\n## 核心工作流程\n\nJules 扩展与 Gemini CLI 协同工作，加速创意编码流程，允许开发者将任务委派给 Jules，同时保持在 Gemini CLI 中的工作流。\n\n*   **Gemini CLI**：作为终端中的协作器和协调器，用于用户主动关注的任务。\n*   **Jules 扩展**：作为自主助手，在后台的虚拟机 (VM) 中工作，负责克隆代码、安装依赖项和修改文件。\n\n## Jules 扩展可处理的任务类型\n\nJules 扩展能够处理多种异步任务，从而提高开发效率：\n\n*   **异步任务**：可以直接从 Gemini CLI 指派 Jules 扩展独立完成任务。\n*   **后台错误修复**：在用户处理 Gemini CLI 中的其他同步任务时，可以指派 Jules 在后台修复多个错误。\n*   **新分支中的更改**：在解决 GitHub 上的问题后，Jules 扩展可以将更改提交到一个新分支。\n\n## 开始使用\n\n### 先决条件\n\n在使用 Jules 扩展之前，需要满足以下条件：\n\n1.  **安装 Gemini CLI**：确保已安装 Gemini CLI，且版本为 v0.4.0 或更新。\n2.  **拥有 Jules 账户**：在 jules.google.com 注册一个 Jules 账户。\n3.  **连接仓库**：在 Jules 控制台中将您的 GitHub 仓库连接到您的 Jules 账户。\n\n### 安装\n\n通过在终端中运行以下命令来安装 Jules 扩展：\n\n```shell\ngemini extensions install https://github.com/gemini-cli-extensions/jules --auto-update\n```\n\n*   `--auto-update` 参数是可选的，如果指定，扩展将在新版本发布时自动更新。\n\n### 使用\n\n*   **启动 Jules 任务**：使用 `/jules` 命令，后跟您的提示。例如：\n\n    ```shell\n    /jules Convert commonJS modules to ES modules\n    ```\n    一旦任务启动，扩展将在后台完成它。\n\n*   **检查任务状态**：使用 `/jules` 命令并查询任务状态。例如：\n\n    ```shell\n    /jules what is the status of my last task?\n    ```\n\n## 加速您的编码工作流\n\n鼓励开发者尝试 Gemini CLI 中的 Jules 扩展，并在 Jules 扩展仓库中分享其如何帮助加速编码工作流的反馈。如果支持该项目，请考虑给仓库点赞。\n\n## 更多信息\n\n*   Jules extension for Gemini CLI\n*   所有 Gemini CLI 扩展\n*   Jules 文档\n*   Gemini CLI 文档",
      "shortSummary": "本文宣布推出 Gemini CLI 的 Jules 扩展，这是一个自主助手，旨在异步处理编码任务。Jules 在后台虚拟机中工作，负责克隆代码、安装依赖项和修改文件，从而让开发者能够将任务（如错误修复和分支更改）委派给它，同时专注于 Gemini CLI 中的主要工作。用户需安装 Gemini CLI，注册 Jules 账户并连接 GitHub 仓库，然后通过 `/jules` 命令启动和管理任务。",
      "translated_title": "介绍 Gemini CLI 的 Jules 扩展",
      "images": [],
      "contentSource": "完整文章",
      "content": "Introducing the Jules extension for Gemini CLI, an autonomous sidekick for developers. It accelerates coding workflows by offloading tasks like asynchronous work, bug fixes, and changes in new branches to Jules, while you stay in flow with Gemini CLI. Get started by installing the extension and using the /jules command to initiate and check task statuses."
    },
    {
      "title": "推出Coral NPU：面向边缘AI的全栈平台 (原标题: Introducing Coral NPU: A full-stack platform for Edge AI)",
      "link": "https://developers.googleblog.com/en/introducing-coral-npu-a-full-stack-platform-for-edge-ai/",
      "pubDate": "Tue, 14 Oct 2025 16:00:00 GMT",
      "isoDate": "2025-10-14T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 推出Coral NPU：面向边缘AI的全栈平台\n\nGoogle于2025年10月14日推出了Coral NPU，这是一个全栈、开源平台，旨在解决限制低功耗边缘设备和可穿戴设备上强大、始终在线AI的核心性能、碎片化和隐私挑战。\n\n## 边缘AI面临的挑战\n\n生成式AI极大地改变了我们对技术的期望，但下一个技术飞跃是将智能直接嵌入到我们的个人环境中。为了实现真正有帮助的、主动的AI（如实时翻译、理解物理环境），它必须在可穿戴和随身设备上运行。这带来了三个核心挑战：\n\n*   **性能差距：** 复杂的机器学习模型需要大量计算，远超边缘设备的有限功耗、散热和内存预算。\n*   **碎片化成本：** 为各种专有处理器编译和优化ML模型既困难又昂贵，阻碍了设备间的一致性能。\n*   **用户信任赤字：** 个人AI必须优先考虑个人数据的隐私和安全。\n\n## Coral NPU解决方案\n\nCoral NPU平台基于Google原有的Coral项目，与Google Research和Google DeepMind合作设计，为硬件设计师和ML开发者提供了构建下一代私密、高效边缘AI设备所需的工具。它是一个AI优先的硬件架构，旨在实现超低功耗、始终在线的边缘AI。\n\n*   **统一的开发体验：** 简化了环境感知等应用的部署。\n*   **低功耗设计：** 专为可穿戴设备的全天候AI而设计，最大限度地减少电池使用，并可配置以支持更高性能用例。\n*   **开放可用：** 相关的文档和工具已发布，供开发者和设计师立即开始构建。\n\n## AI优先的架构\n\n传统的芯片设计在通用CPU（灵活但ML效率低）和专用加速器（ML效率高但缺乏灵活性）之间存在权衡。Coral NPU通过颠覆传统芯片设计来解决这一问题，它优先考虑ML矩阵引擎而非标量计算，从芯片层面优化AI架构，从而创建了一个专为更高效的设备端推理而设计的平台。\n\n![Coral NPU全平台](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/The_full_platform_v4_Fin_Alpha.original.png)\n\n作为一个完整的参考神经网络处理单元（NPU）架构，Coral NPU为下一代节能、ML优化片上系统（SoC）提供了构建模块。\n\n*   **RISC-V基础：** 架构基于一套符合RISC-V ISA的架构IP块，设计用于最小功耗，非常适合始终在线的环境感知。\n*   **性能表现：** 基础设计提供512 GOPS的性能，同时仅消耗几毫瓦，为边缘设备、听戴设备、AR眼镜和智能手表提供强大的设备端AI。\n*   **开放可扩展：** 基于RISC-V的开放可扩展架构为SoC设计师提供了修改基础设计或将其用作预配置NPU的灵活性。\n\nCoral NPU架构包含以下组件：\n\n*   **标量核心：** 轻量级、C可编程的RISC-V前端，管理数据流到后端核心，采用简单的“运行到完成”模型，实现超低功耗和传统CPU功能。\n*   **向量执行单元：** 强大的单指令多数据（SIMD）协处理器，符合RISC-V向量指令集（RVV）v1.0，支持对大型数据集的并行操作。\n*   **矩阵执行单元：** 高效的量化外积乘累加（MAC）引擎，专为加速基本神经网络操作而构建（该矩阵核心仍在开发中，将于今年晚些时候在GitHub上发布）。\n\n![Coral NPU设计灵感](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Inspiration_of_Coral_v4_Fin_Alpha.original.png)\n\n## 统一的开发者体验\n\nCoral NPU架构是一个简单、C可编程的目标，可以与IREE和TFLM等现代编译器无缝集成，从而轻松支持TensorFlow、JAX和PyTorch等ML框架。\n\n*   **全面的软件工具链：** 包括TFLM编译器、通用MLIR编译器、C编译器、自定义内核和模拟器，为开发者提供灵活的路径。\n*   **优化编译流程：** 例如，JAX框架的模型首先使用StableHLO方言导入MLIR格式，然后输入IREE编译器，该编译器应用硬件特定插件识别Coral NPU架构，并进行渐进式降低优化，最终生成紧凑的二进制文件，可在边缘设备上高效执行。\n*   **行业标准工具：** 简化ML模型的编程，并在各种硬件目标上提供一致的体验。\n\n![Coral NPU编译器工具链](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/The_compiler_toolchain_v4_Fin_Alpha.original.png)\n\nCoral NPU的协同设计过程侧重于两个关键领域：\n\n1.  高效加速当前设备端视觉和音频应用中领先的基于编码器的架构。\n2.  与Gemma团队密切合作，优化Coral NPU以支持小型Transformer模型，确保加速器架构支持边缘生成式AI的下一代发展。\n\n这种双重关注意味着Coral NPU有望成为第一个开放、基于标准、低功耗的NPU，能够将大型语言模型（LLMs）引入可穿戴设备。\n\n## 目标应用\n\nCoral NPU旨在实现超低功耗、始终在线的边缘AI应用，特别关注环境感知系统。其主要目标是在可穿戴设备、手机和物联网（IoT）设备上实现全天候AI体验，同时最大限度地减少电池使用。\n\n潜在用例包括：\n\n*   **情境感知：** 检测用户活动（如步行、跑步）、接近度或环境（如室内/室外、移动中），以启用“请勿打扰”模式或其他情境感知功能。\n*   **音频处理：** 语音和语音检测、关键词识别、实时翻译、转录和基于音频的辅助功能。\n*   **图像处理：** 人物和物体检测、面部识别、手势识别和低功耗视觉搜索。\n*   **用户交互：** 通过手势、音频提示或其他传感器驱动输入实现控制。\n\n## 硬件强制隐私\n\nCoral NPU的核心原则是通过硬件强制安全来建立用户信任。其架构旨在支持CHERI等新兴技术，提供细粒度的内存级安全和可扩展的软件分区。通过这种方法，敏感的AI模型和个人数据可以被隔离在硬件强制的沙盒中，从而减轻基于内存的攻击。\n\n## 构建生态系统\n\n开放硬件项目的成功离不开强大的合作伙伴关系。Google正与Synaptics合作，Synaptics是其首个战略硅合作伙伴，也是物联网嵌入式计算、无线连接和多模态传感领域的领导者。Synaptics已宣布推出其新的Astra™ SL2610系列AI原生物联网处理器，该产品线采用了其Torq™ NPU子系统，这是Coral NPU架构的业界首个生产实现。Torq™ NPU设计支持Transformer模型和动态操作符，使开发者能够为消费和工业物联网构建面向未来的边缘AI系统。\n\n此次合作支持了Google对统一开发者体验的承诺。Synaptics Torq™边缘AI平台基于IREE和MLIR的开源编译器和运行时构建。这一合作是为智能、情境感知设备构建共享开放标准的重要一步。\n\n## 总结\n\n通过Coral NPU，Google正在为个人AI的未来构建一个基础层。目标是提供一个通用、开源且安全的平台，供行业在此基础上进行构建，从而促进一个充满活力的生态系统。这将使开发者和芯片供应商能够超越当前碎片化的局面，在边缘计算的共享标准上进行协作，从而加速创新。",
      "shortSummary": "Google推出Coral NPU，一个全栈开源平台，解决低功耗边缘AI的性能、碎片化和隐私挑战。它采用AI优先的RISC-V架构，提供512 GOPS性能，功耗仅数毫瓦。平台提供统一开发体验，支持主流ML框架，赋能可穿戴设备、手机及IoT的全天候私密AI应用，如情境感知和实时翻译。Coral NPU强调硬件强制隐私，并与Synaptics等伙伴共建开放生态，加速边缘AI创新。",
      "translated_title": "推出Coral NPU：面向边缘AI的全栈平台",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/The_full_platform_v4_Fin_Alpha.original.png",
          "alt": "The full platform_v4_Fin_Alpha",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Inspiration_of_Coral_v4_Fin_Alpha.original.png",
          "alt": "Inspiration of Coral_v4_Fin_Alpha",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/The_compiler_toolchain_v4_Fin_Alpha.original.png",
          "alt": "The compiler toolchain_v4_Fin_Alpha",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "完整文章",
      "content": "Coral NPU is a full-stack platform for Edge AI, addressing performance, fragmentation, and user trust deficits. It's an AI-first architecture, prioritizing ML matrix engines, and offers a unified developer experience. Designed for ultra-low-power, always-on AI in wearables and IoT, it enables contextual awareness, audio/image processing, and user interaction with hardware-enforced privacy. Synaptics is the first partner to implement Coral NPU."
    }
  ],
  "lastUpdated": "2025-11-17T10:33:39.254Z"
}
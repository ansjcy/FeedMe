{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "Gemini Embedding 现已在 Gemini API 中普遍可用 (原标题: Gemini Embedding now generally available in the Gemini API)",
      "link": "https://developers.googleblog.com/en/gemini-embedding-available-gemini-api/",
      "pubDate": "Sun, 13 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-13T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Gemini Embedding 现已普遍可用\n\nGoogle 于2025年7月14日宣布，其首个 Gemini Embedding 文本模型（`gemini-embedding-001`）现已在 Gemini API 和 Vertex AI 中向开发者普遍可用。\n\n### 核心亮点与性能\n\n*   **领先地位**：自2025年3月实验性发布以来，该嵌入模型在 Massive Text Embedding Benchmark (MTEB) 多语言排行榜上一直名列前茅。\n*   **卓越表现**：在检索、分类等多种任务中，其性能超越了 Google 此前的文本嵌入模型以及其他商业产品。\n*   **统一体验**：`gemini-embedding-001` 在科学、法律、金融和编码等多个领域提供统一的尖端体验。\n\n以下是 Gemini Embedding 与其他商业专有模型的比较：\n\n![嵌入模型对比图](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EmbedingsChart_16x9_RD2-V01.original.jpg)\n\n*注：图表中“传统 Google 模型”结合了3个 Gemini API 和 Vertex AI 模型（`text-embedding-004`、`text-embedding-005` 和 `text-multilingual-embedding-002`）的最高分数。更详细的结果可在技术报告中查阅。*\n\n### 模型详情\n\n*   **多功能性**：支持超过100种语言。\n*   **输入长度**：最大输入令牌长度为2048。\n*   **MRL 技术**：利用 Matryoshka Representation Learning (MRL) 技术，允许开发者将输出维度从默认的3072进行缩减，以优化性能和存储成本。\n*   **推荐维度**：为获得最高质量结果，建议使用3072、1536或768的输出维度。\n\n### 费率限制与定价\n\n*   **免费与付费层级**：Gemini API 提供免费和付费层级，开发者可以免费试用 `gemini-embedding-001`，或为生产需求选择更高限制的付费服务。\n*   **定价**：该模型定价为每100万输入令牌0.15美元。\n\n### 如何开始使用\n\n*   开发者现在可以通过 Gemini API 访问 `gemini-embedding-001` 模型。\n*   可以通过 Google AI Studio 免费开始使用。\n*   兼容现有的 `embed_content` 端点。\n*   提供了 Python 代码示例和详细的开发者文档及快速入门指南。\n\n### 模型弃用与迁移建议\n\n*   **实验版弃用**：实验性模型 `gemini-embedding-exp-03-07` 将于2025年8月14日停止支持，用户无需重新嵌入内容。\n*   **传统模型弃用**：\n    *   `embedding-001` 将于2025年8月14日弃用。\n    *   `text-embedding-004` 将于2026年1月14日弃用。\n*   **强烈建议**：Google 强烈建议用户尽快将项目迁移到最新的模型。\n\n### 未来展望\n\n*   Gemini Embedding 即将支持 Batch API，以实现异步数据处理和更低的成本。\n*   未来将发布更多具有更广泛模态和功能的嵌入模型。",
      "shortSummary": "Google 宣布其首个 Gemini Embedding 文本模型（`gemini-embedding-001`）现已在 Gemini API 和 Vertex AI 中普遍可用。该模型在多语言基准测试中表现出色，支持100多种语言，并提供灵活的输出维度。它提供免费和付费层级，定价为每100万输入令牌0.15美元。Google 鼓励开发者尽快迁移到此新模型，因旧版和实验性模型将陆续弃用。未来还将支持 Batch API，并推出更多功能。",
      "translated_title": "Gemini Embedding 现已在 Gemini API 中普遍可用",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EmbedingsChart_16x9_RD2-V01.original.jpg",
          "alt": "Embedings Chart",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "The Gemini Embedding text model is now generally available in the Gemini API and Vertex AI. This versatile model has consistently ranked #1 on the MTEB Multilingual leaderboard since its experimental launch in March, supports over 100 languages, has a 2048 maximum input token length, and is priced at $0.15 per 1M input tokens."
    },
    {
      "title": "企业真相在行动：Apigee API hub 赋能强大的开发者门户 (原标题: Enterprise truth in action: Apigee API hub fueling powerful Developer Portals)",
      "link": "https://developers.googleblog.com/en/apigee-api-hub-fueling-developer-portals/",
      "pubDate": "Sun, 13 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-13T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 企业真相在行动：Apigee API hub 赋能强大的开发者门户\n\nGoogle Cloud 的 Apigee 团队致力于提供策略和工具，帮助客户构建强大有效的 API 生态系统。其中，API 的发现机制至关重要。文章详细阐述了 Apigee 平台中两个既独立又紧密相连的组件——Apigee API hub 和开发者门户——如何满足不同角色的需求。Apigee API hub 被视为核心的“真相承载引擎”，它赋能并提升了开发者门户的功能，是企业代理（agentic）策略的基石。\n\n## Apigee API hub：企业所有 API 的真相来源\n\nApigee API hub 被比作 API 程序的“中枢神经系统”。它提供一个集中化的位置，用于编目组织内所有 API 及其数据（无论 API 风格、生命周期阶段或托管环境），从而成为“企业真相”的权威来源。这为治理和一致性奠定了基础，帮助团队防止蔓延、构建更好的 API，并最终为用户提供更优质的体验。\n\n![Apigee API hub metrics](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_VZss8uJ.original.png)\n\nApigee API hub 主要关注组织内部 API 生产者的需求，包括平台工程师、API 架构师、安全专家以及负责构建和管理 API 的开发人员。对于这些用户，Apigee API hub 是唯一的真相来源，其功能包括：\n\n*   **全面的 API 概览和元数据：** Apigee API hub 能够自动发现和编目所有 API，创建一个包含丰富元数据的统一存储库。这包括 API 生命周期阶段、版本、规范和文档等信息，提供 API 生态系统的完整准确视图。这些全面且机器可读的数据正是 AI 代理理解和与企业系统交互所需的，作为服务的核心注册表。\n*   **基于标准的集中式治理：** 该 hub 允许在整个 API 生命周期中建立和执行一致的治理。通过维护单一的真相来源，可以有效确保质量一致性、遵守标准、管理安全性、跟踪 API 成熟度，并就 API 策略做出明智决策，例如识别可货币化的 API。这种统一的真相来源对于建立治理至关重要，不仅适用于人类开发者，也适用于控制和保护 AI 代理如何访问和利用 API 组合，确保安全性、API 风格和数据格式的一致性。\n*   **增强内部协作：** 该 hub 通过提供集中且一致的 API 信息来源，促进内部协作。这有助于促进 API 重用，减少冗余，并简化开发工作流程。\n\n![Apigee API hub refund](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_05Kg96Y.original.png)\n\n## 开发者门户：为 API 消费者量身定制的体验\n\n相比之下，开发者门户就像一个“店面”，API 消费者（即构建应用程序的开发人员）通过它发现并与 API 交互。并非组织内生产的每个 API 都旨在供外部消费。Apigee API hub 作为超集管理所有 API，而开发者门户则暴露其中经过精心选择的子集，并使用自定义的样式和品牌。\n\n![Developer Portals](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_7JWBY5z.original.png)\n\n为了真正有效，这些门户必须由 Apigee API hub 中存在的“企业真相”提供支持。门户提供 hub 功能的精选且用户友好的子集，专注于无缝的 API 消费：\n\n*   **真实有效的 API 发现：** 开发者门户依赖于 Apigee API hub 元数据的准确性和完整性，使开发人员能够轻松找到所需的 API。\n*   **API 消费的“出口”：** Apigee API hub 充当控制中心，提供一个受控的“出口”，有选择地将特定 API 及其相关的“企业真相”发布到开发者门户。这确保只有经过批准和相关的 API 才能供消费。\n\n![Developer Portals 2](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image7_2RPZWOQ.original.png)\n\n## 释放 API 潜力\n\nApigee API hub 和开发者门户虽然独立，但共同构成一个统一的系统。hub 的全面目录和“企业真相”直接赋能并驱动开发人员的门户体验，并且现在，更关键的是，它们成为新兴 AI 代理策略不可或缺的基础。\n\n通过理解 Apigee API hub 作为 API 生产者和代理的核心存储库的作用，以及门户作为面向消费者的子集和受控“出口”的作用，组织可以充分释放其 API 的潜力并加速创新。\n\n文章最后鼓励用户开始使用 Apigee API hub 和开发者门户，并提及一个 GitHub 示例，展示如何将非托管 API 导入 hub 并将其文档发布到开发者门户。此外，还预告了 2025 年 7 月 31 日的线上活动，以深入了解 hub 和门户的功能。",
      "shortSummary": "Apigee API hub 和开发者门户是 Google Cloud Apigee 平台中两个关键组件。Apigee API hub 是企业所有 API 的“真相来源”，面向 API 生产者，提供集中编目、治理和内部协作，也是 AI 代理策略的基石。开发者门户则是面向 API 消费者的“店面”，展示并允许交互 Apigee API hub 中精选的 API 子集。两者虽独立但紧密相连，共同构成统一系统，赋能 API 发现、管理和消费，帮助组织释放 API 潜力并加速创新。",
      "translated_title": "企业真相在行动：Apigee API hub 赋能强大的开发者门户",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_VZss8uJ.original.png",
          "alt": "Apigee API hub metrics",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_05Kg96Y.original.png",
          "alt": "Apigee API hub refund",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_7JWBY5z.original.png",
          "alt": "Developer Portals",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image7_2RPZWOQ.original.png",
          "alt": "Developer Portals 2",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "The Apigee API hub and Developer Portals are distinct but interconnected parts of the Apigee platform that help organizations discover and manage APIs for different personas, unlocking API potential and accelerating innovation."
    },
    {
      "title": "使用 Firebase Studio 推进代理式 AI 开发 (原标题: Advancing agentic AI development with Firebase Studio)",
      "link": "https://developers.googleblog.com/en/advancing-agentic-ai-development-with-firebase-studio/",
      "pubDate": "Wed, 09 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-09T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 使用 Firebase Studio 推进代理式 AI 开发\n\n在 Google Cloud Summit London 大会上，Google Cloud 宣布了 Firebase Studio 的重大进展。Firebase Studio 是一个基于云的 AI 工作区，旨在通过集成强大的 AI 功能，重新定义 AI 辅助开发，并帮助开发者构建下一代代理式应用程序。\n\n## 主要更新亮点\n\nFirebase Studio 的最新更新包括：\n\n*   **多功能代理模式 (Agent modes)**：提供与 Gemini 交互的不同方式。\n*   **模型上下文协议 (Model Context Protocol, MCP) 的基础支持**：增强工作流的可扩展性。\n*   **Gemini CLI 集成**：将强大的 AI 功能直接融入开发者的工作流程。\n\n## 1. 引入自主代理模式：您的 AI 伙伴，由您定义\n\nFirebase Studio 现已提供三种与 Gemini 交互的模式，包括全新的自主代理模式。开发者可以根据需求在这些模式之间无缝切换，以加速开发任务，这得益于 Gemini 2.5 强大的代码理解和推理能力。\n\n![Agent Mode](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_xvxrYmH.original.png)\n\n### 模式详解：\n\n*   **Ask 模式 (对话与规划)**\n    *   **用途：** 用于与 Gemini 进行讨论和规划，非常适合头脑风暴、代码规划和协作讨论复杂问题。\n    *   **特点：** 纯粹的对话模式，不会对文件进行任何修改。\n*   **Agent 模式 (建议与批准)**\n    *   **用途：** Gemini 可以提出对应用程序的修改建议。\n    *   **特点：** 开发者始终处于控制之中，必须在任何文件被修改之前批准所有建议的更改。这提供了完整的监督，并允许轻松地在更改集成到项目之前进行代码审查。\n*   **Agent (Auto-run) 模式 (自主运行)**\n    *   **用途：** Gemini 可以自主推理并生成整个应用程序，或向现有应用程序添加功能。\n    *   **示例：** 它可以跨多个文件进行代码更改、编写测试、修复错误和重构组件，所有这些都只需一个提示。\n    *   **安全：** 为了安全起见，在删除文件、运行终端命令或使用外部工具之前，始终需要获得开发者的许可。\n\n### 个性化指导：\n\n代理模式可以利用项目级别的规则文件（如 `.idx/airules.md`、`GEMINI.md` 或 `.cursorrules`）提供个性化指导，确保 Gemini 遵循特定的设计模式和偏好。系统会自动检测并加载这些文件中的指令，提供高度可定制的体验。\n\n## 2. 通过模型上下文协议 (MCP) 释放可扩展性\n\n除了新的代理模式，Firebase Studio 还在预览对模型上下文协议 (MCP) 的基础支持。现在，开发者可以将 MCP 服务器添加到工作区，从而扩展和个性化 Firebase 中 Gemini 的工作流程。例如，可以使用 Firebase MCP 服务器在构建或调试应用程序时，通过自然语言探索 Cloud Firestore 中的数据；或者使用 Context7 获取特定库的上下文（如使用 MediaPipe 的设备端机器学习构建应用程序）。\n\n## 3. Gemini CLI 集成到 Firebase Studio\n\nGemini CLI 是一个功能强大且免费的工具，可用于代码生成、内容生成和研究等多种任务。它提供慷慨的使用层级、高级 AI 功能、与 Google Search 的实时上下文集成以及开源架构，支持定制和贡献。现在，Gemini CLI 已直接集成到 Firebase Studio 中。\n\n如果开发者在终端上花费大量时间进行代码生成、调试、执行命令或管理项目文件等任务，Gemini CLI 提供无缝的 AI 驱动体验，无需切换到单独的聊天窗口。\n\n## 实际影响：Firebase Studio 的应用案例\n\nFirebase Studio 的 AI 功能已被广泛应用于简化工作流程并加速产品发布。实际案例包括：\n\n*   为氢经济创建采购平台。\n*   为用户提供个性化时尚造型师。\n*   帮助宝可梦爱好者通过 AI 驱动的卡片扫描和识别管理卡片收藏。\n*   通过引人注目的可视化和以人为本的分析，将建筑设计变为现实。\n\nGoogle Cloud 承诺将继续推出新功能和更新，帮助开发者快速轻松地交付专业品质的应用程序。鼓励开发者探索 Firebase Studio 的新功能，并在 X 和 LinkedIn 上使用 #FirebaseStudio 分享他们的作品。",
      "shortSummary": "Firebase Studio 推出重大更新，旨在通过集成 AI 推进代理式 AI 开发。主要亮点包括：三种多功能代理模式（Ask、Agent、Agent Auto-run），提供从对话到自主代码生成的能力；对模型上下文协议 (MCP) 的基础支持，增强工作流可扩展性；以及 Gemini CLI 的直接集成，实现终端内无缝的 AI 辅助开发。这些更新旨在简化开发流程，加速应用发布，并已在多个实际案例中展现出显著效果。",
      "translated_title": "使用 Firebase Studio 推进代理式 AI 开发",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_xvxrYmH.original.png",
          "alt": "Agent Mode",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Updates in Firebase Studio include new Agent modes, foundational support for the Model Context Protocol (MCP), and Gemini CLI integration, all designed to redefine AI-assisted development allow developers to create full-stack applications from a single prompt and integrate powerful AI capabilities directly into their workflow."
    },
    {
      "title": "发布 GenAI Processors：构建强大灵活的 Gemini 应用 (原标题: Announcing GenAI Processors: Build powerful and flexible Gemini applications)",
      "link": "https://developers.googleblog.com/en/genai-processors/",
      "pubDate": "Wed, 09 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-09T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 发布 GenAI Processors：构建强大灵活的 Gemini 应用\n\nGoogle DeepMind 于 2025 年 7 月 10 日发布了 GenAI Processors，这是一个新的开源 Python 库。该库旨在解决使用大型语言模型（LLM）构建复杂 AI 应用（特别是处理多模态输入和需要实时响应的应用）时面临的挑战。这类应用通常涉及复杂的拼接数据处理步骤、异步 API 调用和自定义逻辑，随着复杂性增加，代码可能变得脆弱且难以维护。\n\n## GenAI Processors 核心概念\n\nGenAI Processors 提供了一个抽象层，定义了一个统一的 `Processor` 接口，用于处理从输入处理、预处理到模型调用和输出处理的所有环节。其核心是将所有输入和输出视为 `ProcessorParts` 的异步流（即双向流）。`ProcessorParts` 是标准化的数据部分（例如，一段音频、文本转录、图像帧）及其相关元数据，它们在管道中流动。这种基于流的 API 允许无缝地链接和组合不同的操作，从低级数据操作到高级模型调用。\n\n![GenAI Processors library](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_kBE2xzY.original.png)\n\nGenAI Processors 库旨在优化 `Processor` 的并发执行。在执行流中，任何部分都可以在其图中所有祖先计算完成后并发生成。该流程保持输出流相对于输入流的顺序，并将以最小化首个令牌时间（TTFT）的方式执行。这种并发优化是自动进行的：将 `Processor` 应用于输入流将尽可能自动触发并发执行。\n\n## 应用示例与优势\n\n该库使得构建实时应用变得简单，例如：\n\n*   **实时代理（Live Agent）**：只需几行代码，即可使用 Gemini Live API 构建能够实时处理音频和视频流的代理。文章提供了结合摄像头和麦克风输入、通过 Gemini Live API 处理并播放音频输出的代码示例。\n*   **基于标准文本 LLM 的实时代理**：利用 GenAI Processor 库的双向流能力和 Google Speech API，可以构建一个将麦克风输入转换为文本、通过 LLM 生成响应、再将文本转换为音频并播放的代理。\n\n即使对于非流式用例，一旦数据可用就立即处理也能显著减少延迟和首个令牌时间（TTFT），这对于提供良好用户体验至关重要。GenAI Processors 通过利用 Python 的原生特性，提供了一种在不增加代码复杂性的情况下编写响应式应用程序的方法。例如，旅行规划器和研究代理等基于回合的代理可以利用 GenAI Processors 的并发功能来提高响应速度。\n\n## 核心设计原则\n\nGenAI Processors 的核心是 `Processor` 概念：一个封装特定工作单元的基本构建块。它接收输入流，执行操作，并输出结果流。这种简单、一致的 API 是该库强大和灵活的基石。\n\n其核心设计决策及其为开发者带来的好处包括：\n\n*   **模块化设计**：将复杂工作流分解为自包含的 `Processor` 单元，确保代码可重用性、可测试性，并显著简化复杂管道的维护。\n*   **异步与并发**：充分利用 Python 的 `asyncio` 来高效处理 I/O 密集型和计算密集型任务，从而实现响应式应用程序，无需手动线程或复杂的并发管理。\n*   **与 Gemini API 集成**：专用的处理器，如 `GenaiModel`（用于基于回合的交互）和 `LiveProcessor`（用于实时流式传输），简化了与 Gemini API 的交互，包括 Live API 的复杂性，减少了样板代码并加速了集成。\n*   **可扩展性**：通过继承基类或使用装饰器，可以轻松创建自定义处理器，将自己的数据处理逻辑、外部 API 或专业操作无缝集成到管道中。\n*   **统一的多模态处理**：`ProcessorPart` 包装器提供了一个一致的接口，用于在管道中处理各种数据类型（文本、图像、音频、JSON 等）。\n*   **流操作实用程序**：内置用于分割、连接和合并异步流的实用程序，为复杂管道中的数据流提供精细控制。\n\n## 如何开始\n\n开始使用 GenAI Processors 非常简单。可以通过 pip 安装：`pip install genai-processors`。\n\n为了帮助用户熟悉该库，官方提供了一系列 Colab 笔记本，引导用户了解核心概念并演示如何构建各种类型的处理器和应用程序。建议从 Content API Colab 和 Processor Intro Colab 开始。用户还可以探索仓库中的 `examples/` 目录，获取构建更复杂应用程序（如研究代理和实时评论代理）的实际演示。\n\n## 展望与社区贡献\n\nGenAI Processors 目前处于早期阶段，但它为解决 AI 应用中复杂工作流和编排挑战提供了坚实的基础。虽然 Google GenAI SDK 支持多种语言，但 GenAI Processors 目前仅支持 Python。\n\n`core/` 目录包含基本处理器，官方积极鼓励社区为 `contrib/` 目录贡献更专业的功能。Google DeepMind 期待与开发者社区合作，扩展该库并构建更复杂的 AI 系统。\n\n鼓励开发者查看 GitHub 上的 GenAI Processors 仓库：[https://github.com/google-gemini/genai-processors](https://github.com/google-gemini/genai-processors)。\n\n## 致谢\n\nGenAI Processors 是一个优秀团队奉献和辛勤工作的结果。文章对 Juliette Love, KP Sawhney, Antoine He, Will Thompson, Arno Eigenwillig, Ke Wang, Parth Kothari, Tim Blyth, Philipp Schmid, Patrick Löber, Omar Sanseviero, Alexey Kolganov, Adam Langley, Evan Senter, Seth Odoom, Thierry Coppey, 和 Murat Ozturk 等在将此库变为现实中发挥关键作用的个人表示感谢。",
      "shortSummary": "Google DeepMind 发布了 GenAI Processors，这是一个新的开源 Python 库，旨在简化复杂、多模态、实时 LLM 应用的构建。它提供了一个统一的 `Processor` 接口，将所有输入输出视为异步流，支持无缝链接和并发执行。该库通过模块化设计、异步处理和与 Gemini API 的深度集成，帮助开发者构建更强大、响应更快的 AI 应用，尤其适用于实时代理等场景。目前支持 Python，并鼓励社区贡献。",
      "translated_title": "发布 GenAI Processors：构建强大灵活的 Gemini 应用",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_kBE2xzY.original.png",
          "alt": "GenAI Processors library",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "GenAI Processors is a new open-source Python library from Google DeepMind designed to simplify the development of AI applications, especially those handling multimodal input and requiring real-time responsiveness, by providing a consistent \"Processor\" interface for all steps from input handling to model calls and output processing, for seamless chaining and concurrent execution."
    },
    {
      "title": "T5Gemma：一种新的编码器-解码器Gemma模型集合 (原标题: T5Gemma: A new collection of encoder-decoder Gemma models)",
      "link": "https://developers.googleblog.com/en/t5gemma/",
      "pubDate": "Tue, 08 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-08T16:00:00.000Z",
      "creator": "Google",
      "summary": "### T5Gemma：编码器-解码器架构的新篇章\n\n**引言**\n\n在大型语言模型（LLMs）快速发展的背景下，虽然解码器模型占据了主导地位并展现出强大的生成能力，但经典的编码器-解码器架构（如T5）因其高推理效率、设计灵活性和更丰富的编码器输入理解能力，在摘要、翻译和问答等实际应用中仍是热门选择。然而，这种强大的架构相对受到的关注较少。\n\n本文介绍了 **T5Gemma**，这是一个新的编码器-解码器LLM集合。它通过一种名为“适应性”（adaptation）的技术，将预训练的解码器模型转换为编码器-解码器架构。T5Gemma基于Gemma 2框架，包括适应后的Gemma 2 2B和9B模型，以及一系列新训练的T5尺寸模型（Small、Base、Large和XL）。项目团队发布了预训练和指令微调的T5Gemma模型，以期为社区研究和开发开启新机遇。\n\n**从解码器到编码器-解码器：模型适应性**\n\nT5Gemma的核心问题是：能否基于预训练的解码器模型构建顶级的编码器-解码器模型？答案是肯定的，通过探索“模型适应性”技术。其核心思想是利用已预训练的解码器模型权重来初始化编码器-解码器模型的参数，然后通过UL2或PrefixLM预训练进一步适应它们。\n\n![模型适应性概览](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Chart-1.original.png)\n\n这种适应方法具有高度灵活性，允许创造性地组合模型尺寸。例如，可以搭配一个大型编码器和一个小型解码器（如9B编码器与2B解码器）来创建“不平衡”模型。这使得模型能够针对特定任务（如摘要，其中对输入的深度理解比生成输出的复杂性更关键）微调质量-效率权衡。\n\n**性能表现：质量与效率的平衡**\n\n实验结果表明，T5Gemma模型在多个基准测试（如SuperGLUE，衡量学习到的表示质量）中，其性能与解码器Gemma模型相当或更优，几乎主导了质量-推理效率的帕累托前沿。\n\n![编码器-解码器模型基准测试](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Encoder-decoder_models_benchmarks.original.png)\n\n这种性能优势不仅是理论上的，也转化为实际的质量和速度。在测量GSM8K（数学推理）的实际延迟时，T5Gemma展现出明显优势。例如，T5Gemma 9B-9B在相似延迟下实现了比Gemma 2 9B更高的精度。更令人印象深刻的是，T5Gemma 9B-2B在精度上比2B-2B模型有显著提升，而其延迟几乎与小得多的Gemma 2 2B模型相同。这些实验最终表明，编码器-解码器适应性提供了一种灵活而强大的方式来平衡质量和推理速度。\n\n**基础与微调能力**\n\nT5Gemma在预训练和指令微调后均展现出强大的能力：\n\n*   **预训练后**：T5Gemma在需要推理的复杂任务上取得了显著进展。例如，T5Gemma 9B-9B在GSM8K（数学推理）上比原始Gemma 2 9B模型高出9分以上，在DROP（阅读理解）上高出4分。这表明，通过适应性初始化的编码器-解码器架构有潜力创建更强大、性能更好的基础模型。\n\n    ![预训练模型详细结果](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/pretrained-model-results.original.png)\n\n*   **指令微调后**：与Gemma 2 IT相比，T5Gemma IT的性能差距全面显著扩大。例如，T5Gemma 2B-2B IT的MMLU分数比Gemma 2 2B跃升近12点，其GSM8K分数从58.0%增至70.7%。适应性架构不仅可能提供更好的起点，还能更有效地响应指令微调，最终形成一个更强大、更有用的最终模型。\n\n    ![微调+RLHF模型结果](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/results-for-fine-tuned-RLHFed-models.original.png)\n\n**T5Gemma检查点发布**\n\n项目团队非常高兴地发布了构建强大、通用编码器-解码器模型的新方法，即通过适应预训练的解码器LLM（如Gemma 2）。为加速进一步研究并允许社区在此基础上进行开发，团队发布了一套T5Gemma检查点。发布内容包括：\n\n*   **多种尺寸**：T5尺寸模型（Small、Base、Large和XL）、Gemma 2模型（2B和9B），以及介于T5 Large和T5 XL之间的一个额外模型。\n*   **多种变体**：预训练和指令微调模型。\n*   **灵活配置**：一个强大且高效的不平衡9B-2B检查点，用于探索编码器和解码器尺寸之间的权衡。\n*   **不同训练目标**：使用PrefixLM或UL2目标训练的模型，分别提供最先进的生成性能或表示质量。\n\n希望这些检查点能为研究模型架构、效率和性能提供宝贵资源。\n\n**入门指南**\n\n文章提供了相关链接，包括研究论文、Hugging Face和Kaggle上的模型权重下载、Colab notebook以及Vertex AI上的模型推理指南。",
      "shortSummary": "T5Gemma是基于Gemma 2框架的新型编码器-解码器大语言模型集合，通过将预训练的解码器模型转换为编码器-解码器架构实现。它在推理效率和质量上表现出色，在多个基准测试中优于或媲美同类解码器模型，尤其在数学推理等复杂任务上展现显著提升。该项目发布了多种尺寸和配置的预训练及指令微调模型，旨在促进编码器-解码器架构的研究与应用。",
      "translated_title": "T5Gemma：一种新的编码器-解码器Gemma模型集合",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Chart-1.original.png",
          "alt": "decoder-only model",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Encoder-decoder_models_benchmarks.original.png",
          "alt": "Encoder-decoder models benchmarks",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/pretrained-model-results.original.png",
          "alt": "Detailed results for pretrained models",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/results-for-fine-tuned-RLHFed-models.original.png",
          "alt": "Results for fine-tuned + RLHFed models",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "T5Gemma is a new family of encoder-decoder LLMs developed by converting and adapting pretrained decoder-only models based on the Gemma 2 framework, offering superior performance and efficiency compared to its decoder-only counterparts, particularly for tasks requiring deep input understanding, like summarization and translation."
    },
    {
      "title": "Gemini API 中的批处理模式：事半功倍 (原标题: Batch Mode in the Gemini API: Process more for less)",
      "link": "https://developers.googleblog.com/en/scale-your-ai-workloads-batch-mode-gemini-api/",
      "pubDate": "Sun, 06 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-06T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini API 批处理模式：事半功倍\n\nGoogle 于2025年7月7日推出了 Gemini API 的批处理模式（Batch Mode），这是一个全新的异步端点，专为高吞吐量、对延迟不敏感的工作负载设计。该模式允许用户提交大型作业，将调度和处理工作卸载给API，并在24小时内获取结果，同时享受比同步API低50%的折扣。\n\n## 核心优势\n\n批处理模式是处理那些数据已准备就绪且无需即时响应任务的理想工具。通过将这些大型作业与实时流量分离，用户可以获得三大关键益处：\n\n*   **成本节约**：批处理作业的定价比给定模型的标准费率低50%。\n*   **更高吞吐量**：批处理模式具有更高的速率限制，能够处理更多请求。\n*   **简便的API调用**：无需管理复杂的客户端排队或重试逻辑。可用结果将在24小时内返回。\n\n## 简单的工作流程\n\nAPI设计简洁直观。用户将所有请求打包到一个文件中，提交作业，并在作业完成后检索结果。以下是开发者目前利用批处理模式完成任务的一些方式：\n\n*   **批量内容生成与处理**：\n    Reforged Labs 专注于深度视频理解，利用 Gemini 2.5 Pro 每月分析和标记大量视频广告。实施批处理模式彻底改变了他们的运营，显著降低了成本，加快了客户交付速度，并实现了获取有意义市场洞察所需的大规模可扩展性。\n    ![批量内容生成与处理](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_qhTloW2.original.png)\n\n*   **模型评估**：\n    Vals AI 对基础模型进行基准测试，涵盖法律、金融、税务和医疗保健等实际用例。他们正在使用批处理模式提交大量评估查询，而不受速率限制的约束。\n    ![模型评估](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_uvTbuTT.original.png)\n\n## 快速上手\n\n用户可以使用 Google GenAI Python SDK 立即开始使用批处理模式。基本流程包括：\n\n1.  创建一个包含多个请求的 JSONL 文件。\n2.  使用 `client.files.upload()` 方法上传该文件。\n3.  使用 `client.batches.create()` 方法创建批处理作业，指定模型和源文件。\n4.  等待作业完成（最长24小时），然后通过 `client.files.download()` 方法下载结果文件并处理其内容。\n\n## 展望\n\nGemini API 的批处理模式正在逐步向所有用户推出。这仅仅是批处理能力的开始，Google 正在积极努力扩展其功能，未来将提供更强大、更灵活的选项。",
      "shortSummary": "Gemini API 推出批处理模式，专为高吞吐量、非延迟敏感型任务设计。它允许用户提交大型作业，在24小时内获取结果，并享受50%的成本折扣。主要优势包括显著的成本节约、更高的吞吐量和简化的API调用。开发者可利用其进行批量内容生成、模型评估等。该模式已通过Python SDK提供，未来将进一步扩展功能。",
      "translated_title": "Gemini API 中的批处理模式：事半功倍",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image2_qhTloW2.original.png",
          "alt": "Bulk content generation and processing",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image3_uvTbuTT.original.png",
          "alt": "Model evaluations",
          "title": "",
          "position": 2
        }
      ],
      "contentSource": "完整文章",
      "content": "The new batch mode in the Gemini API is designed for high-throughput, non-latency-critical AI workloads, simplifying large jobs by handling scheduling and processing, and making tasks like data analysis, bulk content creation, and model evaluation more cost-effective and scalable, so developers can process large volumes of data efficiently."
    },
    {
      "title": "介绍 Gemma 3n：开发者指南 (原标题: Introducing Gemma 3n: The developer guide)",
      "link": "https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/",
      "pubDate": "Wed, 25 Jun 2025 16:00:00 GMT",
      "isoDate": "2025-06-25T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 介绍 Gemma 3n：开发者指南\n\n## 引言\nGemma 模型自去年初发布以来，已发展成为一个拥有超过 1.6 亿次总下载量的繁荣生态系统。在此基础上，Google 正式发布了 **Gemma 3n**，这是一款专为开发者社区设计的移动优先架构模型。Gemma 3n 得到了 Hugging Face Transformers、llama.cpp、Google AI Edge、Ollama、MLX 等流行工具的支持，方便开发者轻松进行微调和部署。本文旨在深入探讨 Gemma 3n 背后的创新、分享新的基准测试结果，并指导开发者如何开始构建。\n\n## Gemma 3n 的新特性\nGemma 3n 代表了设备端 AI 的重大进步，将强大的多模态能力带到边缘设备，其性能此前仅在去年的云端前沿模型中可见。\n\n*   **多模态设计**：Gemma 3n 原生支持图像、音频、视频和文本输入，以及文本输出。\n*   **针对设备优化**：Gemma 3n 模型专注于效率，提供两种基于有效参数的尺寸：E2B（5B 原始参数，2GB 内存占用）和 E4B（8B 原始参数，3GB 内存占用）。通过架构创新，其内存占用可与传统 2B 和 4B 模型媲美。\n*   **突破性架构**：Gemma 3n 的核心是新颖的组件，如用于计算灵活性的 MatFormer 架构、用于内存效率的逐层嵌入 (PLE)、用于架构效率的 LAuReL 和 AltUp，以及针对设备端用例优化的新型音频和基于 MobileNet-v5 的视觉编码器。\n*   **增强的质量**：Gemma 3n 在多语言（支持 140 种文本语言和 35 种多模态理解语言）、数学、编码和推理方面均有质量提升。E4B 版本在 LMArena 评分中达到 1300 分以上，使其成为首个参数量低于 100 亿的模型达到此基准。\n    ![LMArena Text Arena Elo Score rankings for Gemini 1.5 Pro, Gemma 3n E4B llama 4 Maverick 17B 128E GPT 4.1-nano and Phi-4](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma_3n_Chart_1_RD1-V01_1.original.png)\n\n## MatFormer：一个模型，多种尺寸\nGemma 3n 的核心是 MatFormer (🪆Matryoshka Transformer) 架构，这是一种新颖的嵌套式 Transformer，专为弹性推理而设计。它像俄罗斯套娃一样：一个更大的模型包含更小、功能齐全的自身版本。这种方法将 Matryoshka 表示学习的概念从嵌入扩展到所有 Transformer 组件。\n![MatFormer in Nano V3](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_3h2xBRA.original.jpg)\n在 4B 有效参数 (E4B) 模型的 MatFormer 训练过程中，一个 2B 有效参数 (E2B) 的子模型同时在其内部得到优化。这为开发者提供了两种强大的能力和用例：\n\n1.  **预提取模型**：开发者可以直接下载并使用主 E4B 模型以获得最高能力，或使用已提取的独立 E2B 子模型，后者可提供高达 2 倍的推理速度。\n2.  **通过 Mix-n-Match 自定义尺寸**：为了更精细地控制以适应特定硬件限制，开发者可以使用 Mix-n-Match 方法创建 E2B 和 E4B 之间的一系列自定义尺寸模型。MatFormer Lab 工具已发布，展示如何检索这些通过 MMLU 等基准评估确定的最优模型。\n    ![Custom Sizes with Mix-n-Match](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_5lfhlBO.original.png)\n展望未来，MatFormer 架构也为弹性执行铺平了道路，允许单个部署的 E4B 模型在运行时动态切换 E4B 和 E2B 推理路径，从而根据当前任务和设备负载实时优化性能和内存使用（此功能不属于本次发布的实现）。\n\n## 逐层嵌入 (PLE)：提升内存效率\nGemma 3n 模型集成了逐层嵌入 (PLE)。这项创新专为设备端部署而设计，因为它在不增加设备加速器（GPU/TPU）所需高速内存占用的情况下，显著提高了模型质量。\n尽管 Gemma 3n E2B 和 E4B 模型的总参数量分别为 5B 和 8B，但 PLE 允许这些参数的很大一部分（与每层相关的嵌入）在 CPU 上高效加载和计算。这意味着只有核心 Transformer 权重（E2B 约 2B，E4B 约 4B）需要驻留在通常更受限制的加速器内存 (VRAM) 中。\n![Per-Layer Embeddings](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image6_BdtLmLG.original.jpg)\n\n## KV 缓存共享：加速长上下文处理\n处理长输入对于许多高级设备端多模态应用至关重要。Gemma 3n 引入了 KV 缓存共享功能，旨在显著加速流式响应应用的“首个令牌生成时间”。该功能优化了模型处理初始输入阶段（“预填充”阶段）的方式，通过直接共享中间层键和值，与 Gemma 3 4B 相比，预填充性能提高了 2 倍。\n\n## 音频理解：引入语音转文本和翻译\nGemma 3n 使用基于通用语音模型 (USM) 的高级音频编码器。该编码器每 160 毫秒的音频生成一个令牌，然后将其作为输入集成到语言模型中，提供声音上下文的细粒度表示。这种集成的音频能力为设备端开发解锁了关键功能，包括：\n\n*   **自动语音识别 (ASR)**：直接在设备上实现高质量的语音转文本转录。\n*   **自动语音翻译 (AST)**：将口语翻译成另一种语言的文本。在英语与西班牙语、法语、意大利语和葡萄牙语之间的翻译任务中，AST 表现尤其出色。\n\n在发布时，Gemma 3n 编码器可处理长达 30 秒的音频片段，但其底层是一个流式编码器，未来将支持任意长度的音频和低延迟、长流式应用。\n\n## MobileNet-V5：新的最先进视觉编码器\n除了集成的音频功能外，Gemma 3n 还配备了新型高效视觉编码器 MobileNet-V5-300M，为边缘设备上的多模态任务提供了最先进的性能。\n\n*   **主要特性**：原生支持 256x256、512x512 和 768x768 像素的多种输入分辨率；在大量多模态数据集上共同训练，擅长广泛的图像和视频理解任务；在 Google Pixel 设备上每秒处理高达 60 帧，实现实时、设备端视频分析和交互体验。\n*   **架构创新**：包括 MobileNet-V4 块的先进基础、显著扩展的混合深度金字塔模型（比最大的 MobileNet-V4 变体大 10 倍），以及新颖的多尺度融合 VLM 适配器。\n*   **性能提升**：MobileNet-V5-300M 大幅超越了 Gemma 3 中的基线 SoViT。在 Google Pixel Edge TPU 上，它在量化后提供 13 倍的速度提升，所需参数减少 46%，内存占用减少 4 倍，同时在视觉语言任务中提供显著更高的准确性。\n\n## Gemma 3n 的可访问性与生态系统\nGoogle 与 AMD、Hugging Face、NVIDIA 等众多开源开发者合作，确保 Gemma 3n 在流行工具和平台上的广泛支持。此外，Google 还推出了 **Gemma 3n 影响力挑战赛**，鼓励开发者利用 Gemma 3n 独特的设备端、离线和多模态能力，构建造福世界的产品，挑战赛提供 150,000 美元的奖金。\n\n## 立即开始使用 Gemma 3n\n开发者可以通过以下方式探索 Gemma 3n 的潜力：\n\n*   **直接体验**：使用 Google AI Studio 快速试用 Gemma 3n，并可直接部署到 Cloud Run。\n*   **下载模型**：在 Hugging Face 和 Kaggle 上获取模型权重。\n*   **学习与集成**：查阅全面的文档，或从推理和微调指南开始。\n*   **使用喜爱的设备端 AI 工具**：Google AI Edge Gallery/LiteRT-LLM、Ollama、MLX、llama.cpp、Docker、transformers.js 等。\n*   **使用喜爱的开发工具**：Hugging Face Transformers 和 TRL、NVIDIA NeMo Framework、Unsloth 和 LMStudio。\n*   **灵活部署**：Gemma 3n 提供多种部署选项，包括 Google GenAI API、Vertex AI、SGLang、vLLM 和 NVIDIA API Catalog。",
      "shortSummary": "Gemma 3n 是 Google 发布的移动优先、多模态 AI 模型，专为设备端应用设计。它采用创新的 MatFormer 架构实现灵活尺寸（E2B/E4B），通过逐层嵌入和 KV 缓存共享优化内存与长上下文处理。Gemma 3n 原生支持图像、音频、视频和文本输入，并集成了基于 USM 的高级音频编码器和 MobileNet-V5 视觉编码器，提供语音识别、翻译及最先进的视觉理解能力。该模型高度优化，支持多种流行开发工具，并鼓励开发者参与影响力挑战赛。",
      "translated_title": "介绍 Gemma 3n：开发者指南",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma_3n_Chart_1_RD1-V01_1.original.png",
          "alt": "LMArena Text Arena Elo Score rankings for Gemini 1.5 Pro, Gemma 3n E4B llama 4 Maverick 17B 128E GPT 4.1-nano and Phi-4",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_3h2xBRA.original.jpg",
          "alt": "MatFormer in Nano V3",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image4_5lfhlBO.original.png",
          "alt": "Custom Sizes with Mix-n-Match",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image6_BdtLmLG.original.jpg",
          "alt": "Per-Layer Embeddings",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "The Gemma 3n model has been fully released, building on the success of previous Gemma models and bringing advanced on-device multimodal capabilities to edge devices with unprecedented performance. Explore Gemma 3n's innovations, including its mobile-first architecture, MatFormer technology, Per-Layer Embeddings, KV Cache Sharing, and new audio and MobileNet-V5 vision encoders, and how developers can start building with it today."
    },
    {
      "title": "使用新的Data Commons Python客户端库解锁更深层洞察 (原标题: Unlock deeper insights with the new Python client library for Data Commons)",
      "link": "https://developers.googleblog.com/en/pythondatacommons/",
      "pubDate": "Wed, 25 Jun 2025 16:00:00 GMT",
      "isoDate": "2025-06-25T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Data Commons 新Python客户端库：解锁更深层洞察\n\n## 引言\n数据是各领域进步的基石，能够帮助我们衡量现状、识别趋势并预测未来。Google的Data Commons旨在组织全球公开统计数据，使其更易于访问和使用。它是一个开源知识图谱，整合了来自不同来源的大量公共数据，简化了开发者、研究人员和数据分析师的访问和理解。Google搜索也使用Data Commons来回答查询，例如“旧金山的人口是多少？”。\n\n今天，我们宣布基于V2 REST API的Data Commons新Python客户端库正式发布。这个新库将极大地增强数据开发者利用Data Commons的能力。\n\n## 实际影响：与ONE.org合作\n这一里程碑的实现，得益于我们的合作伙伴The ONE Campaign（一个致力于为非洲经济机会和健康生活创造所需投资的全球组织）的愿景和重大贡献。我们将Data Commons构建为一个开源平台，正是为了鼓励社区贡献和实现创新用途，而与The ONE Campaign的合作完美地体现了这一目标。ONE组织倡导、设计并编码了该客户端库，旨在让数据科学家和分析师能够利用Python分析工具和库的丰富生态系统，访问Data Commons的丰富洞察。\n\n## 支持自定义Data Commons实例\nData Commons平台还允许联合国或ONE等组织托管自己的Data Commons实例。这些自定义实例能够将专有数据集与基础的Data Commons知识图谱无缝集成。组织可以利用Data Commons的数据框架和工具，同时完全控制其数据和资源。\n\nV2库中最具影响力的新增功能之一是其对自定义实例的强大支持。这意味着您现在可以使用Python库以编程方式查询任何公共或私有实例——无论是本地托管、组织内部托管还是在Google Cloud Platform上托管。\n\n## 强大的新功能\nPython库使得对Data Commons数据执行常见查询变得非常容易，例如：\n*   探索知识图谱的结构。\n*   从人口统计、经济、教育、能源、环境、健康和住房等领域的200多个数据集中，检索200,000多个统计变量的数据。\n*   轻松将其他数据集中的实体映射到Data Commons中的实体。\n\n与V1库相比，客户端库的V2版本提供了许多技术改进，包括：\n*   **Pandas DataFrame API支持**：作为集成模块，通过单一安装包提供，可与同一客户端中的其他API端点无缝使用。\n*   **新的便捷方法**：针对常见数据查询提供了多个新方法。\n*   **API密钥管理**：API密钥管理和其他有状态操作内置于客户端类中。\n*   **Pydantic集成**：与Pydantic库集成，提高了类型安全性、验证和序列化能力。\n*   **多种响应格式支持**：支持JSON、Python字典和列表等多种响应格式。\n\n以下是一个使用示例，展示了如何绘制国际贫困线以下人口比例的图表：\n```python\nvariable = \"sdg/SI_POV_DAY1\"\nvariable_name = \"Proportion of population below international poverty line\"\ndf = client.observations_dataframe(variable_dcids=variable, date=\"all\", parent_entity=\"Earth\", entity_type=\"Continent\")\ndf = df.pivot(index=\"date\", columns=\"entity_name\", values=\"value\")\nax = df.plot(kind=\"line\")\nax.set_xlabel(\"Year\")\nax.set_ylabel(\"%\")\nax.set_title(variable_name)\nax.legend()\nax.plot()\n```\n![图表显示各大洲国际贫困线以下人口比例](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/DC_blogpost_screenshot1.original.png)\n\n## 开始使用\n要开始使用Data Commons Python库，您可以直接从PyPI安装软件包。我们还提供了全面的资源来帮助您深入了解，包括参考文档和作为Google Colab笔记本提供的在线教程。\n\n对于目前使用V1 Python API的用户，我们强烈建议升级到新的V2 Python库。V1 API计划弃用，采用新库可确保您能够访问最新功能并获得持续支持。\n\n## 开源协作\n这个库是开源协作力量的明证。开源代码可在GitHub上获取，我们欢迎社区根据Google贡献者许可协议做出贡献。",
      "shortSummary": "Google发布了基于V2 REST API的Data Commons新Python客户端库，现已正式可用。该库旨在帮助数据开发者更深入地利用Data Commons的公共统计数据，支持探索知识图谱、检索海量变量数据，并与Pandas等工具无缝集成。新版本还增强了对自定义Data Commons实例的支持，并得益于ONE.org的重大贡献。建议V1用户升级，以获取最新功能和持续支持。该库是开源项目，欢迎社区贡献。",
      "translated_title": "使用新的Data Commons Python客户端库解锁更深层洞察",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/DC_blogpost_screenshot1.original.png",
          "alt": "Graph showing proportion of population below international poverty line across continental regions",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Google has released a new Python client library for Data Commons – an open-source knowledge graph that unifies public statistical data, and enhances how data developers can leverage Data Commons by offering improved features, support for custom instances, and easier access to a vast array of statistical variables – developed with contributions from The ONE Campaign."
    },
    {
      "title": "使用 Gemini 2.5 Flash-Lite 模拟神经操作系统 (原标题: Simulating a neural operating system with Gemini 2.5 Flash-Lite)",
      "link": "https://developers.googleblog.com/en/simulating-a-neural-operating-system-with-gemini-2-5-flash-lite/",
      "pubDate": "Tue, 24 Jun 2025 16:00:00 GMT",
      "isoDate": "2025-06-24T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 使用 Gemini 2.5 Flash-Lite 模拟神经操作系统\n\n本文探讨了一种新的计算范式，即构建一个生成式、无限的计算机体验原型，该原型模拟了一个操作系统，其中每个屏幕都由大型语言模型实时生成。该原型利用 Gemini 2.5 Flash-Lite 模型，其低延迟对于创建即时响应的交互至关重要。\n\n### 核心技术概念\n\n1.  **模型条件化以实现即时 UI 生成**\n    *   为了实时生成用户界面 (UI)，模型需要清晰的结构和上下文。\n    *   提示被分为两部分：\n        *   **UI 宪法 (UI constitution)**：一个系统提示，包含一组固定的 UI 生成规则，定义了操作系统级别的样式、主屏幕格式以及嵌入地图等元素的逻辑。\n        *   **UI 交互 (UI interaction)**：一个 JSON 对象，捕获用户最近的操作（例如，点击图标），作为模型生成下一个屏幕的具体查询。例如，点击“保存笔记”按钮会生成一个包含 `id`、`type`、`value`、`elementType`、`elementText` 和 `appContext` 等信息的 JSON 对象。\n    *   这种双部分上下文设置方法使模型能够在生成基于特定实时用户输入的新屏幕的同时，保持一致的外观和感觉。\n\n2.  **使用交互追踪实现上下文感知**\n    *   单个交互提供即时上下文，而一系列交互则能提供更丰富的故事。\n    *   原型可以利用过去 N 次交互的追踪来生成更具上下文相关性的屏幕。\n    *   通过调整交互追踪的长度，可以在上下文准确性和 UI 可变性之间进行平衡。\n\n3.  **流式传输 UI 以实现响应式体验**\n    *   为了使系统感觉快速，原型利用模型流式传输和浏览器原生解析器实现渐进式渲染。\n    *   模型分块生成 HTML 代码，系统持续将其附加到组件状态，React 随后重新渲染内容。\n    *   这使得浏览器能够尽快显示有效的 HTML 元素，为用户创造了界面几乎即时呈现在屏幕上的体验。\n\n4.  **通过生成式 UI 图实现状态保持**\n    *   默认情况下，模型每次用户输入都会从头开始生成新屏幕，这可能导致非确定性、无状态的体验。\n    *   为了引入状态性，演示系统可以选择为会话特定的 UI 图构建内存缓存。\n    *   当用户导航到已生成的屏幕时，系统会从图中提供存储的版本，而无需再次查询 Gemini。\n    *   当用户请求缓存中没有的新屏幕时，UI 图会增量增长。\n    *   此方法在不影响生成输出质量的情况下实现了状态保持。\n\n### 即时生成式 UI 的潜在应用\n\n尽管这是一个概念原型，但其底层框架可应用于更实际的用例：\n\n*   **上下文快捷方式**：系统可以观察用户的交互模式，生成一个临时的 UI 面板以加速任务。例如，当用户比较多个网站上的航班时，一个浮动小部件可以即时出现，带有动态生成的按钮，用于比较价格或直接预订航班。\n*   **现有应用程序中的“生成模式”**：开发者可以向其应用程序添加“生成模式”。例如，在 Google 日历中，用户可以激活此模式以查看即时 UI。当移动日历邀请时，系统可以根据与会者的日程生成一个屏幕，以一系列可直接选择的按钮形式呈现最佳替代时间，而不是标准的对话框。这将创建一种混合体验，其中生成式和静态 UI 元素在同一应用程序中无缝共存。\n\n探索此类新颖概念有助于我们理解人机交互新范式的发展。随着模型变得更快、更强大，生成式界面代表了未来研究和开发的一个有前景的领域。",
      "shortSummary": "本文介绍了一个使用 Gemini 2.5 Flash-Lite 模拟神经操作系统的研究原型。该系统能实时生成用户界面，通过“UI 宪法”和“UI 交互”提供上下文，并利用交互追踪提升相关性。为确保响应速度，系统采用流式传输和渐进式渲染。通过构建内存中的 UI 图，原型实现了状态保持。潜在应用包括上下文快捷方式和现有应用中的“生成模式”，预示着人机交互的新范式。",
      "translated_title": "使用 Gemini 2.5 Flash-Lite 模拟神经操作系统",
      "images": [],
      "contentSource": "完整文章",
      "content": "A research prototype simulating a neural operating system generates UI in real-time adapting to user interactions with Gemini 2.5 Flash-Lite, using interaction tracing for contextual awareness, streaming the UI for responsiveness, and achieving statefulness with an in-memory UI graph."
    },
    {
      "title": "Imagen 4 现已在 Gemini API 和 Google AI Studio 中推出 (原标题: Imagen 4 is now available in the Gemini API and Google AI Studio)",
      "link": "https://developers.googleblog.com/en/imagen-4-now-available-in-the-gemini-api-and-google-ai-studio/",
      "pubDate": "Mon, 23 Jun 2025 16:00:00 GMT",
      "isoDate": "2025-06-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Imagen 4 现已在 Gemini API 和 Google AI Studio 中推出\n\nGoogle 于 2025 年 6 月 24 日宣布，其最新、最强大的文本到图像模型 Imagen 4 已在 Gemini API 中推出付费预览，并在 Google AI Studio 中提供有限的免费测试。Imagen 4 在文本渲染方面比之前的图像模型有了显著改进，并进一步提升了文本到图像生成的质量。\n\n### Imagen 4 系列模型\n\nImagen 4 系列包含两个模型，旨在满足不同的创意需求：\n\n*   **Imagen 4：**\n    *   适用于大多数任务的首选模型。\n    *   作为旗舰文本到图像模型，它能够处理各种图像生成任务，并在质量上，尤其是在文本生成方面，比 Imagen 3 有显著提升。\n    *   定价：每张输出图像 0.04 美元。\n\n*   **Imagen 4 Ultra：**\n    *   适用于需要图像精确遵循指令的场景。\n    *   该模型旨在生成与文本提示高度对齐的输出，与其他领先的图像生成模型相比，表现出色。\n    *   定价：每张输出图像 0.06 美元。\n\n未来几周内将推出额外的计费层级，目前用户可以申请更高的 Imagen 4 和 4 Ultra 速率限制。\n\n### Imagen 4 实际应用示例\n\n以下是使用 Imagen 4 Ultra 生成的一些图像示例，展示了该模型在各种风格和内容上的多功能性：\n\n*   **提示：** 一个三格的宇宙史诗漫画。第一格：星云中的微小“星尘”；雷达显示异常（文字“ANOMALY DETECTED”），船体文字“stardust”。飞行员低语。第二格：生物发光巨兽出现；控制台红色文字“WARNING!”。第三格：巨兽在小行星群中追逐飞船；控制台红色文字“SHIELD CRITICAL!”，屏幕文字“EVADE!”。飞行员尖叫，音效“CRUNCH!”，“ROOOOAAARR!”。\n    ![一个由 Imagen 4 生成的三格宇宙史诗漫画](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3-panel-cosmic-epic-comic-imagen-4.original.png)\n\n*   **提示：** 一张京都复古旅行明信片正面：樱花下的标志性宝塔，远处白雪皑皑的山脉，晴朗的蓝天，色彩鲜艳。\n    ![一个由 Imagen 4 生成的京都复古旅行明信片正面](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/vintage-travel-postcard-kyoto-imagen-4.original.png)\n\n*   **提示：** 一张冒险情侣在日出时分徒步登上山顶的照片，他们举起手臂庆祝胜利，下方山谷的史诗般全景，戏剧性的光线。\n    ![一个由 Imagen 4 生成的冒险情侣在日出时分徒步登上山顶的照片](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/adventurous-couple-photograph-imagen-4.original.png)\n\n*   **提示：** 一张前卫时尚编辑照片：模特身穿一件蓬松、建筑感十足的礼服，站在一个闪烁的外星景观上，双星落日，超现实色彩，高概念，电影感。\n    ![一个由 Imagen 4 生成的前卫时尚编辑照片](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/avant-garde-fashion-photo-shoot-imagen-4.original.png)\n\n### 开始使用 Imagen\n\n为了维护信任和透明度，所有由 Imagen 4 模型生成的图像都将包含一个不可见的数字 SynthID 水印。用户可以通过官方文档和教程开始使用 Imagen 4。Google 期待看到用户通过 Gemini API 和 Google AI Studio 使用 Imagen 4 创造的作品，并计划在未来几周内使这些模型普遍可用。",
      "shortSummary": "Google 已在 Gemini API 和 Google AI Studio 中推出其最新的文本到图像模型 Imagen 4。Imagen 4 提供显著改进的文本渲染和图像生成质量。该系列包含 Imagen 4（通用型，每张0.04美元）和 Imagen 4 Ultra（高精度型，每张0.06美元）。所有生成图像都将包含不可见的数字水印。用户现可通过文档和教程开始使用，未来几周将普遍可用。",
      "translated_title": "Imagen 4 现已在 Gemini API 和 Google AI Studio 中推出",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/3-panel-cosmic-epic-comic-imagen-4.original.png",
          "alt": "A 3-panel cosmic epic comic generated by Imagen 4",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/vintage-travel-postcard-kyoto-imagen-4.original.png",
          "alt": "Front of a vintage travel postcard for Kyoto generated by Imagen 4",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/adventurous-couple-photograph-imagen-4.original.png",
          "alt": "Photograph of an adventurous couple hiking on a mountain peak at sunrise generated by Imagen 4",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/avant-garde-fashion-photo-shoot-imagen-4.original.png",
          "alt": "Avant-garde fashion editorial shot generated by Imagen 4",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "Imagen 4, Google's advanced text-to-image model, is now available in paid preview via the Gemini API and Google AI Studio, offering significant quality improvements, especially for text generation within images. The Imagen 4 family includes Imagen 4 for general tasks and Imagen 4 Ultra for high-precision prompt adherence, with all generated images featuring a non-visible SynthID watermark."
    }
  ],
  "lastUpdated": "2025-07-15T10:33:35.859Z"
}
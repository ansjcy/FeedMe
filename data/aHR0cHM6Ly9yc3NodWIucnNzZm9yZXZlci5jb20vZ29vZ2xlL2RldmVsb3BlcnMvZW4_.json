{
  "sourceUrl": "https://rsshub.rssforever.com/google/developers/en",
  "title": "Google Developers Blog",
  "description": "Google Developers Blog - Powered by RSSHub",
  "link": "https://developers.googleblog.com",
  "items": [
    {
      "title": "宣布 Imagen 4 Fast 以及 Imagen 4 系列在 Gemini API 中的普遍可用性 (原标题: Announcing Imagen 4 Fast and the general availability of the Imagen 4 family in the Gemini API)",
      "link": "https://developers.googleblog.com/en/announcing-imagen-4-fast-and-imagen-4-family-generally-available-in-the-gemini-api/",
      "pubDate": "Thu, 14 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-14T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Imagen 4 系列在 Gemini API 中普遍可用\n\nGoogle 近日宣布，其最先进的文本到图像模型 Imagen 4 现已在 Gemini API 和 Google AI Studio 中普遍可用。此次发布标志着文本到图像生成质量的重大飞跃，尤其在文本渲染方面相比之前的模型有了显著改进。\n\n### Imagen 4 系列模型\n\n为了满足不同的创意需求，Imagen 4 系列提供了多种模型，让用户可以在质量、速度和成本之间取得平衡：\n\n*   **Imagen 4 Fast**：\n    *   **特点**：专为速度而设计，是快速图像生成和高吞吐量任务的理想选择。\n    *   **成本**：每张输出图像仅需 0.02 美元，价格亲民。\n*   **Imagen 4**：\n    *   **特点**：旗舰模型，适用于各种高质量图像生成任务，在文本渲染等领域有显著提升。\n*   **Imagen 4 Ultra**：\n    *   **特点**：当创意愿景需要最高水平的细节和严格遵循提示时，Imagen 4 Ultra 能提供高度一致的结果。\n\n### 更高分辨率带来更多细节\n\n为了进一步拓展创意边界，Imagen 4 和 Imagen 4 Ultra 现在支持生成高达 2K 分辨率的图像。这使得创建细节惊人、清晰锐利的视觉效果成为可能，非常适合营销素材或复杂的艺术作品。\n\n### Imagen 4 Fast 实际应用示例\n\n以下是一些使用 Imagen 4 Fast 创建的图像示例，展示了该模型在各种风格和内容上的多功能性：\n\n*   **风景/自然图像**：\n    *   **描述**：黎明时分的壮丽山脉景观，前景是清澈的湖泊，倒映着白雪皑皑的山峰。\n    *   **图片**：\n        ![Imagen 4 Fast demo - landscape](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Imagen-4-fast-demo-landscape.original.png)\n\n*   **四格漫画**：\n    *   **描述**：一个复古风格的四格漫画。第一格显示一只友好的猫坐在 Chromebook 旁边，屏幕上是 https://ai.dev 网站，配文：“Imagen 4 现已普遍可用！” 第二格显示一只狗说：“我们还推出了 Imagen 4 FAST，它以每张图像仅 0.02 美元的价格提供低延迟图像！” 第三格显示猫说：“2K 图像升级也可用！” 第四格显示猫和狗击掌，配文：“立即在 AI Studio 中尝试 Imagen 4！”\n    *   **图片**：\n        ![Imagen 4 Fast demo - four panel comic strip](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-four-panel-comic-strip.original.png)\n\n*   **复古科幻电影海报**：\n    *   **描述**：一张复古科幻电影海报，采用喷绘艺术风格。海报上有一艘细节丰富的宇宙飞船，向右飞过一个充满恒星的深空中的充满活力的星云。飞船的两个引擎发出明亮的蓝色发光轨迹。海报顶部的标题是“SUPER GALACTICA: THE LAST NEBULA”，采用粗体、斜面、金属铬字体，带有阴影。下方副标题“STARFALLS REVENGE”以更简洁、干净的白色字体书写。整个图像具有复古、风化的外观，带有破旧的米白色边框。最底部以小字体写着：“此海报由 AI 创建，此免责声明亦然 :)”。\n    *   **图片**：\n        ![Imagen 4 Fast demo - retro sci-fi movie poster](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-retro-sci-fi-movie-poster.original.png)\n\n### 负责任的 AI\n\n作为对负责任 AI 承诺的一部分，所有由 Imagen 4 系列生成的图像都使用 SynthID 进行了不可察觉的水印处理。Google 鼓励用户查阅官方文档和操作指南，开始使用 Imagen 4 进行创作。",
      "shortSummary": "Google 宣布其先进的文本到图像模型 Imagen 4 及其新推出的 Imagen 4 Fast 已在 Gemini API 和 Google AI Studio 中普遍可用。Imagen 4 系列在图像质量，特别是文本渲染方面有显著提升。Imagen 4 Fast 专为速度和成本效益设计，每张图像仅需 0.02 美元。Imagen 4 和 Imagen 4 Ultra 支持高达 2K 分辨率。所有 Imagen 4 生成的图像都使用 SynthID 进行水印处理，以确保负责任的 AI 应用。",
      "translated_title": "宣布 Imagen 4 Fast 以及 Imagen 4 系列在 Gemini API 中的普遍可用性",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Imagen-4-fast-demo-landscape.original.png",
          "alt": "Imagen 4 Fast demo - landscape",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-four-panel-comic-strip.original.png",
          "alt": "Imagen 4 Fast demo - four panel comic strip",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/imagen-4-fast-demo-retro-sci-fi-movie-poster.original.png",
          "alt": "Imagen 4 Fast demo - retro sci-fi movie poster",
          "title": "",
          "position": 3
        }
      ],
      "contentSource": "完整文章",
      "content": "Google announces the general availability of Imagen 4, its advanced text-to-image model, in the Gemini API and Google AI Studio, featuring significant improvements in text rendering. The new Imagen 4 Fast model, designed for speed and rapid image generation, is now available alongside Imagen 4 and Imagen 4 Ultra, with Imagen 4 and Imagen 4 Ultra also supporting up to 2K resolution image generation."
    },
    {
      "title": "介绍 Gemma 3 270M：超高效AI的紧凑型模型 (原标题: Introducing Gemma 3 270M: The compact model for hyper-efficient AI)",
      "link": "https://developers.googleblog.com/en/introducing-gemma-3-270m/",
      "pubDate": "Wed, 13 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-13T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 介绍 Gemma 3 270M：超高效AI的紧凑型模型\n\n**发布日期：** 2025年8月14日\n\nGemma系列开放模型近期发展迅速，继Gemma 3、Gemma 3 QAT和移动优先的Gemma 3n之后，谷歌推出了Gemma 3 270M。这款模型是Gemma 3工具包中的一个高度专业化新成员，旨在为开发者提供构建AI的实用工具，并已助力Gemma系列下载量突破2亿。\n\n### Gemma 3 270M 概览\n\nGemma 3 270M是一个拥有2.7亿参数的紧凑型模型，从头开始设计，专注于任务特定的微调，并内置了强大的指令遵循和文本结构化能力。它在IFEval基准测试中表现出色，为同等规模的模型设立了新的性能标准，使复杂的AI能力在设备端和研究应用中更易于访问。\n\n![Gemma 3 270M](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3-270M_Chart01_RD3-V01.original.jpg)\n\n### 核心能力\n\n1.  **紧凑而强大的架构：**\n    *   总参数：2.7亿（1.7亿嵌入参数，1亿用于Transformer块）。\n    *   大词汇量：25.6万个词元，能够处理特定和罕见的词元，是特定领域和语言微调的强大基础模型。\n\n2.  **极致的能源效率：**\n    *   功耗极低。在Pixel 9 Pro SoC上的内部测试显示，INT4量化模型进行25次对话仅消耗0.75%的电池电量，是Gemma系列中最节能的模型。\n\n3.  **指令遵循能力：**\n    *   发布了经过指令微调的模型和预训练检查点。\n    *   虽然不适用于复杂的对话场景，但它能很好地遵循通用指令。\n\n4.  **生产就绪的量化：**\n    *   提供量化感知训练（QAT）检查点，支持以INT4精度运行模型，性能下降极小，这对于部署在资源受限设备上至关重要。\n\n### “物尽其用”的理念\n\nGemma 3 270M体现了“物尽其用”的工程哲学。它是一个高质量的基础模型，开箱即用就能很好地遵循指令，其真正的力量通过微调得以释放。经过专业化处理后，它能以卓越的准确性、速度和成本效益执行文本分类和数据提取等任务。通过使用紧凑而强大的模型，可以构建精简、快速且运营成本显著降低的生产系统。\n\n### 实际应用案例\n\n*   **Adaptive ML与SK Telecom的合作：** Adaptive ML通过微调Gemma 3 4B模型来应对多语言内容审核的挑战。结果显示，专业化的Gemma模型在特定任务上超越了许多大型专有模型的性能。\n*   **创意应用：** Gemma 3 270M被用于驱动一个基于Transformers.js的睡前故事生成器网络应用。其小巧的尺寸和高性能使其非常适合离线、基于网络的创意任务。\n\n### 何时选择 Gemma 3 270M\n\nGemma 3 270M继承了Gemma 3系列的先进架构和强大的预训练基础，为自定义应用提供了坚实的基础。它是以下场景的理想选择：\n\n*   **高吞吐量、明确定义的任务：** 适用于情感分析、实体提取、查询路由、非结构化到结构化文本处理、创意写作和合规性检查等功能。\n*   **对毫秒和微分成本敏感：** 大幅降低或消除生产中的推理成本，并为用户提供更快的响应。微调后的270M模型可以在轻量级、廉价的基础设施上或直接在设备上运行。\n*   **需要快速迭代和部署：** Gemma 3 270M的小尺寸允许快速进行微调实验，帮助您在数小时而非数天内找到适合您用例的完美配置。\n*   **需要确保用户隐私：** 由于模型可以完全在设备上运行，您可以构建处理敏感信息的应用程序，而无需将数据发送到云端。\n*   **需要一系列专业化任务模型：** 可以在不超出预算的情况下，构建和部署多个自定义模型，每个模型都经过专业训练以执行不同的任务。\n\n### 开始微调\n\nGemma 3 270M与Gemma 3系列其他模型采用相同架构，并提供快速入门的指南和工具。您可以在Gemma文档中找到使用Gemma 3 270M进行完整微调的指南。\n\n*   **下载模型：** 可从Hugging Face、Ollama、Kaggle、LM Studio或Docker获取预训练和指令微调模型。\n*   **试用模型：** 可在Vertex AI或使用llama.cpp、Gemma.cpp、LiteRT、Keras和MLX等流行推理工具进行试用。\n*   **开始微调：** 使用Hugging Face、UnSloth和JAX等您喜欢的工具。\n*   **部署解决方案：** 微调完成后，您可以将专业化模型部署到任何地方，从本地环境到Google Cloud Run。\n\nGemmaverse的理念是创新无大小。通过Gemma 3 270M，谷歌赋能开发者构建更智能、更快、更高效的AI解决方案。",
      "shortSummary": "Gemma 3 270M是谷歌推出的一款紧凑型、2.7亿参数的AI模型，专为任务特定微调设计。它具备强大的指令遵循能力和极高的能源效率，可在设备端运行，大幅降低推理成本并保护用户隐私。该模型非常适合需要高效率、快速迭代和专业化AI解决方案的场景，使先进AI更易于部署和访问，推动创新。",
      "translated_title": "介绍 Gemma 3 270M：超高效AI的紧凑型模型",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3-270M_Chart01_RD3-V01.original.jpg",
          "alt": "Gemma 3 270M",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Google's new Gemma 3 270M is a compact, 270-million parameter model offering energy efficiency, production-ready quantization, and strong instruction-following, making it a powerful solution for task-specific fine-tuning in on-device and research settings."
    },
    {
      "title": "Gemini CLI + VS Code：原生差异比较和上下文感知工作流 (原标题: Gemini CLI + VS Code: Native diffing and context-aware workflows)",
      "link": "https://developers.googleblog.com/en/gemini-cli-vs-code-native-diffing-context-aware-workflows/",
      "pubDate": "Tue, 12 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-12T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini CLI + VS Code：原生差异比较和上下文感知工作流\n\nGemini CLI 的最新更新为 VS Code 带来了更深层次的集成，旨在提升开发者的命令行应用体验。此次更新将智能功能直接引入 VS Code 集成终端，通过理解上下文并提供即时建议，彻底改变了开发者与项目互动的方式。\n\n## 新特性：更深层次的集成\n\n此次更新从根本上改变了 Gemini CLI 与编辑器的交互方式，使开发工作流更加流畅高效。\n\n*   **工作区与选择上下文感知**\n    当 VS Code IDE 连接到 Gemini CLI 时，CLI 可以直接访问您的工作区。它能够感知您打开的文件并访问选定的文本。这使得 CLI 能够提供有针对性且与上下文相关的建议，因为它能准确理解您当前正在处理的内容。\n\n*   **原生编辑器内差异比较 (Native In-editor Diffing)**\n    Gemini CLI 的建议现在可以直接在 VS Code 内部触发全屏差异比较视图。这提供了全面的并排更改审查。至关重要的是，您可以在接受更改之前直接在此差异视图中修改代码，从而获得完全的控制和灵活性。\n\n## 如何开始\n\n准备好体验了吗？设置过程非常简单。\n\n1.  **先决条件**\n    *   Gemini CLI 版本 0.1.20 或更高。\n    *   在 VS Code 的集成终端中运行 CLI。\n\n2.  **一次性设置**\n    在您的集成终端中运行 `/ide install` 命令，以安装必要的配套扩展。\n\n3.  **切换集成状态**\n    完成一次性设置后，您可以轻松管理集成：\n    *   激活：运行 `/ide enable`\n    *   停用：运行 `/ide disable`\n\n立即启用 IDE 集成，体验使用 Gemini CLI 和 VS Code 构建项目的新方式。",
      "shortSummary": "Gemini CLI 最新更新深度集成 VS Code，提供智能、上下文感知的开发体验。核心功能包括：CLI 直接访问工作区和选定文本，实现精准建议；以及原生编辑器内全屏差异比较，允许直接修改代码。用户需满足版本要求并在VS Code终端运行`/ide install`进行一次性设置，随后可轻松启用或禁用集成，大幅提升开发效率和控制力。",
      "translated_title": "Gemini CLI + VS Code：原生差异比较和上下文感知工作流",
      "images": [],
      "contentSource": "完整文章",
      "content": "The latest Gemini CLI update provides a deep IDE integration within VS Code for intelligent, context-aware suggestions, and native in-editor diffing, allowing developers to review and modify proposed changes directly within the diff view for a more efficient workflow."
    },
    {
      "title": "认识Jules最犀利的批评者和最有价值的盟友 (原标题: Meet Jules’ sharpest critic and most valuable ally)",
      "link": "https://developers.googleblog.com/en/meet-jules-sharpest-critic-and-most-valuable-ally/",
      "pubDate": "Mon, 11 Aug 2025 16:00:00 GMT",
      "isoDate": "2025-08-11T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Jules AI 编码代理的新“批评者”功能\n\n## 介绍\nJules 是一款 AI 编码代理，能够构建、重构和搭建代码，让开发者专注于其他任务。然而，这种便利性有时会导致细微的错误、遗漏的边缘情况和未经测试的假设。为了解决这些问题，Jules 引入了一项新功能——“批评者”（critic），它能在代码提交给用户之前对其进行审查和批判。\n\n## 批评者的角色与“批评者增强生成”\n“批评者”功能简单而强大：当 Jules 构建代码时，批评者会对其提出质疑。每一个提议的更改在完成之前都会经过对抗性审查。可以把批评者看作 Jules 的同行评审员，它深入了解代码质量原则，并敢于指出潜在的问题，例如重复发明了有风险的轮子。\n\n这项功能直接集成到代码生成过程中，被称为“批评者增强生成”（critic-augmented generation）。在当前版本中，它是一个一次性过程，在单个通道中评估最终输出。未来的里程碑目标是使其成为一个真正的多步骤代理，能够使用工具调用，或在子任务之后、规划之前触发。目前，它一次性审查完整的生成内容。这将借鉴多步骤研究，其中批评者使用外部工具（如代码解释器或搜索引擎）验证输出，并从结果中学习。\n\n## 批评者的具体作用\n批评者不直接修复代码，而是标记出问题，然后将其反馈给 Jules 进行改进。例如：\n*   一个通过所有测试但引入了微妙逻辑错误的补丁：批评者会指出“输出符合预期情况，但在未见输入上失败。”\n*   一个能编译但默默丢弃了所需字段的更改：批评者会指出“函数签名已更新，但未处理所有参数。”\n*   一个能工作但使用了低效方法的代码：批评者会指出“算法产生正确结果，但具有不必要的 O(n²) 复杂度。”\n\n由于此过程发生在补丁生成之后和提交之前（如果仍有问题，可能会多次进行），Jules 可以实时重新规划。我们的目标是减少低质量的拉取请求（PRs），提高测试覆盖率，增强安全性。\n\n## 与传统工具的区别\n批评者功能与传统的代码检查工具（如 Linter）和测试不同：\n*   **Linter**：遵循浅层、固定的规则。\n*   **测试**：验证特定的断言。\n*   **批评者**：理解代码背后的意图和上下文。它更接近于一种无参考评估方法，在不需要黄金标准实现的情况下判断代码的正确性和健壮性。\n\n它还借鉴了“LLM-as-a-judge”（大语言模型作为评判者）的研究，即一个模型评估另一个模型的工作质量和正确性。这种自动化评判与生成过程紧密集成时特别有用，能将审查转化为实时的反馈循环。\n\n## 工作流程\n批评者功能的工作流程如下：\n1.  用户提示 Jules 开始一项任务。\n2.  批评者功能在单个通道中审查候选补丁及其描述，并做出总体判断。\n3.  Jules 根据反馈进行响应，在完成之前进行改进。之后，批评者可以再次审查更新后的补丁，并继续标记任何它认为必要的问题，直到不再存在问题。\n4.  用户收到已经过内部审查的代码。\n\n这借鉴了“行动者-批评者”（actor-critic）强化学习（RL）的原理，其中“行动者”生成，“批评者”评估。在 RL 中，这个循环根据学习信号更新行动者和批评者。在我们的“LLM-as-critic”设置中，模式类似：提出，然后评估。然而，反馈不是更新学习参数，而是影响当前状态和下一步行动。同样的原则也支撑着“LLM-as-a-judge”的研究，其中批评者的评估在不重新训练的情况下指导质量。\n\n## 重要性\n在快速迭代的世界中，批评者将审查过程提前，并融入到生成行为本身。这意味着用户审查的代码已经过内部的质询、完善和压力测试。当然，用户在使用前仍应仔细审查生成的代码。\n\n优秀的开发者不仅编写代码，他们还会质疑代码。现在，Jules 也能做到。",
      "shortSummary": "Jules AI编码代理推出一项“批评者”功能，在用户看到代码前对其进行审查。该功能作为Jules的同行评审员，能识别并标记AI生成代码中的细微错误、低效或逻辑问题。Jules会根据批评者的反馈实时重构代码，以提高质量、测试覆盖率和安全性。它不同于传统Linter或测试，能理解代码意图和上下文，借鉴了“LLM作为评判者”的理念。最终，用户将获得经过内部审查、更高质量的代码。",
      "translated_title": "认识Jules最犀利的批评者和最有价值的盟友",
      "images": [],
      "contentSource": "完整文章",
      "content": "Jules' critic functionality addresses potential issues like subtle bugs and missed edge cases in AI-generated code by acting as a peer reviewer within the generation process. This \"critic-augmented generation\" means proposed code changes undergo adversarial review, allowing Jules to improve its output and ultimately deliver higher-quality, pre-reviewed code."
    },
    {
      "title": "Google 开发者计划正在演进 (原标题: The Google Developer Program is evolving)",
      "link": "https://developers.googleblog.com/en/google-developer-program-join-connect-code/",
      "pubDate": "Thu, 31 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-31T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Google 开发者计划正在演进\n\nGoogle 于2025年8月1日宣布了Google开发者计划的最新进展，旨在通过强大的AI工具和资源，帮助开发者更快、更智能地进行构建。此次更新引入了多项增强功能，以更深入地融入开发者工作流程，并连接他们所需的专业知识。\n\n## 访问 Google AI 工具的更大灵活性\n\n为了让高级资源更易于访问，Google 推出了 Google 开发者计划月度订阅计划，费用为每月 24.99 美元*。该计划提供所有 AI 增强型高级福利，包括：\n*   用于 Vertex AI 和 Google AI Studio 的 Google Cloud 积分。\n*   Gemini Code Assist Standard。\n*   30 个 Firebase Studio 工作区，用于将全栈应用程序投入生产。\n*   以及更多其他福利。\n\n开发者可以通过新的福利仪表板轻松激活所有福利。\n\n![Google Developer Program pricing](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-pricing.original.png)\n![Google Developer Program benefits](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-benefits.original.png)\n\n*注：Google 开发者计划月度订阅计划目前仅在美国可用，未来几周将推广到其他国家。\n\n## 统一的协作中心：Google 开发者计划论坛\n\nGoogle 还推出了新的 Google 开发者计划论坛，网址为 `discuss.google.dev`。这个新平台将开发者的 Google 开发者计划资料、社区和兴趣整合在一起，使得提问、分享知识、与同行联系、寻求错误帮助以及分享发现变得更加容易。\n\n现有的 Google Cloud、Workspace Developer、AppSheet 和 Looker 社区及其所有历史内容和讨论已迁移到这个新的中心论坛。\n\n![Google Developer Program forums](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-forums.original.png)\n\n## 加速您的 AI 之旅：加入 Google Cloud & NVIDIA 社区\n\n在 Google I/O 大会上，Google 宣布了新的 Google Cloud & NVIDIA 社区，专为有兴趣在 Google Cloud 上利用 NVIDIA 尖端技术的实践者而建。社区成员可以获得独家学习路径，例如亲身体验 GKE 和 NVIDIA NIM 进行 AI 推理任务。此外，在完成学习路径后，限时可获得 Google Cloud 积分。\n\n未来几周将推出新的学习路径。\n\n![Accelerate your AI journey: Join the Google Cloud & NVIDIA community](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-cloud-nvidia-community-google-developer-.original.png)\n\n## 立即开始\n\n无论开发者是寻求更灵活的工具访问方式，渴望与社区建立更紧密的联系，还是希望通过 AI 提升生产力，Google 开发者计划都能提供相应支持。访问 `developers.google.com/program` 了解更多信息并探索您的 Google 开发者计划福利。",
      "shortSummary": "Google 开发者计划于2025年8月1日宣布重大演进，旨在通过AI工具赋能开发者。核心更新包括：推出每月24.99美元的月度计划（美国），提供Google Cloud积分、Gemini Code Assist等高级AI福利；上线统一的Google开发者计划论坛（discuss.google.dev），整合现有社区；以及成立Google Cloud & NVIDIA社区，提供AI学习路径和积分。这些举措旨在提供更灵活的工具访问、更强的社区连接和AI驱动的生产力提升。",
      "translated_title": "Google 开发者计划正在演进",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-pricing.original.png",
          "alt": "Google Developer Program pricing",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-benefits.original.png",
          "alt": "Google Developer Program benefits",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-developer-program-forums.original.png",
          "alt": "Google Developer Program forums",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-cloud-nvidia-community-google-developer-.original.png",
          "alt": "Accelerate your AI journey: Join the Google Cloud & NVIDIA community",
          "title": "",
          "position": 4
        }
      ],
      "contentSource": "完整文章",
      "content": "The Google Developer Program is rolling out major updates to make its tools and community more accessible and powerful. These enhancements include a new flexible monthly subscription tier, a centralized GDP Forum for collaboration, and increased Gemini CLI access for all members."
    },
    {
      "title": "Veo 3 Fast 和新的图像到视频功能 (原标题: Veo 3 Fast and new image-to-video capabilities)",
      "link": "https://developers.googleblog.com/en/veo-3-fast-image-to-video-capabilities-now-available-gemini-api/",
      "pubDate": "Wed, 30 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-30T16:00:00.000Z",
      "creator": "Google",
      "summary": "## Veo 3 Fast 和新的图像到视频功能发布\n\n### 发布概览\n\n*   **日期：** 2025年7月31日\n*   **核心内容：** 在Veo 3发布后，谷歌现推出Veo 3 Fast模型，并为Veo 3和Veo 3 Fast引入了图像到视频（image-to-video）功能。\n*   **可用性：** 这两款模型及其图像到视频功能均已通过Gemini API提供付费预览。\n\n### Veo 3 Fast：更快、更高效的模型\n\nVeo 3 Fast是Veo 3的优化版本，旨在提高速度和降低成本，使开发者能够更快地迭代，同时高效地生成高质量输出。\n\n*   **主要特点：**\n    *   比Veo 3更快、更具成本效益。\n    *   支持文本到视频（text-to-video）和图像到视频（image-to-video）两种模式。\n    *   在优化速度和业务用例的同时，保持高质量视频输出（含音频）。\n*   **理想应用场景：**\n    *   **程序化广告：** 为自动生成广告创意的后端服务提供支持。\n    *   **快速原型设计：** 快速进行不同创意概念的A/B测试。\n    *   **规模化内容创作：** 构建需要快速生产社交媒体内容的应用程序。\n*   **定价：** 0.40美元/秒（含音频）。\n\n### 新的图像到视频功能\n\n开发者现在可以使用Veo 3和Veo 3 Fast，通过输入图像生成高质量的视频内容（含音频）。这项新功能能够将静态图像转换为动态视频片段，同时保持内容的一致性。\n\n*   **操作方式：**\n    *   只需提供一张图像和文本提示，即可引导模型实现所需的动作、叙事和音频。\n*   **定价：** 图像到视频的输出定价与文本到视频的输出相同（Veo 3为0.75美元/秒，含音频）。\n*   **主要优势：**\n    *   **高质量视频生成：** 从单张图像创建流畅、电影级的视频，保持风格一致性和细节，并包含音频。\n    *   **精确提示：** 结合图像输入和描述性文本提示，精确指导视频内容的动作、风格和演变。\n    *   **无缝API集成：** 通过直观的Gemini API访问此强大新功能，易于集成到现有工作流程和应用程序中。\n\n### 实际应用案例：OpusClip\n\nOpusClip利用Veo 3的图像到视频功能，增强客户的视频编辑体验并生成B-roll视频。Veo 3能够将静态图像作为第一帧，通过生成流畅、电影般的运动使其生动起来，帮助创作者以最小的努力获得引人入胜的视频内容。\n\n### 展望与行动\n\n谷歌对开发者将利用Veo 3、Veo 3 Fast和通过Gemini API提供的图像到视频功能创造出什么感到非常兴奋。鼓励开发者查阅Gemini API视频生成文档或Veo食谱，立即开始构建。",
      "shortSummary": "谷歌推出了Veo 3 Fast模型，该模型针对速度和成本进行了优化，并为Veo 3和Veo 3 Fast引入了新的图像到视频功能。Veo 3 Fast更快速、经济，适用于程序化广告、快速原型设计和规模化内容创作。图像到视频功能允许用户将静态图像转换为高质量、连贯的动态视频，并可通过文本提示进行精确控制。这两项功能均已通过Gemini API提供付费预览。",
      "translated_title": "Veo 3 Fast 和新的图像到视频功能",
      "images": [],
      "contentSource": "完整文章",
      "content": "Google introduces Veo 3 Fast, an optimized model for speed and price, along with new image-to-video capabilities for both Veo 3 and Veo 3 Fast, enabling developers to efficiently create high-quality video content from text or still images, with varying pricing based on the model and audio inclusion, now available in the Gemini API."
    },
    {
      "title": "介绍 LangExtract：一个由 Gemini 驱动的信息提取库 (原标题: Introducing LangExtract: A Gemini powered information extraction library)",
      "link": "https://developers.googleblog.com/en/introducing-langextract-a-gemini-powered-information-extraction-library/",
      "pubDate": "Tue, 29 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-29T16:00:00.000Z",
      "creator": "Google",
      "summary": "LangExtract 简介\n\n在当今数据丰富的世界中，有价值的洞察常常隐藏在非结构化文本中，例如详细的临床笔记、冗长的法律文件、客户反馈和新闻报道。手动筛选或构建定制代码来处理这些数据既耗时又容易出错，而简单地使用现代大型语言模型（LLMs）可能会引入错误。为了解决这一挑战，LangExtract 应运而生。\n\nLangExtract 概述\n\nLangExtract 是一个新推出的开源 Python 库，旨在帮助开发者以编程方式提取所需的确切信息，同时确保输出结构化并可靠地追溯到其来源。它为各种 LLM（如 Gemini 模型）提供了一个轻量级接口，用于根据自定义指令将大量非结构化文本处理成结构化信息，确保灵活性和可追溯性。\n\n核心功能与优势\n\nLangExtract 提供了一系列独特的功能，使其在信息提取方面非常有用：\n\n*   **精确源定位**：每个提取的实体都被映射回其在源文本中的精确字符偏移量。这提供了可追溯性，通过在原始文本中视觉高亮显示每次提取，使得评估和验证提取的信息变得更加容易。\n*   **可靠的结构化输出**：用户可以使用 LangExtract 的数据表示定义所需的输出，并提供“少量示例”（few-shot examples）。LangExtract 利用这些示例来强制执行模式，并利用 Gemini 等支持模型中的“受控生成”（Controlled Generation）功能，确保输出始终保持结构化。\n*   **优化长上下文信息提取**：从大型文档中检索信息可能很复杂。LangExtract 通过采用分块策略、并行处理和对更小、更集中的上下文进行多次提取，来处理这一问题，从而提高多事实检索场景中的召回率。\n*   **交互式可视化**：LangExtract 可以在几分钟内将原始文本转换为交互式、自包含的 HTML 可视化，方便用户在上下文中审查提取的实体，并支持探索数千个注释。\n*   **灵活支持 LLM 后端**：用户可以使用他们偏好的模型，无论是基于云的 LLM（如 Google 的 Gemini 系列）还是开源的设备端模型。\n*   **跨领域灵活性**：只需几个精心选择的示例，即可为任何领域定义信息提取任务，无需对 LLM 进行微调。LangExtract 可以“学习”用户所需的输出，并将其应用于大量新的文本输入。\n*   **利用 LLM 世界知识**：除了提取有根据的实体外，LangExtract 还可以利用模型的“世界知识”来补充提取的信息。这些信息可以是明确的（即源自源文本）或推断的（即源自模型的固有世界知识）。此类补充知识的准确性和相关性，特别是推断出的知识，很大程度上受所选 LLM 能力和引导提取的提示示例的精确性影响。\n\n快速入门示例 (莎士比亚)\n\nLangExtract 提供了一个简单的流程来从文本中提取信息：\n\n1.  **安装库**：通过 `pip install langextract` 命令进行安装。\n2.  **定义提取任务**：提供清晰的提示和高质量的“少量示例”来指导模型。\n3.  **运行提取**：使用 `lx.extract()` 函数对输入文本执行提取。\n4.  **保存与可视化**：将结果保存到 JSONL 文件，然后生成交互式 HTML 文件以查看注释。这种可视化功能非常适合演示或评估提取质量。\n\n专业领域应用\n\nLangExtract 的核心思想最初应用于医疗信息提取，并能有效处理临床文本，例如识别药物、剂量及其属性，并映射它们之间的关系。这一能力是促成该库研究的核心部分。\n\n为了展示 LangExtract 在专业领域的强大功能，开发团队还在 Hugging Face 上开发了一个名为 RadExtract 的交互式结构化放射学报告演示。该演示展示了 LangExtract 如何处理自由文本的放射学报告，并自动将其关键发现转换为结构化格式，同时突出重要发现。这种方法在放射学中非常重要，因为结构化报告可以增强清晰度、确保完整性并改善研究和临床护理的数据互操作性。\n\n**免责声明**：上述药物提取示例和结构化报告演示仅用于说明 LangExtract 的基本功能。它们不代表已完成或批准的产品，不用于诊断或建议任何疾病或状况的治疗，也不应用于医疗建议。\n\n资源与下一步\n\nLangExtract 团队期待看到开发者如何利用 LangExtract 从文本中解锁洞察。用户可以深入研究文档，探索 GitHub 存储库中的示例，并立即开始转换非结构化数据。",
      "shortSummary": "LangExtract 是一个由 Gemini 驱动的新型开源 Python 库，旨在帮助开发者从非结构化文本中高效提取结构化信息。它利用大型语言模型（如 Gemini）和少量示例，确保输出的精确性、可追溯性和结构化。该库能优化长上下文信息提取，灵活支持多种 LLM 后端，并适用于不同领域。LangExtract 还提供交互式可视化功能，简化了从文本中获取洞察的过程，尤其适用于医疗、金融等专业领域。",
      "translated_title": "介绍 LangExtract：一个由 Gemini 驱动的信息提取库",
      "images": [],
      "contentSource": "完整文章",
      "content": "LangExtract is a new open-source Python library powered by Gemini models for extracting structured information from unstructured text, offering precise source grounding, reliable structured outputs using controlled generation, optimized long-context extraction, interactive visualization, and flexible LLM backend support."
    },
    {
      "title": "Gemini Embedding：赋能RAG和上下文工程 (原标题: Gemini Embedding: Powering RAG and context engineering)",
      "link": "https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/",
      "pubDate": "Tue, 29 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-29T16:00:00.000Z",
      "creator": "Google",
      "summary": "# Gemini Embedding：赋能RAG和上下文工程\n\n自Gemini Embedding文本模型全面上市以来，开发者们迅速采纳它来构建先进的AI应用。除了传统的分类、语义搜索和检索增强生成（RAG）等用例，许多人现在正利用“上下文工程”技术为AI代理提供完整的操作上下文。嵌入技术在此过程中至关重要，因为它能高效识别并将文档、对话历史和工具定义等关键信息直接整合到模型的“工作记忆”中。\n\n以下示例展示了各行各业的组织如何利用Gemini Embedding模型来驱动复杂的系统：\n\n## Gemini Embedding 的实际应用\n\n### 1. 赋能全球内容智能——Box\n\n*   **公司：** Box，一个智能内容管理平台。\n*   **应用：** 整合Gemini Embedding以实现关键用例：从复杂文档中回答问题并提取洞察。\n*   **性能提升：** 在评估中，`gemini-embedding-001`在超过81%的时间内找到了正确答案，召回率比其他嵌入模型提高了3.6%。\n*   **核心优势：** 模型内置的多语言支持对全球用户而言是一项有前景的进步，使Box AI能够从不同语言和区域的内容中解锁洞察。\n*   **图片：** ![Box AI - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Box-AI-Gemini-Embedding.original.png)\n\n### 2. 提高金融数据分析的准确性——re:cap\n\n*   **公司：** re:cap，一家金融科技公司。\n*   **应用：** 使用嵌入技术对大量B2B银行交易进行分类。\n*   **性能提升：** 通过与之前的Google模型（`text-embedding-004`和`text-embedding-005`）在21,500笔交易数据集上进行基准测试，`gemini-embedding-001`的F1分数分别提高了1.9%和1.45%。F1分数平衡了模型的精确度和召回率，对分类任务至关重要。\n*   **核心优势：** Gemini Embedding等强大模型直接带来了显著的性能提升，帮助re:cap为其客户提供更敏锐的流动性洞察。\n*   **图片：** ![re:cap - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/re-cap.original.png)\n\n### 3. 实现法律发现中的语义精度——Everlaw\n\n*   **公司：** Everlaw，一个为法律专业人士提供可验证RAG以分析大量发现文档的平台。\n*   **应用：** 需要在数百万份专业文本中实现精确的语义匹配。\n*   **性能提升：** 内部基准测试显示，`gemini-embedding-001`表现最佳，在从140万份包含行业特定和复杂法律术语的文档中发现相关答案方面达到了87%的准确率，超过了Voyage（84%）和OpenAI（73%）模型。\n*   **核心优势：** Gemini Embedding的Matryoshka特性使Everlaw能够使用紧凑的表示，将基本信息集中在更少的维度中，从而最大限度地减少性能损失，降低存储成本，并提高检索和搜索效率。\n*   **图片：** ![Everlaw - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/everlaw.original.png)\n\n### 4. 提升开发者代码库搜索能力——Roo Code\n\n*   **公司：** Roo Code，一个开源AI编码助手。\n*   **应用：** 使用Gemini Embedding模型为其代码库索引和语义搜索提供支持。开发者需要一种能理解意图而非仅仅语法的搜索。\n*   **性能提升：** 通过将`gemini-embedding-001`与Tree-sitter结合进行逻辑代码分割，Roo Code即使对于不精确的查询也能提供高度相关的结果。初步测试发现，Gemini Embedding显著改进了其LLM驱动的代码搜索。\n*   **核心优势：** 使代码搜索更灵活、准确，并与开发者工作流程更一致。\n*   **图片：** ![ROO Code - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ROOCode.original.png)\n\n### 5. 提供个性化心理健康支持——Mindlid\n\n*   **公司：** Mindlid，一个AI健康伴侣。\n*   **应用：** 利用`gemini-embedding-001`理解对话历史，从而提供实时适应用户的上下文感知和有意义的洞察。\n*   **性能提升：** 实现了持续的亚秒级延迟（中位数：420毫秒）和可衡量的82%前3召回率，比OpenAI的`text-embedding-3-small`召回率提升了4%。\n*   **核心优势：** 提高了AI支持的相关性和速度，提供最相关的信息。\n*   **图片：** ![Mindlid - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Mindlid.original.png)\n\n### 6. 增强AI助手的上下文和效率——Interaction Co. (Poke)\n\n*   **公司：** Interaction Co.，正在构建Poke，一个AI电子邮件助手。\n*   **应用：** Poke使用Gemini Embedding执行两个关键功能：检索用户“记忆”和识别相关电子邮件以增强上下文。\n*   **性能提升：** 整合`gemini-embedding-001`后，Poke的语言模型以更快的速度和更高的精度检索数据。他们报告称，与Voyage-2相比，嵌入100封电子邮件的平均时间减少了90.4%，仅需21.45秒。\n*   **核心优势：** 大幅提升了电子邮件自动化中数据检索的速度和精度。\n*   **图片：** ![Poke - Gemini Embedding](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Poke.original.png)\n\n## 未来智能代理的基础\n\n随着AI系统变得更加自主，它们的有效性将取决于我们提供给它们的上下文质量。像`gemini-embedding-001`这样的高性能嵌入模型是构建下一代能够推理、检索信息并代表我们行动的智能代理的基础。\n\n**注意：** 性能指标由开发者提供，未经Google独立证实。",
      "shortSummary": "Gemini Embedding模型已广泛应用于RAG和上下文工程等高级AI应用，通过高效整合关键信息，显著提升了AI系统的性能。文章展示了其在多个行业的成功案例：Box提升全球内容智能，re:cap提高金融数据分析准确性，Everlaw实现法律发现语义精度，Roo Code优化代码搜索，Mindlid提供个性化心理健康支持，以及Poke增强AI邮件助手效率。Gemini Embedding是构建未来智能代理的关键基础。",
      "translated_title": "Gemini Embedding：赋能RAG和上下文工程",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Box-AI-Gemini-Embedding.original.png",
          "alt": "Box AI - Gemini Embedding",
          "title": "",
          "position": 1
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/re-cap.original.png",
          "alt": "re:cap - Gemini Embedding",
          "title": "",
          "position": 2
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/everlaw.original.png",
          "alt": "Everlaw - Gemini Embedding",
          "title": "",
          "position": 3
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/ROOCode.original.png",
          "alt": "ROO Code - Gemini Embedding",
          "title": "",
          "position": 4
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Mindlid.original.png",
          "alt": "Mindlid - Gemini Embedding",
          "title": "",
          "position": 5
        },
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Poke.original.png",
          "alt": "Poke - Gemini Embedding",
          "title": "",
          "position": 6
        }
      ],
      "contentSource": "完整文章",
      "content": "The Gemini Embedding model enhances AI applications, particularly through context engineering, which is being successfully adopted by various organizations across industries to power context-aware systems, leading to significant improvements in performance, accuracy, and efficiency."
    },
    {
      "title": "机器人专家与 JAX 的旅程：在最优控制和仿真中寻找效率 (原标题: A roboticist's journey with JAX: Finding efficiency in optimal control and simulation)",
      "link": "https://developers.googleblog.com/en/a-roboticists-journey-with-jax/",
      "pubDate": "Mon, 28 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-28T16:00:00.000Z",
      "creator": "Google",
      "summary": "# 机器人专家与 JAX 的旅程：在最优控制和仿真中寻找效率\n\nJAX 正在被越来越多的开发者用于广泛的计算任务，其作用已超越最初对大规模 AI 的关注。尽管它仍然是开发大型语言模型 (LLMs) 和基础模型的流行框架，但 JAX 也在各种科学领域获得发展势头，尤其是在机器人学中，它在仿真、控制以及学习方法集成方面展现出强大的能力。\n\n最近，西北大学机器人学博士生兼研究员 Max Muchen Sun 的经历清晰地展示了 JAX 如何解决机器人研究中的关键挑战，特别是在复杂控制算法的计算效率以及模型驱动和学习驱动方法无缝结合方面。\n\n## Max 的 JAX 之旅：效率与集成\n\nMax 对 JAX 的兴趣始于对计算效率的追求。在导师 Ian Abraham 的引导下，他开始接触 JAX。他们当时正在研究遍历控制 (ergodic control)，这是一种用于覆盖问题的控制框架，其计算复杂性远高于标准控制公式。为了实现实时遍历控制，Max 最初使用标准 NumPy 并利用了向量化和广播特性。\n\n### JAX 的核心优势\n\n1.  **`vmap` 的强大功能**：\n    *   `vmap` 是 Max 第一个关注的 JAX 特性。\n    *   它结合并进一步泛化了标准 NumPy 的向量化和广播机制，通过函数转换和组合抽象，使得并行化推理和实现变得更加容易。\n2.  **`scan` 的效率提升**：\n    *   `scan` 最初不太直观，但最终成为模拟动态系统轨迹的有效工具。\n    *   在轨迹优化中，系统动力学的正向仿真是一个核心操作，需要重复执行并经常成为计算瓶颈。\n    *   使用 `scan`，轨迹仿真速度比基于标准 NumPy 的实现快两个数量级。这种易用性和显著的速度优势使 Max 完全投入到 JAX 生态系统中。\n\n### 模型驱动与学习驱动方法的融合\n\nMax 博士研究的核心重点是将模型驱动控制与学习驱动表示相结合，用于自主探索和多智能体协作。他认为模型驱动方法并非独立的解决方案，而是提高学习效率和鲁棒性的结构。JAX 的可组合性使其成为融合模型驱动和学习驱动流程的理想选择。\n\n#### 项目案例：\n\n*   **机器人探索 (RSS 论文)**：\n    *   Max 将生成模型中的流匹配 (flow matching) 与模型驱动的最优控制相结合，用于机器人探索。\n    *   通过基于 LQR 的更新，利用流梯度将状态空间流映射到控制，类似于动态系统上的反向传播。\n    *   最初，流匹配模块在 PyTorch 中构建，LQR 使用 C++，但集成缓慢。\n    *   切换到 JAX 后，他使用 `vmap` 和 `grad` 重新实现了流匹配部分，并利用了 JAX 工具如 OTT (Optimal Transport Toolbox)。唯一缺少的是一个 JAX 原生 LQR 管道。\n*   **多智能体协作 (ICRA 论文)**：\n    *   Max 将模型驱动的博弈论控制流程集成到生成轨迹模型中，以从演示中学习多智能体协作。\n    *   他没有将博弈论控制作为完整的解决方案（通常计算成本高昂且需要手动指定损失），而是将博弈论计算作为结构化层嵌入到条件变分自编码器 (CVAE) 中。这在不牺牲性能的情况下提高了数据效率。\n    *   两个组件都在 JAX 中实现：CVAE 使用 Flax，控制层从头开始构建。JAX 使其无缝衔接：`grad` 可以直接通过平衡点进行微分。他还构建了一个基于 JAX 的 iLQGames 求解器用于生成合成数据。\n\n### LQRax 的诞生\n\n在这些项目之后，Max 意识到他正在大量重用用于动态系统计算（尤其是基于 LQR 的计算）的 JAX 代码。由于他以非标准方式使用 LQR 来集成学习驱动和模型驱动控制，他将其打包成一个独立的 JAX 原生求解器——**LQRax**。\n\n*   **LQRax 的特性**：支持 GPU 加速、`vmap`、`scan` 和 `grad`，实现了向量化和可微分的 LQR。\n*   **应用示例**：Max 在 LQRax 中包含了遍历控制和博弈论控制的示例，以强调模型驱动方法如何补充学习。\n\n### JAX 的使用环境与未来展望\n\nMax 在 CPU 和 GPU 上都使用 JAX，其方式与机器学习社区有所不同。例如，在流匹配项目中，LQR 在 CPU 上运行更快，而流匹配梯度在 GPU 上更快。他没有使用 TPU，因为通常所有计算都在本地进行。几年前，他尝试在 Nvidia Jetson 上安装 JAX，当时很困难。他很高兴 JAX 现在支持这些嵌入式平台，这对于机器人学至关重要。他正在使用 Jetson 在四足机器人上测试人群导航算法，并计划很快将 JAX 集成到该项目中。\n\n展望未来，Max 将继续使用 JAX，原因与他最初开始使用时相同：\n\n1.  **计算效率**：尤其是基于 GPU 的并行化，在机器人学中变得越来越重要。除了训练，它还支持新的模型驱动控制可能性，如大规模并行仿真和实时参数更新，类似于具身主动学习。\n2.  **模型集成**：JAX 使将模型驱动结构直观地集成到学习流程中成为可能，无论是用于动力学、损失塑形还是可微分求解器。这种灵活性让他对进一步推动研究充满热情。\n\n## JAX 机器人生态系统\n\nMax 的经验展示了 JAX 为机器人社区提供的几个关键优势。`vmap` 实现的并行操作显著加速，以及 `scan` 实现的轨迹仿真加速，对于实时控制和复杂规划至关重要。此外，JAX 的函数式范式和自动微分能力使其非常适合将经典的模型驱动技术与现代学习驱动组件相结合。\n\nMax 的 LQRax 包是 JAX 原生机器人工具活跃生态系统的重要补充。在仿真领域，JAX 通过 Brax 和新的 MuJoCo XLA (MJX) 等大规模并行引擎提供了强大的基础，MJX 将流行的标准 MuJoCo 物理引擎直接引入 JAX。社区中也出现了专业工具，例如用于控制驱动多体动力学的 JaxSim 库。\n\n在轨迹优化领域，LQRax 作为 Trajax 等先驱之后的一个受欢迎的现代库，为研究人员构建下一代控制系统提供了支持。它完美地体现了 JAX 精神，提供了一个强大、可组合的工具，弥合了模型驱动控制和深度学习之间的鸿沟。",
      "shortSummary": "JAX正日益成为机器人学领域的重要工具，Max Muchen Sun的经验证明了其在最优控制和仿真中的高效性。JAX的`vmap`和`scan`功能显著提升了计算效率，加速了并行操作和轨迹仿真。它还使得模型驱动与学习驱动方法无缝集成成为可能，Max开发的`LQRax`库便是例证。JAX在CPU、GPU及嵌入式平台上的支持，使其成为构建下一代智能机器人系统的理想选择，推动了实时控制和复杂规划的发展。",
      "translated_title": "机器人专家与 JAX 的旅程：在最优控制和仿真中寻找效率",
      "images": [],
      "contentSource": "完整文章",
      "content": "Max's journey introduces LQRax, a JAX-native LQR solver, which exemplifies the growing JAX robotics ecosystem that includes tools like Brax, MJX, and JaxSim, highlighting the benefits of JAX for computational efficiency in optimal control and simulation, and for seamlessly integrating model-based and learning-based approaches."
    },
    {
      "title": "代理式体验：MCP 是您 AI 未来的正确工具吗？ (原标题: The agentic experience: Is MCP the right tool for your AI future?)",
      "link": "https://developers.googleblog.com/en/the-agentic-experience-is-mcp-the-right-tool-for-your-ai-future/",
      "pubDate": "Wed, 23 Jul 2025 16:00:00 GMT",
      "isoDate": "2025-07-23T16:00:00.000Z",
      "creator": "Google",
      "summary": "## 企业AI集成与Apigee的角色\n\n随着企业竞相将人工智能（AI）投入运营，挑战不仅在于构建和部署大型语言模型（LLM），还在于如何将其无缝集成到现有API生态系统中，同时保持企业级的安全性、治理和合规性。Apigee致力于在此旅程中引领企业，通过增强生成式AI代理的安全性、可扩展性和治理能力，从而简化其与应用程序的集成。\n\n### 模型上下文协议（MCP）的兴起与局限\n\n模型上下文协议（MCP）已成为集成离散API作为工具的事实标准方法。然而，MCP正在迅速演变，并且尚未完全满足企业对身份验证（AuthN）、授权（AuthZ）和可观测性（Observability）的需求。将API转化为代理式工具的旅程，远不止一个单一协议所能涵盖。\n\n### Apigee如何赋能企业级AI\n\nApigee作为Google Cloud的原生API管理平台，能够将您现有的企业API带入AI领域。Apigee承诺将继续引导企业在不断变化的AI格局中进行代理式转型，并确保为所有AI工作负载提供一流的企业级功能。\n\n#### 使MCP具备企业级能力\n\n在网络中利用MCP服务需要特定的安全约束。例如，您可能希望为MCP服务器本身添加身份验证，并根据消费应用程序授权对特定工具的访问。此外，您可能需要提供一流的可观测性信息，以跟踪哪些工具正在被谁使用。最后，您需要确保MCP服务器所提供的下游API也具备最低限度的安全保障。\n\nApigee提供了一个MCP服务器的开源示例，它精确地提供了这种类型的API安全性，并且所有这些功能现在都可用于您的MCP服务并得到支持。\n\n#### 通过Apigee API产品实现安全与治理\n\n此示例展示了如何利用Apigee的API产品对工具进行身份验证和授权控制。此外，最终位于MCP服务器背后的API（在此案例中部署到Cloud Run）本身也托管在Apigee上，因此它们获得了与Apigee上托管的其他任何API相同的安全性、分发和可观测性功能。这弥合了托管API与探索性AI交互之间的鸿沟，利用Apigee丰富的功能集来保护、扩展和治理您的AI旅程。此演示展示了如何立即启动并运行MCP服务器，同时提供所需的必要企业级控制。即使MCP标准发生变化，此设置也易于适应，因为它最终只是像其他任何后端一样通过Apigee提供服务。\n\n如下图所示，Apigee将API产品引入这些代理和MCP工具，并将其转化为AI产品。这些AI产品拥有自己的消费者和开发者，就像其他任何API一样。\n\n![API产品到AI产品](https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_2ySlzKi.original.png)\n\n#### 参考架构与资源\n\nApigee的GitHub仓库提供了快速入门指南、示例工件和文档，将帮助您构建和部署Apigee中的参考MCP服务架构，并理解通过利用API产品将API暴露为AI代理工具的步骤。\n\n### 未来展望\n\nAI集成之旅将随着时间推移而不断调整和变化：MCP正在演变，例如从最初无身份验证到使用OAuth进行授权和资源服务的转变。Google Apigee致力于与这种演变同步发展。\n\n了解更多关于如何使用Apigee操作生成式AI应用程序，并查阅Apigee的AI策略文档。",
      "shortSummary": "Apigee帮助企业将AI代理（如LLMs）安全、可扩展地集成到现有API生态系统中。尽管模型上下文协议（MCP）是工具集成方法，但其缺乏企业级安全功能。Apigee提供了一个开源MCP服务器示例，利用其API管理平台为MCP服务提供认证、授权和可观测性，确保企业级安全与治理，并支持API产品化，从而简化AI集成并适应未来变化。",
      "translated_title": "代理式体验：MCP 是您 AI 未来的正确工具吗？",
      "images": [
        {
          "url": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image5_2ySlzKi.original.png",
          "alt": "API product to AI product",
          "title": "",
          "position": 1
        }
      ],
      "contentSource": "完整文章",
      "content": "Apigee helps enterprises integrate large language models (LLMs) into existing API ecosystems securely and scalably, addressing challenges like authentication and authorization not fully covered by the evolving Model Context Protocol (MCP), and offering an open-source MCP server example that demonstrates how to implement enterprise-ready API security for AI agents."
    }
  ],
  "lastUpdated": "2025-08-18T10:34:34.391Z"
}